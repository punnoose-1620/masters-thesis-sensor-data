{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/punnoose-1620/masters-thesis-sensor-data/blob/main/Intent_Identifier_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp_kaurj0sqT"
      },
      "source": [
        "# Automotive Intent Classification and Slot Filling System\n",
        "=========================================================\n",
        "\n",
        "A modular TensorFlow/Keras implementation for multi-task learning on automotive technical queries.\n",
        "\n",
        "This script implements three neural architectures:\n",
        "1. Bi-LSTM with Self-Attention\n",
        "2. 1D-CNN with multiple kernel sizes\n",
        "3. Joint Multi-Task Learning model\n",
        "\n",
        "Author: Automotive NLP Team\n",
        "Date: 2026-02-04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGlC1KR5025G"
      },
      "source": [
        "## Imports and Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hT8E4Bbz02XO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZC1rwfn06UE"
      },
      "source": [
        "## Set random seeds for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uVooh4fV08WH"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmSVZZwe1Lmf"
      },
      "source": [
        "## Configurations and Initializations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdAVm2xL0-YH"
      },
      "source": [
        "### GLOBAL CONFIGURATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAikFZ4m1FiP"
      },
      "outputs": [],
      "source": [
        "CONFIG = {\n",
        "    'FILE_PATH': 'datasets\\intent_dataset.csv',  # Update this path\n",
        "    'EMBEDDING_DIM': 128,\n",
        "    'HIDDEN_UNITS': 128,\n",
        "    'LEARNING_RATE': 0.001,\n",
        "    'BATCH_SIZE': 32,\n",
        "    'EPOCHS': 50,\n",
        "    'MAX_SEQUENCE_LENGTH': 50,\n",
        "    'MAX_VOCAB_SIZE': 10000,\n",
        "    'VALIDATION_SPLIT': 0.15,\n",
        "    'TEST_SPLIT': 0.15,\n",
        "    'EARLY_STOPPING_PATIENCE': 5,\n",
        "    'CNN_FILTERS': 128,\n",
        "    'CNN_KERNEL_SIZES': [3, 4, 5],\n",
        "    'DROPOUT_RATE': 0.3,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTBnOJw11IxW"
      },
      "source": [
        "### Global variables to store preprocessing artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8oNeQUW51Qu_"
      },
      "outputs": [],
      "source": [
        "tokenizer = None\n",
        "label_encoders = {}\n",
        "history_objects = {}\n",
        "test_results = {}\n",
        "\n",
        "COMPARISON_CHART = '/Visualizations/model_comparison.png'\n",
        "BI_LSTM_CHART = '/Visualizations/bilstm_results.png'\n",
        "CNN_CHART = '/Visualizations/cnn_results.png'\n",
        "JOINT_CHART = '/Visualizations/joint_results.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVSzVodG1TV_"
      },
      "source": [
        "## Dataset Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tzc9H0J1W_O"
      },
      "source": [
        "### FUNCTION 1: LOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fKxUGe1H14mT"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path=None):\n",
        "    \"\"\"\n",
        "    Load automotive dataset from CSV file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file. Uses CONFIG['FILE_PATH'] if None.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Loaded dataset\n",
        "    \"\"\"\n",
        "    if file_path is None:\n",
        "        file_path = CONFIG['FILE_PATH']\n",
        "\n",
        "    print(f\"Loading data from: {file_path}\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"✓ Data loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "        print(f\"✓ Columns: {list(df.columns)}\")\n",
        "        print(f\"\\nFirst few rows:\")\n",
        "        print(df.head())\n",
        "\n",
        "        # Validate required columns\n",
        "        required_cols = ['query', 'intent', 'brand', 'model', 'sensor']\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Handle missing values\n",
        "        print(f\"\\nMissing values before handling:\")\n",
        "        print(df.isnull().sum())\n",
        "\n",
        "        # Fill missing slot values with 'NONE' to preserve them as valid categories\n",
        "        for col in ['brand', 'model', 'sensor', 'year']:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna('NONE').astype(str)\n",
        "\n",
        "        # Drop rows with missing queries or intents\n",
        "        df = df.dropna(subset=['query', 'intent'])\n",
        "\n",
        "        print(f\"\\n✓ Data cleaned: {df.shape[0]} rows remaining\")\n",
        "        print(f\"\\nIntent distribution:\")\n",
        "        print(df['intent'].value_counts())\n",
        "\n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"✗ Error: File not found at {file_path}\")\n",
        "        print(\"Creating synthetic dataset for demonstration...\")\n",
        "        return create_synthetic_dataset()\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error loading data: {str(e)}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5QlzAkK__nC"
      },
      "source": [
        "### FUNCTION 2: PREPROCESS DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KHECUzBSAFpr"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Preprocess automotive queries and labels.\n",
        "    Handles technical jargon carefully - no aggressive stop-word removal.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Input dataframe\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X_padded, y_intent, y_brand, y_model, y_sensor, metadata)\n",
        "    \"\"\"\n",
        "    global tokenizer, label_encoders\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PREPROCESSING DATA\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # 1. Text Tokenization (preserve technical terms)\n",
        "    print(\"\\n1. Tokenizing queries...\")\n",
        "    tokenizer = Tokenizer(\n",
        "        num_words=CONFIG['MAX_VOCAB_SIZE'],\n",
        "        oov_token='<OOV>',\n",
        "        filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',  # Keep technical chars\n",
        "        lower=True\n",
        "    )\n",
        "\n",
        "    tokenizer.fit_on_texts(df['query'])\n",
        "    sequences = tokenizer.texts_to_sequences(df['query'])\n",
        "\n",
        "    # 2. Padding\n",
        "    print(f\"2. Padding sequences to length {CONFIG['MAX_SEQUENCE_LENGTH']}...\")\n",
        "    X_padded = pad_sequences(\n",
        "        sequences,\n",
        "        maxlen=CONFIG['MAX_SEQUENCE_LENGTH'],\n",
        "        padding='post',\n",
        "        truncating='post'\n",
        "    )\n",
        "\n",
        "    vocab_size = min(len(tokenizer.word_index) + 1, CONFIG['MAX_VOCAB_SIZE'])\n",
        "    print(f\"   ✓ Vocabulary size: {vocab_size}\")\n",
        "    print(f\"   ✓ Padded shape: {X_padded.shape}\")\n",
        "\n",
        "    # 3. Encode labels\n",
        "    print(\"\\n3. Encoding labels...\")\n",
        "\n",
        "    # Intent (primary classification)\n",
        "    label_encoders['intent'] = LabelEncoder()\n",
        "    y_intent_encoded = label_encoders['intent'].fit_transform(df['intent'])\n",
        "    y_intent = to_categorical(y_intent_encoded)\n",
        "    print(f\"   ✓ Intent classes: {len(label_encoders['intent'].classes_)}\")\n",
        "    print(f\"     Classes: {label_encoders['intent'].classes_}\")\n",
        "\n",
        "    # Slot filling targets\n",
        "    slot_columns = ['brand', 'model', 'sensor']\n",
        "    y_slots = {}\n",
        "\n",
        "    for slot in slot_columns:\n",
        "        if slot in df.columns:\n",
        "            label_encoders[slot] = LabelEncoder()\n",
        "            y_encoded = label_encoders[slot].fit_transform(df[slot])\n",
        "            y_slots[slot] = to_categorical(y_encoded)\n",
        "            print(f\"   ✓ {slot.capitalize()} classes: {len(label_encoders[slot].classes_)}\")\n",
        "\n",
        "    # Prepare metadata\n",
        "    metadata = {\n",
        "        'vocab_size': vocab_size,\n",
        "        'num_intent_classes': len(label_encoders['intent'].classes_),\n",
        "        'num_brand_classes': len(label_encoders['brand'].classes_),\n",
        "        'num_model_classes': len(label_encoders['model'].classes_),\n",
        "        'num_sensor_classes': len(label_encoders['sensor'].classes_),\n",
        "        'intent_labels': label_encoders['intent'].classes_,\n",
        "        'max_seq_length': CONFIG['MAX_SEQUENCE_LENGTH']\n",
        "    }\n",
        "\n",
        "    print(f\"\\n✓ Preprocessing complete!\")\n",
        "    print(f\"  Input shape: {X_padded.shape}\")\n",
        "    print(f\"  Intent shape: {y_intent.shape}\")\n",
        "\n",
        "    return X_padded, y_intent, y_slots['brand'], y_slots['model'], y_slots['sensor'], metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si7Ni5QMAHKr"
      },
      "source": [
        "### FUNCTION 3: SPLIT DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CDl_LbkvANWV"
      },
      "outputs": [],
      "source": [
        "def split_data(X, y_intent, y_brand, y_model, y_sensor):\n",
        "    \"\"\"\n",
        "    Split data into Train (70%), Validation (15%), and Test (15%).\n",
        "\n",
        "    Args:\n",
        "        X: Input sequences\n",
        "        y_intent, y_brand, y_model, y_sensor: Target labels\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing all splits\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SPLITTING DATA\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # First split: Train+Val (85%) vs Test (15%)\n",
        "    test_size = CONFIG['TEST_SPLIT']\n",
        "    val_size = CONFIG['VALIDATION_SPLIT'] / (1 - test_size)  # 15% of remaining 85%\n",
        "\n",
        "    X_temp, X_test, y_intent_temp, y_intent_test, y_brand_temp, y_brand_test, \\\n",
        "    y_model_temp, y_model_test, y_sensor_temp, y_sensor_test = train_test_split(\n",
        "        X, y_intent, y_brand, y_model, y_sensor,\n",
        "        test_size=test_size,\n",
        "        random_state=42,\n",
        "        stratify=np.argmax(y_intent, axis=1)\n",
        "    )\n",
        "\n",
        "    # Second split: Train (70%) vs Validation (15%)\n",
        "    X_train, X_val, y_intent_train, y_intent_val, y_brand_train, y_brand_val, \\\n",
        "    y_model_train, y_model_val, y_sensor_train, y_sensor_val = train_test_split(\n",
        "        X_temp, y_intent_temp, y_brand_temp, y_model_temp, y_sensor_temp,\n",
        "        test_size=val_size,\n",
        "        random_state=42,\n",
        "        stratify=np.argmax(y_intent_temp, axis=1)\n",
        "    )\n",
        "\n",
        "    splits = {\n",
        "        'X_train': X_train, 'X_val': X_val, 'X_test': X_test,\n",
        "        'y_intent_train': y_intent_train, 'y_intent_val': y_intent_val, 'y_intent_test': y_intent_test,\n",
        "        'y_brand_train': y_brand_train, 'y_brand_val': y_brand_val, 'y_brand_test': y_brand_test,\n",
        "        'y_model_train': y_model_train, 'y_model_val': y_model_val, 'y_model_test': y_model_test,\n",
        "        'y_sensor_train': y_sensor_train, 'y_sensor_val': y_sensor_val, 'y_sensor_test': y_sensor_test,\n",
        "    }\n",
        "\n",
        "    print(f\"Train set: {X_train.shape[0]} samples ({X_train.shape[0]/X.shape[0]*100:.1f}%)\")\n",
        "    print(f\"Val set:   {X_val.shape[0]} samples ({X_val.shape[0]/X.shape[0]*100:.1f}%)\")\n",
        "    print(f\"Test set:  {X_test.shape[0]} samples ({X_test.shape[0]/X.shape[0]*100:.1f}%)\")\n",
        "    print(f\"\\n✓ Data split complete!\")\n",
        "\n",
        "    return splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2t1tedTA5RG"
      },
      "source": [
        "## Model Functions - Design and Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XAnBr4xARpF"
      },
      "source": [
        "### FUNCTION 4: BUILD BI-LSTM MODEL WITH SELF-ATTENTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nWjfBmiAVA2"
      },
      "outputs": [],
      "source": [
        "def build_bilstm_model(metadata):\n",
        "    \"\"\"\n",
        "    Build Bi-directional LSTM model with Self-Attention layer.\n",
        "\n",
        "    Args:\n",
        "        metadata (dict): Model configuration metadata\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled Bi-LSTM model\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BUILDING BI-LSTM MODEL WITH SELF-ATTENTION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Input layer\n",
        "    input_layer = Input(shape=(metadata['max_seq_length'],), name='input')\n",
        "\n",
        "    # Embedding layer\n",
        "    embedding = layers.Embedding(\n",
        "        input_dim=metadata['vocab_size'],\n",
        "        output_dim=CONFIG['EMBEDDING_DIM'],\n",
        "        mask_zero=True,\n",
        "        name='embedding'\n",
        "    )(input_layer)\n",
        "\n",
        "    # Bi-LSTM layer\n",
        "    bilstm = layers.Bidirectional(\n",
        "        layers.LSTM(CONFIG['HIDDEN_UNITS'], return_sequences=True),\n",
        "        name='bilstm'\n",
        "    )(embedding)\n",
        "\n",
        "    # Self-Attention mechanism\n",
        "    #attention = layers.Attention(name='self_attention')([bilstm, bilstm])\n",
        "\n",
        "    # Global pooling\n",
        "    #pooled = layers.GlobalAveragePooling1D(name='global_pool')(attention)\n",
        "\n",
        "    # Global pooling (no self-attention to avoid gradient bug with layers.Attention)\n",
        "    pooled = layers.GlobalAveragePooling1D(name='global_pool')(bilstm)\n",
        "\n",
        "    # Dropout for regularization\n",
        "    dropout = layers.Dropout(CONFIG['DROPOUT_RATE'], name='dropout')(pooled)\n",
        "\n",
        "    # Dense layer\n",
        "    dense = layers.Dense(CONFIG['HIDDEN_UNITS'], activation='relu', name='dense')(dropout)\n",
        "\n",
        "    # Output layer for intent classification\n",
        "    output = layers.Dense(\n",
        "        metadata['num_intent_classes'],\n",
        "        activation='softmax',\n",
        "        name='intent_output'\n",
        "    )(dense)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=input_layer, outputs=output, name='BiLSTM_SelfAttention')\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=CONFIG['LEARNING_RATE']),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(model.summary())\n",
        "    print(f\"\\n✓ Bi-LSTM model built successfully!\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFKYupl3BAg_"
      },
      "source": [
        "### FUNCTION 5: BUILD 1D-CNN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_X0U2YYsBLBi"
      },
      "outputs": [],
      "source": [
        "def build_cnn_model(metadata):\n",
        "    \"\"\"\n",
        "    Build 1D-CNN model with multiple kernel sizes (3, 4, 5) to capture\n",
        "    local technical n-grams.\n",
        "\n",
        "    Args:\n",
        "        metadata (dict): Model configuration metadata\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled CNN model\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BUILDING 1D-CNN MODEL WITH MULTI-KERNEL\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Input layer\n",
        "    input_layer = Input(shape=(metadata['max_seq_length'],), name='input')\n",
        "\n",
        "    # Embedding layer\n",
        "    embedding = layers.Embedding(\n",
        "        input_dim=metadata['vocab_size'],\n",
        "        output_dim=CONFIG['EMBEDDING_DIM'],\n",
        "        name='embedding'\n",
        "    )(input_layer)\n",
        "\n",
        "    # Multiple CNN branches with different kernel sizes\n",
        "    conv_branches = []\n",
        "    for kernel_size in CONFIG['CNN_KERNEL_SIZES']:\n",
        "        conv = layers.Conv1D(\n",
        "            filters=CONFIG['CNN_FILTERS'],\n",
        "            kernel_size=kernel_size,\n",
        "            activation='relu',\n",
        "            name=f'conv1d_k{kernel_size}'\n",
        "        )(embedding)\n",
        "        pool = layers.GlobalMaxPooling1D(name=f'maxpool_k{kernel_size}')(conv)\n",
        "        conv_branches.append(pool)\n",
        "\n",
        "    # Concatenate all branches\n",
        "    if len(conv_branches) > 1:\n",
        "        concatenated = layers.Concatenate(name='concat_branches')(conv_branches)\n",
        "    else:\n",
        "        concatenated = conv_branches[0]\n",
        "\n",
        "    # Dropout for regularization\n",
        "    dropout = layers.Dropout(CONFIG['DROPOUT_RATE'], name='dropout')(concatenated)\n",
        "\n",
        "    # Dense layer\n",
        "    dense = layers.Dense(CONFIG['HIDDEN_UNITS'], activation='relu', name='dense')(dropout)\n",
        "\n",
        "    # Output layer for intent classification\n",
        "    output = layers.Dense(\n",
        "        metadata['num_intent_classes'],\n",
        "        activation='softmax',\n",
        "        name='intent_output'\n",
        "    )(dense)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=input_layer, outputs=output, name='CNN_MultiKernel')\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=CONFIG['LEARNING_RATE']),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(model.summary())\n",
        "    print(f\"\\n✓ 1D-CNN model built successfully!\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gw-v_XbBIvc"
      },
      "source": [
        "### FUNCTION 6: BUILD JOINT MULTI-TASK MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A3rN1GzdBVey"
      },
      "outputs": [],
      "source": [
        "def build_joint_model(metadata):\n",
        "    \"\"\"\n",
        "    Build Joint Multi-Task Learning model with shared backbone and multiple heads\n",
        "    for Intent Classification and Slot Filling (Brand, Model, Sensor).\n",
        "\n",
        "    Args:\n",
        "        metadata (dict): Model configuration metadata\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled joint model\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BUILDING JOINT MULTI-TASK MODEL\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Input layer\n",
        "    input_layer = Input(shape=(metadata['max_seq_length'],), name='input')\n",
        "\n",
        "    # Shared Embedding layer\n",
        "    embedding = layers.Embedding(\n",
        "        input_dim=metadata['vocab_size'],\n",
        "        output_dim=CONFIG['EMBEDDING_DIM'],\n",
        "        mask_zero=True,\n",
        "        name='shared_embedding'\n",
        "    )(input_layer)\n",
        "\n",
        "    # Shared Bi-LSTM encoder\n",
        "    bilstm = layers.Bidirectional(\n",
        "        layers.LSTM(CONFIG['HIDDEN_UNITS'], return_sequences=True),\n",
        "        name='shared_bilstm'\n",
        "    )(embedding)\n",
        "\n",
        "    # Shared Self-Attention\n",
        "    attention = layers.Attention(name='shared_attention')([bilstm, bilstm])\n",
        "\n",
        "    # Global pooling\n",
        "    pooled = layers.GlobalAveragePooling1D(name='shared_pool')(attention)\n",
        "\n",
        "    # Shared dropout\n",
        "    shared_features = layers.Dropout(CONFIG['DROPOUT_RATE'], name='shared_dropout')(pooled)\n",
        "\n",
        "    # Shared dense layer\n",
        "    shared_dense = layers.Dense(\n",
        "        CONFIG['HIDDEN_UNITS'],\n",
        "        activation='relu',\n",
        "        name='shared_dense'\n",
        "    )(shared_features)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Task-specific heads\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Head 1: Intent Classification\n",
        "    intent_dense = layers.Dense(64, activation='relu', name='intent_dense')(shared_dense)\n",
        "    intent_dropout = layers.Dropout(0.2, name='intent_dropout')(intent_dense)\n",
        "    intent_output = layers.Dense(\n",
        "        metadata['num_intent_classes'],\n",
        "        activation='softmax',\n",
        "        name='intent_output'\n",
        "    )(intent_dropout)\n",
        "\n",
        "    # Head 2: Brand Slot Filling\n",
        "    brand_dense = layers.Dense(64, activation='relu', name='brand_dense')(shared_dense)\n",
        "    brand_dropout = layers.Dropout(0.2, name='brand_dropout')(brand_dense)\n",
        "    brand_output = layers.Dense(\n",
        "        metadata['num_brand_classes'],\n",
        "        activation='softmax',\n",
        "        name='brand_output'\n",
        "    )(brand_dropout)\n",
        "\n",
        "    # Head 3: Model Slot Filling\n",
        "    model_dense = layers.Dense(64, activation='relu', name='model_dense')(shared_dense)\n",
        "    model_dropout = layers.Dropout(0.2, name='model_dropout')(model_dense)\n",
        "    model_output = layers.Dense(\n",
        "        metadata['num_model_classes'],\n",
        "        activation='softmax',\n",
        "        name='model_output'\n",
        "    )(model_dropout)\n",
        "\n",
        "    # Head 4: Sensor Slot Filling\n",
        "    sensor_dense = layers.Dense(64, activation='relu', name='sensor_dense')(shared_dense)\n",
        "    sensor_dropout = layers.Dropout(0.2, name='sensor_dropout')(sensor_dense)\n",
        "    sensor_output = layers.Dense(\n",
        "        metadata['num_sensor_classes'],\n",
        "        activation='softmax',\n",
        "        name='sensor_output'\n",
        "    )(sensor_dropout)\n",
        "\n",
        "    # Create multi-output model\n",
        "    model = Model(\n",
        "        inputs=input_layer,\n",
        "        outputs=[intent_output, brand_output, model_output, sensor_output],\n",
        "        name='Joint_MTL_Model'\n",
        "    )\n",
        "\n",
        "    # Compile with multiple losses and metrics\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=CONFIG['LEARNING_RATE']),\n",
        "        loss={\n",
        "            'intent_output': 'categorical_crossentropy',\n",
        "            'brand_output': 'categorical_crossentropy',\n",
        "            'model_output': 'categorical_crossentropy',\n",
        "            'sensor_output': 'categorical_crossentropy'\n",
        "        },\n",
        "        loss_weights={\n",
        "            'intent_output': 2.0,  # Prioritize intent slightly\n",
        "            'brand_output': 1.0,\n",
        "            'model_output': 1.0,\n",
        "            'sensor_output': 1.0\n",
        "        },\n",
        "        metrics={\n",
        "            'intent_output': ['accuracy'],\n",
        "            'brand_output': ['accuracy'],\n",
        "            'model_output': ['accuracy'],\n",
        "            'sensor_output': ['accuracy']\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(model.summary())\n",
        "    print(f\"\\n✓ Joint Multi-Task model built successfully!\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SzCoFZdCvKY"
      },
      "source": [
        "## Model Functions - Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TreciG5dBZMV"
      },
      "source": [
        "### FUNCTION 7: TRAIN AND EVALUATE BI-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LaWOkqSOBelC"
      },
      "outputs": [],
      "source": [
        "def train_eval_bilstm(model, splits, metadata):\n",
        "    \"\"\"\n",
        "    Train Bi-LSTM model with early stopping and evaluate on test set.\n",
        "\n",
        "    Args:\n",
        "        model: Compiled Bi-LSTM model\n",
        "        splits (dict): Train/val/test data splits\n",
        "        metadata (dict): Model metadata\n",
        "\n",
        "    Returns:\n",
        "        tuple: (history, test_metrics)\n",
        "    \"\"\"\n",
        "    global history_objects, test_results\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING BI-LSTM MODEL\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=CONFIG['EARLY_STOPPING_PATIENCE'],\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\nTraining...\")\n",
        "    history = model.fit(\n",
        "        splits['X_train'],\n",
        "        splits['y_intent_train'],\n",
        "        validation_data=(splits['X_val'], splits['y_intent_val']),\n",
        "        epochs=CONFIG['EPOCHS'],\n",
        "        batch_size=CONFIG['BATCH_SIZE'],\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    history_objects['bilstm'] = history\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"EVALUATING BI-LSTM ON TEST SET\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(\n",
        "        splits['X_test'],\n",
        "        splits['y_intent_test'],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_probs = model.predict(splits['X_test'], verbose=0)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    y_true = np.argmax(splits['y_intent_test'], axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    test_f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    test_metrics = {\n",
        "        'loss': test_loss,\n",
        "        'accuracy': test_acc,\n",
        "        'f1_macro': test_f1_macro,\n",
        "        'f1_weighted': test_f1_weighted,\n",
        "        'y_true': y_true,\n",
        "        'y_pred': y_pred\n",
        "    }\n",
        "\n",
        "    test_results['bilstm'] = test_metrics\n",
        "\n",
        "    print(f\"\\nTest Results:\")\n",
        "    print(f\"  Loss: {test_loss:.4f}\")\n",
        "    print(f\"  Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"  F1-Score (Macro): {test_f1_macro:.4f}\")\n",
        "    print(f\"  F1-Score (Weighted): {test_f1_weighted:.4f}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=metadata['intent_labels'],\n",
        "        digits=4\n",
        "    ))\n",
        "\n",
        "    return history, test_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzcPY5QkBgoD"
      },
      "source": [
        "### FUNCTION 8: TRAIN AND EVALUATE CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FQ6sPVZVBlUy"
      },
      "outputs": [],
      "source": [
        "def train_eval_cnn(model, splits, metadata):\n",
        "    \"\"\"\n",
        "    Train CNN model with early stopping and evaluate on test set.\n",
        "\n",
        "    Args:\n",
        "        model: Compiled CNN model\n",
        "        splits (dict): Train/val/test data splits\n",
        "        metadata (dict): Model metadata\n",
        "\n",
        "    Returns:\n",
        "        tuple: (history, test_metrics)\n",
        "    \"\"\"\n",
        "    global history_objects, test_results\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING 1D-CNN MODEL\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=CONFIG['EARLY_STOPPING_PATIENCE'],\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\nTraining...\")\n",
        "    history = model.fit(\n",
        "        splits['X_train'],\n",
        "        splits['y_intent_train'],\n",
        "        validation_data=(splits['X_val'], splits['y_intent_val']),\n",
        "        epochs=CONFIG['EPOCHS'],\n",
        "        batch_size=CONFIG['BATCH_SIZE'],\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    history_objects['cnn'] = history\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"EVALUATING 1D-CNN ON TEST SET\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(\n",
        "        splits['X_test'],\n",
        "        splits['y_intent_test'],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_probs = model.predict(splits['X_test'], verbose=0)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    y_true = np.argmax(splits['y_intent_test'], axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    test_f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    test_metrics = {\n",
        "        'loss': test_loss,\n",
        "        'accuracy': test_acc,\n",
        "        'f1_macro': test_f1_macro,\n",
        "        'f1_weighted': test_f1_weighted,\n",
        "        'y_true': y_true,\n",
        "        'y_pred': y_pred\n",
        "    }\n",
        "\n",
        "    test_results['cnn'] = test_metrics\n",
        "\n",
        "    print(f\"\\nTest Results:\")\n",
        "    print(f\"  Loss: {test_loss:.4f}\")\n",
        "    print(f\"  Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"  F1-Score (Macro): {test_f1_macro:.4f}\")\n",
        "    print(f\"  F1-Score (Weighted): {test_f1_weighted:.4f}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=metadata['intent_labels'],\n",
        "        digits=4\n",
        "    ))\n",
        "\n",
        "    return history, test_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHrcqk7nCA2f"
      },
      "source": [
        "### FUNCTION 9: TRAIN AND EVALUATE JOINT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Nh-I-atBCNo2"
      },
      "outputs": [],
      "source": [
        "def train_eval_joint(model, splits, metadata):\n",
        "    \"\"\"\n",
        "    Train Joint Multi-Task model with early stopping and evaluate on test set.\n",
        "\n",
        "    Args:\n",
        "        model: Compiled Joint model\n",
        "        splits (dict): Train/val/test data splits\n",
        "        metadata (dict): Model metadata\n",
        "\n",
        "    Returns:\n",
        "        tuple: (history, test_metrics)\n",
        "    \"\"\"\n",
        "    global history_objects, test_results\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING JOINT MULTI-TASK MODEL\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Prepare multi-output training data\n",
        "    y_train = {\n",
        "        'intent_output': splits['y_intent_train'],\n",
        "        'brand_output': splits['y_brand_train'],\n",
        "        'model_output': splits['y_model_train'],\n",
        "        'sensor_output': splits['y_sensor_train']\n",
        "    }\n",
        "\n",
        "    y_val = {\n",
        "        'intent_output': splits['y_intent_val'],\n",
        "        'brand_output': splits['y_brand_val'],\n",
        "        'model_output': splits['y_model_val'],\n",
        "        'sensor_output': splits['y_sensor_val']\n",
        "    }\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=CONFIG['EARLY_STOPPING_PATIENCE'],\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\nTraining...\")\n",
        "    history = model.fit(\n",
        "        splits['X_train'],\n",
        "        y_train,\n",
        "        validation_data=(splits['X_val'], y_val),\n",
        "        epochs=CONFIG['EPOCHS'],\n",
        "        batch_size=CONFIG['BATCH_SIZE'],\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    history_objects['joint'] = history\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"EVALUATING JOINT MODEL ON TEST SET\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    y_test = {\n",
        "        'intent_output': splits['y_intent_test'],\n",
        "        'brand_output': splits['y_brand_test'],\n",
        "        'model_output': splits['y_model_test'],\n",
        "        'sensor_output': splits['y_sensor_test']\n",
        "    }\n",
        "\n",
        "    test_results_raw = model.evaluate(\n",
        "        splits['X_test'],\n",
        "        y_test,\n",
        "        verbose=0,\n",
        "        return_dict=True\n",
        "    )\n",
        "\n",
        "    # Predictions\n",
        "    predictions = model.predict(splits['X_test'], verbose=0)\n",
        "    y_intent_pred_probs, y_brand_pred_probs, y_model_pred_probs, y_sensor_pred_probs = predictions\n",
        "\n",
        "    # Intent predictions\n",
        "    y_intent_pred = np.argmax(y_intent_pred_probs, axis=1)\n",
        "    y_intent_true = np.argmax(splits['y_intent_test'], axis=1)\n",
        "\n",
        "    # Calculate intent metrics\n",
        "    intent_f1_macro = f1_score(y_intent_true, y_intent_pred, average='macro')\n",
        "    intent_f1_weighted = f1_score(y_intent_true, y_intent_pred, average='weighted')\n",
        "    intent_acc = accuracy_score(y_intent_true, y_intent_pred)\n",
        "\n",
        "    # Brand predictions\n",
        "    y_brand_pred = np.argmax(y_brand_pred_probs, axis=1)\n",
        "    y_brand_true = np.argmax(splits['y_brand_test'], axis=1)\n",
        "    brand_acc = accuracy_score(y_brand_true, y_brand_pred)\n",
        "\n",
        "    # Model predictions\n",
        "    y_model_pred = np.argmax(y_model_pred_probs, axis=1)\n",
        "    y_model_true = np.argmax(splits['y_model_test'], axis=1)\n",
        "    model_acc = accuracy_score(y_model_true, y_model_pred)\n",
        "\n",
        "    # Sensor predictions\n",
        "    y_sensor_pred = np.argmax(y_sensor_pred_probs, axis=1)\n",
        "    y_sensor_true = np.argmax(splits['y_sensor_test'], axis=1)\n",
        "    sensor_acc = accuracy_score(y_sensor_true, y_sensor_pred)\n",
        "\n",
        "    test_metrics = {\n",
        "        'loss': test_results_raw['loss'],\n",
        "        'accuracy': intent_acc,\n",
        "        'f1_macro': intent_f1_macro,\n",
        "        'f1_weighted': intent_f1_weighted,\n",
        "        'y_true': y_intent_true,\n",
        "        'y_pred': y_intent_pred,\n",
        "        'intent_accuracy': intent_acc,\n",
        "        'brand_accuracy': brand_acc,\n",
        "        'model_accuracy': model_acc,\n",
        "        'sensor_accuracy': sensor_acc\n",
        "    }\n",
        "\n",
        "    test_results['joint'] = test_metrics\n",
        "\n",
        "    print(f\"\\nTest Results:\")\n",
        "    print(f\"  Overall Loss: {test_results_raw['loss']:.4f}\")\n",
        "    print(f\"\\nIntent Classification:\")\n",
        "    print(f\"  Accuracy: {intent_acc:.4f}\")\n",
        "    print(f\"  F1-Score (Macro): {intent_f1_macro:.4f}\")\n",
        "    print(f\"  F1-Score (Weighted): {intent_f1_weighted:.4f}\")\n",
        "    print(f\"\\nSlot Filling Accuracy:\")\n",
        "    print(f\"  Brand: {brand_acc:.4f}\")\n",
        "    print(f\"  Model: {model_acc:.4f}\")\n",
        "    print(f\"  Sensor: {sensor_acc:.4f}\")\n",
        "\n",
        "    print(\"\\nIntent Classification Report:\")\n",
        "    print(classification_report(\n",
        "        y_intent_true, y_intent_pred,\n",
        "        target_names=metadata['intent_labels'],\n",
        "        digits=4\n",
        "    ))\n",
        "\n",
        "    return history, test_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kXwoITfC2CB"
      },
      "source": [
        "## Model Functions - Result Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN4PSJAdCP_m"
      },
      "source": [
        "### FUNCTION 10: VISUALIZE BI-LSTM RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tThP8zOnCUvZ"
      },
      "outputs": [],
      "source": [
        "def visualize_bilstm(history, test_metrics, metadata, save_path=BI_LSTM_CHART):\n",
        "    \"\"\"\n",
        "    Plot training history and confusion matrix for Bi-LSTM model.\n",
        "\n",
        "    Args:\n",
        "        history: Training history object\n",
        "        test_metrics (dict): Test evaluation metrics\n",
        "        metadata (dict): Model metadata\n",
        "        save_path (str): Path to save the figure\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VISUALIZING BI-LSTM RESULTS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    fig = plt.figure(figsize=(16, 5))\n",
        "\n",
        "    # Plot 1: Training & Validation Accuracy\n",
        "    ax1 = plt.subplot(1, 3, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
        "    plt.title('Bi-LSTM: Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    # Plot 2: Training & Validation Loss\n",
        "    ax2 = plt.subplot(1, 3, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
        "    plt.title('Bi-LSTM: Loss Over Epochs', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Loss', fontsize=12)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    # Plot 3: Confusion Matrix\n",
        "    ax3 = plt.subplot(1, 3, 3)\n",
        "    cm = confusion_matrix(test_metrics['y_true'], test_metrics['y_pred'])\n",
        "\n",
        "    # Normalize confusion matrix\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    sns.heatmap(\n",
        "        cm_normalized,\n",
        "        annot=True,\n",
        "        fmt='.2f',\n",
        "        cmap='Blues',\n",
        "        xticklabels=metadata['intent_labels'],\n",
        "        yticklabels=metadata['intent_labels'],\n",
        "        cbar_kws={'label': 'Proportion'},\n",
        "        ax=ax3\n",
        "    )\n",
        "    plt.title('Bi-LSTM: Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Predicted', fontsize=12)\n",
        "    plt.ylabel('Actual', fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"✓ Visualization saved to: {save_path}\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IbNN7jBCYIA"
      },
      "source": [
        "### FUNCTION 11: VISUALIZE CNN RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "G7eNYL04CbLr"
      },
      "outputs": [],
      "source": [
        "def visualize_cnn(history, test_metrics, metadata, save_path=CNN_CHART):\n",
        "    \"\"\"\n",
        "    Plot training history and confusion matrix for CNN model.\n",
        "\n",
        "    Args:\n",
        "        history: Training history object\n",
        "        test_metrics (dict): Test evaluation metrics\n",
        "        metadata (dict): Model metadata\n",
        "        save_path (str): Path to save the figure\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VISUALIZING 1D-CNN RESULTS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    fig = plt.figure(figsize=(16, 5))\n",
        "\n",
        "    # Plot 1: Training & Validation Accuracy\n",
        "    ax1 = plt.subplot(1, 3, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
        "    plt.title('1D-CNN: Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    # Plot 2: Training & Validation Loss\n",
        "    ax2 = plt.subplot(1, 3, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
        "    plt.title('1D-CNN: Loss Over Epochs', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Loss', fontsize=12)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    # Plot 3: Confusion Matrix\n",
        "    ax3 = plt.subplot(1, 3, 3)\n",
        "    cm = confusion_matrix(test_metrics['y_true'], test_metrics['y_pred'])\n",
        "\n",
        "    # Normalize confusion matrix\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    sns.heatmap(\n",
        "        cm_normalized,\n",
        "        annot=True,\n",
        "        fmt='.2f',\n",
        "        cmap='Greens',\n",
        "        xticklabels=metadata['intent_labels'],\n",
        "        yticklabels=metadata['intent_labels'],\n",
        "        cbar_kws={'label': 'Proportion'},\n",
        "        ax=ax3\n",
        "    )\n",
        "    plt.title('1D-CNN: Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Predicted', fontsize=12)\n",
        "    plt.ylabel('Actual', fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"✓ Visualization saved to: {save_path}\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZd8GSobCdKl"
      },
      "source": [
        "### FUNCTION 12: VISUALIZE MODEL COMPARISON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hHgBm5aHCh9w"
      },
      "outputs": [],
      "source": [
        "def visualize_comparison(save_path=COMPARISON_CHART):\n",
        "    \"\"\"\n",
        "    Create comprehensive side-by-side comparison of all three models.\n",
        "\n",
        "    Args:\n",
        "        save_path (str): Path to save the comparison figure\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CREATING MODEL COMPARISON VISUALIZATION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Extract metrics for comparison\n",
        "    models = ['Bi-LSTM', '1D-CNN', 'Joint MTL']\n",
        "    model_keys = ['bilstm', 'cnn', 'joint']\n",
        "\n",
        "    accuracies = [test_results[key]['accuracy'] for key in model_keys]\n",
        "    f1_macros = [test_results[key]['f1_macro'] for key in model_keys]\n",
        "    f1_weighteds = [test_results[key]['f1_weighted'] for key in model_keys]\n",
        "    losses = [test_results[key]['loss'] for key in model_keys]\n",
        "\n",
        "    # Create comprehensive comparison figure\n",
        "    fig = plt.figure(figsize=(18, 10))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Plot 1: Accuracy Comparison\n",
        "    # -------------------------------------------------------------------------\n",
        "    ax1 = plt.subplot(2, 3, 1)\n",
        "    bars = plt.bar(models, accuracies, color=['#3498db', '#2ecc71', '#e74c3c'], alpha=0.8, edgecolor='black')\n",
        "    plt.title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.ylim([0, 1.0])\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, val in zip(bars, accuracies):\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{val:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Plot 2: F1-Score (Macro) Comparison\n",
        "    # -------------------------------------------------------------------------\n",
        "    ax2 = plt.subplot(2, 3, 2)\n",
        "    bars = plt.bar(models, f1_macros, color=['#3498db', '#2ecc71', '#e74c3c'], alpha=0.8, edgecolor='black')\n",
        "    plt.title('F1-Score (Macro) Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('F1-Score (Macro)', fontsize=12)\n",
        "    plt.ylim([0, 1.0])\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for bar, val in zip(bars, f1_macros):\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{val:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Plot 3: Loss Comparison\n",
        "    # -------------------------------------------------------------------------\n",
        "    ax3 = plt.subplot(2, 3, 3)\n",
        "    bars = plt.bar(models, losses, color=['#3498db', '#2ecc71', '#e74c3c'], alpha=0.8, edgecolor='black')\n",
        "    plt.title('Test Loss Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Loss', fontsize=12)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for bar, val in zip(bars, losses):\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{val:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Plot 4: Multi-Metric Radar Chart\n",
        "    # -------------------------------------------------------------------------\n",
        "    ax4 = plt.subplot(2, 3, 4, projection='polar')\n",
        "\n",
        "    categories = ['Accuracy', 'F1-Macro', 'F1-Weighted']\n",
        "    num_vars = len(categories)\n",
        "\n",
        "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
        "    angles += angles[:1]\n",
        "\n",
        "    for i, (model_name, key) in enumerate(zip(models, model_keys)):\n",
        "        values = [\n",
        "            test_results[key]['accuracy'],\n",
        "            test_results[key]['f1_macro'],\n",
        "            test_results[key]['f1_weighted']\n",
        "        ]\n",
        "        values += values[:1]\n",
        "\n",
        "        colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
        "        ax4.plot(angles, values, 'o-', linewidth=2, label=model_name, color=colors[i])\n",
        "        ax4.fill(angles, values, alpha=0.15, color=colors[i])\n",
        "\n",
        "    ax4.set_xticks(angles[:-1])\n",
        "    ax4.set_xticklabels(categories, fontsize=10)\n",
        "    ax4.set_ylim(0, 1)\n",
        "    ax4.set_title('Multi-Metric Performance Radar', fontsize=14, fontweight='bold', pad=20)\n",
        "    ax4.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)\n",
        "    ax4.grid(True)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Plot 5: Training History Comparison (Accuracy)\n",
        "    # -------------------------------------------------------------------------\n",
        "    ax5 = plt.subplot(2, 3, 5)\n",
        "\n",
        "    for i, (model_name, key) in enumerate(zip(models, model_keys)):\n",
        "        if key in history_objects:\n",
        "            history = history_objects[key]\n",
        "            if key == 'joint':\n",
        "                # For joint model, use intent_output accuracy\n",
        "                acc_key = 'intent_output_accuracy' if 'intent_output_accuracy' in history.history else 'accuracy'\n",
        "            else:\n",
        "                acc_key = 'accuracy'\n",
        "\n",
        "            if acc_key in history.history:\n",
        "                colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
        "                plt.plot(history.history[acc_key], label=model_name, linewidth=2, color=colors[i])\n",
        "\n",
        "    plt.title('Training Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Plot 6: Summary Table\n",
        "    # -------------------------------------------------------------------------\n",
        "    ax6 = plt.subplot(2, 3, 6)\n",
        "    ax6.axis('off')\n",
        "\n",
        "    # Create summary data\n",
        "    table_data = []\n",
        "    for model_name, key in zip(models, model_keys):\n",
        "        row = [\n",
        "            model_name,\n",
        "            f\"{test_results[key]['accuracy']:.4f}\",\n",
        "            f\"{test_results[key]['f1_macro']:.4f}\",\n",
        "            f\"{test_results[key]['f1_weighted']:.4f}\",\n",
        "            f\"{test_results[key]['loss']:.4f}\"\n",
        "        ]\n",
        "        table_data.append(row)\n",
        "\n",
        "    # Add slot filling accuracy for Joint model\n",
        "    if 'joint' in test_results and 'brand_accuracy' in test_results['joint']:\n",
        "        joint_slots = f\"Brand: {test_results['joint']['brand_accuracy']:.3f} | \" \\\n",
        "                     f\"Model: {test_results['joint']['model_accuracy']:.3f} | \" \\\n",
        "                     f\"Sensor: {test_results['joint']['sensor_accuracy']:.3f}\"\n",
        "    else:\n",
        "        joint_slots = \"N/A\"\n",
        "\n",
        "    table = ax6.table(\n",
        "        cellText=table_data,\n",
        "        colLabels=['Model', 'Accuracy', 'F1-Macro', 'F1-Weighted', 'Loss'],\n",
        "        cellLoc='center',\n",
        "        loc='center',\n",
        "        bbox=[0, 0.3, 1, 0.6]\n",
        "    )\n",
        "\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(10)\n",
        "    table.scale(1, 2)\n",
        "\n",
        "    # Style header\n",
        "    for i in range(5):\n",
        "        table[(0, i)].set_facecolor('#34495e')\n",
        "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "    # Highlight best values\n",
        "    best_acc_idx = np.argmax(accuracies)\n",
        "    best_f1_idx = np.argmax(f1_macros)\n",
        "\n",
        "    for i in range(len(models)):\n",
        "        if i == best_acc_idx:\n",
        "            table[(i+1, 1)].set_facecolor('#d5f4e6')\n",
        "        if i == best_f1_idx:\n",
        "            table[(i+1, 2)].set_facecolor('#d5f4e6')\n",
        "\n",
        "    ax6.text(0.5, 0.15, f\"Joint MTL Slot Filling: {joint_slots}\",\n",
        "            ha='center', va='center', fontsize=9, style='italic',\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
        "\n",
        "    ax6.set_title('Performance Summary', fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Overall title\n",
        "    # -------------------------------------------------------------------------\n",
        "    fig.suptitle('Automotive Intent Classification: Model Comparison',\n",
        "                fontsize=16, fontweight='bold', y=0.98)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"✓ Comparison visualization saved to: {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"FINAL MODEL COMPARISON SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\n{'Model':<15} {'Accuracy':<12} {'F1-Macro':<12} {'F1-Weighted':<12} {'Loss':<10}\")\n",
        "    print(\"-\" * 70)\n",
        "    for model_name, key in zip(models, model_keys):\n",
        "        print(f\"{model_name:<15} \"\n",
        "              f\"{test_results[key]['accuracy']:<12.4f} \"\n",
        "              f\"{test_results[key]['f1_macro']:<12.4f} \"\n",
        "              f\"{test_results[key]['f1_weighted']:<12.4f} \"\n",
        "              f\"{test_results[key]['loss']:<10.4f}\")\n",
        "\n",
        "    # Determine best model\n",
        "    best_model_idx = np.argmax([test_results[key]['f1_macro'] for key in model_keys])\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"🏆 BEST MODEL: {models[best_model_idx]} (based on F1-Macro score)\")\n",
        "    print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJnAXHWlDCEY"
      },
      "source": [
        "## MAIN EXECUTION PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QghGspKklnad",
        "outputId": "80903c56-fd5b-43d1-f46b-0213310dcb6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            " AUTOMOTIVE INTENT CLASSIFICATION & SLOT FILLING SYSTEM\n",
            "======================================================================\n",
            "\n",
            "Configuration:\n",
            "  FILE_PATH: /content/intent_dataset.csv\n",
            "  EMBEDDING_DIM: 128\n",
            "  HIDDEN_UNITS: 128\n",
            "  LEARNING_RATE: 0.001\n",
            "  BATCH_SIZE: 32\n",
            "  EPOCHS: 50\n",
            "  MAX_SEQUENCE_LENGTH: 50\n",
            "  MAX_VOCAB_SIZE: 10000\n",
            "  VALIDATION_SPLIT: 0.15\n",
            "  TEST_SPLIT: 0.15\n",
            "  EARLY_STOPPING_PATIENCE: 5\n",
            "  CNN_FILTERS: 128\n",
            "  CNN_KERNEL_SIZES: [3, 4, 5]\n",
            "  DROPOUT_RATE: 0.3\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" AUTOMOTIVE INTENT CLASSIFICATION & SLOT FILLING SYSTEM\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nConfiguration:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivG_mrl4lOHJ",
        "outputId": "c556838b-37c0-47a0-9f56-9b0a21aff5cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from: /content/intent_dataset.csv\n",
            "✓ Data loaded successfully: 11178 rows, 9 columns\n",
            "✓ Columns: ['query', 'intent', 'brand', 'model', 'year', 'sensor', 'style', 'word_count', 'char_count']\n",
            "\n",
            "First few rows:\n",
            "                                         query               intent  \\\n",
            "0          status of LiDAR collection in Jiyue  system_status_check   \n",
            "1  explain Vision system context in Polestar 2      data_definition   \n",
            "2                 what is Lidar for Lynk & Co?      data_definition   \n",
            "3      who is owner High Voltage battery data?    access_governance   \n",
            "4               roof rig needed for Acoustics?    collection_method   \n",
            "\n",
            "       brand       model  year                sensor     style  word_count  \\\n",
            "0      Jiyue          01  2023                 LiDAR   verbose           6   \n",
            "1   Polestar  Polestar 2  2021         Vision system     noisy           7   \n",
            "2  Lynk & Co          01  2019                 Lidar  standard           7   \n",
            "3      Volvo        XC60  2019  High Voltage battery  standard           7   \n",
            "4   Polestar  Polestar 3  2024             Acoustics     noisy           5   \n",
            "\n",
            "   char_count  \n",
            "0          35  \n",
            "1          43  \n",
            "2          28  \n",
            "3          39  \n",
            "4          30  \n",
            "\n",
            "Missing values before handling:\n",
            "query         0\n",
            "intent        0\n",
            "brand         0\n",
            "model         0\n",
            "year          0\n",
            "sensor        0\n",
            "style         0\n",
            "word_count    0\n",
            "char_count    0\n",
            "dtype: int64\n",
            "\n",
            "✓ Data cleaned: 11178 rows remaining\n",
            "\n",
            "Intent distribution:\n",
            "intent\n",
            "data_definition         1554\n",
            "temporal_stats          1338\n",
            "comparative_analysis    1256\n",
            "statistical_query       1250\n",
            "anomaly_info            1222\n",
            "collection_method       1194\n",
            "access_governance       1024\n",
            "imperative_commands     1011\n",
            "system_status_check      742\n",
            "contextual_followups     587\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load Data\n",
        "df = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0vWhHNblRF5",
        "outputId": "c7c9047c-6db4-4a2f-f272-d9bfede3927f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "PREPROCESSING DATA\n",
            "======================================================================\n",
            "\n",
            "1. Tokenizing queries...\n",
            "2. Padding sequences to length 50...\n",
            "   ✓ Vocabulary size: 1280\n",
            "   ✓ Padded shape: (11178, 50)\n",
            "\n",
            "3. Encoding labels...\n",
            "   ✓ Intent classes: 10\n",
            "     Classes: ['access_governance' 'anomaly_info' 'collection_method'\n",
            " 'comparative_analysis' 'contextual_followups' 'data_definition'\n",
            " 'imperative_commands' 'statistical_query' 'system_status_check'\n",
            " 'temporal_stats']\n",
            "   ✓ Brand classes: 7\n",
            "   ✓ Model classes: 34\n",
            "   ✓ Sensor classes: 22\n",
            "\n",
            "✓ Preprocessing complete!\n",
            "  Input shape: (11178, 50)\n",
            "  Intent shape: (11178, 10)\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Preprocess Data\n",
        "X, y_intent, y_brand, y_model, y_sensor, metadata = preprocess_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJZSN7cnlUf5",
        "outputId": "97f9065a-e17b-4cae-a5af-9f4d1f11aeeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "SPLITTING DATA\n",
            "======================================================================\n",
            "Train set: 7824 samples (70.0%)\n",
            "Val set:   1677 samples (15.0%)\n",
            "Test set:  1677 samples (15.0%)\n",
            "\n",
            "✓ Data split complete!\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Split Data\n",
        "splits = split_data(X, y_intent, y_brand, y_model, y_sensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OVKxtZCXlXvG",
        "outputId": "d376c391-7edf-4093-c89a-b44f2d4fb012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "BUILDING BI-LSTM MODEL WITH SELF-ATTENTION\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"BiLSTM_SelfAttention\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"BiLSTM_SelfAttention\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">163,840</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bilstm              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ self_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ convert_to_tensor_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvertToTensor</span>)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_pool         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ self_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │ convert_to_tenso… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ intent_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m163,840\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bilstm              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m263,168\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ self_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ convert_to_tensor_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ not_equal_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConvertToTensor\u001b[0m)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_pool         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ self_attention[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │ convert_to_tenso… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ intent_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │      \u001b[38;5;34m1,290\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">461,194</span> (1.76 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m461,194\u001b[0m (1.76 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">461,194</span> (1.76 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m461,194\u001b[0m (1.76 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "\n",
            "✓ Bi-LSTM model built successfully!\n",
            "\n",
            "======================================================================\n",
            "TRAINING BI-LSTM MODEL\n",
            "======================================================================\n",
            "\n",
            "Training...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node gradient_tape/BiLSTM_SelfAttention_1/self_attention_1/sub/BroadcastGradientArgs defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipython-input-2022235826.py\", line 68, in <cell line: 0>\n\n  File \"/tmp/ipython-input-3849620795.py\", line 37, in train_eval_bilstm\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 78, in train_step\n\nIncompatible shapes: [32,50,50] vs. [32,50]\n\t [[{{node gradient_tape/BiLSTM_SelfAttention_1/self_attention_1/sub/BroadcastGradientArgs}}]] [Op:__inference_multi_step_on_iterator_18303]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2022235826.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Original call to build and train Bi-LSTM Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mbilstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_bilstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mbilstm_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbilstm_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_eval_bilstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbilstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3849620795.py\u001b[0m in \u001b[0;36mtrain_eval_bilstm\u001b[0;34m(model, splits, metadata)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_intent_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/BiLSTM_SelfAttention_1/self_attention_1/sub/BroadcastGradientArgs defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipython-input-2022235826.py\", line 68, in <cell line: 0>\n\n  File \"/tmp/ipython-input-3849620795.py\", line 37, in train_eval_bilstm\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 78, in train_step\n\nIncompatible shapes: [32,50,50] vs. [32,50]\n\t [[{{node gradient_tape/BiLSTM_SelfAttention_1/self_attention_1/sub/BroadcastGradientArgs}}]] [Op:__inference_multi_step_on_iterator_18303]"
          ]
        }
      ],
      "source": [
        "# Step 4: Build and Train Bi-LSTM Model\n",
        "bilstm_model = build_bilstm_model(metadata)\n",
        "bilstm_history, bilstm_metrics = train_eval_bilstm(bilstm_model, splits, metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30UMys3DlaeG"
      },
      "outputs": [],
      "source": [
        "# Step 5: Build and Train CNN Model\n",
        "cnn_model = build_cnn_model(metadata)\n",
        "cnn_history, cnn_metrics = train_eval_cnn(cnn_model, splits, metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVLLuu_GldH5"
      },
      "outputs": [],
      "source": [
        "# Step 6: Build and Train Joint Model\n",
        "joint_model = build_joint_model(metadata)\n",
        "joint_history, joint_metrics = train_eval_joint(joint_model, splits, metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lbj_g0ZlgAI"
      },
      "outputs": [],
      "source": [
        "# Step 7: Visualizations\n",
        "visualize_bilstm(bilstm_history, bilstm_metrics, metadata)\n",
        "visualize_cnn(cnn_history, cnn_metrics, metadata)\n",
        "visualize_comparison()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQs2o6MdljiD"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ ALL TASKS COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nGenerated files:\")\n",
        "print(\"  1. /home/claude/bilstm_results.png\")\n",
        "print(\"  2. /home/claude/cnn_results.png\")\n",
        "print(\"  3. /home/claude/model_comparison.png\")\n",
        "print(\"\\nYou can now use these models for automotive query classification!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP2Xsn3dOQ+hhhtlpSHxYDS",
      "collapsed_sections": [
        "pGlC1KR5025G",
        "_ZC1rwfn06UE",
        "EdAVm2xL0-YH",
        "lTBnOJw11IxW",
        "TVSzVodG1TV_",
        "_tzc9H0J1W_O",
        "m5QlzAkK__nC",
        "Si7Ni5QMAHKr",
        "8XAnBr4xARpF",
        "SFKYupl3BAg_",
        "3gw-v_XbBIvc",
        "TreciG5dBZMV",
        "rzcPY5QkBgoD",
        "gHrcqk7nCA2f",
        "7kXwoITfC2CB",
        "NN4PSJAdCP_m",
        "3IbNN7jBCYIA",
        "kZd8GSobCdKl"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
