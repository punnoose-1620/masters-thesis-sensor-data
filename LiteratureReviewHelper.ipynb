{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dcVrKA9ZnrR_",
        "ivvLF87Q0vz6",
        "-h1uwFXEvSDB",
        "wSgIgLilz6re",
        "GyMRTyP0jZKK",
        "k2zRpniTlkCZ",
        "D71M2DEnqpK_"
      ],
      "authorship_tag": "ABX9TyPuS0eD2zWwR4GcYhjphK5+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/punnoose-1620/masters-thesis-sensor-data/blob/main/LiteratureReviewHelper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform Relevance analysis for all papers related to an idea."
      ],
      "metadata": {
        "id": "K0moeaSAjzjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expected File Structure :\n",
        "```\n",
        "papers_folder\n",
        "  |---subfolder\n",
        "      |---paper1\n",
        "      |---paper2\n",
        "      |---notepad\n",
        "```"
      ],
      "metadata": {
        "id": "xhIvxhXbj7u_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Installs"
      ],
      "metadata": {
        "id": "l0r-iO7iqjFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai\n",
        "!pip install pdfplumber"
      ],
      "metadata": {
        "id": "2ayBYGYK4D09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, ConfigDict\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from typing import Type, Optional\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pdfplumber\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "lkqiHktNjrj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declare class for return types"
      ],
      "metadata": {
        "id": "dcVrKA9ZnrR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContextualSummary(BaseModel):\n",
        "  summary: str"
      ],
      "metadata": {
        "id": "PK15GmKV2VXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Author(BaseModel):\n",
        "  name: str\n",
        "  institution: str"
      ],
      "metadata": {
        "id": "7tGDRoQvqb-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Paper(BaseModel):\n",
        "  title: str\n",
        "  abstract: str\n",
        "  methodology: str\n",
        "  conclusion: str\n",
        "  relevance: float\n",
        "  relevant_pages: list\n",
        "  citation: str\n",
        "  paperType: str\n",
        "  authors: list[Author]\n",
        "\n",
        "  model_config = ConfigDict(extra='allow')"
      ],
      "metadata": {
        "id": "BNPEuVOJoSuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declare Static Queries"
      ],
      "metadata": {
        "id": "ivvLF87Q0vz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_DETAILS = {\n",
        "    \"title\": \"Title of the Paper\",\n",
        "    \"abstract\": \"Abstract section from the paper\",\n",
        "    \"methodology\": \"What is done in the paper and how it is done, including relevant technical details?\",\n",
        "    \"conclusion\": \"What was the results of this paper with regard to our context?\",\n",
        "    \"relevance\": \"Relevance score (0-1) for how relevant this paper is to our context.\",\n",
        "    \"relevant_pages\": \"List of pages that have content relevant to our topic.\",\n",
        "    \"citation\": \"String to cite this paper\",\n",
        "    \"paperType\": \"What type of paper is this (qualitative/quantitative)?\",\n",
        "    \"authors\": [\n",
        "        {\n",
        "            \"name\": \"Author Name\",\n",
        "            \"institution\": \"Institution of Author\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "CQPlWqzl2ReU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_QUERY_SUMMARIZER = \"\"\"\n",
        "You are an academically profound individual well versed in the domain of the reference paper. Do not miss any technical terms that might be relevant to this domain. Summarize this paper.\n",
        "\"\"\"\n",
        "\n",
        "SYSTEM_QUERY_RELEVANCE = f\"\"\"\n",
        "You are an academically profound individual well versed in the domain of both papers. Do not miss any technical terms that might be relevant to this domain. Output must be Strictly in this format :\n",
        "{CLASS_DETAILS}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hCUAq1VfucPQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declare Models for each purpose"
      ],
      "metadata": {
        "id": "-h1uwFXEvSDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SUMMARIZATION_MODEL = \"gemini-2.5-flash-lite\"\n",
        "RELEVANCE_MODEL = \"gemini-2.5-pro\"\n",
        "MODEL_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "HlAjbxPFvVWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure API Key for LLM"
      ],
      "metadata": {
        "id": "wSgIgLilz6re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=MODEL_API_KEY)"
      ],
      "metadata": {
        "id": "kZNd4AZdz_Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declare Folder Path"
      ],
      "metadata": {
        "id": "rGw0xZHKjWUo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xjEaO-ejPNu"
      },
      "outputs": [],
      "source": [
        "FOLDER_PATH = \"\"\n",
        "PROJECT_CONTEXT = \"\"\"\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to get paths for files and notepads from a folder"
      ],
      "metadata": {
        "id": "GyMRTyP0jZKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getFilesAndNotepads(folderPath:str):\n",
        "    file_paths = []\n",
        "    notepad_paths = []\n",
        "\n",
        "    for root, _, files in os.walk(folderPath):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if file.lower().endswith(('.pdf')):\n",
        "                file_paths.append(file_path)\n",
        "            elif file.lower().endswith(('.txt')):\n",
        "                notepad_paths.append(file_path)\n",
        "\n",
        "    return file_paths, notepad_paths"
      ],
      "metadata": {
        "id": "49qGZE5Cjczd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions to read content from Documents"
      ],
      "metadata": {
        "id": "k2zRpniTlkCZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ca2108"
      },
      "source": [
        "def read_txt_file_content(file_path: str) -> str:\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        return content\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: The file at {file_path} was not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred while reading the file: {e}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_pdf_contents(pdf_path, detect_columns=True):\n",
        "    \"\"\"\n",
        "    Read all contents from a PDF file, handling both single and multi-column layouts.\n",
        "\n",
        "    Args:\n",
        "        pdf_path: Path to the PDF file\n",
        "        detect_columns: Whether to automatically detect and handle multi-column layouts\n",
        "\n",
        "    Returns:\n",
        "        Extracted text as a string\n",
        "\n",
        "    Example:\n",
        "        text = read_pdf_contents(\"research_paper.pdf\")\n",
        "        print(text)\n",
        "    \"\"\"\n",
        "    all_text = []\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_num, page in enumerate(pdf.pages, 1):\n",
        "            if detect_columns:\n",
        "                # Get page dimensions\n",
        "                page_width = page.width\n",
        "                page_height = page.height\n",
        "                words = page.extract_words()\n",
        "\n",
        "                # Detect multi-column layout\n",
        "                is_multi_column = False\n",
        "                if len(words) >= 20:\n",
        "                    midpoint = page_width / 2\n",
        "                    left_words = sum(1 for w in words if (w['x0'] + w['x1']) / 2 < midpoint)\n",
        "                    right_words = sum(1 for w in words if (w['x0'] + w['x1']) / 2 > midpoint)\n",
        "                    total = len(words)\n",
        "                    is_multi_column = (left_words / total >= 0.3 and right_words / total >= 0.3)\n",
        "\n",
        "                # Extract based on column detection\n",
        "                if is_multi_column:\n",
        "                    split_point = page_width * 0.5\n",
        "                    left_text = page.crop((0, 0, split_point, page_height)).extract_text() or \"\"\n",
        "                    right_text = page.crop((split_point, 0, page_width, page_height)).extract_text() or \"\"\n",
        "                    page_text = f\"{left_text}\\n\\n{right_text}\".strip()\n",
        "                else:\n",
        "                    page_text = page.extract_text()\n",
        "            else:\n",
        "                page_text = page.extract_text()\n",
        "\n",
        "            if page_text:\n",
        "                all_text.append(f\"=== Page {page_num} ===\\n{page_text}\")\n",
        "\n",
        "    return \"\\n\\n\".join(all_text)"
      ],
      "metadata": {
        "id": "-cud_EAInSS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to invoke LLM"
      ],
      "metadata": {
        "id": "D71M2DEnqpK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def invoke_gemini(\n",
        "    query: str,\n",
        "    responseClass: Type[BaseModel],\n",
        "    modelName: str,\n",
        "    system_query: Optional[str] = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Invokes Gemini and parses the response into responseClass.\n",
        "    The user query is passed EXACTLY as-is.\n",
        "    \"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\n",
        "        model_name=modelName,\n",
        "        system_instruction=system_query,\n",
        "\n",
        "    )\n",
        "\n",
        "    response = model.generate_content(\n",
        "        query,  # <-- query is untouched\n",
        "        generation_config={\n",
        "            \"response_mime_type\": \"application/json\",\n",
        "            \"response_schema\": responseClass\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Gemini already validates against the schema\n",
        "    return response.parsed\n"
      ],
      "metadata": {
        "id": "GbX59Vmvqsmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Analysis"
      ],
      "metadata": {
        "id": "cTqPLoo2qm-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "papersWithRelevance = []"
      ],
      "metadata": {
        "id": "sSO28Sel5xe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize each paper\n",
        "# Analyze each summary with reference to project idea\n",
        "files, notepads = getFilesAndNotepads(FOLDER_PATH)\n",
        "for paper in tqdm(files, desc=\"Analyzing reference papers....\"):\n",
        "  paper_content = read_pdf_contents(paper)\n",
        "\n",
        "  try:\n",
        "    summary = invoke_gemini(paper_content, ContextualSummary, SUMMARIZATION_MODEL, SYSTEM_QUERY_SUMMARIZER)\n",
        "  except Exception as e:\n",
        "    print(\"ERROR: Summary generation faced an error : \", e)\n",
        "    break\n",
        "\n",
        "  relevance_query = f\"\"\"\n",
        "  Here is my current project idea :\n",
        "  {PROJECT_CONTEXT}\n",
        "\n",
        "  Calculate relevance of this paper with context to my project. Here is the summary of the paper :\n",
        "  {summary.summary}\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    relevance = invoke_gemini(relevance_query, Paper, RELEVANCE_MODEL, SYSTEM_QUERY_RELEVANCE)\n",
        "  except Exception as e:\n",
        "    print(\"ERROR: Relevance calculation faced an error : \", e)\n",
        "    break\n",
        "  relevance.paper_path = paper\n",
        "  papersWithRelevance.append(relevance.model_dump())"
      ],
      "metadata": {
        "id": "6MmL3uHaqmlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all relevances\n",
        "for paper in papersWithRelevance:\n",
        "  print(json.dumps(paper, indent=2))"
      ],
      "metadata": {
        "id": "MUEgEkIk8dyj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}