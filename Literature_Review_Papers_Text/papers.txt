=== Page 1 ===
Towards Automated Safety Requiremen
BalahariVigneshBalu,FlorianGeissler
JosefJiru,NuriaMa
FraunhoferIKS,FraunhoferInstituteforC
{balahari.balu,florian.geissler,francesco.carella,joao-vitor.zac
Abstract
Westudytheautomatedderivationofsafetyrequirementsin
aself-drivingvehicleusecase,leveragingLLMsincombina-
tion with agent-based retrieval-augmented generation. Con-
ventional approaches that utilise pre-trained LLMs to assist
insafetyanalysestypicallylackdomain-specificknowledge.
ExistingRAGapproachesaddressthisissue,yettheirperfor-
mancedeteriorateswhenhandlingcomplexqueriesanditbe-
comesincreasinglyhardertoretrievethemostrelevantinfor-
mation.Thisisparticularlyrelevantforsafety-relevantappli-
cations.Inthispaper,weproposetheuseofagent-basedRAG
toderivesafetyrequirementsandshowthattheretrievedin-
formationismorerelevanttothequeries.Weimplementan
agent-basedapproachonadocumentpoolofautomotivestan-
dardsandtheApollocasestudy,asarepresentativeexample
of an automated driving perception system. Our solution is
testedonadatasetofsafetyrequirementquestionsandan-
swers,extractedfromtheApollodata.Evaluatingasetofse-
lectedRAGmetrics,wepresentanddiscussadvantagesofa
agent-basedapproachcomparedtodefaultRAGmethods.
Introduction
Safety analysis processes are time-consuming and require
involvement of experts who are well versed in the relevant
domain-specificknowledge.Largelanguagemodels(LLMs)
mightassistinsomerepetitivetasks,likederivingoralign-
ing requirements or populating templates for safety docu-
mentation, while keeping the output language (keywords,
quality) consistent. LLMs can also perform reviews of ex-
istingsafetydocumentation,checkingconsistencyandcom-
pleteness, assuring traceability between requirements, sys-
temelementsandverificationsteps.However,toefficiently
supportsafetyengineersinthesetasks,LLMsmustgenerate
highlyreliableandexplainableresults.
At its core, the ability of LLMs to process natural lan-
guage is enabled by an attention mechanism that identi-
fies semantic correlations between tokens to find meaning-
fulcontinuations(Vaswanietal.2017).Nevertheless,there
isalwaysthepossibilitythatplausiblecontinuationsarenot
factually grounded, leading to so-called ”hallucinations”.
These events have to be suppressed or mitigated efficiently
inordertomakeLLMsatrulyusefultoolforsafetyanalysis
tasks.
Theriskofhallucinationsisrelatedtotheinformationac-
cessible to the LLM, and its suitability to solve the task at
5202
rpA
51
]IA.sc[
1v34211.4052:viXra

nts Derivation Using Agent-based RAG
r,FrancescoCarella,Joao-VitorZacchi,
ata,ReinhardStolle
CognitiveSystemsIKS,Munich,Germany
cchi,josef.jiru,nuria.mata,reinhard.stolle}@iks.fraunhofer.de
hand. Model weights are typically trained on a large cor-
pus of data representing general knowledge. To integrate
additional domain-specific information, techniques such as
fine-tuningorretrieval-augmentedgeneration(RAG)(Lewis
et al. 2020) are commonly used. RAG approaches may re-
ducethechanceofhallucinationsiftheysucceedinretriev-
ingrelevantpiecesofinformation,whichthenserveascon-
textinthefinalLLMprompt.Ontheotherhand,ifirrelevant
orevenincorrectcontextisretrieved,theprobabilityofhal-
lucinationsisexacerbated.
Itisthereforeofgreatinterestforallsafetyanalysistasks
toidentifyefficientandreliableRAGarchitectures.Among
variousproposedmethods(Ranjan,Gupta,andSingh2024),
multi-agentRAGsystems(TalebiradandNadiri2023;Salve
etal.2024)seektocreateafruitfulinterplayofagentswhich
each have the capability to access an individual set of doc-
umentsviaRAG.Inthispaper,westudyhowacustomized
agent-basedRAGapproachfaresonaproblemencountered
in almost any safety engineering workflow: deriving safety
requirements for a given system component with a known
insufficiency.Ourworkprovidesimportantobservationson
how RAG-based LLM systems can be leveraged for safety
analysisprocesses.
Background
General workflow of deriving safety requirements: The
task of deriving safety requirements in the automotive do-
mainistypicallybasedonkeystandardssuchasISO26262
(ISO 2018), which has a focus on functional safety to en-
suresafetybymitigatingsystemfailures(hardware/software
faults), and ISO 21448 (SOTIF) (ISO 2022), that discusses
the safety of the intended functionality by addressing per-
formance limitations and misuse scenarios when no faults
exist. The ISO 26262 provides guidelines for the complete
safetylifecycleofautomotivesystems.Thefoundationsfor
deriving the safety requirements is grounded in the safety
lifecycleduringtheconceptphaseinasequentialmanner-
1)Systemdefinition,2)hazardanalysis,3)safetygoalsand
requirements. The process begins with the item definition
thatcontainsthedifferentfunctions,interfaces,andbound-
ariesofthesystemanditsoperatingenvironmentwithother
systemsandusers.Thistaskprimarilydescribesthesystem’s
purposeandcontext.
Afterdefiningthesystem,itsmodesofoperationandop-

=== Page 2 ===
Figure 1: A RAG pipeline showcasing how domain knowledg
servingasinputtotheLLMtogetherwiththeuserquery.Thede
approachhighlightedingreen,whichenablesarefinedcontext
erationaldesigndomain(ODD)areusedtoidentifytheop-
erationalscenarios.Thesubsequenthazardanalysisisbased
on the Hazard and Risk Analysis (HARA) as outlined by
automotive standards (ISO 2018, 2022). It is a structured
process specific to each domain and is used to assess the
hazards, associated risks and required safety measures and
servesasaprerequisitefortheelicitationofsafetyrequire-
ments.Thegoalistoidentifyhazardoussituationsthatcan
cause harm. Techniques like hazard and operability analy-
sis (HAZOP) are used to identify possible deviations from
an intended operation to deduce hazardous scenarios. Each
of these hazardous events are assessed for associated risks
based on three parameters - severity, exposure and control-
lability.Basedonthevaluesassigned,automotivesafetyin-
tegritylevel(ASIL)ratingsaredetermined.TheHARAre-
port documents the hazards, levels of risks associated with
it and the ASIL classification. For every hazardous event
identified, a safety goal is specified so that the associated
riskisaddressedorcontrolled.Amongthose,similarsafety
goalsareaggregatedandthecombinedgoaltakesthehigh-
estASILrating.High-levelsafetyrequirementsaredefined
to meet these safety goals. Since these are referring to the
entiresystem,theyneedtobetranslatedtospecificsubsys-
tems or individual components with the help of techniques
likeafaulttreeanalysis(FTA).Therequirementsforspecific
componentscanhelptopreventsituationslikethefailureof
a component, or the corruption or loss of messages during
thecommunicationofcomponents.
Theabovetasksareperformedbyteamsofvariousstake-

ge is pre-processed and stored to be retrieved later as context,
efault(conventional)RAGapproachisreplacedbyacustomized
retrievalmechanismillustratedindetailinFig.2.
holders and safety experts. The nature of these tasks typi-
callyrequireshumanbrainstorming,expertisewithprevious
domain knowledge, and compliance with relevant standard
guidelines. It is also necessary to understand the outputs
generatedateach stage,astheyrepresentessentialinput to
the next stage. In short, the various tasks in safety analysis
workflowreliesontheintricate,domain-specificexperience
held by safety experts, including a familiarity with the rel-
evant standards. A LLM assistant should be able to mimic
suchcharacteristicsthatareexpectedfromasafetyexpert.
RetrievalAugmentedGeneration:LLMsachievestate-
of-the-art results for domain-specific NLP tasks typically
onlyuponfine-tuningorrespectivere-training.However,if
the fine-tuning training set includes low-quality or too few
samples, the answer quality can still be poor. Pre-trained
LLMs can further generate responses with factual inaccu-
racies (or hallucinations). RAG models, as introduced in
(Lewisetal.2020),oftenprovideacost-effectivesolutionto
the aforementioned problem. Hereby, external information
gets embedded and stored in a vector store. When paired
withapre-trainedretrieverwithaccesstothestoredknowl-
edge,theRAGmodelisabletogenerateoutputsgroundedin
theprovidedknowledge,whilestillholdingtheabilitytobe
diverse, factual and specific in nature. Various approaches
(Izacard and Grave 2020; Guu et al. 2020; Borgeaud et al.
2022;Izacardetal.2023)haveemergedovertimethatseek
toretrievemoretargetedandrelevantcontext,aswellasto
improvetheretrievalquality(Asaietal.2023).

=== Page 3 ===
Figure2:Thesequenceofsteps(readfromtop-to-bottom)depi
retrievalmechanismtoretrieverefinedcontextsintheagent-bas
RelatedWork
The use of LLMs to assist in Systems Theoretic Process
Analysis (STPA) was studied by the authors of (Qi et al.
2023).TheyusedLLMstoperformSTPAandderiveasetof
safetyrequirementsfortwocasestudies-automatedemer-
gencybrakingandelectricitydemandsidemanagementsys-
tems. Different collaboration schemes between human ex-
perts and LLMs were explored. The authors also analyze
theeffectsofinputcomplexitiesandpromptengineeringon
theLLMresults.Thepaperemphasizestheneedforhuman
safetyexpertstocomplementthesafetyanalysisbyLLMs,
whilehighlightingtheissueofnon-reliabilityofLLMs,i.e.,
the generation of factually inaccurate and inconsistent out-
putsduetotheirlimiteddomain-specificknowledge.
The authors of (Nouri et al. 2024) explore the use of
LLMs to automate the HARA, where they define a LLM-
based pipeline and try to improve it by incorporating feed-
backfromsafetyexperts.Thelimitationofalackofdomain-
specific knowledge in understanding technical terms and
processeswithinautomotiveandsafetydomainsisacknowl-
edged,alongwithotherdifficultiessuchasitslimitedcapa-
bilityininterpretingtechnicalinformationpresentedasfig-
ures.Further,inconsistenciesareidentifiedinthegenerated
set of safety requirements in relation to the use of modal
verbs such as ”should” and ”shall”, which has specific
meaning in the context of automotive safety. The authors
counteredtheseidentifiedlimitationsbybreakingdownthe
HARAintosmallertasksdevelopingspecificcontext,guides
andpromptsforeachidentifiedsub-tasks.Toaddresshallu-
cinationsandimprovedexplainability,suchbackgroundin-
formation is included within the prompts to stimulate rea-

ictingtheworkflowoftheproposedalternatemethodofcontext
sedRAGapproachproposedinthispaper.
soningalongwithgeneratedoutputs.
In (Geissler, Roscher, and Trapp 2024), a hybrid LLM-
classicalsafetyworkflowisdiscussedforscenariossuchas
fault propagation in a system graph. A LLM agent is first
guided along pre-formulated categories to identify the spe-
cificproblemathandrepresentedbytheinputprompt.Sub-
sequently,deterministictoolsareleveragedtoactuallysolve
thetask,usingvariablespreparedbythepreviousLLManal-
ysis.
Another relevant study is presented in (Sivakumar et al.
2024). Here, the authors assess the ability of LLMs to un-
derstandandgeneratesafetycasesbasedontheGoalStruc-
turing Notation (GSN). They tested the correctness of gen-
eratedsafetycasesbycomparingthemagainstgroundtruth
safety cases derived from other reference research papers.
Apart from concerns such as hallucinations, or lexical cor-
rectness of generated content, the findings underscore that
theunavailabilityofcontextualinformationaboutreference
safety cases limits the scope and comprehensiveness of the
generatedsafetycases.Whilethepreviousworkfocusedon
thegenerationofthesafetycase,theauthorsof(Goharetal.
2024)useLLMstoidentifypotentialdefeatersinclaimsthat
arepartofanassurancecase.Theyiterativelyprocesseach
claimwithrole-basedpromptingtodemonstratetheLLM’s
effectivenessinidentifyingpotentialdefeatersinazero-shot
setting.
While these works primarily explore the intersection be-
tween LLMs and safety analysis processes, most of them
focus on zero-shot prompting approaches or improvised
prompt engineering techniques to investigate the use of an
LLM for a particular tasks. Frequently encountered con-
cerns include hallucinations and the limited availability of

=== Page 4 ===
Metric Description
Normalized answer simi- Similarity of reference an-
larityscore(NASS) swer and LLM answer, as
assessedbyaLLMjudge.
Retrievalprecision(RP) Decidewhethertheretrieved
context is relevant to the
question, as assessed by a
LLMjudge.
Augmentation accuracy Decidewhethertheretrieved
(AA) context is used in the LLM
answer, as assessed by a
LLMjudge.
Augmentation precision Decide whether the relevant
(AP) retrievedcontextusedinthe
LLManswer,usingRP,AA.
Answerconsistency(AC) Summarizes main points
from the LLM answer and
checks which portion of
those main points is found
also in the context, as
assessedbyaLLMjudge.
Table1:Selectedmetricsadaptedfrom(TonicAI2024).All
metricsarenormalizedtoarangeof0−1.
domain-specificknowledgefortheLLMs.Ourworktakesa
stepfurtherinaddressingthisconcernbyproposingaagent-
basedRAG-basedapproachtoeffectivelytailorthesupport
tothesafetyanalysisprocess.
MethodologyandExperimentalSetup
Customized approach for agent-based RAG: To facili-
tate the incorporation of domain-specific knowledge while
avoiding the overhead cost of fine-tuning or retraining of
LLMs for specific tasks, we propose a novel approach that
empowersthedefaultRAG-basedapproach,utilizingdocu-
mentagentstoperformtaskswithhighercomplexities.This
strategy enhances reliability by working within the bound-
ariesofprovideddomainknowledgeand,asaconsequence,
mitigates hallucinations. Furthermore, the use of document
agentsallowsforamodularandscalablestructuretoaccom-
modatedomain-specificknowledgethatmightbeconstantly
updated.
TheworkflowofadefaultRAG-basedapproachisshow-
casedinFig.1.Thedomain-specificknowledgeintheform
of documents is transformed into the vector representa-
tionsusingtheembeddingmodels,preservingtheirseman-
tic meaning. The relevant documents of different formats
areparsedintodifferentchunks.Thesechunksareconverted
into different embeddings along with the metadata, for use
bytheLLM.Theembeddingsarestoredintheformofvec-
torrepresentationsintheVectorStoreIndex toberetrieved
later. The latter is performed by a Query Engine. It acts as
theinterfacebetweentheAImodelandtheindicesenabling
the retrieval task and translates the query into a suitable

format for the indices to be retrieved. During retrieval, the
queryembeddingiscomparedwiththestoredchunksusing
asimilaritymetrictoidentifythosechunksthatarerelevant
to the query. Finally, the retrieved chunks are included as
contextalong withthequery andprocessed bytheLLM to
generatearesponse.
In addition to the components of a default RAG-based
pipeline,theDocumentAgentisintroducedfordifferentsets
of documents. As shown in the step 3 of Fig. 2, each doc-
ument agent represents a query engine that contains a Vec-
tor Store Index and a Summary Index. Along with the vec-
torstoreindex,thesummaryindexintroducedin(JerryLiu
2024) is an iterative, hierarchical method for summarizing
the document, where a tree-like structure is created with
summaries stored at lower and higher levels, respectively.
Thisenablesthehandlingoflong,complexdocumentswhile
allowingforthestorageofabstractedinformationcontained
in those documents. A query engine is defined for each of
these indices. At the time of creation, an appropriate de-
scriptionispassed,suchthatthevectorqueryenginewould
be used to answer facts about the document and the sum-
maryqueryenginewouldbeusedtoanswersummarization
questionsaboutthedocument.Wheneverthedocumentgets
chosen to retrieve relevant context, based on the query, ei-
ther vector query engine or summary query engine will be
invoked. This selection of an appropriate query engine is
implemented with the OpenAI agent framework (OpenAI
2024).Theresultisadocumentagentforthatparticulardoc-
ument. While the document agent helps to choose between
vector or summary query engine of a document, choosing
the appropriate document is facilitated by the Document
Tool.Thedocumentagentsforeachdocumentarewrapped
withanotherqueryenginealongwithashortdescription(1-
2lines)aboutthecontentsofthedocument.Multipledocu-
menttoolsareindexedtogethertoformtheTop-levelDocu-
mentAgent.
The top-level document agent gets invoked upon receiv-
ingaqueryfromtheuser,asshowninstep2ofFig.2.This
retrieves the top-3 relevant documents. The same query is
againusedwithinthedocumentagentrepresentingthetop-3
retrieved documents to choose between a vector query en-
gineorasummaryqueryengine.Afterchoosingtheappro-
priatequeryengine,arefinedcontextisproducedfromeach
ofthetop-3documents,ifthedocumentsdonotcontainany
relevantinformation,thenthecontextgetsdiscarded.These
refined contexts are passed on along with the user input to
theLLMtogeneratethefinaloutput.
Dataset:Toevaluatethemethodology,wechosethepub-
liclyavailableApollousecasestudyforanautomateddriv-
ing perception system (Zenodo 2022; Apollo Auto 2023;
Kochanthara et al. 2024). A dataset of 58 question-answer
pairs(30safetytactic-basedand28ML-designcomponents)
was collected from the ”Design Assessment” section of
(Zenodo 2022), representing a list of critical system com-
ponents and their respective safety requirements, as gener-
ated by safety experts. In our experimental setup, a ground
truthreferenceanswerisgivenbyasafetyrequirement,and
the respective question is a concatenation of a component
orasetofcomponents(alsocalled”pipeline”),aswellasa

=== Page 5 ===
knowninsufficiency,andpossiblyatriggercondition,ifpro-
vided in (Zenodo 2022). Every question is further embed-
dedinasystemprompt.Followingbestpromptengineering
practices(Zhouetal.2023),thesystempromptwascrafted
to be as specific as possible, eliminating ambiguity regard-
ing the task. A single data point of our dataset is then, for
example(seealsoTab.2):
Prompt: ”Act as a safety engineer, who has the task
to derive safety requirements for a given component
pipeline.Asinput,youaregiventhepipeline,aknown
potentialfunctionalinsufficiency,andpossiblyatrig-
gercondition.
Outputasafetyrequirement,i.e.adescriptionhowthe
functionofthecomponentpipelineshallnotperform
in case the known insufficiency occurs. Consider the
function of the component pipeline and possible fur-
therdownstreamsystemfunctionstostatewhatshall
not happen in case of the functional insufficiency.
Keep your answer as brief as a single sentence, but
makesureasystem-specificrequirementisgiven.Be-
ginyourstatementwith’If...’
INPUT:///{Question}///
OUTPUT:”,
Question: ”Pipeline: Camera obstacle detection,
classification, and tracking pipeline, Known poten-
tial function insufficiency: deteriorated performance
ofcamerabasedobjectdetectionandtrackingdueto
adverseweatherconditions,Triggercondition:mod-
erateincrementlevelsofrain”
Reference answer: ”If the performance of Cam-
era obstacle detection, classification, and tracking
pipeline is deteriorated due to moderate increment
levelsofrain,thenthisdeteriorationinperformance
shall not lead to an incorrect estimation of the state
ofvehiclesorotherobstacles.”
The task given to the LLM is to generate safety require-
mentsforthegiveninputs,andtheperformancewithrespect
tothegroundtruthisevaluatedusingthemetricsdiscussed
inthenextsection.TheentireApollodocumentation(Zen-
odo2022)wasusedassourcematerialforRAG(Retrieval-
Augmented Generation) to assist in this task, except for
thesafetyrequirementdocumentationcontainingtheground
truth.Furthermore,weaddedcontentadoptedfromrelevant
automotive standards such as ISO PAS 8800 (ISO 2024),
ISO 26262 (ISO 2018), ISO 21448 (SOTIF) (ISO 2022),
ISO/TR4804(ISO2020)andUN157(UNECE2021)tothe
documentpoolaccessiblebyRAG.
Model: For LLM access, a pre-trained GPT-3.5 model
(OpenAI 2023) was used both to generate predictions and
to act as a judge LLM for the respective metrics. For both
purposes, the default temperature was used. We compare a
standard RAG approach, our proposed agent-based RAG,
and single LLM calls without RAG context. To implement
both the default and our advanced RAG pipeline, we made
useoftheLLamaIndex(TeamLlamaIndex2023)libraryas
wellastheFAISSvectorstore(Douzeetal.2024).Thede-
faultchunksizewaschosenforparsingcontextinthevector
store.
Metrics: In order to assess the quality of the different

approaches, we apply the metrics in Tab. 1, see (Tonic AI
2024). Each metric are applied to a subset of an individual
tupleof(question,retrievedcontext,LLManswer,reference
answer). In particular, note that RP directly evaluates the
quality of the context retrieval step, while AA, AP, AC are
focused on a semantic match between context and the an-
swer.
Results
1.0
0.8
0.6
0.4
0.2
0.0
NASS RP AA AP AC
serocS
Default RAG Multi-agent RAG (Ours) No RAG
Figure3:Averageandstandarderrorforthemetricsselected
inTab.1for10independentruns.
TheFig.3showstheresultofevaluatingthesafetyrequire-
mentsdatasetwithouragent-basedRAGapproach,compar-
ingtothetwobaselinesofasingleLLMcall(noRAG,only
for NASS), and a default RAG pipeline. We make the fol-
lowingobservations.
• TheNASSscoreisverysimilarforbothRAGapproaches
and even LLM calls without RAG. This suggests that,
onaverage,theLLMcanleveragegenericknowledgeto
phrase answers that are assessed as similar to the cor-
rectresponse.Wefurtherverifiedthatalternativesimilar-
itymetrics,suchastheBERTscore(Zhangetal.2020),
exhibitonlyminimalvariationsforthethreeapproaches.
Aninspectionofselectedexamples(seeTab.2)indicates,
however, that RAG-assisted answers do contain addi-
tionalinformationthatahumanuserwoulddeemuseful.
Forexample,fordeterioratedperformanceofthecamera
systemincaseofrain,theLLMwithoutRAGstatesthat
thisshouldnotleadtoanincorrectestimationofthestate
of other vehicles or obstacles. The answer with default
RAGfurthermentionsthatalternativesensorsshouldbe
activated.Withtheagent-basedRAGapproach,theLLM
answer additionally refers to such other sensor modali-
tieslikeradarorlidarthatareavailablewithinthearchi-
tecture of Apollo, demonstrating the ability to identify
nuancesintheprocessofsafetyrequirementsderivation.
Nevertheless, all answers receive a similar NASS score

=== Page 6 ===
Prompt ”Actasasafetyengineer,whohas
pipeline.Asinput,youaregiven
possibly a trigger condition. Outp
ofthecomponentpipelineshalln
the function of the component pip
statewhatshallnothappenincase
asinglesentence,butmakesurea
with’If...’
INPUT: ///Pipeline: Camera obsta
potentialfunctioninsufficiency:de
trackingduetoadverseweatherc
rain///
OUTPUT:”
Referenceanswer ”IftheperformanceofCameraobs
oratedduetomoderateinclement
leadtoanincorrectestimationoft
LLManswer ”Ifthecamerabasedobjectdetec
(noRAG) inclementlevelsofrain,thepipeli
classification,andtracking.”(NAS
LLM answer (Default ”Iftheperformanceofthecamera-
RAG) erateinclementlevelsofrain,thec
shallnotrelysolelyonthecamera
tectionandtracking.”(NASS:3/5)
LLM answer (Agent- ”Ifthecamera-basedobjectdetec
basedRAG) inclementlevelsofrain,thepipeli
andtracking,butshallalsoutilize
Table2:SelectedexampleLLManswerstothe
bytheLLMjudge.Wethereforeconclude,thatthesimi-
laritymetricssuchasNASSorBERTscorearenotable
tocapturesubtledetailsthatmightstillbeofinteresttoa
humanreviewer.WeexpectthattheNASSscorewillbe
morediscriminativeinmorecomplexproblems,orwhen
usingsmallerLLMmodelswithlessgenericknowledge.
• TheRPmetricissignificantlyhigherforouragent-based
RAG approach than for the default RAG. In the former,
thecontextusedforevaluationisinformationthatispre-
processedbytheRAGagentsafterindividualcalls.Such
a multi-step approach is able to condense chunks from
originalsourcedocumentsintocompactsummaries,that
are semantically highly relevant for the query. This is
not the case for default RAG, where only raw context
chunksareretrievedfromthesourcedocuments.Thiscan
havetheeffect,thatthechunksretrievedbydefaultRAG
match only individual keywords from the prompt (for
example ”insufficiencies”, standard names, etc.) while
missingtheoverallmeaning.Wefurtherobserve,thatthe
default RAG is prone to getting ”stuck” with a specific
document,i.e.,theretrieverextractsalltopchunksfrom
the same, often not even most significant document. As
thelow RPscoreindicates,it tendstoretrieveplenty of
irrelevant information chunks, see also Tab. 3. On the
other hand, the agent-based RAG is more successful in
fusinginformationfromdifferentdocumentsources.
• Due to the above-mentioned condensation of the re-
trieved contexts, the final LLM answers are very simi-
lartotheretrievedcontextsintheagent-basedapproach.
This is reflected in a high AA, AP score, as well as the

sthetasktoderivesafetyrequirementsforagivencomponent
thepipeline,aknownpotentialfunctionalinsufficiency,and
put a safety requirement, i.e. a description how the function
notperformincasetheknowninsufficiencyoccurs.Consider
peline and possible further downstream system functions to
eofthefunctionalinsufficiency.Keepyouranswerasbriefas
asystem-specificrequirementisgiven.Beginyourstatement
acle detection, classification, and tracking pipeline, Known
eterioratedperformanceofcamerabasedobjectdetectionand
conditions,Triggercondition:moderateinclementlevelsof
stacledetection,classification,andtrackingpipelineisdeteri-
levelsofrain,thenthisdeteriorationinperformanceshallnot
thestateofvehiclesorotherobstacles.”
ctionandtrackingperformancedeterioratesduetomoderate
ineshallnotprovideinaccurateordelayedobstacledetection,
SS:4.5/5)
-basedobjectdetectionandtrackingdeterioratesduetomod-
cameraobstacledetection,classification,andtrackingpipeline
ainputandshallactivateanalternativesensorforobjectde-
)
ctionandtrackingperformancedeterioratesduetomoderate
ineshallnotrelysolelyoncameradataforobstacledetection
othersensorinputssuchasradarorlidar.”(NASS:4.5/5)
esamepromptforeachstudiedRAGapproach.
answerconsistency.DefaultRAGalsoscoreshighinAP,
suggestingthatifrelevantcontextwasretrieved,thisalso
carries over to the LLM answer. However, the answers
typically contain content that is missing in the context
(see low AC, AA), and thus had to be generated from
genericknowledge.Theagent-basedRAGalreadyelimi-
natesirrelevantcontextduringpre-processing,leadingto
veryhighAA,AP,ACscores.
ConclusionandOutlook
Forthegivensafetyrequirementsdataset,wefindthatLLM
answerswithhighsimilaritytothereferenceanswercanbe
generated without RAG, or using default RAG. Inspecting
further metrics such as the RP, AA and, AC, however, we
see that our agentic RAG approach retrieves significantly
more relevant context than the default RAG. We interpret
theseresultssuchthattheproblemsetup(useddatasetand
model) is likely too simple to reveal the full benefit of the
agentic RAG approach: Good solutions can be found sim-
plybyleveraginggenericknowledgeoftheLLM,suchthat
the quality of the retrieved context has no significant im-
pact on the answer similarity alone. Nevertheless, the fact
thatthisstrategyretrievesameasurablymorerelevantcon-
textisverypromisingandinsightfulforsafety-criticalappli-
cations. A closer inspection also shows, that a LLM-based
similarity score (here NASS) does not necessarily capture
all quality attributes of a generated requirement. Although
a verification with human expert reviews was out of scope
of this paper, we suspect that such a human scoring metric
wouldprefertheagenticRAGoverthedefaultRAGdueto

=== Page 7 ===
Approach Metriccomponents
DefaultRAG • Retrievedcontext:
– ”ISO 21448:2022(E) Figure 14 2014 E
sensors. The classification can also be
validation targets for multiple-point fun
considerations(seeClause9andC.6.3)
– ”ISO21448:2022(E)2014knownpoten
knownpotentialtriggeringconditions(i
ahazardousbehaviourbasedonexterna
– ”ISO21448:2022(E)KeyaDepending
anelementlevelcanberecognizedeith
pointfunctionalinsufficiency(3.19).b
oneormoreoutputinsufficienciesofot
• Answerconsistentwithcontext:True
• Contextrelevancy:False
• Mainpoints:
– ”Performanceofcamera-basedobjectd
– ”Cameraobstacledetection,classificatio
– ”Activatealternativesensorforobjectd
• Statementderivedfromcontext:True
• Mainpointsfromcontext:False,False,Fa
Agent-based • (Summarized)Retrievedcontext:
RAG
– ”Ifthecamera-basedobjectdetectiona
levelsofrain,thepipelineshallnotrel
shallalsoutilizeothersensorinputssuc
– ”Ifthecamera-basedobjectdetectiona
levelsofrain,thepipelineshallnotrel
insteadutilizeadditionalsensorinputso
• Answerconsistentwithcontext:True
• Contextrelevancy:True
• Mainpoints:
– ”Camera-basedobjectdetectionandtra
– ”Pipelineshouldnotrelysolelyoncam
– ”Othersensorinputssuchasradarorlid
• Statementderivedfromcontext:True
• Mainpointsfromcontext:True,True,True
Table3:Tracedcontextandanalyzedcomponentsofthemetri
defaultRAG,theretrievedcontextisshortenedforvisibility.Fo
theagent’sinstructions.

Example of system architecture with the fusion of two diverse
used during the definition of the validation strategy, where the
nctional insufficiencies can be reduced subject to independence
)....”,
ntialfunctionalinsufficienciesofthesystemanditselementsand
includingreasonablyforeseeabledirectmisuse)thatcouldleadto
alinformationorlessonslearnt(e.g.13.5)....”,
onthearchitectureofthesystemthisfunctionalinsufficiencyon
herasasingle-pointfunctionalinsufficiency(3.28)oramultiple
bAnoutputinsufficiency,eitherbyitselforincombinationwith
therelements,...”
detectionandtrackingdeterioratesinrain”,
on,andtrackingpipelineshouldnotrelysolelyoncamerainput”,
detectionandtracking”
alse
andtrackingperformancedeterioratesduetomoderateinclement
lysolelyoncameradataforobstacledetectionandtracking,but
chasradarorlidar.”
andtrackingperformancedeterioratesduetomoderateinclement
lysolelyoncameradataforobstacledetectionandtracking,but
oralternativedetectionmethods.”
ackingperformancedeterioratesinmoderaterain”
meradataforobstacledetectionandtracking”
darshouldbeutilized”
e
icsRP,AA,AP,ACusingtheexamplegiveninTab.2.Forthe
ortheagent-basedRAG,thecontextissummarizedaccordingto

=== Page 8 ===
itshigherdensityofpotentiallyusefuldetails.Asnextsteps,
wewilltestourstrategywithmorecomplexdatasetsorsim-
plerLLMmodels,inordertoestablishacloserconnectionto
theretrievedcontextrelevanceandtheLLManswerquality.
Acknowledgments
This work was funded by the Bavarian Ministry for Eco-
nomicAffairs,RegionalDevelopmentandEnergyaspartof
aprojecttosupportthethematicdevelopmentoftheInstitute
forCognitiveSystems.
References
Apollo Auto. 2023. Apollo: An Open Au-
tonomous Driving Platform. Available at
https://github.com/ApolloAuto/apollo.
Asai, A.; Wu, Z.; Wang, Y.; Sil, A.; and Hajishirzi, H.
2023. Self-RAG: Learning to Retrieve, Generate, and Cri-
tiquethroughSelf-Reflection. arXiv:2310.11511.
Borgeaud, S.; Mensch, A.; Hoffmann, J.; Cai, T.; Ruther-
ford, E.; Millican, K.; Van Den Driessche, G. B.; Lespiau,
J.-B.;Damoc,B.;Clark,A.;etal.2022.Improvinglanguage
models by retrieving from trillions of tokens. In Interna-
tionalconferenceonmachinelearning,2206–2240.PMLR.
Douze,M.;Guzhva,A.;Deng,C.;Johnson,J.;Szilvasy,G.;
Mazare´,P.-E.;Lomeli,M.;Hosseini,L.;andJe´gou,H.2024.
TheFaisslibrary.
Geissler, F.; Roscher, K.; and Trapp, M. 2024. Concept-
Guided LLM Agents for Human-AI Safety Codesign.
arXiv:2404.15317.
Gohar, U.; Hunter, M. C.; Lutz, R. R.; and Cohen, M. B.
2024. CoDefeater: Using LLMs To Find Defeaters in As-
suranceCases. arXiv:2407.13717.
Guu, K.; Lee, K.; Tung, Z.; Pasupat, P.; and Chang, M.
2020. Retrievalaugmentedlanguagemodelpre-training. In
International conference on machine learning, 3929–3938.
PMLR.
ISO. 2018. ISO 26262:2018 Road vehicles - Functional
Safety. Standard, International Organization for Standard-
ization,Geneva,CH.
ISO. 2020. ISO/TR 4804:2020 Road vehicles - Safety and
cybersecurityforautomateddrivingsystems-Design,veri-
ficationandvalidation.Standard,InternationalOrganization
forStandardization,Geneva,CH.
ISO. 2022. ISO 21448:2022 Road vehicles - Safety of the
intendedfunctionality. Standard,InternationalOrganization
forStandardization,Geneva,CH.
ISO.2024. ISO/PAS8800:2024Roadvehicles-Safetyand
artificial intelligence. Standard, International Organization
forStandardization,Geneva,CH.
Izacard, G.; and Grave, E. 2020. Leveraging passage re-
trievalwithgenerativemodelsforopendomainquestionan-
swering. arXivpreprintarXiv:2007.01282.
Izacard,G.;Lewis,P.;Lomeli,M.;Hosseini,L.;Petroni,F.;
Schick,T.;Dwivedi-Yu,J.;Joulin,A.;Riedel,S.;andGrave,
E.2023. Atlas:Few-shotlearningwithretrievalaugmented

language models. Journal of Machine Learning Research,
24(251):1–43.
Jerry Liu. 2024. A New Document Summary
Index for LLM-powered QA Systems. Avail-
able at https://www.llamaindex.ai/blog/a-new-
document-summary-index-for-llm-powered-qa-systems-
9a32ece2f9ec.
Kochanthara, S.; Singh, T.; Forrai, A.; and Cleophas, L.
2024. SafetyofPerceptionSystemsforAutomatedDriving:
A Case Study on Apollo. ACM Transactions on Software
EngineeringandMethodology,33(3).
Lewis, P.; Perez, E.; Piktus, A.; Petroni, F.; Karpukhin, V.;
Goyal, N.; Ku¨ttler, H.; Lewis, M.; Yih, W.-t.; Rockta¨schel,
T.; et al. 2020. Retrieval-augmented generation for
knowledge-intensive nlp tasks. Advances in Neural Infor-
mationProcessingSystems,33:9459–9474.
Nouri, A.; Cabrero-Daniel, B.; To¨rner, F.; Sivencrona, H.;
and Berger, C. 2024. Engineering Safety Requirements
for Autonomous Driving with Large Language Models.
arXiv:2403.16289.
OpenAI.2023. ChatGPT3.5-turbo.
OpenAI. 2024. OpenAI Agent Framework: Enabling Tool
IntegrationwithOpenAIAgent.from tools. https://platform.
openai.com/docs. Accessed:2025-01-08.
Qi,Y.;Zhao,X.;Khastgir,S.;andHuang,X.2023. Safety
Analysis in the Era of Large Language Models: A Case
StudyofSTPAusingChatGPT. arXiv:2304.01246.
Ranjan,R.;Gupta,S.;andSingh,S.N.2024.AComprehen-
siveSurveyofBiasinLLMs:CurrentLandscapeandFuture
Directions.
Salve,A.;Attar,S.;Deshmukh,M.;Shivpuje,S.;andUtsab,
A. M. 2024. A Collaborative Multi-Agent Approach to
Retrieval-AugmentedGenerationAcrossDiverseData.
Sivakumar, M.; Belle, A. B.; Shan, J.; and Shahandashti,
K.K.2024. PromptingGPT–4tosupportautomaticsafety
case generation. Expert Systems with Applications, 255:
124653.
Talebirad,Y.;andNadiri,A.2023. Multi-AgentCollabora-
tion:HarnessingthePowerofIntelligentLLMAgents.
Team LlamaIndex. 2023. LlamaIndex: A Data
Framework for LLM Applications. Available at
https://github.com/jerryjliu/gpt index.
Tonic AI. 2024. Tonic Validate: A high perfor-
mance LLM/RAG evaluation framework. Available at
https://github.com/TonicAI/tonic validate.
UNECE. 2021. UN Regulation No 157 – Uniform provi-
sions concerning the approval of vehicles with regards to
AutomatedLaneKeepingSystems[2021/389].
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,
L.;Gomez,A.N.;Kaiser,Ł.;andPolosukhin,I.2017. At-
tentionisallyouneed.AdvancesinNeuralInformationPro-
cessingSystems,2017-Decem:5999–6009.
Zenodo. 2022. Safety of Perception System for Auto-
mated Driving: A Case Study on Apollo. Available at
https://zenodo.org/records/8226271.

=== Page 9 ===
Zhang,T.;Kishore,V.;Wu,F.;Weinberger,K.Q.;andArtzi,
Y. 2020. BERTScore: Evaluating Text Generation with
BERT. arXiv:1904.09675.
Zhou, Y.; Muresanu, A. I.; Han, Z.; Paster, K.; Pitis, S.;
Chan, H.; and Ba, J. 2023. Large Language Models Are
Human-Level Prompt Engineers. 11th International Con-
ferenceonLearningRepresentations,ICLR2023.

Paper:BetterCheck - Towards Safeguarding VLMs.pdf
=== Page 1 ===
BetterCheck: Towards
for Automotive Pe
Malsha Ashani Mahawatta Dona, Beatriz C
University of Gothenburg and Ch
Gothenburg
{malsha.mahawatta,beatriz.cabrero-daniel,ch
Abstract—Large language models (LLMs) are growingly
extended to process multimodal data such as text and video
simultaneously. Their remarkable performance in understand-
ing what is shown in images is surpassing specialized neural
networks (NNs) such as Yolo that is supporting only a well-
formed but very limited vocabulary, ie., objects that they
are able to detect. When being non-restricted, LLMs and
in particular state-of-the-art vision language models (VLMs)
show impressive performance to describe even complex traffic
situations.Thisismakingthempotentiallysuitablecomponents
forautomotiveperceptionsystemstosupporttheunderstanding
of complex traffic situations or edge case situation. However,
LLMs and VLMs are prone to hallucination, which mean to
either potentially not seeing traffic agents such as vulnerable
road users who are present in a situation, or to seeing traffic
agentswhoarenotthereinreality.Whilethelatterisunwanted
making an ADAS or autonomous driving systems (ADS) to
unnecessarily slow down, the former could lead to disastrous
decisions from an ADS. In our work, we are systematically
assessing the performance of 3 state-of-the-art VLMs on a
diverse subset of traffic situations sampled from the Waymo
Open Dataset to support safety guardrails for capturing such
hallucinations in VLM-supported perception systems. We ob-
servethatboth,proprietaryandopenVLMsexhibitremarkable
image understanding capabilities even paying thorough atten-
tion to fine details sometimes difficult to spot for us humans.
However,theyarealsostillpronetomakingupelementsintheir
descriptionstodaterequiringhallucinationdetectionstrategies
such as BetterCheck that we propose in our work.
I. INTRODUCTION
Nowadays, the adoption of Large Language Models
(LLMs)canbeseeninvariousdomainsincludingeducation,
research, manufacturing, or healthcare [1], [2]. Applications
ofLLMssuchasPre-trainedTransformers(GPT)indifferent
domains,notlimitedtoabovementionedfields,haveenabled
a positive influence opening new opportunities through their
exceptional understanding and generation capabilities [1].
As modern vehicles grow into intelligent cyber-physical
systems (CPS) [3] that are capable of housing powerful
centralized processing units and hardware accelerators such
as GPUs, executing specialized Neural Networks (NNs)
has become increasingly feasible, which support Advanced
Driver Assistant Systems (ADAS) and Autonomous Driving
(AD). These advanced capabilities enable features such as
real-timeperception,decision-making,controlfunctions,and
even running LLMs locally without relying on cloud-based
infrastructure backends [4], [5].
5202
luJ
32
]VC.sc[
1v22771.7052:viXra

s Safeguarding VLMs
erception Systems
Cabrero-Daniel, Yinan Yu, Christian Berger
halmers University of Technology
g, Sweden
hristian.berger}@gu.se, yinan@chalmers.se
A. Problem Domain and Motivation
LLMs that work with multimodal data offer computer
vision and natural language processing capabilities and are
recently referred to as Vision Language Models (VLMs)
when adopted for understanding image streams [6]. These
VLMs are designed to understand and generate text-based
responses on visual inputs, including images and videos.
Such state-of-the-art VLMs have shown remarkable capa-
bilities in tasks such as image captioning, visual question-
answering, and multimodal reasoning, demonstrating their
potentialinsupportingperceptionandmonitoringtasksinthe
automotivecontext[7].Duetoexceptionalnaturallanguage-
based communication capabilities, they can also be used as
Human Machine Interfaces (HMI) to support in-car passen-
gers [8] and hence, make the vehicle much more accessible
and inclusive.
However, due to the potential risk of hallucinations [9]
generated by LLMs, the trustworthiness of such LLM-
assisted systems and applications remains questionable.
Therefore, when LLM assistance is used within safety-
critical systems such as vehicles, it is important to design
data processing pipelines embodying VLMs with safety
guardrails to spot potential hallucinations and to mitigate
them.
B. Research Goal and Research Questions
The existing literature proposes hallucination detection
strategies for LLM-assisted tasks. Manakul et al. [10] have
evaluated and extended a technique called SelfCheckGPT
that is capable of identifying nonsensical information gen-
erated by LLMs in text-based outputs. Dona et al. [7]
proposeavariantofSelfCheckGPTthatdetectshallucination
in multimodal contexts, specifically targeting automotive
applications. The goal of our study is to determine the
performance of the adapted SelfCheckGPT approach across
different state-of-the-art LLMs when used for captioning
images and for checking for hallucinations. In particular, we
are focusing on the extent to which LLMs overlook traffic
agentsthatmaycriticallyaffectthetrustworthinessofLLM-
assisted perception and monitoring systems.
RQ-1:Whatisthequality,accordingtohumanevaluators,
ofstateoftheartVLMsincaptioningrealworldautomotive
video footage?

=== Page 2 ===
RQ-2: To which extent do each of the tested VLMs
hallucinate traffic agents or overlook them?
RQ-3: To what extent are the selected VLMs able to
checktheirownresults,andthustodiscardcaptionslikelyto
containhallucinationsorthatoverlookrelevanttrafficagents?
C. Contributions and Scope
We systematically assessed the adapted SelfCheckGPT
hallucination detection framework across different combi-
nations of LLMs with the goal to safeguard VLMs for
automotive perception tasks. Our main contribution is the
extensionoftheadaptedSelfCheckGPTpipelinetowardsre-
ducingchancesofoverlookingpotentialtrafficagentsandthe
systematic evaluation of VLMs as captioners and checkers.
D. Structure of the Paper
We structure the paper as follows: Section II reviews
existing hallucination detection and mitigation strategies.
Section III outlines the experiment pipeline for our study.
The results and our interpretations are discussed in Section
IV and Section V, respectively. We conclude the paper in
Section VI.
II. RELATEDWORK
The adoptions and usage scenarios of SelfCheckGPT [10]
wereexploredtoidentifygapsandlimitationsintheexisting
literature. In addition to that, selected studies were reviewed
to understand their applicability in the automotive domain,
specifically targeting LLM-assisted perception systems.
Quiterecently,Sawczynetal.[11]presentedthehallucina-
tion detection technique FactSelfCheck that uses SelfCheck-
GPT as the basis. This method performs the hallucination
detection at the fact level rather than on sentence or passage
level. In this proposed technique, the facts are represented
as a knowledge graph and later on, they are analyzed to
check factual consistency. The sentence and passage level
consistencies are calculated by aggregating the fact-level
scores. According to the authors, the proposed technique
outperforms SelfCheckGPT, which was used as its founda-
tion. However, for this technique to be applicable in the
automotive context, it should be adopted to deal primarily
with image and video data, rather than only with text-based
inputs. In addition to that, adding an intermediate layer
that maps visual content into knowledge triplets (subject-
predicate-object) could add extra weight and a barrier to the
entireprocess,challengingtherequirementofprovidingreal-
time hallucination detections.
SelfCheckAgent [12] is another hallucination detection
technique that refers to SelfCheckGPT as a baseline. This
method combines multiple different agents to provide a
multidimensional approach to detect potential hallucinations
generated by LLMs. The authors have introduced three
agents: a symbolic agent that assesses the factuality of the
response,aspecializeddetectionagenttospothallucinations
by using a fine-tuned transformer-based LLM, and a contex-
tual consistency agent that exploits zero-shot and chain of
thought prompting. While the contextual consistency agent

can be adopted into the field of automotive upon addressing
the limitations related to real-time applicability when chain-
of-thought prompting is being used, the first two types of
agents show limitations that hinder their applicability within
the automotive domain. Overall, this method is limited to
text-based data and does not incorporate multimodal data.
Yang et al. [13] propose a novel hallucination detection
technique that exploits the metamorphic relations identified
in the input text passages. The authors claim that the
proposed method outperforms the SelfCheckGPT technique
upon being evaluated under the same conditions. The pro-
posed technique involves prompting an LLM to generate
subsequent responses using synonyms and antonyms to the
originalresponse.ASelfCheckGPT-basedconsistencycheck
will be carried out later to verify the factual consistency
of each response. Inaccurate responses generated with syn-
onyms and antonyms could lead to unreliable hallucination
detections, even though the technique showcased better re-
sults for certain temperature settings of the models. Since
this technique is based on antonyms and synonyms, there
is a potential risk of introducing double negation and other
semantically related issues that could potentially affect the
overall performance.
Dona et al. [7] proposed a different adaptation of Self-
CheckGPT for the automotive context. This technique ex-
plores the applicability of SelfCheckGPT for perception
related tasks when prompted on image sequences. The au-
thors recorded captions for image sequences, repeating the
processmultipletimes,andcheckedthesentencesofthefirst
caption against the rest of the captions to assess whether
each sentence is supported by the sequence of captions.
Based on a sentence-level consistency score, the authors
have implemented an exclusion mechanism to remove less
consistent sentences from a response, ie., the sentences with
lowconsistencyareconsideredaspotentialhallucinations.In
addition to that, the impact of different state-of-the-art large
language models (LLMs), datasets, and lighting conditions
have been explored, which strengthens the applicability of
SelfCheckGPTwithintheautomotivecontext.Ithasbeenob-
served that the choice of datasets made insignificant impacts
on the final results, highlighting the fact that the proposed
techniquecanbeappliedbroadly,irrespectiveofthedifferent
driving behaviors. This technique has shown potential in
being applied within the automotive context to detect and
mitigate hallucinations when LLM-assisted perception and
monitoring systems are used within vehicles.
III. METHODOLOGY
The overall experiment pipeline is depicted in Figure 1.
We selected 20 driving scenarios from a state-of-the-art
dataset (Waymo) and extracted front camera images and
the corresponding object labels. The selected images were
fed into three state-of-the-art LLMs (GPT-4o, LLaVA, and
MiniCPM-V) with a predefined prompt repeatedly to record
the responses. The collected results were processed and
statistically analyzed to answer the research questions.

=== Page 3 ===
GPT-4o
Describe the
objects.. LLaVA Captions
MiniCPM-V generated by
LLM
LLM Models
Curated Dataset
Step 2 Step 3
Object lables Correctness of Consis
extracted from sentences senten
Waymo
Fig.1:Overviewdiagramoftheexperimentalsetup:Allimage
and MiniCPM-V that we requested to describe the visible obj
the LLMs’/VLMs’ integration into a perception pipeline. The
the ground truth human annotations to analyze the three expe
A. Dataset Curation and Preparation
The Waymo Open Dataset [14] collected in the USA
is covering urban and suburban areas and was used when
conducting this research study. It was collected in 2021 by
Google, including 2030 segments that are approximately 20
secondslong.Eachvideoframecontainsdatacollectedusing
five cameras, LiDAR, and radar sensors. The dataset covers
variousdrivingscenariosunderdifferentweatherconditions,
different day and night times, and neighborhoods, including
urban and residential areas.
For our experiment, we extracted images and their object
labels by sampling every tenth frame, mainly focusing on
front-facing camera images in the training set that are of
1920x1280sizeinpixels.Wecuratedafinaldatasetusedfor
our study, including 500 images selected from 20 different
drivingscenariosdepictingdifferentneighborhoods,weather
conditions, and day/night captures. From each selected driv-
ing scenario, 25 images were manually checked to ensure
thateachselectedimagediffersfromthepreviouslyselected
images from the same scenario. This ensured to curate a
diverse dataset that depicts different conditions, providing a
broad spread in the sampled frames. Figure 2 indicates a
few sample images selected from the Waymo dataset when
curating our dataset.
B. Data Collection
As depicted in Figure 1, the curated dataset was fed into
three state-of-the-art LLMs to collect their responses: We
selected GPT-4o, a proprietary commercial model [15], and
two locally executed models, namely Large Language-and-
Vision Assistant (LLaVA) [16], and MiniCPM-V [17]. We
used the Ollama Python library [18] to access all three
LLMs. The Ollama website [18] contains all the necessary
informationregardingthetokenlimitsandthepromptlengths
each model supports.
As the first step in the experiment pipeline, we prompted
eachLLMtodescribethedifferentobjectsthatarevisiblein
each image. We designed the following prompt after several

BetterCheck
results
GPT-4o
Is S supported
Sentences in i LLaVA
by R?
all captions i MiniCPM-V
LLM Models
3
stency of
nces Ground truth collected by
the human evaluator Analysis of the collected data
esinthecurateddatasetarefedtotheLLMsGPT-4o,LLaVA,
jects in each image using simple short sentences to allow for
e collected responses are evaluated by multiple LLMs against
eriments.
iterations of modifications to retrieve short sentences that
explain only a single object at a time. We provided sample
sentences within the prompt, following formal template-
based prompting techniques to set clear expectations with
the LLMs [19]. We followed the ‘Best of Three (BO3)’
strategy [20] across all images by feeding the same image
three times to each LLM, expecting more polished and
coherent responses with less hallucinations. Each response
R was recorded and subjected to post-processing.
i
Describethedifferentobjectsvisibleintheimage.
Please write very simple and clear sentences. Use
the format: “There are [object].” For example,
“There are cars. There are people. There are
cyclists.”Lookcarefullyandmakesuretomention
all types of objects you see, especially people. If
there are multiple types of objects in the image,
provide a separate sentence for each type.
As the next step of the study, each response R was de-
i
composedintosentence-levels elements.Theindividual
1...n
sentences for all captions were evaluated one by one against
the respective image by a group of human annotators to flag
their respective correctness. Furthermore, each sentence s
i
was evaluated against the object labels extracted from the
Waymo image labels by a group of human annotators to
reporttheconsistencyofthesentences,ie.,tocheckwhether
the LLM is missing any traffic objects that are visible in the
image.Thisaspectofpotentialhallucinationsisofparticular
highest importance when considering LLMs and VLMs for
perceptiontasksasoverlookingtrafficagentsthatarepresent
in a scene can lead to disastrous consequences.
These correctness and consistency evaluation data were
stored and later used as ground truth to evaluate the per-
formance of the LLMs. Given that we involved multiple
human annotators to label correct sentences and consistent
sentences, it was crucial to use an inter-rater agreement to

=== Page 4 ===
Fig. 2: Example frames f
quantify how consistent the annotators were. Therefore, we
created a 15% overlap of captions randomly selected from
each model’s responses for the annotators and evaluated
the human annotators’ agreement using Cohen’s kappa [21]
to assess how much of the human-added annotations were
consistent among the human annotators.
Next, we applied the adapted SelfCheckGPT [7] to check
how well another LLM can check the captions to detect
hallucinations as a means to safeguard VLMs. In this step,
all sentences s that belonged to all captions R were
1...n 1...n
passed to the LLM one by one, along with each caption R
i
at a time, asking whether the sentence is supported by the
respective caption. These binary Yes or No answers were
recorded and analyzed statistically to understand how well
the models were performing.
Context:CONTEXTSentence:SENTENCEIsthe
sentencesupportedbythecontextabove?Answer
Yes or No:
In each instance, we used the same LLM, which was
used as a captioner model before, as the checker model to
assess the consistency in all instances, effectively allowing
the VLMs to “self check” their own results [7].
C. Data Analysis
The study data, including the generations by each of the
VLMs as well as the human annotations, was retrieved and
processed using the following steps:
Step 1: Image captioning. All the sampled images were
prompted three times to each of the tested VLMs, together
with the prompt described above in order to extract captions
in a specific format. Said captions were stored in files,
together with the execution time, to allow for later analysis.
Step 2: Correctness annotation. In a second step, the
humanannotatorswereiterativelyshownallsampledimages
captioned underneath with each of the sentences found
withinthecaptions.Sentenceslongerthan50characterswere
discarded,asdiscussedabove.Thehumanwasthenaskedto
decidewhetherthesentenceiseither“correct”or“incorrect”
with respect to the image.
Step 2.1: Inter-rater agreement. In this step, the results
showthattheinter-rateragreementrangesfrom50%to80%
depending on the set of captions. This is partially due to
some semantic differences between the words used by the
VLMs. For instance, a “pick up truck” could be labeled as a
vehicle, a car, or simply a “truck,” which led to differences

from the Waymo dataset.
in the judgment of the raters. We consider however that
the agreement is substantial for the traffic agent categories
present in the Waymo annotations.
Step 3: Label consistency annotation. The Waymo-
providedlabelswerecross-checkedbythehumanannotators
in this step. To do so, the humans were shown the captions,
sentencebysentence,togetherwithallthelabelscorrespond-
ing to the image that the caption was generated for. The
results were stored in order to study the confusion matrices
and look for the percentage of overlooked traffic agents in
subsequent steps.
Step 4: Self-check. All the sentences within the captions
were programmatically paired with the two other captions
for the image they were generated for in the prompt above.
Step 5: Statistical analysis. Once all the generations
and human annotations were gathered, a complex statistical
analysis was performed. All the results of this analysis are
reported in the following sections, including the percentage
of correct sentences and captions for each model, statistical
analysis for hallucinations (false positives) and overlooks
(false negatives), a frequency word analysis of the generated
sentences not concerned with the relevant traffic-agents, etc.
IV. RESULTS
A. Description of Captions (Steps 1 and 2)
The GPT4o-generated captions were accurate and precise
based on their relevance with the prompt. The captions
contained smaller sentences that explained exactly one ob-
ject. In addition to that, the captions’ length was moderate
compared to the other two models. The model did not seem
to overlook the traffic objects that were present, nor did it
mention objects that were not present in the image. This
naturesignificantlyhelpedtheanalysisandhumanannotating
tasks compared to the other models.
GPT-4o : “There are cars. There are buildings.
There are streetlights. There are power lines.
There are traffic signals. There are shops. There
are trees. There are sidewalks.”
MiniCPM-V showed exemplary capabilities of describing
images. It could identify objects, wordings, an the like,
even if they are appearing afar, making its image captioning
capabilities exceptional. However, it did not closely follow
the instructions provided in the prompt consistently. The
modeloftengeneratedlongsentencesthatdescribedacouple

=== Page 5 ===
of objects, which made it difficult to annotate the sentences
as correct or not, given that the sentences could be only
partially incorrect. For instance, a single sentence could be
explaining about a vehicle that is visible and a fire hydrant
that is not visible in the image. Also it was noted that the
responses generated by MiniCPM-V are poetic sometimes.
MiniCPM-Vdoesnotseemtomissanything,butithasmany
hallucinations.
MiniCPM-V:“There’sanSUVparkedonacurb
to our left. And another one in front of it, and
then three more further down the road. It’s all
lined up like little soldiers.”
The captions generated with LLaVA were often short
and followed the prompt accurately, generating only short
sentences that describe one object at a time. However, the
model hallucinated a lot, especially with fire hydrants and
parking meters that seemed to be everywhere. At the same
time, LLaVA also managed to miss some objects when they
were actually present in the picture.
LLaVA:“Theskyisovercast.Therearebuildings
alongthestreet.Therearecarsontheroad.There
are parking meters alongside the curb. There are
several parked cars on the side of the street.”
1) What are the captions that are not about the Waymo-
annotated traffic agents?: The Waymo dataset provided
objectlabelson Unknown,Vehicles,Pedestrians,Signs,and
Cyclists.WecomparedtheLLM-generatedsentencesagainst
the Waymo-identified object labels to evaluate what critical
traffic objects the models did overlook when describing the
images. We analyzed the remaining sentences to understand
what other objects the models were tempted to describe.
As seen in Figure 3a, GPT-4o often identified streets,
street markings, lamps, hydrants, poles, structures, build-
ings, mailboxes, patches, posts, shadows, signposts, and
streetlights. LLaVA often identified streets, buildings, signs,
constructions, parking, buses, cones, corners, and poles as
summarizedinFigure3c.MiniCPM-Voftenidentifiedroads,
clouds,specificcolors,poles,stopsigns,wires,grasspatches,
lanes,andbicycles(thoughitseldommentionedthecyclists,
as prompted) as outlined in Figure 3b.
B. Quality of the captions (steps 2 and 3)
WhenevaluatingtheLLM-generatedresponsesagainstthe
human-annotated ground truth for the correctness of each
sentence, GPT4o’s sentence-level correctness was 99.6%
whereas the caption-level correctness was 97.1%.
MiniCPM-V’s sentence-level correctness reached 94.8%
while its caption correctness remained 88% . We excluded
the sentences that exceeded the character limit of 50, con-
sidering MiniCPM-V’s tendency to generate longer sen-
tences. Only around 5% of the short sentences generated
by MiniCPM-V were incorrect.

Llava’s sentence correctness was 85.6% and caption-level
correctness was 71.9% indicating the lowest results. 28,1%
of the captions generated by Llava contained one or more
incorrect sentences.
The Figure 4 indicates these results in a bar chart.
When performance metrics were computed to statistically
evaluate the models, GPT-4o achieved 100.0% precision
(0.0% false positive rate), 78.04% recall, 87.67% F1 score,
88.2% accuracy, 100.0% specificity, and an overall MCC of
0.7885.
MiniCPM-V achieved 100.0% precision, 25.56% recall
(becauseofthe74.44%falsenegativerate),40.71%F1score,
60.0% accuracy, 100.0% specificity, and an overall MCC of
0.37.
LLaVA achieved 100.0% precision, 56.41% recall
(43.59% false negative rate), 72.13% F1 score, 76.58%
accuracy, 100.0% specificity, and an overall MCC of 0.61.
It makes sense that all models got 0 false positives, given
that the Waymo annotations are manual and well-made.
It is therefore impossible that the selected models find a
pedestrian, a vehicle, or a cyclist that the humans did not
spot.Thus,the0.0%falsepositiverateand100.0%precision.
In this application case, however, as discussed by Dona
et al. [7], the relevant metrics here are recall (to look for
overlooking traffic agents) and MCC (to judge the overall
performance of the models while compensating for class
imbalance and the high precision).
C. BetterCheck (step 4)
In [7], the authors evaluate the proposed adaptation of
SelfCheckGPT for the automotive domain across different
LLMs. We employed the same methodology under step 4
and checked the results to evaluate their performance. When
sentence-level consistency was checked by prompting each
sentenceandthecaptionstoanLLM,tocheckwhethereach
sentence is supported by each response, we could compute
the following metrics. Under this step, the same captioner
modelhasbeenusedtochecktheirownresults.Forinstance,
GPT-4o-generated captions are checked by GPT-4o itself.
GPT-4oachieved99.72%precision,91.43%recall,95.4%
f1 score, 91.21% accuracy, 40.91% specificity, 59.09% false
positive rate, 8.57% false negative rate. However, GPT-4o’s
MCC is only 0.07513.
MiniCPM-V achieved 100.0% precision, 25.56% recall
(because of a 74.44% false negative rate), 40.71% F1 score,
60.0% accuracy, 100.0% specificity. The overall MCC was
0.3702.
LLaVAachieved88.96%precision,88.81%recall,88.89%
F1score,80.64%accuracy,25.09%specificity,74.91%false
positive rate, 11.19% false negative rate. However, LLaVA’s
overall MCC was only of 0.1384.
V. ANALYSISANDDISCUSSION
In order to address RQ-1, we compared the four models’
abilitytogeneratecorrectcaptions.Thiswasdonebyanalyz-
ingthehuman-annotatedgroundtruthdataforeachsentence
in the generated captions. The results of this analysis show

=== Page 6 ===
(a)WordsinGPT-4ocaptionsthatarecor- (b) Words in MiniC
rect but do not contain references to any are correct but do no
of the Waymo-annotated traffic agents. to any of the Waym
agents.
Fig. 3: Wordclouds for the most common words in the correc
once removed the sentences mentioning the traffic agents ann
Fig. 4: Bar chart showing the correctness of the sentences
by each model (step 2).
that GPT-4o is the model with the highest proportion of
correct sentences within the captions, closely followed by
MiniCPM-V,asseeninFigure4.Moreover,acomprehensive
description of the captions by each of the models as well as
their limitations, is provided in Section IV-A.
In order to address RQ-1, we studied the word frequency
in the captions that were annotated as correct by the human
annotators but that did not mention any of the traffic agents
annotated in Waymo. The goal was to understand to what
extentarethemodelsprovidingrelevantcaptions.Theresults
in Section IV-A.1, and more specifically in Figure 3, show
that VLMs are very capable of returning context-specific
and relevant descriptions of the ego-vehicle’s environment,
though their generations might be difficult to programmati-
cally interpret.
Also addressing RQ-2, we studied the amount of halluci-
nations,definedasdetectingobjectsandtrafficagentsthatare
not in the image, that each model presented in the generated
captions.TheresultsinSectionIV-Bshowthatallmodelsare
rathersuccessfulatgeneratingimagecaptionsaboutrelevant
traffic agents and their environment (e.g., the weather and
visibilityconditions).Atthesametime,allthetestedmodels
also overlooked vulnerable road users in some occasions, as
is summarised in Figure 5.
In a second step to address RQ-2, we also compared
the generated captions to the Waymo-provided annotations
for the images for relevant traffic agents. Section IV-B

CPM-V captions that (c) Words in LLaVA captions that are
ot contain references correct but do not contain references to
mo-annotated traffic any of the Waymo-annotated agents.
ct sentences within the captions by each of the tested models,
notated within Waymo.
compares the selected models in that regard, and discusses
thetrade-offthatcanbemadebetweenappropriatestatistical
metrics depending on the application case. For instance,
recall might be the most relevant metric when it comes to
identifyingvulnerableroadagentsinfrontoftheegovehicle.
MCC however, might highlight some vulnerabilities of the
classifier, such as class imbalance.
Finally, in order to address RQ-3, we explore the correla-
tion between the human annotation on sentence correctness
and the self-check by each of the models, as described in
Section III, following the work by Manakul et al. [10] and
Dona et al. [7]. The results clearly show, in line with Dona
et al. [7], that the selected models can check their own
generations to improve the overall correctness of the image
captionsbyremovingsentencesthatarenotconsistentacross
prompt repetitions, as presented in Section IV-C, and more
specifically in Figure 6.
VI. CONCLUSIONANDFUTUREWORK
State-of-the art vision language models (VLMs) show
remarkable performance when processing multimodal data
in various application domains. In our work, we have sys-
tematically assessed the performance of 3 VLMs, GPT-4o,
LLaVA, and MiniCPM-V on a curated subset of the Waymo
Open Dataset to evaluate two crucial quality parameters:
To what extent to VLMs overlook traffic agents that are
present in a traffic scence, and to what extent are VLMs
prone to describe traffic agents that are not there in reality.
While the latter may lead to overly defensive driving of an
autonomous driving system (ADS), facing the former may
lead to disastrous decisions of an ADS in reality when not
braking the vehicle in a critical traffic situation.
We observed that even both, the proprietary LLM GPT-
4o and the open LLM MiniCPM-V show exceptional per-
formance in describing a given traffic situation at hand.
Yet, the latter model is still more prone to see more things
that are actually not present or are located somewhere else
in the analyzed image than reported in its response. Our
results show that LLMs’ and VLMs’ performance allows
their applicability for feature detection and extraction in au-
tomotivecontextscomplementingstate-of-the-artspecialized
neural networks (NNs) like Yolo, which have a very limited
vocabulary, ie., known objects that they can find in images,
compared to LLMs.

=== Page 7 ===
(a) Confusion matrix showing the hallu- (b) Confusion matrix
cinations and overlooks for GPT-4o sen- cinations and overloo
tences (against Waymo annotations). sentences (against W
Fig. 5: Confusion matrices for traffic agents in Waymo a
(a) Confusion matrix for GPT-4o sen- (b) Confusion matr
tences (against human annotations). sentences (against hu
Fig. 6: Confusion matrices for the human annotation on sen
However, we also conclude that safeguarding LLMs and
VLMs that are part of a perception pipeline in automotive
systemsisunavoidabletolowerthechancesforfacingissues
with the two, aforementioned quality parameters. We have
proposed BetterCheck as an adaption to the state-of-the-art
hallucination detection technique SelfCheckGPT, where a
combination of VLMs and LLMs are used to assess jointly
aVLM’sresponsetoanimageunderstandingprompt.While
the results are pointing into the right direction, today’s
state-of-the-art VLMs are still too resource intense, either
from a computational perspective when executed locally,
or from the network round-trip-time when accessed in a
cloud, to be considered for deployment in an ADAS or
AD. However, we expect that next generations of these
models will further address these aspects and hence, making
themapotentiallyvaluableadditiontoautomotiveperception
systems. Furthermore, better prompting techniques to tailor
an LLM’s or VLM’s output to be suitable for a perception
systemwithmultiplecomponentsareneededfindingtheright
balance of allowing these models to be as descriptive and
detailedaspossible,whileprovidingthemcertainguidingto
make them compatible for automated processing that may
require a restricted vocabulary.

x showing the hallu- (c) Confusion matrix showing the hallu-
oks for MiniCPM-V cinations and overlooks for LLaVA sen-
Waymo annotations). tences (against Waymo annotations).
annotations (human) and detected by each of the models.
rix for MiniCPM-V (c) Confusion matrix for LLaVA sen-
uman annotations). tences (against human annotations).
ntence correctness and the self-check by each of the models.
ACKNOWLEDGMENTS
This work has been supported by the Swedish Foundation
for Strategic Research (SSF), Grant Number FUS21-0004
SAICOM, Swedish Research Council (VR) under grant
agreement2023-03810,andtheWallenbergAI,Autonomous
Systems and Software Program (WASP) funded by the Knut
and Alice Wallenberg Foundation.
REFERENCES
[1] T. Brown et al., “Language Models are Few-Shot Learners,” in
Advances in Neural Information Processing Systems (H. Larochelle,
M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, eds.), vol. 33,
pp.1877–1901,CurranAssociates,Inc.,2020.
[2] M.Sallam,“ChatGPTUtilityinHealthcareEducation,Research,and
Practice:SystematicReviewonthePromisingPerspectivesandValid
Concerns,”Healthcare,vol.11,no.6,2023.
[3] M. A. M. Dona, B. Cabrero-Daniel, Y. Yu, and C. Berger, “Tapping
in a remote vehicle’s onboard llm to complement the ego vehicle’s
field-of-view,”arXivpreprintarXiv:2408.10794,2024.
[4] M. R. A. H. Rony, C. Suess, S. R. Bhat, V. Sudhi, J. Schneider,
M.Vogel,R.Teucher,K.E.Friedl,andS.Sahoo,“CarExpert:Lever-
aging Large Language Models for In-Car Conversational Question
Answering,”2023.
[5] “BMW Intelligent Personal Assistant powered by the Alexa large
languagemodel(LLM),”2024. Accessed:2024-02-26.
[6] F.Bordesetal.,“Anintroductiontovision-languagemodeling,”2024.
[7] M.A.M.Dona,B.Cabrero-Daniel,Y.Yu,andC.Berger,“Llmscan
checktheirownresultstomitigatehallucinationsintrafficunderstand-
ingtasks,”inIFIPInternationalConferenceonTestingSoftwareand
Systems,pp.114–130,Springer,2024.

=== Page 8 ===
[8] M. Azarafza, M. Nayyeri, C. Steinmetz, S. Staab, and A. Rettberg,
“Hybrid reasoning based on large language models for autonomous
cardriving,”arXivpreprintarXiv:2402.13602,2024.
[9] L.Huangetal.,“Asurveyonhallucinationinlargelanguagemodels:
Principles,taxonomy,challenges,andopenquestions,”2023.
[10] P.Manakul,A.Liusie,andM.J.Gales,“Selfcheckgpt:Zero-resource
black-boxhallucinationdetectionforgenerativelargelanguagemod-
els,”arXiv:2303.08896,2023.
[11] A.Sawczyn,J.Binkowski,D.Janiak,B.Gabrys,andT.Kajdanowicz,
“Factselfcheck:Fact-levelblack-boxhallucinationdetectionforllms,”
2025.
[12] D. Muhammed, G. Rabby, and S. Auer, “Selfcheckagent: Zero-
resourcehallucinationdetectioningenerativelargelanguagemodels,”
2025.
[13] B.Yang,M.A.A.Mamun,J.M.Zhang,andG.Uddin,“Hallucination
detectioninlargelanguagemodelswithmetamorphicrelations,”2025.
[14] P. Sun et al., “Scalability in perception for autonomous driving:
Waymo open dataset,” in Proceedings of the IEEE/CVF Conference
onComputerVisionandPatternRecognition(CVPR),June2020.
[15] OpenAI,:,A.Hurst,etal.,“Gpt-4osystemcard,”2024.
[16] H.Liu,C.Li,Q.Wu,andY.J.Lee,“Visualinstructiontuning,”2023.
[17] Y.Yaoetal.,“Minicpm-v:Agpt-4vlevelmllmonyourphone,”2024.
[18] Ollama,“Ollama,”2024. Accessed:May1,2025.
[19] S. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li,
A.Gupta,H.Han,S.Schulhoff,P.S.Dulepet,S.Vidyadhara,D.Ki,
S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D.
Costa,S.Gupta,M.L.Rogers,I.Goncearenco,G.Sarli,I.Galynker,
D.Peskoff,M.Carpuat,J.White,S.Anadkat,A.Hoyle,andP.Resnik,
“The prompt report: A systematic survey of prompt engineering
techniques,”2025.
[20] K. Ronanki, B. Cabrero-Daniel, and C. Berger, “Chatgpt as a tool
for user story quality evaluation: Trustworthy out of the box?,” in
International Conference on Agile Software Development, pp. 173–
181,Springer,2022.
[21] J.Cohen,“Acoefficientofagreementfornominalscales,”Educational
andpsychologicalmeasurement,vol.20,no.1,pp.37–46,1960.

Paper:Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance.pdf
=== Page 1 ===
Cleaning Maintenance Logs w
Predictive M
ValeriuDimidov,FaisalHawlader,S
InterdisciplinaryCentreforSecu
Universityof
29AvenueJ.F.Kennedy
firstname.last
ABSTRACT
Economic constraints, limited availability of datasets for re-
producibilityandshortagesofspecializedexpertisehavelong
been recognized as key challenges to the adoption and ad-
vancement of predictive maintenance (PdM) in the automo-
tivesector.Recentprogressinlargelanguagemodels(LLMs)
presentsanopportunitytoovercomethesebarriersandspeed
upthetransitionofPdMfromresearchtoindustrialpractice.
Under these conditions, we explore the potential of LLM-
based agents to support PdM cleaning pipelines. Specifi-
cally, we focus on maintenance logs, a critical data source
for training well-performing machine learning (ML) mod-
els, but one often affected by errors such as typos, missing
fields, near-duplicate entries, andincorrect dates. Weevalu-
ateLLMagentsoncleaningtasksinvolvingsixdistincttypes
of noise. Ourfindings show that LLMs are effective athan-
dlinggenericcleaningtasksandofferapromisingfoundation
for future industrial applications. While domain-specific er-
rors remain challenging, these results highlight the potential
forfurtherimprovementsthroughspecializedtraininganden-
hancedagenticcapabilities.
1. INTRODUCTION
Industrial data-driven PdM initiatives involving automotive
vehiclesoftenspanseveralyearsduetotherarityoffailures
and the need to accumulate extensive sensor data. In their
earlystages,suchprojectsprimarilyconsistofpassivelycol-
lectingoperationaldataandmaintenancelogs. However,the
dataacquisitionprocessistypicallyneithermonitoredbyhu-
mansnorsupportedbyautomatedmechanismstovalidatethe
correctnessofrawdata. Consequently,theresultingdatasets
arefrequentlynoisyandrequireextensivecleaningbeforebe-
ingusedindownstreamtasks.
These data quality issues are well-documented in the PdM
literature. For instance, the authors of (Prytz, Nowaczyk,
Rognvaldsson,&Byttner,2015)reportcommonproblemsin
5202
voN
7
]IA.sc[
1v11350.1152:viXra

with LLM Agents for Improved
Maintenance
SasanJafarnejadandRaphae¨lFrank
urity,ReliabilityandTrust(SnT)
Luxembourg
yL-1855,Luxembourg
tname@uni.lu
truck maintenance logs, such as missing entries, manual in-
put errors, and low fault resolution. They note that main-
tenance logs were not originally designed for data mining
purposes and argue that such limitations introduce substan-
tiallabelnoiseintopredictivemodels. Alongthesamelines,
theauthorsof(DelMoral,Nowaczyk,&Pashami,2022)em-
phasize that real-world repair logs related to hospital steril-
izers often contain uncertain dates, undocumented interven-
tions,andrecordsthatdonotreflectactualfailuresbutrather
preventive maintenance activities. In addition, in an ad hoc
study aimed at identifying key data quality pitfalls that pre-
vent Finnish multinational OEMs from providing effective
after-salesmaintenanceservices,theauthorsof(Madhikermi,
Buda,Dave,&Framling,2017)highlightthattechniciansfre-
quentlyomitcriticalfieldssuchascomponentcodes, reason
codes, and action codes. These omissions severely hinder
rootcauseanalysis,failureprediction,andthetrainingofre-
liablemodels.
Currently, data cleaning activities are carried out at the
end of the monitoring phase of a PdM project. They fol-
low an iterative error-detection and error-repair cycle, rely-
ing on pipelines implemented through scripts and software
tools. Nevertheless,theprocessremainspartlymanual,time-
consuming, and error-prone, often failing to eliminate all
sources of inconsistency. As a result, some records cannot
berepairedandarediscarded,whileothersareonlypartially
corrected,leavingresidualnoisethatultimatelydegradesthe
performanceofpredictivemodels.
This challenge motivates the exploration of novel AI-driven
approaches, suchasLLM-basedagents, toenablemoreeffi-
cientandreliabledatacurationinPdM.Inparticular, LLMs
offerthepotentialtoshiftthecleaningparadigmfrombatch-
oriented processing to stream-based, real-time correction,
allowing agents to detect and repair errors as records are
ingested. This study represents an initial step toward a
broader investigation into whether LLM-based maintenance
1

=== Page 2 ===
ANNUALCONFERENCEOFTHEPROGNOSTICS
log cleaning can outperform traditional approaches. By
benchmarking LLM agents across diverse noise types, we
aim to assess their strengths, limitations, and suitability for
industrialdeployment. Tosupportthisinvestigation,ourcon-
tributionsarefourfold:
1. Defineataxonomyofcommonnoisepatternsspecificto
automotivePdMdata.
2. Propose an open source framework for generating syn-
theticlogswithcontrollednoise. Theframework,named
AgenticPdmDataCleaner,ispubliclyavailable1.
3. BenchmarkmultipleLLMsoncleaningtasks.
4. Analyzeerrortypesandlimitations,providingguidance
foradaptingLLMagentstoindustrialPdMsettings.
The remainder of this manuscript is structured as follows.
Section 2 reviews related work on data cleaning techniques,
ranging from classical rule-based and probabilistic ap-
proaches to recent LLM-driven frameworks. Section 3
presents our framework for synthetic fleet data generation,
including the system model, data sources, and controlled
noiseinjectionmechanismsdesignedtoreproducereal-world
inconsistencies in maintenance logs. Section 4 introduces
ourmethodology,detailingtheLLM-basedagentframework,
task definitions, and evaluation setup. Section 5 provides
information about the benchmarking configuration and the
metrics used to evaluate the experiments. Section 6 reports
the benchmarking results, while Section 7 discusses the
scientific and industrial implications of our findings, em-
phasizing both the strengths and limitations of the proposed
approach. Finally,Section8concludesthepaperandoutlines
directionsforfutureresearch.
2. RELATEDWORK
Classical data cleaning approaches rely on rule-based vali-
dation,statisticalprofiling,andintegrityconstraintstodetect
andcorrectinconsistencies(Fan&Geerts,2012;Ilyas&Chu,
2015). Toovercometheirlimitations,(Chuetal.,2015)pro-
posedKataraasasystemthatleveragesknowledgebasesand
crowdsourcing. The system maps table semantics to exter-
nal knowledge, validates uncertain cases with human input,
andsuggeststop-krepairsforerroneoustuples,therebycom-
bining automated reasoning with selective crowd involve-
ment. HoloClean extends this line of research by introduc-
ing a probabilistic inference framework that unifies signals
from integrity constraints, external data, and statistical co-
occurrencepatternstoperformholisticdatarepairing,signifi-
cantlyimprovingrepairqualitycomparedtoisolatedmethods
(Rekatsinas,Chu,Ilyas,&Re´,2017).
Subsequent works, increasingly based on ML, divided the
data cleaning task into error detection and error correc-
tion. HoloDetectaddressesdetectionbyframingitasafew-
1https://github.com/sntubix/agentic-pdm-log-cleaning

SANDHEALTHMANAGEMENTSOCIETY2025
shot learning problem (Heidari, McGrath, Ilyas, & Rekatsi-
nas, 2019), while Raha automates the configuration of mul-
tiple detection strategies to minimize manual intervention
(Mahdavi et al., 2019). For correction, Baran provides a
unified framework that ensembles candidate repairs through
semi-supervised and transfer learning (Mahdavi & Abedjan,
2020).
More recently, large language models have been explored
as general-purpose engines for structured data curation.
(Narayan, Chami, Orr,&Re´, 2022)demonstratedthatfoun-
dation models like GPT-3 can be adapted to entity match-
ing, error detection, schema matching, and imputation via
prompting, achieving competitive performance with mini-
mal supervision. (Zhang, Dong, Xiao, & Oyamada, 2024)
extended this view by benchmarking GPT-3.5, GPT-4, and
GPT-4oasdatapreprocessorsacrossmultipletasks,showing
that LLMs can rival specialized baselines when guided by
prompt engineering techniques such as zero/few-shot con-
ditioning, contextualization, and batch prompting. Beyond
staticprompting,(Bendinelli,Dox,&Holz,2025)introduced
a benchmark where LLM agents iteratively clean intention-
ally corrupted datasets through tool calls and performance
feedback, correcting simple row-level anomalies but strug-
glingwithdistributionalshiftsandcontextualerrors. Finally,
(Qi, Miao, & Wang, 2025) proposed CleanAgent, which
integrates declarative APIs with LLM-based agents to au-
tomate data standardization tasks such as date and address
formatting.
Despitetheseadvances,thepotentialofLLM-basedagentsto
curatedomain-specificPdMlogsremainslargelyunexplored,
leavinganopenquestionabouttheirapplicabilitytoindustrial
environments.
3. FRAMEWORK FOR SYNTHETIC FLEET DATA GEN-
ERATIONWITHNOISEINJECTION
Intheautomotivesector,thereleaseofproductiondataisrare.
This is primarily due to privacy concerns and the reluctance
ofOEMsandworkshopstodisclosedetailsaboutequipment
reliabilityorinternalprocesses.Toaddressthislimitation,we
developedasyntheticdatagenerationframeworkthatserves
asaproxyforthereal-worldscenariosweaimtoinvestigate.
Thelogschemausedinourframeworkisasimplifiedadap-
tationoftheontologyproposedby(Woods,Selway,Bikaun,
Stumptner,&Hodkiewicz,2024).Nevertheless,forthescope
ofthisstudy,thegeneratedlogsaresufficient.
Theframeworksupportsthegenerationofsyntheticfleetdata
in both tabular and time-series formats. It includes mech-
anisms for controlled noise injection into tabular data, en-
abling systematic evaluation of an agent’s ability to detect
and repair inconsistencies when correlating multiple tables
orlinkingtabularrecordswithtime-seriessignals. Inthecur-
rentimplementation,thefleetregistryandtime-seriesdataare
2

=== Page 3 ===
ANNUALCONFERENCEOFTHEPROGNOSTICS
Sensor Data Stream
[odometer, speed, rpm,...,temp]
... ...
(a)
Telematics
Automobiles
Devices
Fleet
Faulty (b)
Vehicle
Healthy
Vehicle (e)
Figure1.FleetMonitoring,Repair,
generatedwithoutnoiseandserveascleanreferencesignals.
Thesecanbeleveragedbyagentstoinferorcorrectcorrupted
entriesinthemaintenancelogs.
A synthetic data generator provides several benefits. It en-
ablesthecreationofdiversedatasetsforstudyingthestatisti-
calsignificanceofproposedmethodologiesandcanbesafely
ingestedbyLLMswithoutraisingprivacyconcerns. Further-
more,giventhatLLMstendtomemorizebenchmarkdatasets,
synthetic generators provide a means to overcome this issue
byallowingbenchmarkingondatasetswithsimilarstatistical
distributionsbutnovelinstances.
3.1. SystemModel
The overall architecture of the fleet monitoring and main-
tenance logging process is depicted in Figure 1. The fleet
F ={v ,v ,...,v }consistsofN vehicles,eachequipped
1 2 N
with telematics devices that stream telemetry to a central
monitoring platform P. When a failure is detected, the af-
fectedvehicleissenttoaworkshopW forrepair,wheretech-
niciansconsulttheplatformP toretrievediagnosticdataand
vehicleinformation. Oncetheinterventioniscompleted,the
maintenance activity isrecorded in the maintenance logM,
which contains both administrative details—such as identi-
fiers,dates,andvehiclereferences—andtechnicaldetailsde-
scribingtheaffectedsystem,subsystem,andcomponent,the
activity performed, and additional contextual metadata. A
completeschemaofMisprovidedinSection3.2.4.
ModelingAssumptions
Toisolatetheimpactofdataqualityissuesinthemaintenance
logs,weassumethefollowingsimplifications:
A1 FleetHomogeneity—allvehiclessharethesamemake,
model,andcomponentspecifications.

SANDHEALTHMANAGEMENTSOCIETY2025
Monitoring
Platform
Vehicle / Sensors
(c)
Information Retreival
(d)
[maintenance record]
Maintenance Log
Workshop
andMaintenanceLoggingProcess.
A2 Fleet Staticity — no vehicles are added to or removed
fromthefleetduringthemonitoringperiod.
A3 Uniform Operational Profile — all vehicles are as-
sumedtooperateunderthesameusagepatternsandduty
cycles.
A4 SingleMaintenanceEventConstraint—eachvehicle
experiencesatmostonemaintenanceevent.
A5 Centralized Maintenance Facility — all repairs are
performedatasinglefacilityusingastandardizedmain-
tenancelogschema.
A6 Corrective Repairs — all the maintenance records are
relatedtocorrectivemaintenanceactivities
Although these assumptions simplify the naturally diverse
andevolvingcharacteristicsofreal-worldfleetmanagement,
andbyextension,thepreprocessingofmaintenancerecords,
they enable the construction of a controlled benchmarking
dataset. Future developments will aim to relax these con-
straintstobetterreflectreal-worldconditions.
3.2. DataSources
The process described in the previous section gives rise to
four data sources that capture different aspects of the fleet
monitoring and maintenance workflow: Fleet Registry, Sen-
sorData,ServiceOperationsCatalog,andMaintenanceLog.
Together,theyprovidethefoundationforvalidating,cleaning
andtransformingmaintenancerecords.
3.2.1. FleetRegistry
ThefleetregistryF storesthemasterrecordsofallvehicles
in the monitored fleet. Each entry corresponds to a unique
deviceinstalledonavehicleandincludeskeyidentifierssuch
asthedevice id,name,license plate,andVIN.
3

=== Page 4 ===
ANNUALCONFERENCEOFTHEPROGNOSTICS
(a)Fleet
deviceid name licenseplate VIN
0 b754A (b754A) AH4657 KT6HA8
1 b242F (b242F) CT9935 0T1UNZ
2 b189E (b189E) KA4582 RKR3PC
3 b338E (b338E) PO9928 N6NGFA
(b)SensorTable
deviceid date odometer kmtraveled
0 b338E 2022-06-14 358156 196
1 b338E 2022-06-15 358257 100
2 b338E 2022-06-16 358257 0
3 b338E 2022-06-17 358257 0
4 b338E 2022-06-18 358257 0
5 b338E 2022-06-19 358257 0
6 b338E 2022-06-20 358257 0
7 b338E 2022-06-21 358365 108
8 b338E 2022-06-22 358556 190
(d)Mainte
wonum startdate enddate licenseplate system subsyste
WO129 2021-05-03 2021-05-07 AH4657 Powertrain Engine
WO827 2021-01-02 2021-01-06 CT9935 BrakeSystem Hydrauli
WO329 2021-08-31 2021-09-04 KA4582 HVAC AirCond
WO679 2022-06-16 2022-06-21 PO9928 Steering Rackand
Figure2.Cleandataexcerpts:(a)FleetRegistry,(b)SensorT
(a)Mainte
wonum startdate enddate licenseplate system subsystem
WO129 2021-05-03 2021-05-07 (b754A) Powertrain Engine
WO827 2021-01-02 2021-01-06 CT9935 BrakeSysem Hydraulic
WO329 2021-08-31 2021-09-04 KA4582 HVAC AirCondi
WO679 2022-06-16 2022-06-21 PO9928 Steering Rackand
WO333 2022-06-16 2022-06-21 TEST - -
WO429 2021-08-31 2021-09-04 WI0000 HVAC Cooling
Figure3.NoisyM
Thisregistryservesasareferenceforlinkingvehicleidenti-
fiersacrosssensordata,maintenancelogs,andotherdatasets.
3.2.2. SensorData
ThesensordatasetScontainstime-stampedoperationalmea-
surements collected from onboard devices. In the cur-
rent implementation, it includes a single signal, namely the
odometer km reading for each vehicle, indexed by the
unique device id and a date field. The odometer km
values represent the cumulative distance traveled by the ve-
hicleatthegivendate,providingamonotonicallyincreasing
metric of vehicle usage. The linkage of device id to the
fleet registry ensures consistent association between sensor
readingsandthecorrespondingvehiclemetadata.
3.2.3. ServiceOperationsCatalog
Eachinterventionperformedduringaworkshopvisitcanbe
mapped to a predefined taxonomy, referred to as the service
operations catalog. In our service operations catalog, each
workshopinterventionisorganizedalongathree-tierhierar-
chy. At the top level is the system, a broad functional do-
mainofthevehiclesuchasPowertrain,Chassis,orElectrical.

SANDHEALTHMANAGEMENTSOCIETY2025
Registry
8KW6LWZD5747
ZHC09032KBLY
C0K6HVW3ZSWA
AHS53H7R4C44
(c)ServiceOperationsCatalog
System Subsystem Component Activity
0 Powertrain Engine CylinderHead Repair
1 BrakeSystem HydraulicBrake BrakePads Replace
2 HVAC Air Compressor Repair
Conditioning
3 Steering RackandPinion SteeringRack Replace
4 HVAC Cooling CoolantPump Replace
enanceLog
em component activity workdescription
CylinderHead Repair Repairedcylinderhead.
icBrake BrakePads Replace Replacedbrakepads.
ditioning Compressor Repair Repairedairconditioningcompressor.
dPinion SteeringRack Replace Replacedsteeringrack.
Table,(c)ServiceOperationsCatalog,(d)MaintenanceLog.
enanceLog
m component activity workdescription label
CylinderHead Repair Repairedcylinderhead. M1
cBrake BrakePads Replace Replacedbrakepads. M3
itioning Repair Repairedairconditioning.... M4
Pinion SteeringRack Replace Replacedsteeringrack. M6
- Test TestingtheITsystem. M5
CoolantPump Replace Replacedworn-out... M2
MaintenanceLog.
Within each system, we distinguish subsystems that narrow
thefocusofthetask(e.g.,theEngineorTransmissionwithin
the Powertrain system). Finally, the most specific category
is the component, which identifies the exact part addressed
during the intervention. Beyond this hierarchical classifica-
tion, every record also specifies the type of activity, such as
replacementorrepair.
Theserviceoperationscatalogusedinthisworkspans10sys-
tems,26subsystems,and34componentsacross142entries.
Unliketheotherdatasources,itisstaticandwasconstructed
manually.
3.2.4. MaintenanceLog
The maintenance log M contains structured fields that cap-
ture the administrative and technical aspects of a mainte-
nance intervention. Administrative fields include identi-
fiers such as the work order number (wo num) as well as
temporal information (start date, end date) and the
license plateusedtolinktheinterventiontoaspecific
vehicle. Technical fields specify the scope of the interven-
tion,fromthehigh-levelsystemdowntothesubsystem
and individual component, along with the performed
4

=== Page 5 ===
ANNUALCONFERENCEOFTHEPROGNOSTICS
activity and its textual work description. Addi-
tional metadata provide contextual information for subse-
quent analyses: work order type indicates whether the
interventionwascorrective,preventive,orpredictive.
3.3. NoiseInjectionFramework
To realistically evaluate the ability of LLM-based agents
to clean maintenance records, we introduce a noise injec-
tion framework that systematically corrupts otherwise clean
synthetic logs. This framework is grounded in a taxon-
omyofcommonerrorsobservedinindustrialdatasets—such
as identifier misalignments, missing values, and incorrect
dates—andprovidesmechanismstoreproducetheminacon-
trolledmanner.Bygeneratingpairedcleanandnoisydatasets
withconfigurableproportionsofeachnoisetype, theframe-
work enables reproducible benchmarking and fine-grained
analysis of model performance under diverse data quality
challenges.
3.3.1. NoiseTaxonomy
In real-world PdM deployments, maintenance logs rarely
conformperfectlytotheirintendedschema. Noisecanarise
fromhumanerror,inconsistentdataentrypractices,orincom-
pleteintegrationbetweenworkshopandfleetmonitoringsys-
tems. For the purposes of our study, we denote the absence
ofnoiseasM0andintroducesixadditionalnoisetypes:
M1 Vehicle identifier misalignment – The default vehi-
cle identifier field license plate is replaced with
device id, name, or VIN, breaking the linkage be-
tween maintenance records and the fleet registry. As
shown in Figure 3a, record WO129 has (b754A) as
license plate,whichisadevicenameinFigure2a.
M2 Out-of-fleet vehicles – Records reference valid plates
belonging to vehicles outside the monitored fleet
F, introducing exogenous observations. For ex-
ample, Figure 3a, record WO429 lists WI0000 as
license plate,whichisabsentfromtheFleetReg-
istry(Figure2a).
M3 Invalid values – Categorical fields (system,
subsystem, component, activity) contain to-
kens outside the controlled vocabulary (typos or non-
standard labels). For instance, in Figure 3a the record
WO827hasatypointhefieldsystem.
M4 Missing values – One categorical field is left empty,
yielding structurally missing information. In Figure 3a,
recordWO329containsanemptycomponentfield.
M5 Digitalsystemtest–Entriesdocumentinstallation,cal-
ibration, ortestingofthemonitoringsystemratherthan
vehicle maintenance interventions and should be segre-
gated. ConsideringFigure3a,therecordWO333hasnu-
merousfieldslabeledasTEST.

SANDHEALTHMANAGEMENTSOCIETY2025
M6 Wrong end dates – The end date is inconsistent
with the intervention timeline inferred from oper-
ational signals. Specifically, record WO679 reports
end date=2022-06-21,whichconflictswiththeusage
patternforb338EinFigure2b.
These categories represent the primary types of noise ob-
served in a real-world log and fleet environment provided
byGrupo<A>2,aColombianmultinationaloperatingacross
various industrial sectors including automotive equipment
manufacturing, machinery, and mining. The dataset was
collected between 2021 and 2024. It includes structured
fields such as vehicle plate number, work order ID, compo-
nent name, action code, mechanic information, timestamps,
odometerreadings,costofmaintenance,andsystem/subsys-
temclassification.Thisrichschemaenabledtheidentification
andcategorizationofreal-worldnoisepatternsinfleetmain-
tenance logs and was instrumental in the development and
validationoftheproposedmethods.
3.3.2. NoiseInjectionMechanisms
Definitions
• N: Totalnumberofentriestogenerate.
• T ={t ,t ,...,t }: Setofnoisetypes
1 2 K
• π = (π ,π ,...,π ): Proportions of each noise type,
1 2 K
with
(cid:80)K
π =1.
k=1 k
• D ⊂D:Subsetofentriesoftypet ,with|D |=π N.
k k k k
Eachnoisetypet ∈ T isassociatedwithanoisegenerator
k
S ,whichdefineshowcorruptedorcleanentriesarecreated.
k
Regardless of the noise category, each generator yields two
aligneddatasets:thecleanrecordsEandthenoisyrecordsE′.
The framework is designed to be fully configurable, allow-
ing the user to adjust the proportions π of each noise type
k
to match specific experimental setups. Moreover, the noise
taxonomy is extensible: new noise types can be seamlessly
incorporated by defining additional generators and integrat-
ingthemintoT. Thisdesignenablesthecreationofdiverse
andrealisticnoisepatterns,supportingbothcontrolledexper-
imentsandexploratoryevaluations.
• AbsenceofNoise
S :E →E
k
Thisgeneratorreturnstheinputentryunaltered.Itisused
to generate noise-free records and corresponds to t =
k
t ,thespecialcaserepresentingabsenceofnoise.
0
• CorruptiveNoise
S :E →E′
k
2https://www.grupoa.co/
5

=== Page 6 ===
ANNUALCONFERENCEOFTHEPROGNOSTICS
The generator receives a clean entry E and applies a
transformationtoproduceacorruptedversionE′.
• GenerativeNoise
S :∅→E′
k
Thegeneratordoesnotrelyonanexistingcleanentrybut
generatescorruptedentriesfromscratch.
Table1.Classificationofnoisetypes
ID Name NoiseType
M1 VehicleIdmisalignment Corruptive
M2 Out-of-fleetvehicles Generative
M3 Invalidvalues Corruptive
M4 Missingvalues Corruptive
M5 Digitalsystemtest Generative
M6 Wrongenddates Corruptive
Table 1mapseachimplementednoisetypetothecorrespond-
ingclassinournoisetaxonomy.
3.3.3. FleetDataGeneration
The fleet data generation process follows a two-step ap-
proach. First, we create a clean dataset that integrates in-
formation from the fleet registry, service operations catalog,
andsensorsignalstoproduceconsistentmaintenancerecords.
This clean version serves as the ground truth. In the second
step, we regenerate the maintenance log by injecting con-
trollednoiseaccordingtopredefinedcategories,whilekeep-
ing the other data sources unchanged. The result is a pair
ofaligneddatasets—cleanandnoisy—thatenablesystematic
benchmarkingofLLM-basedagentsunderrealisticdataqual-
itychallenges.
CleanDataSources
The process of clean fleet data generation depends on three
key parameters: the time interval during which the fleet is
monitored,thecountryofregistration,andastaticserviceop-
erationscatalog.
The generation begins with the creation of the device table,
whichlistsallvehiclesinthesimulatedfleet. Foreachvehi-
cle, a unique internal identifier is assigned, following a pre-
definedpattern(e.g.,b742C),alongwithalicenseplategen-
erated according to the country of registration format. Each
entry also includes a globally unique vehicle identification
number (VIN) and a display name, which by default is the
device id enclosed in parentheses. The number of entries in
this table is determined by the expected number of mainte-
nancerecords,asdefinedinAssumptionA1.
Once the fleet registry is established, the maintenance table
isgenerated. Currently,allnoisegeneratorsintheframework
inherit from a common noise-free schema E, which defines
thestructureandcontentofcleanmaintenancerecords. Un-

SANDHEALTHMANAGEMENTSOCIETY2025
der this schema, each vehicle is associated with an activity
randomlydrawnfromtheserviceoperationsoftheworkshop.
Thestartdateofeachrecordisselecteduniformlyatrandom
withinthemonitoringperiod,andtheenddateissetbetween
fourandsevendayslater.Thetextualwork description
is produced by a large language model instructed to in-
clude both the component and activity terms in a concise,
technician-stylenote.
The final stage involves producing the sensor time-series,
which records daily odometer readings for each vehicle
acrossthemonitoringwindow. Thesimulationbeginsbyas-
signing an initial odometer value uniformly at random be-
tween 0 and 300,000 km. Each subsequent day, the trav-
eleddistanceisdrawnfromanormaldistributionwithmean
µ=200kmandstandarddeviationσ =20km.Maintenance
periodsinfluencethesignal: nodistanceisrecordedfordays
entirelywithinamaintenanceinterval,whilethefirstandlast
daysofsuchintervalscontributehalfofthesampleddistance.
At the end of the clean data generation process, we obtain
the tuple ⟨F,S,W,M⟩, where F denotes the fleet registry,
S thesensortime-series,W theworkshopmetadata,andM
themaintenancelog.ThecleanmaintenancelogMservesas
thegroundtruthforalldownstreamevaluationtasks.
NoisyDataSources
Inthenoisegenerationstep, themaintenancetableMisre-
generatedwhilepreservingtheotherdatasources.Eachnoise
generatorisinvokedinthesamesequenceasinthecleangen-
erationprocess.
Corruptivenoises(M1,M3,M4,M6)operatebycopyingthe
cleanrecordsE andmodifyingselectedfields, whereasgen-
erativenoises(M2,M5)createentirelynewrecordsE′ with-
out referencing the clean dataset. Specifically, M1 replaces
the license plate field with another vehicle identifier
(e.g.,device table,VIN);M3invalidatesservicecatalog
fields (system, subsystem, component, activity)
through fixed invalid labels, typos, field swaps, or mis-
matchedhierarchysubstitutions; M4clearsoneormorecat-
egoricalfields;M6shiftstheend datefieldforward,inor-
dertocreateaninconsistencywiththeinterventiontimeline.
On the generative side, M2 produces valid-looking mainte-
nance entries linked to license plates absent from the mon-
itored fleet, and M5 synthesizes maintenance records docu-
mentingtestingofthefleetmonitoringsystem.
Thenoisy-datagenerationyieldsthetuple
⟨F,S,W,M′⟩,
whereM′isthenoisyversionofthemaintenancelog,replac-
ingthecleanMfromthenoise-freedataset. Additionally,it
includes, for each record, a label indicating the applied per-
6

=== Page 7 ===
ANNUALCONFERENCEOFTHEPROGNOSTICS
Data
Sources
(2) <tools> Log Cleaning API
accept
reject
(1) (3)
update
LLM-based Agent
Figure4. AgentenvironmentwithdatasourcesandLogCleaningAPI.(1)
Anoisyrecordm′ isprovidedtotheLLM-basedagent;(2)theagentop-
k
tionallyqueriesenterprisedatasourcesthroughdatabasetools;(3)theagent
issuesastructuredactiontotheLogCleaningAPI:accept,reject,orupdate.
turbationoperator(i.e.,thespecificnoisetype)ormarkingit
asnoise-freewhennocorruptionispresent.
4. METHODOLOGY
4.1. LLM-empoweredlogcleaning
We propose to replace the traditional batch oriented log
cleaning process with an LLM empowered stream process-
ing pipeline. The key changes lie in two aspects. First, we
transitionfromofflinebatchprocessing,wherelogentriesare
accumulatedandcleanedretrospectively,torealtimestream
processing, which enables immediate detection and correc-
tion of anomalies as records are ingested. Second, we aug-
mentthestreamprocessingpipelinewithanovelLLM-based
component. Thiscomponentactsasanintelligentagentthat
notonlydetectsnoisyorincompletelogentriesbutalsoper-
formscontextualrepairs.
4.2. AgentEnvironment
To evaluate the ability of LLM-based agents to detect and
clean noisy maintenance logs, we design a digital environ-
ment that exposes two interfaces to the agent: (i) read-only
tools over the enterprise data sources (Section 3.2) and (ii)
adedicatedLogCleaningAPI.Theformerisinstantiatedon
topofarelationalDBwhilethelatterisimplementedasaset
ofagenticoutputfunctions.
Table2summarizestheDBtoolsusedinourstudy.Theagent
isequippedwithcapabilitiestolisttheavailabledatabaseta-
bles,inspecttheirschema,andquerythedatatheycontain.In
practice,theassumptionthatallrelevantinformationresides
within a single data source does not always hold. However,
in our experimental setup, the focus is not on evaluating the
agent’sabilitytooperateacrossheterogeneousplatforms,but
rather on assessing its capacity to successfully complete the
curationtasks.
TheLogCleaningAPIisspecifiedinTable3. ThisAPIen-

SANDHEALTHMANAGEMENTSOCIETY2025
ables the agent to select exactly one of three actions on a
record based on its work order number field: accept, reject,
orupdate.
Table2.Databasetoolsavailabletotheagent.
Tool Signature PurposeandReturn
listtables () Enumeratesavailabletables
sotheagentcandiscoverthe
databasesurfacebefore
issuingqueries.
describetable (tablename) Providesschema
introspectionforagiventable
(columnsanddatatypes).
runsql (query, limit) ExecutesaSQLSELECT
querywitharowcap
(limit)toavoidlarge
responses.
Table3.LogCleaningAPImethodsavailabletotheagent.
Method Signature Purpose
accept (wonum) Confirmstherecordasclean.
reject (wonum) Markstherecordas
out-of-scopeorirreparable.
update (wonum, field, value) Appliesasinglefield-level
correctiontotherecord
beforeacceptingit.
4.3. Task
The core task is formulated as a three-class classification
problem over individual maintenance log entries. Given a
noisyrecordm’,theLLM-basedagentmustselectoneofthe
followingmutuallyexclusiveactions:
1. accept-therecordiscleanandrequiresnomodification.
2. reject-therecordisirreparableorout-of-scope
3. update - the record contains correctable noise, and the
agentmustapplyasingle-fieldcorrection.
Weobservethatnoise-freerecordsmustalwaysbeaccepted,
records affected by generative noise must be rejected, and
recordsaffectedbycorruptivenoisemustbeupdated.
Figure4illustratestheexpectedend-to-endworkflow. (1)A
raw record m′ is passed to the LLM-based agent. (2) The
k
agent orchestrates a short sequence of tool calls. (3) Based
onthegatheredevidence,theagentmustchooseexactlyone
actionandsubmitittotheLogCleaningAPI.
The outputs of the experiments fall into four categories. In
addition to the three valid actions, the task may fail due to
theagent’sinabilitytocorrectlyinvoketheavailabletoolsor
outputfunctions. Thesefailurecasesareexplicitlytrackedto
assesstherobustnessofeachmodel.
Akeyconstraintinthisstudyisthatnoexamplesmustbepro-
videdintheprompt. Theagentisguidedsolelybyasystem
prompt and task instructions, which define its role as a data
curator,listtheavailabledatabasetools,andspecifytheper-
mittedAPIactions. Thisdesignchoiceensuresthattheagent
must generalize to unseen noise patterns. This constraint
7

=== Page 8 ===
ANNUALCONFERENCEOFTHEPROGNOSTICS
Table4.Selectedlargelanguagemodelsforbenchmarking:contextandprice
(per1Mtokens).
Model Prov. Ctx(k) Costin/out
nemotron-nano-9b-v2 NVIDIA 131 $0.04/$0.16
gpt-oss-20b OpenAI 131 $0.04/$0.15
gpt-oss-120b OpenAI 131 $0.072/$0.28
qwen3-next-80b-a3b-instr. Qwen 262 $0.098/$0.391
kimi-k2-0905 MoonshotAI 262 $0.38/$1.522
gpt-5 OpenAI 400 $1.25/$10.00
reflects real-world PdM scenarios, where corrupted records
mayarriveinisolation,noisepatternsmayevolveovertime,
andpriorexamplesmaynotbeavailableorrepresentative.As
such, the agent must rely on schema understanding, contex-
tual reasoning, and external data sources to make informed
decisions.
This setup allows us to assess the agent’s robustness and
adaptabilityinrealistic,zero-shotconditions.
4.4. ExperimentalProtocol
ThisresearchaimstoevaluatethecapabilityofLLMstoclean
noisymaintenancerecords. Theevaluationisstructuredinto
three main steps: environment generation, prompt engineer-
ing,andper-modelevaluation.
Environment Generation Given a fleet size N and a set
of per-noise proportions π , we instantiate R + 1 environ-
k
ments as described in Section 3.3.3, using distinct random
seedstoensurestatisticalindependence.Eachenvironmentis
associatedwithaparametersetθ, sampledrandomlyfroma
predefinedsearchspaceΘ.
PromptEngineering Weselectanenvironmentandalarge
language model (outside the evaluation set LLM) and fine-
tune a prompt p. The output of this step is a parametric
prompt template T, which adapts to each individual record
m.
Per-Model Evaluation For each llm ∈ LLM and each
environment–parameterpair(ϵ,θ),weperformthefollowing
steps:
1) Tabular Serialization. Flatten the noisy maintenance
log of environment ϵ into an iterable collection M =
ser
m(i), where each record is represented as a set of
field–valuepairs.
2) Record Processing. For each record m in the serial-
ized maintenance log M , we construct a task-specific
ser
prompt p tailored to the record’s content. This prompt
is then submitted to the selected language model, along
withtheenvironment-specificparametersθ, resultingin
an action a. The action is propagated to the original

SANDHEALTHMANAGEMENTSOCIETY2025
record to produce a cleaned version mˆ. Each cleaned
record is then added to the cumulative set of processed
records,denotedbyMˆ.
Finally, we compute evaluation metrics by comparing the
cleaned records Mˆ against the reference targets of environ-
mentenv. Thesemetricsarethenaggregatedacrossallenvi-
ronmentstoproduceaglobalperformancesummaryforeach
model. Moredetailsaboutthemetricswillbeprovidedinthe
followingsections.
Input: LLM,N,{π },Θ,R
k
ENV←{};
forr ←1toR+1do
env ←GenerateFleetEnv(N,{π });
k
θ ←SelectParameters(Θ);
ENV.append(env,θ);
end
t←BuildPromptTemplate(ENV.pop())
foreachllm∈LLM do
foreach(env,θ)∈ENV do
M′ ←TabularDataSerialization(env.M’);
ser
Mˆ ←{};
foreachm′ ∈M′ do
ser
p←BuildPrompt(t,m′);
a←CallLLM(p,llm,θ);
mˆ ←ApplyAction(m′,a);
Mˆ ←Mˆ ∪mˆ.
end
end
end
Algorithm1:ExperimentDesign
4.5. LLMs
WeevaluatesixproductionLLMs, groupedbycapacityinto
small(Nemotron-Nano-9B-v2),medium(Gpt-Oss-20B),and
large(Qwen3-Next-80B-A3B-Instruct,Gpt-Oss-120B,Kimi-
K2-0905, and Gpt-5). These models have been chosen for
their agentic capabilities (tool/function calling and schema-
constrained outputs), long context windows, and diverse
providerecosystems.
NVIDIA’s Nemotron is a 9B-parameter hybrid model that
combines Mamba-2/MLP layers with a small number of
attention blocks, targeting long-context reasoning at mod-
est compute. OpenAI’s open-weight Gpt-Oss models use
Mixture-of-Experts architecture (MoE). Gpt-oss-20b acti-
vates 3.6Bparameterspertoken,whilethe120Bmodelacti-
vates 5.1B.Qwen3-Next-80B-A3B-Instructadoptsahybrid
MoElayout,with80Btotalparametersand 3Bactivatedper
tokenforefficiencyat256kcontext. Kimi-K2-0905extends
theboundariesofsparsescaling,reporting∼1Ttotalparam-
eterswith∼32Bactivepertokenandsupportfor256k-token
contexts. Finally, Gpt-5 serves as a production baseline at
the top end of quality. OpenAI does not disclose parameter
8

=== Page 9 ===
ANNUALCONFERENCEOFTHEPROGNOSTICS
Table5.ErrorDetectionRate(EDR)andError
Noise nemotron gpt-oss-20b kim
EDR ECR EDR ECR EDR
noisefree 96.7% – 92.7% – 98.7%
vehicleidmis. 0.0% 0.0% 6.7% 4.0% 6.0%
out-of-fleetveh. 100.0% – 98.0% – 96.0%
invalidvalue 24.7% 21.3% 72.7% 70.7% 82.0%
missingvalue 7.3% 0.7% 95.3% 92.0% 81.3%
digitalsystemtest 98.7% – 97.3% – 95.3%
wrongenddate 0.7% 0.0% 0.7% 0.0% 0.0%
Table6.LLMusagemetrics
Model Requesttokens Response
nemotron 716250±14379 393667
gpt-oss-20b 1160641±50397 229529±
kimi-k2 1921833±148116 48136
qwen3 4944233±305278 119794±
gpt-oss-120b 1855565±48748 169320
gpt-5 1043889±30472 455698±
countsorinternalsparsity,sowetreatitasablack-boxdense
systemandrelyonthepublicinterfaceforcomparability.
Table4reportsthecontextwindowsizesandtoken-levelpric-
ingforeachlargelanguagemodelselectedforbenchmarking.
These cost estimates are sourced from OpenRouter3, which
provides unified access to a diverse set of commercial and
open-weight models through a standardized API. All prices
are reported per 1 million tokens, separated into input and
outputrates,andreflectpublicpricingtiersatthetimeofeval-
uation.
5. PROMPTING, BENCHMARK CONFIGURATION AND
METRICS
Prompting All experiments in this study were performed
using zero-shot prompting. The prompt template was man-
ually crafted and evaluated using Gpt-5 Mini. The system
prompt, user prompt template, and instruction set are pro-
videdintheAppendix(seeAppendixFigs.5–7).
DatasetConfiguration Forallexperiments,wefixthefleet
size to N = 210 vehicles and generate a total of 210 main-
tenance records per environment. The noise distribution is
uniformacrossallcategories,with30recordsforeachofthe
sixnoisetypes(M toM )and30noise-freerecords(M ).
1 6 0
Despite the fact that real-world maintenance logs exhibit
highly skewed noise distributions (e.g., test records occur
sporadically, while typos are more frequent), this balanced
setupfacilitatesper-noise-typeanalysis.
We generate R = 31 independent environments using dis-
tinctrandomseedstoensurestatisticalrobustness. Eachen-
vironmentisassociatedwithapairofLLM-specificdecoding
parameters,randomlysampledfromthespace:
Θ={temperature∈(0,0.2), top p∈(0.7,1.0)}
3https://openrouter.ai/

SANDHEALTHMANAGEMENTSOCIETY2025
CorrectedRate(ECR)bynoisetypeandmodel
mi-k2 qwen3 gpt-oss-120b gpt-5
ECR EDR ECR EDR ECR EDR ECR
– 92.7% – 97.3% – 99.3% –
5.3% 6.7% 2.7% 9.3% 9.3% 27.7% 27.7%
– 98.0% – 94.7% – 98.7% –
82.0% 86.0% 86.0% 81.3% 81.3% 83.7% 83.7%
81.3% 93.3% 87.3% 99.3% 99.3% 100.0% 100.0%
– 56.0% – 94.7% – 99.7% –
0.0% 4.0% 0.0% 0.0% 0.0% 0.0% 0.0%
sperexperimentandmodel
etokens Time(s) Cost(USD)
±8705 4230.52±786.67 0.09±0.00
±18124 3543.66±423.41 0.08±0.00
±2736 3008.82±705.35 0.80±0.06
±10829 3213.85±139.56 0.21±0.01
±4478 3907.89±448.30 0.18±0.00
±14705 11051.15±1718.27 5.86±0.17
This sampling introduces controlled variability in decoding
behavior, allowing us to evaluate model robustness under
slightchangesingenerationdynamics.
Retry Mechanism and Failure Handling To account for
transient failures and improve robustness, we implement a
structuredretrymechanismduringinference. Eachrecordis
allowedmultipleattemptstobeprocessedsuccessfullybefore
beingmarkedasfailed.Theretrypolicyisdefinedasfollows:
• Output generation: The model is allowed up to 50 re-
tries to produce a valid structured output conforming to
theLogCleaningAPIschema.
• Toolinvocation: Iftheagentfailstoexecuteatoolcall
(e.g.,SQLqueryorschemainspection),itisallowedup
to3retriespertool.
• Record-levelrecovery:Ifarecordfailsduetopersistent
outputortoolinvocationerrors,theentirerepairprocess
is re-executed up to 3 times before the record is defini-
tivelylabeledasfailed.
Thismechanismensuresthatoccasionaldecodinganomalies
or transient tool failures do not disproportionately affect the
evaluationmetrics.Allfailurecasesareexplicitlytrackedand
includedinthefinalanalysistoreflectthepracticalreliability
ofeachmodelunderrealisticdeploymentconditions.
Metrics The cleaned dataset Mˆ is compared against the
groundtruthtocompute:
• Error Detection Rate (EDR) — proportion of records
forwhichthecorrectactionwasselected.
• ErrorCorrectionRate(ECR)—proportionofrecords
forwhichthecorrectfield-levelfixwasapplied(onlyfor
updateactions).
9

=== Page 10 ===
ANNUALCONFERENCEOFTHEPROGNOSTICS
Inadditiontotask-specificperformance,wetrackthefollow-
ingusagemetricsforeachexperimentexecution: totalnum-
ber of request and response tokens, total execution time (in
seconds),estimatedcost(inUSD).
6. RESULTS
Table5summarizesperformanceacrosssixnoisecategories,
aswellasthenoise-freecondition,usingtheEDRand,where
applicable, the ECR. Noise-free records were reliably han-
dled by all models: EDRs exceeded 92% across the board,
withGpt-5reaching99.3%. Forgenerativenoise,digitalsys-
tem test entries were almost always flagged correctly. Most
models achieved near-perfect rejection, and Gpt-5 led with
99.7%EDR.
Corruptivenoiseshowedsharperseparationbetweenmodels.
Large models handled categorical typos and missing values
substantiallybetterthansmallerones: Gpt-5attained83.7%
EDR/ECR on typos and 100% on missing values, indicat-
ingbothaccurateactionselectionandsuccessfulsingle-field
repair. GPT-OSS-120B closely tracked this behavior with
81.3% EDR/ECR on invalid values and 99.3% on missing
values. In contrast, Nemotron struggled on the same cate-
gories (24.7% EDR on typos and 7.3% on missing values),
underscoringsensitivitytofine-grainededits.Bycomparison,
GPT-OSS-20B,Kimi-K2,andQwen3showedbettercapabil-
ities on these categories. The two most challenging corrup-
tive cases were wrong end dates and vehicle identifier mis-
alignments, where these models also struggled. All models
failedtocorrectwrongenddates(0%ECR),andonlyGpt-5
showedmoderatesuccessonidentifiermisalignment(27.7%
EDR/ECR). These results suggest that temporal consistency
checksandcross-tableidentifierresolutionremainopenprob-
lemsforcurrentagenticsetups.
Table 6 reports resource usage per experiment, revealing a
clear cost–quality trade-off. Gpt-5 was the most expensive
and slowest configuration (average $5.86 and 11051s per
experiment), consistent with its top performance on several
categories. Gpt-Oss-120B offered a favorable price–latency
trade-off at roughly 1.86M input and 169k output tokens,
3908s runtime, and an estimated $0.18 per experiment.
Nemotron, while the least capable on correction tasks, was
the most economical (about $0.09 per run). Kimi-K2 and
Qwen3offeredamorebalancedprofile,deliveringmid-range
EDR/ECRwithsub-$1costs.
Overall,higherEDR/ECRoncorruptivenoisecorrelateswith
increased token usage and latency. In contrast, budget-
friendlymodelsprovidefast,low-costpassesthatmaysuffice
for high-confidence acceptance/rejection but lag on precise
repairs.

SANDHEALTHMANAGEMENTSOCIETY2025
7. DISCUSSION
We observed that the agentic approach enabled a shift from
batch processing to stream processing in maintenance log
cleaning. The methodology simulated stream processing by
handling one record at a time, which—through integration
with external tools—enabled intelligent and context-aware
data curation. A key advantage was the autonomy of the
agents: they operated without explicit cleaning task specifi-
cation.Theagentsalsodemonstratedcontextualreasoningby
leveragingmultipletablesinrealtimewheninferringcorrec-
tions. Moreover,thisapproachenabledtheextensionofdata
curationtaskstoincludetime-seriesinformation,whereastra-
ditionalsolutionsweretypicallylimitedtotabularformats.
From a cost–quality perspective, among all models GPT-
OSS-120B stands out as a strong value option. It delivered
a favorable price–latency profile while remaining competi-
tive on generic repairs. These characteristics make it attrac-
tivewhenbudgetsorlatencyconstraintsaretight,especially
relativetothepremium GPT-5 configuration. Moreover,be-
causetheGPT-OSSlineisopen-weight,GPT-OSS-120Bcan
beexecutedandfine-tunedonprivateinfrastructuretotarget
domain-specificnoisepatterns.
Notably,evensmallandmedium-sizedmodelsdemonstrated
theabilitytoperformcleaningtasks.Forinstance,Nemotron,
with only 9B parameters, successfully detected generative
noise, while Gpt-Oss-20B handled invalid and missing val-
ueswithagooddegreeofaccuracy.
The response time for processing individual records ranged
from a few seconds to several minutes, which we consider
acceptableforsmallandmediumfleetcontexts,giventherar-
ityoffailures.
Despitethesepromisingresultsinperformingsector-agnostic
data cleaning, the inability to handle domain-specific noise
remained a significant limitation. Errors detectable through
temporal misalignments and entity association are precisely
where LLM agents could provide the most value. We be-
lievethatcurrentLLMshavenotbeentrainedonstructured,
domain-specific cases and therefore lack the inductive bias
required to generalize effectively in such contexts. Conse-
quently,moreadvancedpromptingstrategiesandfine-tuning,
thoughattheexpenseofautonomy,couldbeemployedtoim-
proveperformanceintheseareas.
Finally,whilethesynthetic-datageneratorenabledcontrolled
benchmarkingandreproducibility,relianceonsyntheticlogs
limitstheexternalvalidityofourfindingsinoperationalset-
tings. This choice reflects privacy and confidentiality con-
straints around proprietary fleet data. To close this gap, it is
necessarytodeployandevaluatethepipelineonde-identified
maintenancelogsfromindustry.
10

=== Page 11 ===
ANNUALCONFERENCEOFTHEPROGNOSTICS
8. CONCLUSIONSANDFUTUREWORK
Inthisstudy,weinvestigatedthepotentialofLLMagentsto
cleannoisymaintenancelogsinPdMapplications. Weintro-
duced a synthetic data generation framework that simulates
realistic noise patterns across six categories, including both
genericanddomain-specificanomalies. Webenchmarkedsix
production-grade LLMs using a stream-based agentic setup,
whereeachmodelwastaskedwithclassifyingandrepairing
individual log entries via structured API calls. Performance
wasevaluatedusingerrordetectionrateanderrorcorrection
rate, alongside usage metrics such as runtime, token con-
sumption,andcost. LLMagentsperformedwellatidentify-
ingcorruptivenoise,recognizingnoise-freerecords,andcar-
rying out domain-agnostic repairs. By contrast, they under-
performed on domain-specific noise patterns, where schema
and process knowledge are required. These findings should
beinterpretedinlightofouruseofsyntheticlogs,whichmay
limitexternalvalidity.
Building on this initial investigation, several extensions are
envisionedtofurtheradvancetheevaluationandtheapplica-
bilityofLLMagentsinautomotiveindustrialsettings. First,
the synthetic fleet data generator should incorporate an ex-
panded noise taxonomy that captures more complex errors,
such as multi-field corruptions, time-series inconsistencies,
inter-record contradictions, and semantic mismatches. Ad-
ditionally, the data schema could be enriched with nested
structures and optional fields to better capture the complex-
ity and variability of real-world maintenance logs. To ad-
dress the current limitations in handling temporal inconsis-
tencies and cross-table reasoning, we propose three key en-
hancements: (i) integrating temporal-logic validators into
theagent’stoolsettoenableconsistencychecksacrosstime-
stampedfields;(ii)adoptingahybridrule–LLMarchitecture,
where deterministic rules are used to pre-validate and post-
validate temporal fields and entity relationships, while the
LLM focuses on proposing semantic repairs; and (iii) fine-
tuning the models on domain-specific corpora to improve
their inductive bias and contextual understanding. Further-
more, we plan to incorporate persistent memory, allowing
agentstomaintaincontextacrossmultiplerecordsandlever-
agehistoricaldecisionsformorecoherentandinformedrea-
soning.
Ultimately, to strengthen external validity and enhance the
practicalsignificanceofourfindings,weplantoevaluatethe
agents using authentic maintenance logs obtained from in-
dustrial partners, with appropriate anonymization protocols
in place. This will allow us to rigorously assess the gen-
eralizability, robustness, and domain-specific adaptability of
theproposedLLM-basedcleaningapproachunderreal-world
conditions.
Overall,LLM-basedmaintenancelogcleaningshowsstrong
potentialtooutperformtraditionalapproachesintermsofau-

SANDHEALTHMANAGEMENTSOCIETY2025
tonomy,flexibility,andreal-timeresponsiveness. Whilecur-
rent limitations exist, we believe these can be mitigated. As
such, LLMs represent a promising direction for future PdM
data cleaning pipelines, especially as the technology contin-
uestomature.
ACKNOWLEDGEMENT
This research was funded in whole, or in part, by the Lux-
embourg National Research Fund (FNR), grant reference
BRIDGES/2022/IS/17270233. For the purpose of open ac-
cess, and in fulfillment of the obligations arising from the
grant agreement, the authors have applied a Creative Com-
mons Attribution 4.0 International (CC BY 4.0) license to
any Author Accepted Manuscript version arising from this
submission.
The authors gratefully acknowledge Grupo<A> for provid-
ingaccesstothedatasetusedinthisstudy,whichwasessen-
tialforthedevelopmentandvalidationoftheresearch.
REFERENCES
Bendinelli, T., Dox, A., & Holz, C. (2025). Explor-
ing LLM agents for cleaning tabular machine learn-
ing datasets (No. arXiv:2503.06664). arXiv. doi:
10.48550/arXiv.2503.06664
Chu, X., Morcos, J., Ilyas, I. F., Ouzzani, M., Papotti, P.,
Tang, N., & Ye, Y. (2015). KATARA: A data clean-
ing system powered by knowledge bases and crowd-
sourcing. In Proceedings of the 2015 ACM SIGMOD
international conference on management of data (pp.
1247–1261). ACM. doi: 10.1145/2723372.2749431
DelMoral, P., Nowaczyk, S.,&Pashami, S. (2022). Filter-
ing misleading repair log labels to improve predictive
maintenance models. In Proceedings of the european
conference of the phm society 2022 (Vol. 7, pp. 110–
117). doi: 10.36001/phme.2022.v7i1.3360
Fan, W., & Geerts, F. (2012). Foundations of data qual-
ity management (Vol. 4). Morgan and Claypool. doi:
10.2200/S00439ED1V01Y201207DTM030
Heidari, A., McGrath, J., Ilyas, I. F., & Rekatsinas,
T. (2019). HoloDetect: Few-shot learning
for error detection.. Retrieved 2025-08-13, from
http://arxiv.org/abs/1904.02285 doi:
10.1145/3299869.3319888
Ilyas, I.F.,&Chu, X. (2015). Trendsincleaningrelational
data: Consistency and deduplication. , 5(4), 281–393.
doi: 10.1561/1900000045
Madhikermi,M.,Buda,A.,Dave,B.,&Framling,K. (2017).
11

=== Page 12 ===
ANNUALCONFERENCEOFTHEPROGNOSTICSANDHEALTHMANAGEMENTSOCIETY2025
Key data quality pitfalls for condition based mainte-
nance. In20172ndinternationalconferenceonsystem
reliability and safety (ICSRS) (pp. 474–480). IEEE. SystemPrompt
doi: 10.1109/ICSRS.2017.8272868
You are a meticulous data curator focused on workshop
Mahdavi, M., & Abedjan, Z. (2020). Baran: effec- maintenancelogs.
tive error correction via a unified context representa- Whencorrectingrecords,youaccessthefollowingresources
tion and transfer learning. , 13(12), 1948–1961. doi:
10.14778/3407790.3407801 inthedatabase:
Mahdavi, M., Abedjan, Z., Castro Fernandez, R., Madden, • fleet registry—containsallvehiclesbelongingto
thetargetfleet.
S.,Ouzzani,M.,Stonebraker,M.,&Tang,N. (2019).
• service catalog—definesvalidcategoriesandtheir
Raha: Aconfiguration-free error detection system. In hierarchicalstructureformaintenancerecords.
Proceedings of the 2019 international conference on
• signal odometer—tracksodometerreadingsforall
management of data (pp. 865–882). ACM. doi: vehiclesinthefleet.
10.1145/3299869.3324956
Usetheseresourcestovalidateandcorrectincomingmainte-
Narayan,A.,Chami,I.,Orr,L.,&Re´,C. (2022). Canfoun- nancerecords.
dation models wrangle your data? , 16(4), 738–746.
Figure5.SystemPrompt.
doi: 10.14778/3574245.3574258
Prytz, R., Nowaczyk, S., Rognvaldsson, T., & Byt-
tner, S. (2015). Predicting the need for ve-
hicle compressor repairs using maintenance records
and logged vehicle data. Engineering Applica-
Instructions
tions of Artificial Intelligence, 41, 139–150. doi:
Spotinconsistencies,checkDBtablesandproposecorrections
10.1016/j.engappai.2015.02.009
whenneeded.
Qi, D., Miao, Z., & Wang, J. (2025). CleanA-
Figure6.Agentinstructions.
gent: Automating data standardization with LLM-
based agents (No. arXiv:2403.08291). arXiv. doi:
10.48550/arXiv.2403.08291
Rekatsinas, T., Chu, X., Ilyas, I. F., & Re´, C.
(2017). HoloClean: holistic data repairs with
UserPromptTemplate
probabilistic inference. , 10(11), 1190–1201. doi:
10.14778/3137628.3137631 Youaregiventhenextmaintenancerecord:
Woods, C., Selway, M., Bikaun, T., Stumptner, M., & Hod- ⟨record⟩
kiewicz,M. (2024). Anontologyformaintenanceac- Selectexactlyoneactionandinvokethecorrespondingoutput
tivitiesanditsapplicationtodataquality.,15(2),319–
function:
352. doi: 10.3233/SW-233299
Zhang, H., Dong, Y., Xiao, C., & Oyamada, M. • accept(work order number)—therecordisvalid
andrequiresnochanges.
(2024). Large language models as data prepro-
• reject(work order number) — the record is in-
cessors (No. arXiv:2308.16361). arXiv. doi: validoroutofscopeforthisfleet.
10.48550/arXiv.2308.16361
• update(work order number, field, value)
— the record contains a correctable error; apply a
APPENDIX
single-fieldfix.
Usetheappropriatefunctiontoclassifytherecord.
Figure7.Userprompttemplateusedtoguideagenticdecision-making.
12

Paper:GateLens - A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics.pdf
=== Page 1 ===
GateLens: A Reasoning-E
Automotive Softwar
Arsham Gholamzadeh Khoee, Shuai Wang, Yinan Yu
Chalmers University of Technology
Gothenburg, Sweden
{arsham.khoee, shuaiwa, yinan, robert.feldt}@cha
Abstract—Ensuring reliable software release decisions is criti-
calinsafety-criticaldomainssuchasautomotivemanufacturing.
Release validation relies on large tabular datasets, yet manual
analysis is slow, costly, and error-prone. While Large Language
Models (LLMs) offer promising automation potential, they face
challenges in analytical reasoning, structured data handling,
and ambiguity resolution. This paper introduces GateLens, an
LLM-based system for analyzing tabular data in the automotive
domain.GateLenstranslatesnaturallanguagequeriesintoRela-
tionalAlgebra(RA)expressionsandgeneratesoptimizedPython
code. Unlike traditional multi-agent or planning-based systems
that can be slow, opaque, and costly to maintain, GateLens
emphasizes speed, transparency, and reliability. Experimental
results show that GateLens outperforms the existing Chain-of-
Thought (CoT) + Self-Consistency (SC) based system on real-
world datasets, particularly in handling complex and ambigu-
ous queries. Ablation studies confirm the essential role of the
RA layer. Industrial deployment shows over 80% reduction
in analysis time while maintaining high accuracy across test
result interpretation, impact assessment, and release candidate
evaluation. GateLens operates effectively in zero-shot settings
withoutrequiringfew-shotexamplesoragentorchestration.This
work advances deployable LLM system design by identifying
key architectural features—intermediate formal representations,
executionefficiency,andlowconfigurationoverhead—crucialfor
safety-critical industrial applications.
Index Terms—Large Language Models, Tabular Question
Answering, Software Release Analytics, Automotive Software
Testing, Test Result Interpretation, Interpretable Reasoning
I. INTRODUCTION
Validating software releases in the automotive industry is
a multifaceted challenge, particularly for embedded software
in safety-critical systems. Modern vehicles integrate numer-
ous subsystems, making this process complex and resource-
intensive. Each integration phase involves gating steps—
critical checkpoints where tests verify compliance with pre-
defined quality standards. Failures at these gates can ripple
throughthesystem,delayingdependentsubsystemsregardless
of their individual quality. Release managers tasked with
safeguardingqualitymustanalyzevastquantitiesoftestresults
and validation data. While essential for ensuring safety and
reliability,thisprocessistime-consumingandpronetohuman
error in data interpretation.
Thesoftwareindustry’stransitionfrommanualtoautomated
processes has entered a new era with the emergence of
Large Language Models (LLMs) (Liu et al., 2024; Chang
et al., 2024). Companies are increasingly integrating these
AI agents into their workflows, seeking more cost-effective
5202
guA
1
]ES.sc[
2v53712.3052:viXra

Enhanced LLM Agent for
re Release Analytics
Yu, Robert Feldt Dhasarathy Parthasarathy
Volvo Group
Gothenburg, Sweden
almers.se dhasarathy.parthasarathy@volvo.com
and optimized solutions for complex software engineering
tasks (Leung and Murphy, 2023). However, direct application
of LLMs to software release validation is hindered by limita-
tionsininterpretablereasoningandunderstandingoftechnical
specifications (Marques, 2024; Austin et al., 2021).
To address these challenges, we introduce GateLens, a
reasoning-enhanced LLM agent (Miehling et al., 2025) to
supportreleasevalidationintheautomotivedomain.GateLens
integrates structured relational analysis with domain-specific
expertise, leveraging a reasoning layer built on Relational
Algebra (RA) to break down complex validation tasks into
systematic analytical steps. GateLens simplifies three critical
aspects of release validation:
1. Test Result Analysis: Analyzing test execution outcomes
is foundational to release validation. This involves analyzing
pass/fail patterns across comprehensive test suites, identifying
recurring failures, and validating test coverage metrics. In
automotive software, where a single release might involve a
large number of test cases across multiple vehicle functions,
this task becomes particularly demanding. Release engineers
must not only identify failed tests but also understand their
patterns,assesscoverageadequacy,andevaluatetestexecution
stability.
2. Impact Assessment: Impact Assessment is a systematic
process for evaluating how software issues affect vehicle
functionality and safety during release validation. It involves
three phases: first, a critical failure analysis identifies the root
cause and immediate effects of an issue, such as an ABS
module causing a 200ms brake signal delay that exceeds the
100msthreshold.Second,acomponent-levelimpactevaluation
traces how the issue propagates through interconnected sys-
tems,assessingbothdirecteffects,likeproblematicemergency
braking, and indirect effects, such as reduced stability control
performance.Finally,anintegrationriskassessmentquantifies
the severity of these impacts against safety thresholds and
functional requirements, categorizing issues like the ABS de-
lay as system-wide risks with critical severity. This structured
process enables engineers to understand system-wide effects,
ensuring all safety and functionality requirements are met
before release.
3. Release Candidate Analysis: The final quality gate in-
volvesevaluatingReleaseCandidates(RCs)againstpredefined
qualitygatesandcriteria.Thisencompassesanalyzingwhether
aparticularRCmeetsallqualitythresholds,identifyingpoten-

=== Page 2 ===
tial release blockers, and validating compliance with release
requirements. In automotive software, where releases must
meet stringent safety and quality standards, this analysis
requires careful validation of each RC against established
criteria,ensuringallprerequisitesforasafeandreliablerelease
are satisfied.
Thetraditionalreleasevalidationprocessdemandsextensive
manual effort. Release engineers meticulously analyze test
results, assess impacts, verify RCs against quality gates, and
report findings to stakeholders, such as release managers. As
automotivesoftwaresystemsgrowincreasinglycomplex,these
manualworkflowsbecomemorechallenging,time-consuming,
and error-prone.
This work aims to streamline release validation by au-
tomating key analysis workflows, enabling engineers to focus
on high-value analysis and discussion. By providing deeper
analytical insights, the proposed approach reduces the time
needed to deliver accurate validation results, empowering
releasemanagerstomakeinformeddecisionsmoreefficiently.
Our contributions can be summarized as follows:
• Wedesignanarchitectureoptimizedfortime-andsafety-
criticalenvironments,minimizingLLMinvocationswhile
preserving reasoning depth. GateLens operates in a zero-
shot setting, avoiding the need for few-shot examples or
multi-agent coordination, which improves generalizabil-
ity, execution speed, reduces maintenance overhead, and
enhances transparency.
• We introduce a scalable and maintainable framework
for automotive software release validation, developed in
response to observed limitations in traditional planning-
based multi-agent system. GateLens handles diverse user
queries with higher robustness and clarity, supporting
effectivedecision-makingacrossawiderrangeofrelease
engineering tasks.
• We conduct a comprehensive empirical evaluation, in-
cluding comparisons with a CoT+SC system, ablation of
the RA module, and performance across multiple LLMs
(GPT-4oandLlama3.170B).Theseexperimentsdemon-
strateGateLens’sperformanceadvantagesincomplexand
ambiguous queries.
• We report on real-world industrial deployment in a
partner automotive company, where GateLens reduces
analysis time by over 80% and demonstrates strong
generalization across user roles, highlighting its practical
value and deployment-readiness in safety-critical release
validation workflows.
II. BACKGROUNDANDMOTIVATION
Software release decisions in the automotive industry in-
volve multiple stakeholders and extensive data analysis. Mod-
ern vehicles integrate hundreds of software components, each
requiringrigoroustestingandvalidation.Theprocessadvances
through distinct phases: component-level testing, integration
testing, system-level validation, and vehicle validation testing.
Component-level testing verifies individual software modules,
2

integration testing ensures proper interaction between compo-
nents, system-level validation examines the complete system
behavior, and vehicle validation testing evaluates software
performance under real vehicle conditions on closed tracks.
Thedevelopmentcyclegrowsincomplexitywitheachinte-
gration phase. This increasing complexity presents challenges
inmanaginglarge-scaletestresults,trackinginterdependencies
between components, correlating test failures across different
subsystems, and maintaining historical context for recurring
issues. The iterative nature of software testing and validation
further expands this data ecosystem.
Thewiderangeofstakeholdersinthereleaseprocesscreates
additional challenges in data interpretation and presentation.
Project managers need high-level progress indicators, veri-
fication engineers require detailed technical insights, quality
engineers focus on trend analysis and improvement metrics,
and release engineers need specific release-readiness indica-
tors. This variety of perspectives necessitates different views
ofthesameunderlyingdata,makingtheanalysisprocessmore
complex.
Release managers function as gatekeepers in the software
deployment pipeline. They handle test result analysis, cross-
system impact assessment, decision-making, stakeholder co-
ordination, and safety compliance verification. The manual
workflowintroducesvulnerabilities:time-intensiveprocessing,
potentialerrorsininterpretation,decisiondelays,andcommu-
nication barriers between technical and business teams.
Within this process, statisticians provide an overall view
of the data to project managers and quality engineers for
future businessdecisions. Theexisting manualapproach faces
several limitations, particularly regarding time and resource
constraints. These include labor-intensive data analysis, de-
layed response to critical issues, limited capacity for com-
prehensive analysis, and bottlenecks in the release pipeline.
Communication challenges further complicate the process,
withmisalignmentbetweentechnicalanalystsandstatisticians,
varying interpretations of project requirements, inconsistent
reporting formats, and knowledge transfer gaps.
InternalTestingonClosedTrackrepresentsacrucialvalida-
tion phase. Release managers must analyze extensive datasets
to evaluate progression readiness. The manual query process
for report generation can impact release timelines, business
objectives, and subsystem integration schedules.
The deployment of intelligent assistants presents oppor-
tunities to address these challenges through automated data
processing and analysis, standardized reporting frameworks,
real-time insights generation, and stakeholder-specific view
generation. However, current automation solutions, including
basic LLM implementations, face limitations in understand-
ing complex technical specifications, maintaining structured
analysis steps, handling domain-specific requirements, and
processing automotive validation data systematically.
These limitations highlight the need for enhanced solu-
tions combining domain expertise with advanced analytical
reasoning capabilities. Such solutions must facilitate efficient
decision-making while maintaining high safety and quality
2

=== Page 3 ===
Fig. 1: GateLens top-level architecture: The system processes
data manipulation code using the enhanced reasoning layer wit
decision-support resource.
standards in automotive software development (Wang et al.,
2024a). Effective intelligent assistants can transform the re-
lease decision process, enabling release managers to prioritize
resultinterpretationandstrategicdecision-makingoverroutine
data analysis.
III. APPROACHANDMETHODOLOGY
The complexity of automotive software release validation
demands a system that can bridge the gap between human-
centric inquiries and precise technical analysis. GateLens
addresses this challenge by utilizing LLM agents to trans-
formnaturallanguagequeriesintoactionableinsightsthrough
systematic analysis. At its core, GateLens must fulfill three
fundamental requirements:
1. Query Understanding: The system must accurately inter-
pretdiverseuserqueries,rangingfromhigh-levelmanagement
questions to detailed technical inquiries about specific test
cases.
2. Query Transformation: The system needs to transform
theseinterpretationsintostructuredformalexpressions,ensur-
ing consistent and verifiable reasoning structures.
3.AnalysisExecution:Thesystemmustgenerateandexecute
precise analysis code that processes validation data according
to these formal expressions.
ThearchitectureofGateLensisdrivenbythesefundamental
requirements,establishingasystematicpipelinefortransform-
ing user queries into analytical results. The system leverages
RA to enhance LLMs’ reasoning capabilities and transform
user queries into formal relational operations. To support
this transformation, GateLens employs domain-specific data
schemas that guide its relational modeling and enhance the
generation of RA expressions. This approach ensures both
accessibility for non-technical stakeholders and the precision
required for automotive software validation.
A. System Overview
TheprimaryobjectiveofGateLensistogenerateexecutable
code that performs precise test data analysis based on user
queries. The system’s workflow consists of two main phases:
query interpretation and code generation. As illustrated in
Figure 1, GateLens first processes user queries through an
LLM agent that translates natural language inputs into for-
mal RA expressions. This translation incorporates a detailed
3

high-level queries from the end user, generates the necessary
th the help of RA, executes it, and outputs the result table as a
relationalmodelofthetestdata,ensuringprecisespecification
ofautomotivedomainconcepts.TheresultingRAexpressions
serve as a pivotal intermediate representation that is more
transparent to both LLM agents and humans. In the second
phase, these formal expressions are passed to the coder agent,
which generates executable desirable code, such as SQL or
Python code, to perform the required analysis on the test data
and produce results.
B. Core Components
Thesystemarchitectureconsistsoftwoprimarycomponents
that work in tandem to transform natural language queries
into executable code: the query interpreter agent and the
coder agent. The query interpreter agent first translates user
queries into RA expressions, providing a structured frame-
work for analytical reasoning. The coder agent then converts
these formal expressions into executable code, completing the
transformationpipeline.Thistwo-stageapproachensuresboth
analytical precision and efficient implementation, where the
prompt engineering flow and prompt structure are presented
in Figure 2.
1) QueryInterpreter: Thequeryinterpreteragentisrespon-
sible for converting user queries into formal RA expressions,
providingapreciseframeworkforanalyticalreasoning.Before
initiating this translation, the agent consults the knowledge
base, comprising the data schema and domain-specific con-
text. The data schema provides a detailed understanding of
the dataset, including its relational modeling, detailed field
descriptions, and data types. Using this information, the agent
verifies whether the query is relevant and within the scope of
the dataset (Manik et al., 2021). This validation step ensures
that only supported and meaningful queries are processed,
improving both accuracy and efficiency. Once the query is
confirmedtobeinscope,theagentleveragesthedataschemas
to interpret and decompose the query into formal RA expres-
sions.
The agent’s primary function is to map natural language
queriesintoformalRAexpressions,enhancingLLMreasoning
through structured decomposition (Khot et al., 2022). This
approach extends traditional Chain-of-Thoughts (CoT) (Wei
et al., 2022) reasoning by constraining the model to think
within a formal system framework (Zhang et al., 2023a).
Instead of generating free-form solutions, the agent must
3

=== Page 4 ===
express analytics through a limited set of standard operations:
selection, projection, union, set difference, cartesian product,
and rename as basic operations, as well as derived operations
such as join, intersection, and division and complemented by
aggregationfunctionslikeaverage,minimum,maximum,sum,
and count.
By limiting operations to this standard set, the agent effec-
tively handles ambiguous queries through formal translation,
ensures technical precision, and prevents deviation from ana-
lytical requirements. The formal nature of RA enables query
optimization, which the agent incorporates by prioritizing
data reduction operations early in the expression chain. This
optimization strategy involves applying filters first, then per-
forming expensive operations on the reduced dataset, thereby
minimizing processing time and resource utilization.
The translation to RA offers two significant advantages.
First, it makes the analytics more transparent in technical
terms, allowing for clear interpretation and validation of the
reasoning process. Second, it ensures that every solution
generatedispreciselydefinedandfeasibleforimplementation,
preventing the agent from proposing impractical or undefined
analytical approaches.
2) Coder: The coder agent is responsible for generating
executable code from given RA expressions. Upon receiving
an RA expression, the agent follows precise instructions to
produce code that delivers the finalanalytical results. This ca-
pability allows the agent to generate complete, self-contained
code at once, eliminating the need for step-by-step generation
and execution phases.
To ensure the generated code meets quality standards, we
designed prompts that specifically instruct the LLM to in-
clude essential validation mechanisms. The prompts explicitly
require data type validation instructions for numerical and
categorical field handling, null value checking procedures to
maintaindataintegrity,validationofnumericaloperations,and
validationofjoinconditionstoensurepropermatchingofkey
columns between tables.
By generating the entire code in a single pass rather than
through iterative refinement, the agent significantly reduces
processing overhead, system response time, and resource con-
sumption while minimizing potential errors that could arise
from multiple execution steps. This streamlined yet precise
approachensuresbothefficiencyandreliabilityintheanalysis
R
pipeline,fullyalignedwiththeformalrigorofRAexpressions
and improving overall system responsiveness to user queries.
R
C. Data Handling
R
A key architectural decision in GateLens is its indirect
interaction with test data. Rather than exposing sensitive
R
test data directly to LLM agents, which could raise privacy
concerns (Boudewijn et al., 2023) and exceed input context
limitations,thesystemoperatesondataschemasandrelational
models. This approach serves multiple critical purposes:
• Privacy Protection: Sensitive automotive test data re-
mains secure within the organization’s infrastructure
4

Fig. 2: Overview of the prompt engineering flow and prompt
structure within the GateLens system architecture.
• Scalability: The system can handle large-scale test
datasets that would exceed LLM context windows
• Knowledge Integration: Data schemas and relational
models serve as an essential knowledge base, providing
necessary structural understanding without raw data ex-
posure
The final execution of the generated code runs on the test
datain thetargetenvironment,maintaining dataprivacywhile
delivering precise analytical results.
IV. EXPERIMENTALEVALUATION
In this section, we aim to answer the following research
questions:
RQ1: How effectively does GateLens address user queries and
deliver accurate results across various query categories?
RQ2: How robust is GateLens in handling out of scope queries
and imprecise queries?
RQ3: How does the RA reasoning procedure contribute to the
overall performance of GateLens?
RQ4: How does the number of few-shot examples impact
GateLens’s performance?
A. Experimental Setup
To address the research questions introduced in Section IV,
we designed and conducted extensive experiments to evaluate
the performance of GateLens.
4

=== Page 5 ===
The experimental data comprises two distinct benchmarks.
The first benchmark consists of 50 queries designed with the
assistance of release engineers, quality engineers, and verifi-
cation engineers. To assess GateLens’s performance across a
spectrum of query complexities, these queries are categorized
into four difficulty levels. The four levels of query difficulty
are defined as follows:
Level 1 Simple queries involving a single operation such as
filtering or sorting.
Level 2Queriescombiningtwoorthreebasicoperations,such
as multiple filtering followed by sorting.
Level 3 Queries involving more than three operations, poten-
tially including grouping and aggregating.
Level 4 Complex queries requiring multiple advanced opera-
tions beyond basic filtering and sorting, such as grouping and
aggregating for statistical calculations.
The second benchmark is derived from real-world user
queries collected from production logs at our partner com-
pany. These queries were sourced from the historical logs of
an agentic system that employed a well-established tabular
data reasoning approach combining CoT (Wei et al., 2022)
prompting with Self-Consistency (SC) (Wang et al., 2022).
Thissystemwasusedinproductiontosupportsoftwarerelease
analytics,andthecollectedqueriesreflectawiderangeofuser
roles, query types, and domain-specific requirements. While
this system performs effectively in many scenarios, its limita-
tionsbecomeapparentastherangeofrolesandusersexpands,
leadingtoasignificantdiversificationofqueries.Thisbroader
query diversity exposes the system’s reliance on few-shot
examples, making it less capable of handling highly complex,
ambiguous,orill-definedqueriesthatrequiregreaterflexibility
and adaptability. Nevertheless, this preliminary system played
a critical role in data collection for GateLens by providing
query logs used to develop and validate our approach. From
these logs, we filtered out near-duplicates and selected 244
frequently repeated unique queries, which we then organized
into eight functional categories based on their purposes.
In order to assess GateLens’s performance, we run exper-
iments with two large language models (LLMs): GPT-4o, a
leading commercial model, and Llama 3.1 70b, a recently
released open-source model. We also benchmark GateLens
against the CoT+SC agentic system currently used to support
the company’s release decisions. Our comparative analysis is
designed to quantify the improvements introduced by Gate-
Lens’s novel architecture.
To address the challenge of handling out-of-scope user
queries during real-time interactions, GateLens incorporates
an in-scopefiltering mechanism asexplained inSection III-B.
This mechanism ensures that the system only attempts to
process queries that fall within its scope, thereby improving
reliabilityandreducingerrors.Performanceevaluationfocused
on two key aspects:
1) Quality of responses: Measured using precision, recall,
andF1Score,whichreflectthesystem’sabilitytoaddress
relevant queries correctly.
5

2) Coverageofrelevantqueries:Ensuringthesystemdoes
not reject a significant proportion of valid queries, thus
maintaining broad applicability.
Additionally, an ablation study is conducted to examine the
contribution of the RA reasoning mechanism of GateLens.
In our experiments, the evaluation of system performance
is based on the following definitions: A True Positive (TP)
occurs when the system produces a result that matches the
manually generated ground-truth result, specifically when the
finaloutputoftheexecutedcodematchestheexpectedground-
truth output. A False Positive (FP) occurs when the sys-
tem provides an incorrect result, meaning the executed code
produces output that differs from the ground-truth. A False
Negative (FN) occurs when the system fails to provide any
result for a query. True Negatives (TNs) are not applicable
since we focus on valid queries producing meaningful output.
Based on these definitions, we calculate Precision, Recall,
and F1 scores to assess the performance of the system. Preci-
sionensuresthatincorrectresultsareminimized,recallensures
relevant queries are addressed, and the F1 score balances the
two to provide an overall assessment of system performance.
B. Performance in Addressing User Queries (RQ1)
We conducted experiments to compare the performance of
GateLens across the two introduced benchmarks. The first
benchmark, consisting of 50 queries categorized by difficulty
levels, was used to evaluate and compare the performance of
GateLens and CoT+SC. Both systems were tested using GPT-
4o and Llama 3.1 70B as their underlying LLMs. The results
are summarized in Table I.
The results demonstrate that GateLens with GPT-4o signif-
icantly outperforms GateLens with Llama 3.1 70B, indicating
GPT-4o’s superior capability for interpreting and generating
RA. Similarly, CoT+SC with GPT-4o outperforms its Llama
3.1 70B variant, with the performance gap growing as query
complexity increases. CoT+SC performance declines with
query complexity. This underscores the importance of the RA
reasoning mechanism in GateLens, which enables effective
handling of complex, unstructured queries by decomposing
them into logical, structured expressions. Most notably, Gate-
Lens with GPT-4o achieved optimal performance on this
benchmark, maintaining 100% accuracy across all difficulty
levels. This stems from integrating RA reasoning into our
framework. By translating queries into RA expressions, Gate-
Lens explicitly captures the logical structure of operations,
enhancingboththeclarityandprecisionofthegeneratedcode.
The intermediate RA conversion allows the system to focus
on the relevant table operations while filtering out irrelevant
elements in the query, greatly enhancing the problem-solving
capabilities of the LLM agent.
For the second benchmark, results in Table II show that
GateLens (GPT-4o) and CoT+SC (GPT-4o) significantly out-
performed GateLens with Llama 3.1 70B. This performance
disparity is primarily due to the strict code generation re-
quirements of the task, including table filtering, merging
5

=== Page 6 ===
TABLE I: Performance comparison across different models and
designed queries with annotated difficulty levels.
GateLenswithGPT-4o GateLenswithLlama
Level #Queries
Precision Recall F1Score Precision Recall F
1 16 100% 100% 100% 100% 43.75%
2 16 100% 100% 100% 100% 62.5%
3 12 100% 100% 100% 100% 50%
4 6 100% 100% 100% 100% 33%
Total 50 100% 100% 100% 100% 47.31%
TABLEII:PerformancecomparisonofGateLensandtheCoT+S
which consists of 244 real-world queries.
GateLenswithGPT-4o
Category #Queries
Precision Recall F1S
ColumnOperations 17 64.7% 64.7% 64.
ComplexMulti-ConditionQueries 77 86.3% 81.82% 84
ConditionalCalculations 8 100% 87.5% 93.
DataFiltering 32 89.66% 81.25% 85.2
DuplicateRemoval 78 87.67% 82.05% 84.7
GroupingandAggregation 10 80.0% 80.0% 80.
MetadataQueries 13 91.67% 84.61% 88.
TableGeneration 9 88.89% 88.89% 88.8
Total 244 86.02% 81.14% 83.5
strategies, and key-value mapping operations, where GPT-4o
demonstrated markedly superior capabilities.
GateLens with GPT-4o outperformed CoT+SC (GPT-4o)
across most categories, particularly evident in Metadata
Queries (those seeking basic table information). For example,
when processing the query ”Give me the list of release
candidates,” the CoT+SC system often fails to identify the
correct field. A common failure mode in CoT+SC occurred
when user queries included typographical errors or incorrect
casing in field names, with the system directly using the
erroneous fields without correction. GateLens addresses this
limitation through its query-to-RA transformation process,
which incorporates the database’s relational model, adjusts
query fields to match table formats, and can handle fuzzy
matching to detect and correct field names, enabling the
system to resolve typographical errors and ambiguous queries
effectively. This approach improves accuracy and resilience,
particularly in real-world scenarios where user queries may
not always adhere to strict formatting standards.
Across both datasets, GateLens with GPT-4o consistently
delivered the best performance, achieving perfect accuracy
across difficulty levels in the first benchmark and superior
handlingofdiversequerycategoriesinthesecondbenchmark.
This superior performance stems from the system’s ability
to extract logical conditions from natural language queries
and transform them into RA expressions, clarifying query
logic, ensuring accurate, complete condition handling and
minimizingerrorsandomissionsinthegeneratedcode.These
results demonstrate the framework’s enhancement of LLM
performance on complex queries and improved real-world
reliability
C. Robustness:HandlingOutofScopeandImpreciseQueries
(RQ2)
Toassesstherobustnessofourapproachinhandlingdiverse
userqueriesunderreal-worldconditions,weconductedfurther
experiments focusing on filtering out-of-scope queries as well
6

d difficulty levels on the first benchmark, which consists of 50
3.170B CoT+SCwithGPT-4o CoT+SCwithLlama3.170B
F1Score Precision Recall F1Score Precision Recall F1Score
60.87% 93.33% 87.5% 90.32% 100% 93.75% 96.77%
76.92% 100% 81.25% 89.66% 92.31% 75% 82.76%
66.67% 91.67% 91.67% 91.67% 90.91% 83.33% 86.96%
49.62% 66.67% 66.67% 66.67% 60% 50% 54.55%
63.52% 87.91% 81.77% 84.57% 85.81% 75.52% 80.26%
SCsystemacrossdifferentcategoriesonthesecondbenchmark,
o GateLenswithLlama3.170B CoT+SCwithGPT-4o
Score Precision Recall F1Score Precision Recall F1Score
.7% 50% 11.76% 19.04% 76.47% 76.47% 76.47%
4% 100% 24.68% 39.59% 84.75% 64.94% 73.53%
.3% 100% 37.5% 54.55% 87.5% 87.5% 87.5%
25% 90.91% 31.25% 46.51% 86.21% 78.13% 81.97%
77% 100% 23.08% 37.5% 75.93% 52.56% 62.12%
.0% 100% 30% 46.15% 83.33% 50% 62.5%
.0% 100% 15.38% 26.66% 46.15% 46.15% 46.15%
89% 100% 44.44% 61.53% 88.89% 88.89% 88.89%
51% 92.61% 27.26% 41.44% 83.15% 63.52% 70.61%
as processing imprecise queries. For this purpose, the data
analysis team at our industrial partner company manually
selected37out-of-scopequeriesand50imprecisequeriesfrom
the historical logs of the first-generation system, which are
used to perform targeted evaluations.
Out-of-scope queries are those that cannot be meaningfully
answered using the available data. For example, a query
like ”What is the most beautiful truck?” requires subjective
judgmentandcannotberesolvedthroughdatabaseoperations;
it should be identified and filtered as out of scope. On the
other hand, imprecise queries are those that can be answered
using the database but contain ambiguous or inexact terms.
For instance, a query such as ”Find some trucks for cases
that are NOK” is considered imprecise because while it seeks
truck names where test results are ”NOK” (failed), it uses
ambiguous terminology - referring to ”trucks” instead of the
actual database field ”name”, and mentions ”NOK” without
specifying the ”test result” field. Such imprecise queries re-
quire mapping informal language to precise database fields
and conditions for proper execution.
1) HandlingOutofScopeQueries: WecomparedGateLens
with other models; the results can be found in Table III. The
results demonstrate that GateLens with GPT-4o achieved the
best performance, particularly in terms of precision, which
is approximately 40% higher than other models, indicating
GateLens’ ability to avoid generating incorrect results.
The superior precision of GateLens with GPT-4o can be at-
tributedtotwokeyaspectsofitsdesign.First,itsrobustfilter-
ingmechanismensuresthatout-of-scopequeriesareidentified
andexcludedearlyintheprocessingpipeline,preventingirrel-
evant results. Second, the conversion of raw natural language
queries into structured RA expressions enables the model
to isolate and capture task-relevant components of a query.
This structured approach considerably decreases erroneous
outcomes and enhances the model’s ability to handle complex
and diverse query formulations in real-world scenarios.
CoT+SC showed significantly lower precision due to the
6

=== Page 7 ===
TABLE III: Model comparison for out-of-scope queries.
Model Precision Recall F1 Score
GateLens with GPT-4o 92.5% 100% 96.10%
GateLens with Llama 3.1 70B 52.94% 97.30% 68.57%
CoT+SC with GPT-4o 51.10% 89.19% 64.97%
TABLE IV: Model comparison for imprecise queries.
Model Precision Recall F1 Score
GateLens with GPT-4o 92.86% 78% 84.78%
GateLens with Llama 3.1 70B 92.86% 26% 40.63%
CoT+SC with GPT-4o 90% 36% 51.43%
variability of real-world queries and the inconsistency of
user narratives, which often contain a mix of relevant and
irrelevant content. This variability increases uncertainty and
poses challenges for models that struggle to identify task-
relevant information. Although all models demonstrated high
recall, this did not translate into accurate processing.
2) Handling Imprecise Queries: To further assess the ro-
bustness of our approach, we evaluated its performance in
handling imprecise queries, which posed two primary chal-
lenges. First, some queries are informal and conversational in
style,appearingunrelatedtodataanalysisbutactuallycarrying
relevant intent. Second, many queries referred to fields using
terms differing from the column headers.
The results of these experiments are presented in Table IV.
Asshown,GateLenswithGPT-4odemonstratesthebestover-
all performance. In terms of precision, all methods performed
relativelywell,indicatingthatwhenresultsaregenerated,they
are likely to be correct. However, our method significantly
outperformed the others in recall, highlighting its ability to
handle a larger portion of the imprecise queries. As a result,
GateLenswithGPT-4achievedasubstantiallyhigherF1score
compared to other methods, demonstrating that it not only
processes most queries but also produces accurate results for
them.
The observed performance gap between GateLens with
GPT-4oandtheothermodelscanbeattributedtotheirinherent
limitations. Specifically, the Llama 3.1 70B model struggled
to interpret user queries that deviated from the exact column
header descriptions in the database schema. In such cases,
Llama 3.1 70B often converted only the clearly defined parts
of the query into RA, leading to incomplete execution and
reduced accuracy. On the other hand, CoT+SC exhibits low
recall, as it is highly susceptible to confusion by ambiguous
query elements. This causes CoT+SC to frequently generate
incorrect code that fails execution, significantly lowering its
recall rate.
Overall, our approach demonstrated a strong ability to
handle imprecise queries by maintaining high precision and
significantlyimprovingrecall.Thisrobustnessensuresthatthe
systemisadaptabletovariationsandambiguitiesinqueryfor-
mulations, allowing users to freely express their queries with-
out being constrained by strict adherence to column header
names. Such flexibility enhances the system’s practicality and
applicability in real-world scenarios, making it a reliable and
user-friendly tool for diverse interactions.
7

100
95
90
85
80
75
70
1 2 3 4
Level
)%(
1F
100.0 100.0 100.0 100.00 100.0
96.67 96.67
GateLens
Without RA
72.73
(a)Thefirstbenchmarkwithannotateddifficulty
levels.
100
90
80
70
60
50
C ol u m n O
ps
C o m pl ex M
ulti
C o n diti o n al C
al
D at a Filt eri n
g
D u plic at e
Re
Gro u pi n
g
M et a d at
a
Ta bl e G e
n
)%(
1F
GateLens
93.393.3
without RA
88.088.0 88.9
84.0 78.3 85.2 82.0 84.883.4 80.080.0 77.8
64.764.7
(b) The second benchmark with real-world user queries
Fig. 3: Comparison of the original method and the method
without the RA module across different datasets.
D. Effectiveness of the RA module (RQ3)
ToevaluatetheimpactoftheRAmodulethatconvertsuser
queries into RA expressions, we conducted experiments by
removing the RA module from the framework and comparing
theresultstotheoriginalsystem.Theoutcomes,showninFig-
ure 3, demonstrate significant performance degradation across
both benchmarks when operating without the RA module.
In the first benchmark, performance declined most notably
for Level 4 queries, showing a drop exceeding 27%. These
queries, which involve advanced operations like grouping,
aggregating,andstatisticalcalculations,demonstratedthatRA
translation is particularly crucial for handling queries with
multiple,intricateoperations.Similarly,thesecondbenchmark
showsdecreased performancein complex taskssuch asmulti-
condition filtering, duplicate data removal, and table gener-
ation, further emphasizing RA’s effectiveness in managing
complex database operations.
The RA module maintained consistent performance for
simpler queries, demonstrating its versatility across varying
complexity levels. By transforming natural language into
precise, logical representations, the RA module serves as a
critical bridge between user intent and code execution. This
translation process enables the code generator to produce
accurate, efficient executable code for data analysis tasks.
These results establish RA as a fundamental component in
our system’s architecture, significantly enhancing its reason-
ing capabilities and ensuring reliable code generation across
diverse query types and complexity levels. This enables the
system to deliver accurate and efficient solutions for tabular
data analysis tasks.
7

=== Page 8 ===
E. Impact of Few-Shot Examples (RQ4)
To investigate the effect of including few-shot examples in
prompts, we conducted experiments by varying the number
of examples provided to both GateLens and CoT+SC. This
experiment is performed on the first benchmark containing 50
designed queries, with results illustrated in Figure 4.
The results demonstrate that GateLens relies heavily on its
RA translation process, achieving optimal performance even
in a 0-shot setting without any examples. Interestingly, when
a small number of examples are added, GateLens becomes
slightly biased toward them, leading to a minor degradation
in performance. However, it regains optimal performance
with additional examples as the system learns to generalize
better. In contrast, CoT+SC’s performance heavily depends
on in-context examples, showing suboptimal results without
sufficient few-shot examples. While CoT+SC’s performance
improveswith moreexamples,this approachisfundamentally
inefficient and impractical. Increasing example count expands
input context size, leading to higher latency due to the
quadratic complexity of Transformer-based models, particu-
larlyproblematicforreal-timeapplications.Thisalsoescalates
operational costs through increased token usage (higher cloud
API fees) and computational demands. Moreover, the larger
context risks exceeding the maximum length, which can lead
to truncation or lost information, compromising the model’s
response quality. In long contexts, critical content may be
ignored, resulting in a phenomenon known as “lost in the
middle,” which adversely affects overall performance (Liu
et al., 2023).
The results further highlight the critical role of RA in
enabling effective query handling. GateLens, through its RA-
basedtranslationprocess,achievesrobustperformancewithout
requiring extensive in-context learning. GateLens’s indepen-
dencefromexamplesnotonlyensuresconsistentperformance
across diverse queries but also offers practical benefits by
mitigating issues related to context length limitations and
accordingly reducing computational and financial resource
consumption, enhancing system scalability, and minimizing
maintenance needs for adaptation to new tasks. These advan-
tages position GateLens as a robust and efficient solution for
automating the analysis of tabular data in dynamic environ-
ments.
V. INDUSTRIALDEPLOYMENT:LESSONSLEARNED
The deployment of GateLens at a partner automotive
company has provided valuable insights into integrating AI-
assisted analytics into complex industrial workflows, specifi-
callyforstreamliningdecision-makinginautomotivesoftware
release validation.
Automotive software integration at the company typi-
cally occurs across three hierarchical stages: subsystem (con-
trol unit), system (multiple control units), and full vehicle
levels. Each stage involves extensive testing, with results
stored in a central database. Critical Go/No-Go decisions
are made at these stages to determine whether a release
meets quality thresholds. However, stakeholders from diverse
8

100
95.92%
80
84.57%
60
60.00%
52.00%
40
42.00%
20
CoT + SC
0
GateLens
0 10 20 30 40 50
Few-shot Num
)%(
1F
Fig. 4: Comparison of GateLens against CoT+SC across
different numbers of few-shot examples.
backgrounds—including project managers, mechanical engi-
neers, and software engineers—must query the raw data to
evaluate product quality. Many lack expertise in data analyt-
ics, creating bottlenecks and delays in the decision-making
process.
Previously, these analytics were managed by a small team
of 2–3 full-time analysts, who were often overwhelmed by
the volume and diversity of requests. Scaling the team to
meetthecurrentdemandwouldhaverequiredtriplingitssize.
GateLens addresses this challenge by automating much of the
workload,enablingmoreefficientdecision-making.Currently,
GateLens is in an extended pilot phase, supporting a pool of
60-80 users. The analytics team has transitioned to a support
role, helping stakeholders articulate their needs into clear,
actionablepromptsforthesystem.UseradoptionofGateLens
has progressed in phases:
• Small-Scale Pilot: The initial deployment within the
analytics team established benchmarks.
• Expanded Pilot: Five additional users from varied back-
grounds contributed to refining the benchmarks.
• WiderRollout:Thecurrentphaseinvolvesalargergroup
of 60–80 users. Feedback has been highly positive, with
stakeholders recognizing GateLens’s ability to simplify
and accelerate complex analyses.
Since the launch, the number of both new and recurring
users has grown, encompassing diverse roles and types of
queries,therebydemonstratingthetool’sincreasingutilityand
trust. GateLens significantly reduces the time and effort re-
quired for complex analyses, but the shift towards automation
also requires users to take on more responsibility in defining
and clarifying their needs. The transition from a primarily
supportive tool to a more fully automated system is ongoing,
demanding a gradual approach with careful calibration to
ensure the tool continues to meet evolving needs.
The diversity in stakeholders’ needs and backgrounds is an
inevitable factor, leading to a wide range of requirements and
queries when interacting with analytics systems. Our prelimi-
naryagenticsystembasedonCoTandSChasperformedwell
whenservingaspecificgroupofstakeholders.However,aswe
openedthesystemtoabroaderaudience,thevarietyofqueries
increased substantially. Systems that rely heavily on few-
shot learning face significant challenges in these situations,
8

=== Page 9 ===
TABLE V: GateLens (zero-shot) vs CoT+SC (few-shot) perform
role tested, CoT+SC was trained using examples from the othe
#Queries GateLens CoT+SC(Few-shotwith
Roles
(244intotal) F1Score F1Score
Mechanically-oriented 36 94.25% 80.60%
Project-oriented 193 80.21% 78.93%
Software-oriented 15 100% 100%
as they are limited by the relatively small set of few-shot
examples, making it difficult to handle a wider range of
potentially unexpected inputs. Similarly, fine-tuned models
often struggle to adapt to dynamic and diverse environments.
Improving generalization is essential to ensure the scalability
and reliability of analytics systems in these complex, domain-
specific contexts. In our design and development work, we
prioritized the system’s ability to generalize effectively and
meet the needs of a broader and more diverse group of users.
To explore the system’s generalizability, we catego-
rized the roles within the company into three groups:
mechanically-oriented,project-oriented,andsoftware-oriented
roles. Mechanically-oriented roles typically focus on truck-
specific data filtering. Project-oriented roles often combine
meta-queries with conditional filters for release management
and statistical analysis. Software roles emphasize truck soft-
ware applications and user functions. We can see from Ta-
ble V, both GateLens (zero-shot) and CoT+SC (few-shot)
exhibitdifferencesinsystemperformanceacrossthesegroups,
which is likely stemming from the complexity and variety
of their typical queries. Nevertheless, the results demonstrate
that GateLens is capable of supporting all groups to a high
degree. To further evaluate CoT+SC’s dependency on few-
shotexamples,weconductedaleave-one-role-outexperiment.
In this approach, examples from a specific role are excluded
in each iteration. For instance, ’without software’ indicates
that all examples from the software-oriented role have been
removed, while the total number of examples is maintained
by substituting them with examples from other roles. This
highlights the potential challenges with the robustness and
generalizability of techniques that rely on few-shot examples.
This is a crucial factor to consider in industries where diverse
teams collaborate and a wide range of queries may arise.
The impact of automated systems, such as GateLens, on
the release process has been substantial. Compared to the
previous manual process, GateLens has reduced the time re-
quiredforGo/No-Goanalyticsbymorethan80%,significantly
improving operational efficiency. Stakeholders can now focus
on high-level decision-making, freed from the burden of data
preparation and analysis.
A key advantage of GateLens lies in its domain-specific
design. Unlike general-purpose tools like TaskWeaver (Qiao
etal.,2023)orAutoGen(Wuetal.,2023),GateLensistailored
to automotive workflows, making it easier to understand,
debug, and adapt to automotive common procedures. This
focusondomainrelevanceensuresthatthesystemalignsmore
closely with stakeholders’ needs while providing reliable and
nuanced support.
Insummary,thedeploymentofGateLensdemonstrateshow
9

mance across different roles on the second benchmark. For each
er two roles only (leave-one-role-out approach).
hAllRoles) CoT+SC(Few-shotwithLeave-One-Role-Out)
WithoutMechanic WithoutProject WithoutSoftware
73.85%↓(-6.75%) 86.57% 80.60%
78.93% 76.22%↓(-2.71%) 78.40%
100% 100% 82.76%↓(-17.24%)
domain-specific AI solutions can transform critical workflows
in the automotive sector. By automating labor-intensive pro-
cessesandenhancingdecision-making,GateLenshasdelivered
measurable improvements in efficiency and user satisfaction.
However, its success depends on ongoing refinement and
careful management of the transition to full(er) automation.
Balancing automation with user empowerment remains cru-
cial,particularlyinacomplexindustrylikeautomotive,where
diverse stakeholder needs must be met.
GateLens represents a promising step forward, showcasing
the potential of AI-driven systems to improve not only the
automotive domain but also other industries requiring robust,
scalable solutions for intricate processes.
VI. RELATEDWORK
General-purpose LLMs are primarily designed for and
trained on natural languages. Working with tabular data re-
quires specialized adaptations to effectively handle its struc-
turedandheterogeneousnature(Fangetal.,2024;Wangetal.,
2024b; van Breugel and van der Schaar, 2024). First, the
structured tabular data is typically transformed into serialized
text. The performance of the LLM may depend on this
transformation (Min et al., 2024). Subsequently, the serialized
text data is used as input to the LLM for various tasks, such
as question-answering, summarization, or logical reasoning.
Common approaches to improve LLM performance include
prompt engineering, pre-training, fine-tuning, and Retrieval-
Augmented Generation (RAG).
Pre-training and fine-tuning (Zhang et al., 2023b;
Parthasarathyetal.,2024;VMetal.,2024;Dongetal.,2022;
Hegselmann et al.) often face scalability concerns. Although
resource-efficient training techniques have been proposed to
mitigatethesubstantialcomputationaldemandsofLLMs(Han
et al., 2024; Lin et al., 2024), in safety-critical applications
with evolving data and requirements, training LLMs presents
significantchallengesduetotheconstantneedforrigorousval-
idation and verification. This ongoing necessity substantially
increasesresourcedemandsfordevelopmentandmaintenance,
potentiallyexceedingthecapacitiesofmanycompanies.Tech-
niques such as RAG have been employed to dynamically
integrate external knowledge bases during inference, reducing
the need for frequent model updates (Zhao et al., 2024; Gao
et al., 2023). However, such methods can pose challenges in
safety-critical industrial settings as well, since both retrieval
modules and model components must undergo synchronized
updatestomaintainrelevance,reliability,andcompliancewith
validation and verification requirements. Costs would also
be especially high with fine-tuning since re-tuning would be
needed when new and improved base LLMs are released and
should be incorporated.
9

=== Page 10 ===
Prompt engineering techniques are among the most
resource-efficient methods for improving LLM output (Sahoo
et al., 2024; Jin and Lu, 2023). From a user standpoint, when
the input is natural language, prompting techniques can be
broadly categorized based on the type of language generated
by the LLM. These include outputs in natural language,
structured languages (Li et al., 2023), or symbolic languages.
Whenthegeneratedlanguageisnaturallanguage,LLMsoften
fail to consistently follow instructions, particularly when the
instructions are complex or require precise, step-by-step exe-
cution (Pham et al., 2024). This inconsistency arises because
natural language, while flexible and expressive, can be am-
biguous and prone to misinterpretation by LLMs. Structured
languagesincludegeneral-purposelanguages(e.g.Python)(Ye
et al., 2024), query languages (e.g. SQL) (Li et al.; Dong
et al., 2023; Mouravieff et al., 2024), configuration formats
(e.g. YAML or JSON), or other Domain-Specific Languages
(DSLs)(Glennetal.,2024;Daietal.,2024).Theselanguages
aresubsequentlyinterpretedand/orexecutedbyeitherexternal
tools, the same LLM, or another LLM agent. This approach
offerssignificantadvantages,asitenablespreciseexecutionof
tasks. Another popular type of output is symbolic languages.
Literatureshowsthatsymbolicrepresentationsprovideamore
rigorousframeworkforarticulatingpremisesandintent,which
can enhance reasoning capabilities (Pan et al., 2023).
In this paper, we introduce a novel prompt-only (training-
free) approach that bridges natural language and executable
codethroughRA,asymbolicformalismdesignedforrelational
modeling and ideally suited for analyzing tabular data. Unlike
prior work that often relies on complex multi-agent planning,
our approach leverages RA as a lightweight intermediate
representation to enable precise query normalization, disam-
biguation of natural language input, and efficient code gener-
ation. RA acts as an abstraction layer that can target multiple
executionbackends(e.g.,Python,SQL),providingadaptability
across systems. In GateLens, we generate Python code to
support practical industrial deployment and high-performance
execution. GateLens is training-free, feed-forward (single-
pass, without looping or multi-agent orchestration), and thus
easier to verify, trace, maintain, and trust – qualities critical
for safety-critical industrial applications.
VII. DISCUSSIONANDCONCLUSIONS
This study introduced GateLens, a reasoning-enhanced
LLM agent designed for automotive software release vali-
dation. By introducing RA as an intermediate representation
before code generation, Gatelens addresses the ”Unfaithful
Chain-of-Thought (CoT) reasoning” problem in code genera-
tion, where reasoning steps in CoT explanations do not accu-
ratelyreflectthemodel’sactualthoughtprocess(Turpinetal.,
2023). Specifically, GateLens divides the analysis into two
steps: (1) natural language queries are first translated into RA
expressions, and (2) these RA expressions are then converted
into executable code. We use Python as our target language
in step (2) due to its widespread use in our partner company
andthemodel’sstrongperformanceinPython,whichbenefits
1

from more extensive training data. However, this step is also
compatible with RA-to-SQL generation, enabling flexibility
across backends. The inclusion of the RA reasoning module
is a critical factor in improving robustness and scalability, as
evidenced by superior F1 scores in both benchmarking and
industrial evaluations.
In real-world deployment serving 60-80 users, GateLens
demonstrates significant practical value through its user-
friendly interface and robust query processing capabilities,
with users particularly appreciating the flexibility to input,
debug, and refine queries easily. This marks a substantial ad-
vancementinindustrialdatainteraction,successfullyhandling
complex and ambiguous queries while providing practical
support for faster decision-making in safety-critical software
release processes. GateLens demonstrates significant practical
advancements by reducing analysis time by over 80% while
maintaining high accuracy in test result interpretation, impact
assessment, and release candidate evaluation.
Our implementation insights highlight the advantages of
focusing on training-free and single-pass agent systems by
foregrounding the perception phase in the code generation
pipeline. This modular architecture opens opportunities for
incorporatingemergingLLMcapabilitieswhilepreservingthe
system’s practical utility in safety-critical industrial applica-
tions. A phased deployment program is ongoing and shows
that multiple stakeholder groups can be supported, though
the evolving roles and analytical needs require continued
refinement.
Future work will address current limitations by expanding
domain applicability beyond automotive software and testing
alternative LLM configurations to enhance reliability across
othersafety-criticalindustries.Thisapproachdemonstratesthe
potentialforLLM-basedsolutionstotransformindustrialdata
analysis workflows while maintaining the reliability standards
required for critical applications.
VIII. THREATSTOVALIDITY
The validity of our findings is subject to several potential
threats. First, this framework depends on well-defined, static
schemas for accurate query decomposition, which fundamen-
tally limits its effectiveness in environments with incomplete
or frequently changing schemas. Second, the generalizability
of GateLens beyond the automotive software release domain
is limited, as the system relies on domain-specific relational
modelinganddatasets,necessitatingfurthervalidationinother
safety-critical industries. Third, the benchmarks and query
scenarios used for evaluation, derived from historical data
and real-world queries, may not fully capture the diversity
and complexity of potential use cases, which could impact
the robustness of the system in broader deployments. Finally,
the system’s performance depends on the specific LLM con-
figurations used, such as GPT-4o and Llama 3.1 70B, and
their ability to interpret and generate RA expressions. Future
work will address these limitations through broader domain
testing, expanded evaluation scenarios, and alternative LLM
configurations.
10

=== Page 11 ===
ACKNOWLEDGMENTS
This work was partially supported by the Wallenberg AI,
Autonomous Systems and Software Program (WASP) funded
by the Knut and Alice Wallenberg Foundation.
REFERENCES
M. Liu, J. Wang, T. Lin, Q. Ma, Z. Fang, and Y. Wu, “An
empirical study of the code generation of safety-critical
software using llms,” Applied Sciences, vol. 14, p. 1046,
2024.
Y. Chang, X. Wang, J. Wang, Y. Wu, L. Yang, K. Zhu,
H. Chen, X. Yi, C. Wang, Y. Wang et al., “A survey on
evaluation of large language models,” ACM Transactions
on Intelligent Systems and Technology, vol. 15, no. 3, pp.
1–45, 2024.
M. Leung and G. Murphy, “On automated assistants for soft-
ware development: the role of llms,” 2023 38th IEEE/ACM
International Conference on Automated Software Engineer-
ing (ASE), pp. 1737–1741, 2023.
N. Marques, “Using chatgpt in software requirements engi-
neering: a comprehensive review,” Future Internet, vol. 16,
p. 180, 2024.
J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski,
D. Dohan, E. Jiang, C. Cai, M. Terry, Q. Le et al., “Pro-
gram synthesis with large language models,” arXiv preprint
arXiv:2108.07732, 2021.
E. Miehling, K. N. Ramamurthy, K. R. Varshney, M. Riemer,
D. Bouneffouf, J. T. Richards, A. Dhurandhar, E. M. Daly,
M. Hind, P. Sattigeri et al., “Agentic ai needs a systems
theory,” arXiv preprint arXiv:2503.00237, 2025.
L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang, J. Zhang,
Z. Chen, J. Tang, X. Chen, Y. Lin et al., “A survey on
large language model based autonomous agents,” Frontiers
of Computer Science, vol. 18, no. 6, p. 186345, 2024.
L.P.Manik,Z.Akbar,H.F.Mustika,A.Indrawati,D.S.Rini,
A. D. Fefirenta, and T. Djarwaningsih, “Out-of-scope in-
tentdetectiononaknowledge-basedchatbot.”International
JournalofIntelligentEngineering&Systems,vol.14,no.5,
2021.
T. Khot, H. Trivedi, M. Finlayson, Y. Fu, K. Richardson,
P. Clark, and A. Sabharwal, “Decomposed prompting:
A modular approach for solving complex tasks,” arXiv
preprint arXiv:2210.02406, 2022.
J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi,
Q. V. Le, D. Zhou et al., “Chain-of-thought prompting
elicits reasoning in large language models,” Advances in
neural information processing systems, vol. 35, pp. 24824–
24837, 2022.
Z. Zhang, Y. Yao, A. Zhang, X. Tang, X. Ma, Z. He,
Y. Wang, M. Gerstein, R. Wang, G. Liu et al., “Igniting
language intelligence: The hitchhiker’s guide from chain-
of-thought reasoning to language agents,” arXiv preprint
arXiv:2311.11797, 2023.
A. T. P. Boudewijn, A. F. Ferraris, D. Panfilo, V. Cocca,
S. Zinutti, K. De Schepper, and C. R. Chauvenet, “Privacy
measurements in tabular synthetic data: State of the art and
1

future research directions,” in NeurIPS 2023 Workshop on
Synthetic Data Generation with Generative AI, 2023.
X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang,
A. Chowdhery, and D. Zhou, “Self-consistency improves
chain of thought reasoning in language models,” arXiv
preprint arXiv:2203.11171, 2022.
N. F. Liu, K. Lin, J. Hewitt, A. Paranjape, M. Bevilac-
qua, F. Petroni, and P. Liang, “Lost in the middle:
How language models use long contexts,” arXiv preprint
arXiv:2307.03172, 2023.
B. Qiao, L. Li, X. Zhang, S. He, Y. Kang, C. Zhang, F. Yang,
H. Dong, J. Zhang, L. Wang et al., “Taskweaver: A code-
first agent framework,” arXiv preprint arXiv:2311.17541,
2023.
Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li,
L.Jiang,X.Zhang,andC.Wang,“Autogen:Enablingnext-
gen llm applications via multi-agent conversation frame-
work,” arXiv preprint arXiv:2308.08155, 2023.
X. Fang, W. Xu, F. A. Tan, J. Zhang, Z. Hu, Y. J. Qi,
S. Nickleach, D. Socolinsky, S. Sengamedu, C. Faloutsos
et al., “Large language models (llms) on tabular data:
Prediction, generation, and understanding-a survey,” 2024.
Z. Wang, H. Zhang, C.-L. Li, J. M. Eisenschlos, V. Perot,
Z. Wang, L. Miculicich, Y. Fujii, J. Shang, C.-Y. Lee et al.,
“Chain-of-table: Evolving tables in the reasoning chain
for table understanding,” arXiv preprint arXiv:2401.04398,
2024.
B. van Breugel and M. van der Schaar, “Why tabular founda-
tion models should be a research priority,” arXiv preprint
arXiv:2405.01147, 2024.
D. Min, N. Hu, R. Jin, N. Lin, J. Chen, Y. Chen, Y. Li,
G.Qi,Y.Li,N.Lietal.,“Exploringtheimpactoftable-to-
text methods on augmenting llm-based question answering
withdomainhybriddata,”arXivpreprintarXiv:2402.12869,
2024.
T. Zhang, X. Yue, Y. Li, and H. Sun, “Tablellama: Towards
open large generalist models for tables,” arXiv preprint
arXiv:2311.09206, 2023.
V. B. Parthasarathy, A. Zafar, A. Khan, and A. Shahid, “The
ultimate guide to fine-tuning llms from basics to break-
throughs: An exhaustive review of technologies, research,
best practices, applied research challenges and opportuni-
ties,” arXiv preprint arXiv:2408.13296, 2024.
K. VM, H. Warrier, Y. Gupta et al., “Fine tuning llm for en-
terprise: Practical guidelines and recommendations,” arXiv
preprint arXiv:2404.10779, 2024.
H. Dong, Z. Cheng, X. He, M. Zhou, A. Zhou, F. Zhou,
A. Liu, S. Han, and D. Zhang, “Table pre-training: A
survey on model architectures, pre-training objectives, and
downstreamtasks,”arXivpreprintarXiv:2201.09745,2022.
S. Hegselmann, A. Buendia, H. Lang, M. Agrawal, X. Jiang,
and D. Sontag, “TabLLM: Few-shot Classification of Tab-
ular Data with Large Language Models.”
Z.Han,C.Gao,J.Liu,J.Zhang,andS.Q.Zhang,“Parameter-
efficient fine-tuning for large models: A comprehensive
survey,” arXiv preprint arXiv:2403.14608, 2024.
11

=== Page 12 ===
X. Lin, W. Wang, Y. Li, S. Yang, F. Feng, Y. Wei, 29838, 2024.
and T.-S. Chua, “Data-efficient fine-tuning for llm- L. Pan, A. Albalak, X. Wang, and W. Y. Wang, “Logic-
based recommendation,” in Proceedings of the 47th lm: Empowering large language models with symbolic
International ACM SIGIR Conference on Research and solvers for faithful logical reasoning,” arXiv preprint
Development in Information Retrieval, ser. SIGIR ’24. arXiv:2305.12295, 2023.
New York, NY, USA: Association for Computing M. Turpin, J. Michael, E. Perez, and S. Bowman, “Language
Machinery, 2024, p. 365–374. [Online]. Available: models don’t always say what they think: Unfaithful expla-
https://doi.org/10.1145/3626772.3657807 nationsinchain-of-thoughtprompting,”AdvancesinNeural
P. Zhao, H. Zhang, Q. Yu, Z. Wang, Y. Geng, F. Fu, InformationProcessingSystems,vol.36,pp.74952–74965,
L. Yang, W. Zhang, and B. Cui, “Retrieval-augmented gen- 2023.
eration for ai-generated content: A survey,” arXiv preprint
arXiv:2402.19473, 2024.
Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai,
J. Sun, and H. Wang, “Retrieval-augmented generation
for large language models: A survey,” arXiv preprint
arXiv:2312.10997, 2023.
P. Sahoo, A. K. Singh, S. Saha, V. Jain, S. Mondal, and
A. Chadha, “A systematic survey of prompt engineering in
largelanguagemodels:Techniquesandapplications,”arXiv
preprint arXiv:2402.07927, 2024.
Z. Jin and W. Lu, “Tab-cot: Zero-shot tabular chain of
thought,” arXiv preprint arXiv:2305.17812, 2023.
C. Li, J. Liang, A. Zeng, X. Chen, K. Hausman, D. Sadigh,
S. Levine, L. Fei-Fei, F. Xia, and B. Ichter, “Chain of
code: Reasoning with a language model-augmented code
emulator,” arXiv preprint arXiv:2312.04474, 2023.
C. M. Pham, S. Sun, and M. Iyyer, “Suri: Multi-constraint
instruction following for long-form text generation,” arXiv
preprint arXiv:2406.19371, 2024.
J. Ye, M. Du, and G. Wang, “DataFrame QA: A Universal
LLM Framework on DataFrame Question Answering
Without Data Exposure,” 2024, version Number: 1.
[Online]. Available: https://arxiv.org/abs/2401.15463
J. Li, B. Hui, G. Qu, J. Yang, B. Li, B. Li, B. Wang, B. Qin,
R. Geng, N. Huo, X. Zhou, C. Ma, G. Li, K. C. C. Chang,
F. Huang, R. Cheng, and Y. Li, “Can LLM Already Serve
as A Database Interface? A BIg Bench for Large-Scale
Database Grounded Text-to-SQLs.”
X. Dong, C. Zhang, Y. Ge, Y. Mao, Y. Gao, J. Lin, D. Lou
et al., “C3: Zero-shot text-to-sql with chatgpt,” arXiv
preprint arXiv:2307.07306, 2023.
R. Mouravieff, B. Piwowarski, and S. Lamprier, “Learning
relational decomposition of queries for question answering
from tables,” in Proceedings of the 62nd Annual Meeting
of the Association for Computational Linguistics (Volume
1: Long Papers), L.-W. Ku, A. Martins, and V. Srikumar,
Eds. Bangkok, Thailand: Association for Computational
Linguistics, Aug. 2024, pp. 10471–10485. [Online].
Available: https://aclanthology.org/2024.acl-long.564/
P.Glenn,P.P.Dakle,L.Wang,andP.Raghavan,“Blendsql:A
scalable dialect for unifying hybrid question answering in
relational algebra,” arXiv preprint arXiv:2402.17882, 2024.
H. Dai, B. Wang, X. Wan, B. Dai, S. Yang, A. Nova, P. Yin,
M. Phothilimthana, C. Sutton, and D. Schuurmans, “UQE:
A query engine for unstructured databases,” Advances in
NeuralInformationProcessingSystems,vol.37,pp.29807–
12

Paper:GoNoGo - An Efficient LLM-based Multi-Agent System.pdf
=== Page 1 ===
GoNoGo: An Efficient L
System for Streamlinin
Release Deci
Arsham Gholamzadeh Khoee
Yu1[0000−0002−3221−7517], Robert Feldt1[
Patrick Andersson Rh
Parthasarathy2[00
1 Department of Computer Science an
Technology, Gothenburg, Sweden {khoee
2 Volvo Group, Gothenburg, Sweden {a
dhasarathy.parthas
Abstract. Traditional methods for
sions in the automotive industry t
tabularsoftwaretestdata.Theseme
delays in the software release cycle
Large Language Models (LLMs) pr
challenges.However,theirapplicatio
ofhuman-drivenpromptengineering
ment,particularlyforindustrialend
results. In this paper, we propose G
signedtostreamlineautomotivesoft
functionalrequirementsandpractic
vioussystems,GoNoGoisspecificall
and risk-sensitive systems. We eval
different task difficulties using zero
fromindustrialpractice.Ourresults
success rate for tasks up to Level 2
maintains high performance even fo
GoNoGoeffectivelyautomatesdecis
cantlyreducingtheneedformanual
represents an efficient and user-frie
employedinourindustrialpartner’s
leasedecision-making,supportingm
the release process for risk-sensitive
Keywords: LLMs · LLM-based M
tant · Table Analysis Automation ·
1 Introduction
In the automotive industry, decisions a
larly embedded software in risk-sensitiv
4202
peS
92
]IA.sc[
2v58790.8042:viXra

LLM-based Multi-Agent
ng Automotive Software
ision-Making
e1,2[0000−0002−5130−5520], Yinan
[0000−0002−5179−4205], Andris Freimanis2,
hodin2, and Dhasarathy
000−0002−3620−8589]
nd Engineering, Chalmers University of
e, yinan, robert.feldt}@chalmers.se
andris.freimanis, patrick.andersson,
sarathy}@volvo.com
r making software deployment deci-
typically rely on manual analysis of
ethodsoftenleadtohighercostsand
due to their labor-intensive nature.
resent a promising solution to these
ongenerallydemandsmultiplerounds
g,whichlimitstheirpracticaldeploy-
d-userswhoneedreliableandefficient
GoNoGo, an LLM agent system de-
twaredeploymentwhilemeetingboth
calindustrialconstraints.Unlikepre-
lytailoredtoaddressdomain-specific
luate GoNoGo’s performance across
o-shot and few-shot examples taken
sshowthatGoNoGoachievesa100%
difficulty with 3-shot examples, and
or more complex tasks. We find that
sion-makingforsimplertasks,signifi-
lintervention.Insummary,GoNoGo
endly LLM-based solution currently
scompanytoassistwithsoftwarere-
moreinformedandtimelydecisionsin
e vehicle systems.
Multi-agent · Software Release Assis-
Risk-sensitive Systems.
about when to release software, particu-
ve systems, carry immense weight. The

=== Page 2 ===
2 A. Khoee et al.
complexity of modern vehicles, with the
complicatesthisprocess.Eachintegratio
with tests conducted to verify whether
candelaytheintegrationofalldependen
ualquality.Inthisintricateprocess,rele
of gatekeeping could greatly benefit fro
decisions.
Query: For each release candidate, list
fail the most.
date uniqueID name function
19 0 / 0 0 : 6 0 / 0 2 :0 0 0 23 1000 RX-171 Pre- C S o y n s d te it m ioning
19 0 / 0 0 : 6 0 / 0 2 :0 0 0 23 1007 CM-124 Launch Assist
19 0 / 0 0 : 6 0 / 0 2 :0 0 0 23 1007 CM-124 Syn S c m hr a o r n t i K z e a y ti on
24 0 / 0 0 : 2 0 / 0 2 :0 0 0 23 695 RX-126 De V f e ro ri s fi t c S a y ti s o t n em
19 0 / 0 0 : 6 0 / 0 2 :0 0 0 23 1007 CM-124 Co D n y t n ro a l m D i i c a C gn ru o i s s t e i
. . . .
. . . .
. . . .
Field Definitions:
euf: End User Function (E
...
Task planning:
Your role is to plan tabula
decomposing a user quer
be performed to finish th
...
Goals:
Decompose the user que
performed with Python a
...
Constraints:
Do NOT make assumptio
use values that are explic
...
Result: releasecandidate
Zorn
Quasar
.
.
.
Fig.1.Anactualexampledemonstratingth
for automating ad-hoc tabular data analys
Large language models (LLMs) pres
such assistance. In particular, LLMs h

eir multiple levels of integration, further
onlevelinvolvesoneormoregatingsteps,
r gate criteria are fulfilled. Gate failures
ntsubsystems,regardlessoftheirindivid-
easemanagers,bearingtheresponsibility
om assistance to make faster and better
t the test case functions that
... result_statusreleasecandidate euf
g ... NOK Etheris Provid C e o C m a f b o C rt limate
... NOK Etheris Provid C e o C m a f b o C rt limate
n ... OK Etheris Lock Control
m ... NOK Elowen Provid C e o C m a f b o C rt limate
e ic s ... NotRun Etheris V C e L o h im n ic t l i r e t o a S l t i p a o e n n e d d
. . . . . . . . . . . .
EUF) of the test case.
ar data analysis tasks. You do this by
ry into predefined steps that need to
he analysis.
ery into actionable steps to be
and pandas.
ons about values in any column, only
citly provided to you.
function
Power Level Monitor
Climate Status Indicator
.
.
.
heuseoftheLLM-basedmulti-agentsystem
sis.
sent an interesting avenue for providing
have demonstrated strong capabilities in

=== Page 3 ===
GoNoGo: So
zero- and few-shot settings with in-con
have improved reasoning [32], exemplar
panies now use LLMs for software engin
eration, and documentation and resear
tomation improvements over the state-o
However,whenapplyingLLMstoris
unique challenges must be addressed. I
themostprominentchallengesinclude1
nology relevant to the domain; 2) Unde
orvaguelanguageusedbynon-expertst
tionable plans, 3) Enabling interpretabi
system functionality to stakeholders wit
efficiently to meet the time-critical dema
igating potential bottlenecks related to
and5)Designingthesystemtoenablee
ensuring that any issues can be quickly
To address these challenges, we pro
domain-specific requirements using in-c
twoprimaryLLMagents:aPlannerand
ner, which forms the core of the syste
queriesintostep-by-stepinstructionsfor
thesizes and generates executable scrip
Within the Actor, a coder LLM utilizes
memory to produce the most effective P
given data for each instruction generate
This system provides an interface f
illustrated by Figure 1, which shows a
end-users, like release managers, to inte
perspectivewithoutneedingdetailedtec
simply receive a short table that reports
themostforeachreleasecandidateassh
mation,releasemanagerscanmakewell-
the software or not, ensuring that it me
standards in the automotive industry.
time and resources by eliminating the n
ming experts to achieve the desired resu
testdataanalysisacrossmultiplevehicle
ing detailed reports on component func
assists release managers in making infor
forrelease,acceleratingdevelopmentwh
contributions can be summarized as foll
– Wehighlightthepracticalityofthep
in making software release decisions
achieved by enhancing two key capa

oftware Release Multi-agent System 3
ntext learning [5]. Recent advancements
r selection, and prompt design [7]. Com-
neering tasks like API testing, code gen-
rch studies have already shown test au-
of-the-art [28].
sk-sensitive domain-specifictasks,several
In our research with industrial partners,
1)Incorporatingspecificlogicandtermi-
erstanding and parsing high-level queries
takeholdersandtranslatingthemintoac-
ility so that domain experts can explain
thout excessive complexity, 4) Operating
ands of organizational applications, mit-
limited LLM licensing or infrastructure,
easeoftroubleshootingandmaintenance,
identified and resolved.
opose a multi-agent system that encodes
context learning. This system comprises
danActor(refertoFigure2).ThePlan-
em, comprehends and decomposes user
rdataanalysis[14].TheActorthensyn-
pts from these higher-level instructions.
s the self-reflection mechanism besides a
Python script optimized for querying the
ed by the Planner [1,28].
for end-users at our industrial partner,
real-world example of its use. It allows
erpret results from a business and safety
chnicalknowledge.Forexample,theycan
s the test case functions that have failed
howninFigure1.Byreviewingthisinfor-
-informeddecisionsonwhethertorelease
eets both business objectives and safety
This approach can significantly reduce
need for various database and program-
ults for end-users. Our agent automates
edevelopmentintegrationlevels,provid-
ctionality and system interactions. This
rmed decisions about software readiness
hileenhancinggatekeepingreliability.Our
lows:
proposedLLM-basedintelligentassistant
s within the automotive industry. This is
abilities:

=== Page 4 ===
4 A. Khoee et al.
• Domain-specificity: We desig
queriesfromnon-expertstakehol
ping generic language to domain
• Risk-sensitivity: We incorpor
restrict the action space and i
planner.
– Experiments on a total of 50 crafte
system is effective at analyzing dat
software release decision-making.
– Our system, now deployed and activ
company,hasdemonstratedsignifica
decision-making process besides sav
ing reliance on specialized analysts,
The remainder of this paper is stru
overviewofthemanualprocessbehinda
the need for streamlining operations. S
a description of the architecture of our
explanation of the Planner and Actor
present our experimental setup and res
similar research in LLMs for data ana
paper by summarizing key findings and
our work in the context of industrial
sensitive systems.
2 Manual Process of Releas
the Industry
Decidingtogoahead,ornot,withasoft
is a complex task involving multiple st
This section reviews the current, and t
workflow and the need for streamlining.
Vehicledevelopmentprogressesthrou
complex as more components are integr
eachstagetoensurefunctionalityandid
ofdata.Softwarecomponentsrequirere
this data.
Project managers, verification engin
analytics and insights from these tests
cisions. Extracting essential informatio
analyze data for continuous improveme
information to make informed release d
Withinthisprocess,statisticiansprov
managers and quality engineers for futu
cessingisnecessaryduetothecriticalna

gn a framework to handle unstructured
ldersintheautomotiveindustrybymap-
n-specific logic using in-context learning.
rate two predefined atomic operations to
improve the risk-sensitive aspect of the
ed test queries show that our proposed
ta and deriving the required insights for
vely used within our industrial partner’s
antimprovementsinthesoftwarerelease
ving time, improving accessibility, reduc-
, and accelerating overall workflow.
uctured as follows: Section 2 provides an
automotivesoftwarereleasedecisionsand
Section 3 details our approach, including
r LLM-based multi-agent system and an
agents. Furthermore, in Section 4, we
sults. Section 6 provides an overview of
alysis. Finally, Section 7 concludes the
d discussing the broader implications of
software release management and risk-
se Decisions: Insights From
twarereleaseintheautomotiveindustry
takeholders and extensive data analysis.
typical of the industry at large, manual
.
ughmultiplephases,eachbecomingmore
rated. Numerous tests are conducted at
dentifyrevisions,generatingvastamounts
epeatedtestingandvalidation,addingto
neers, and quality engineers need clear
s in order to make software release de-
on is time-consuming. Quality engineers
ent, while release engineers need specific
decisions.
videanoverallviewofthedatatoproject
ure business decisions. Manual data pro-
atureofthesedecisionsandtheirimpact

=== Page 5 ===
GoNoGo: So
on consumer safety. However, this app
errors, partly due to the differing persp
statisticians, who may not fully underst
A critical and typical stage in this
where vehicles equipped with the necess
and rigorous testing of their systems in
tests,releasemanagersanalyzelargeam
to the next test stage. This involves man
that support informed decisions. Error
timely software release, affect business g
Thedeploymentofanintelligentassi
ware release decisions in the automotiv
critical testing on a closed track phase
signing such an LLM-based multi-agent
specificstage.Byrapidlyprocessingtest
temcangeneratecomprehensivereports
Forexample,itcanquicklycompilesum
performance trends across vehicle mode
havior under various conditions. Conse
initial analysis, allowing release manag
making informed decisions. This not on
but also enhances the accuracy and re
lease decisions, ultimately contributing
standards in automotive software develo
3 GoNoGo: Intelligent Softw
3.1 System Requirements
After discussing current needs and opi
sis and decision-making processes with
following main challenges in automating
Understanding User Queries The s
presentedinnaturallanguage[17],w
any provided domain-specific knowl
Translating User Queries to Action
verttheuser’squeryintoconcretest
simpler tasks, determining the orde
ate data manipulation or analysis te
must be carefully managed to adher
Execution and Result Preparation
actions,interactwithdatausingscri
calculations,applyingfilters),andco
for the user.

oftware Release Multi-agent System 5
proach is time-consuming and prone to
pectives of technical data analyzers and
tand the project managers’ goals.
s process is “Testing on Closed Track,”
sary software release undergo systematic
n a controlled environment. After these
mountsofdatatodecidewhethertomove
nually querying data to generate reports
rs or delays in this analysis can hinder
goals, and delay subsystem integration.
istanthasthepotentialtofacilitatesoft-
ve industry [20], particularly during the
e. In this work, we have focused on de-
t system to address the challenges of this
tdatafromclosedtracktesting,thesys-
stailoredtodifferentstakeholders’needs.
mmariesoffailedtests,highlightsoftware
els, or analyze a specific component’s be-
equently, this reduces the time spent on
gers to focus on interpreting results and
nly accelerates the development process
eliability of the information used in re-
g to maintaining high safety and quality
opment.
ware Release Assistant
inions about the software release analy-
our industrial partner, we identified the
g data analysis:
system must interpret queries, typically
withinthespecificdomaincontext,using
ledge.
nable Steps The system needs to con-
teps,breakingdowncomplexqueriesinto
er of operations, and selecting appropri-
echniques. Additionally, the action space
re to risk-sensitive requirements.
n The system must execute the planned
ipts(e.g.,queryingdatabases,performing
ompiletheresultsintothedesiredformat

=== Page 6 ===
6 A. Khoee et al.
These steps rely heavily on the LLM’s d
ability, crucial for effective query instru
work explores techniques for enhancing
systems, particularly for the analysis of
3.2 System Architecture
Our approach to automating tabular d
anintelligentsystemcapableofinterpre
complex analyses, and delivering desire
sists of two main components: the Plann
Examples for few-shot learning and th
module, and some Plugin components.
ture of the developed system.
Planner GoNoGo Agent
Running time: <= 120 secs
High-l evel
Query LLM
Knowledge Base Plan
Examples
Fig.2. Architecture of the LLM-based m
illustration of the interaction procedure o
queriesfrom theend user,performs thereq
resulttableasadecisionsupportresource.
interprets queries and devises analysis str
andself-consistency,supportedbyaKnowl
ing.TheActorincludesaCoderLLMwith
ory and Plugins for code generation and e
GoNoGo for one user query is approximate
requirements.
Planner ThePlanneristhecoreofour
queries and devising appropriate analys
of designing an LLM-based multi-agen
prompting. As decision-making become
agents, the uncertainty within the mu
this, we centralize the complexity with

domain-specific knowledge and reasoning
uction planning [18]. Consequently, this
the reasoning capabilities of LLM agent
f tabular data in industrial contexts.
data analysis leverages LLMs to create
etingnaturallanguagequeries,executing
ed results. The system architecture con-
ner supported by a Knowledge Base and
he Actor including coder LLM, memory
Figure 2 illustrates the overall architec-
Actor
Coder LLM with
Self- reflection
Result Table
Memory <= 20 records (rows)
Plugins
multi-agent system GoNoGo along with the
of the system. GoNoGo receives high-level
quired datamanipulations, andoutputs the
GoNoGocomprisesaPlanneragent,which
rategies using Chain-of-Thought prompting
ledgeBase andExamples forfew-shotlearn-
aSelf-reflection mechanism,utilizingMem-
error resolution. The total running time of
ely 120 seconds, which satisfies typical user
system,responsibleforinterpretinguser
sis strategies. One of the core challenges
nt system is the inherent inaccuracy of
es more distributed over multiple LLM
ulti-agent system increases. To mitigate
hin the Planner, which is responsible for

=== Page 7 ===
GoNoGo: So
the majority of design choices. By focu
for refinement, we aim to create a syste
maintainable.
Ourproblemconsistsoftwomainasp
Thesetwocharacteristicsfrequentlyman
particularly in fields such as healthcare
inaccuracies can have significant conseq
gap in addressing both aspects simult
systemsinpractice.Aspartofoursyste
these aspects. As the Planner is the com
responsibility, these two requirements a
depicted in Figure 3.
Planner Promp
Domain- specificity
Knowledge Base Integration
Few-s hot Learning
Analytical Constraints
Query Plan Optimization
Fig.3.Plannerpromptingstrategiesaddre
in the LLM-based agent system for tabular
Domain-specificity ThePlannerutiliz
tured description of the data and its att
and domain-specific information in the
the system’s performance and applicabi
a comprehensive repository of metadata
tables, possible states and values for ess
nologies,aswellasthesemanticmeanin
the system to understand and interpret
ate analysis plans by using this informa
taking advantage of in-context learning.
pipeline, from query interpretation to re
domain knowledge, enabling the LLM a
and specialized responses to user querie
In our system architecture, we also
ples into the Planner, allowing few-shot
This combination enables the Planner t
drawing on both general knowledge and

oftware Release Multi-agent System 7
using on the Planner as the main agent
em that is both interpretable and easily
pects:domain-specificityandrisk-sensitivity.
nifesttogetherinreal-worldapplications,
and automotive, where unreliability and
quences. However, there is a noticeable
taneously, let alone demonstrating such
em,wewanttoexplicitlyaddressbothof
mponent with the most decision-making
are encoded into the Planner prompts as
pting Strategies
Risk-s ensitivity
Pre- defined Atomic Actions:
Slicing
Operation
Chain-o f-T houghts (CoT) Prompting
Self-c onsistency
essingdomain-specificityandrisk-sensitivity
r data analysis.
zesaKnowledgeBasecontainingastruc-
tributes to provide the necessary context
e prompts given to the LLM, enhancing
ility [15]. The Knowledge Base serves as
a, including detailed descriptions of data
sential fields, and domain-specific termi-
ngsofvariousdataelements.Thisenables
t high-level queries and devise appropri-
ation as input prompts for the Planner,
. This integration ensures that the entire
esult generation, is informed by relevant
agent to provide more accurate, relevant,
es.
feed some input-output pairs as exam-
t learning alongside the Knowledge Base.
to interpret user queries more effectively,
d specific task examples to formulate ap-

=== Page 8 ===
8 A. Khoee et al.
propriate analysis plans. This approach
automated tabular data analysis across
Helpfulpromptsserveasconstraints,
ities[13].Forexample,constraintshelpt
accountformorethanjustbinarystates
‘A’ and its opposite doesn’t always me
binary states might exist. For instance,
compass all possible test statuses; there
such as ‘N/A’, that the model should ta
Thefocusisonpushingthemodelto
involves narrowing down data through fi
sorting and other operations on the re
Accordingly, designed constraints help
each field and the data, providing more
Risk-sensitivity We guide the Plann
to limit the action space of the planner
specifying the columns to select and th
datatobeanalyzed.Operationinvolves
mean, count, etc.) to be performed on t
data obtained from the slicing step. Th
list, with each step described in natura
and column names.
Also, we leverage Chain-of-Though
the reasoning capabilities of our LLM-b
rates intermediate reasoning steps into
downcomplexproblemsintosmaller,mo
mimics human-like reasoning and probl
prompting makes the agent’s decision-m
plicitlyshowingthereasoningsteps,allo
arrived at a particular conclusion or ana
We combine CoT prompting with fe
that not only show input-output pairs b
ing steps. This synergy further enhanc
and complex data analysis tasks [10].
Tofurtherimprovereasoning,weem
CoT prompting. This involves generatin
for the same query, comparing them for
to determine the most reliable outcome
paths, the system becomes less likely t
thought. As a result, for queries with p
help identify different valid interpretati
answer.

h makes the system a powerful tool for
various industries and use cases.
,enhancingtheLLM’sreasoningcapabil-
themodelunderstandthatqueriesshould
sforsomefields.Retrievingrecordswith
ean retrieving all records, as other non-
, ‘successful’ and ‘failed’ tests don’t en-
e may be additional statuses to consider,
ake into account.
ogenerateanoptimizedqueryplan.This
filtering and selection before performing
educed dataset to minimize processing.
the agent explore the characteristics of
e accurate planning.
ner with two pre-defined atomic actions
r: slicing and operation. Slicing involves
he conditions for filtering rows from the
sdescribingtheoperations(suchasmax,
the values of one or more columns of the
he steps should be returned as a Python
al language, including all relevant values
ht (CoT) prompting to further enhance
based agent [23]. This technique incorpo-
the prompt, guiding the model to break
oremanageablesteps[33].Thisapproach
lem-solving processes. Additionally, CoT
making process more transparent by ex-
owinguserstounderstandhowtheagent
alysis result.
ew-shot learning by providing examples
but also include the intermediate reason-
ces the agent’s ability to handle diverse
mployself-consistencyinconjunctionwith
ng multiple independent reasoning paths
r consistency, and using majority voting
e [22]. By considering multiple reasoning
to be misled by a single flawed chain of
potential ambiguity, self-consistency can
ions and provide a more comprehensive

=== Page 9 ===
GoNoGo: So
Actor The Actor is responsible for car
the Planner. It consists of several inte
Self-reflection, Memory, and Plugins, as
The Coder LLM is responsible for
the Planner’s instructions. This compo
plans into concrete, executable code th
requiredPluginsandperformthenecess
mechanism,whichworksintandemwith
generated code, error messages, execut
about the current task [8].
TheSelf-reflectionmechanismisasop
LLMtocriticallyanalyzeitsownoutpu
error occurs during script execution, t
providing feedback to the Coder LLM
to analyze error messages within the ta
improvement of the generated code.
TheSelf-reflectionmechanismoffers
LLMtoautonomouslyidentifyandcorr
reflecting on its own output, thereby re
and intervention. This mechanism prom
allowing each iteration to refine the scri
and reliability [25]. By utilizing the Mem
context-aware adjustments, considering
specific task requirements, which leads
propriate code generation. Automated e
result in a more efficient coding process,
enhancing the robustness and reliabilit
self-reflective capabilities minimize the
bugging process, enabling engineers to
tasks.
This architecture enables the Actor
ysis tasks but also to troubleshoot and
more robust and reliable automated dat
3.3 System Implementation
The system uses Azure OpenAI’s GPT
Actoragents.ThePlannerutilizesspeci
defining the entire data analysis task b
the plan. Moreover, the Actor uses pred
Pythoncodeforexecutingeachstepofth
performing tasks on the given data.

oftware Release Multi-agent System 9
rrying out the analysis plans devised by
eracting components: Coder LLM with
s depicted in Figure 2.
generating executable scripts based on
onent is crucial as it translates abstract
hat can interact with the data using the
saryanalysis.ItincludesaSelf-reflection
haMemorymodule.ThisMemorystores
tion results, and contextual information
phisticatedprocessthatallowstheCoder
utanddecision-makingprocess.Whenan
the Self-reflection mechanism activates,
M. This feedback loop enables the LLM
ask context [11,28], facilitating iterative
severaladvantages:ItenablestheCoder
recterrorsbycontinuouslyanalyzingand
educing the need for external debugging
motes a cycle of continuous improvement,
ipts for progressively better performance
mory module, the Coder LLM can make
g previous errors, execution results, and
s to more precise and contextually ap-
error correction and iterative refinement
, speeding up the development cycle and
ty of the final scripts. Additionally, the
need for human intervention in the de-
o focus on more complex and high-level
to not only generate code for data anal-
d improve its own output, resulting in a
ta analysis system.
T-3.5 Turbo for both the Planner and
iallydesignedpromptsfortaskplanning,
by specifying the details of each step in
defined prompts to generate the required
heprovidedplanwiththepandaslibrary,

=== Page 10 ===
10 A. Khoee et al.
4 Experiments
4.1 Data
The data used for analysis at our indu
and is updated after testing each functi
vehicle. This internal company data co
critical for release decisions, as it inclu
performanceandfunctionalityofsoftwa
information for determining whether t
of development and allow it to be dri
is updated after each test, we used a d
experiments.
Stakeholders often ask questions like
fail the most for release candidate X?”
X is the release candidate’s name and
these questions requires domain knowled
extractandcommunicatetheanswersac
managers can determine if a vehicle me
the next development phase or be driv
only vehicles that meet stringent safet
maintaining high standards in automoti
4.2 Benchmark Overview
ToevaluatetheGoNoGosystem’sperfor
on 15 initial analysis tasks. These task
engineers, quality engineers, and verific
commonhigh-levelqueriesandcriteriafr
workflows.Ourgoalwastodesigntaskst
of the demanding queries necessary for
taskswerethentranslatedintoexplicitt
process,ensuringthatthebenchmarkre
typically encountered by these professio
solutionsforthesequeriesusingPython,
codechunksrepresentingoperationssuc
each query, we generated a series of q
code chunks and formulating correspo
solve. This method expanded our origi
each with a corresponding ground-truth
In this way, we established queries w
Level 1 These are the simplest querie
such as filtering or sorting.
Level 2 These queries combine two or
filtering followed by sorting.

ustrial partner is called “GoNoGo” data
ion of every software component in each
ontains about 40 different fields and is
udes detailed information regarding the
arecomponents.Itprovidesthenecessary
to advance a vehicle to the next phase
iven on open roads. Although the data
dataset of 55,000 records to report our
e “What are the test case functions that
or “What is the Y-status of X?” where
Y is a specific functionality. Answering
dge and an understanding of the data to
ccurately.Byanalyzingthisdata,release
eets the necessary criteria to progress to
ven on public roads. This ensures that
ty and quality standards are advanced,
ive software development.
rmance,wedevelopedabenchmarkbased
ks were defined with the help of release
cation engineers. We identified the most
requentlyusedbytheseendusersintheir
thatcapturethenuancesandcomplexity
r their decision-making processes. These
tableanalysisqueriesthatGoNoGocould
eflectsreal-worldscenariosandchallenges
onals. We created definitive ground-truth
,breakingdownthesolutionsintosmaller
chasfiltering,grouping,andsorting.For
query ablations by incrementally adding
onding queries that these chunks would
inal 15 queries into 50 query ablations,
h solution and Python code.
with four levels of difficulty:
es, typically involving a single operation
three basic operations, such as multiple

=== Page 11 ===
GoNoGo: So
Level 3 Thesequeriesinvolvemoretha
grouping and aggregating.
Level 4 These are the most complex q
erations such as grouping and aggre
basic filtering and sorting.
Thisincrementalapproachtoqueryc
performance at various levels of difficu
any, the system’s performance begins to
capabilities in handling increasingly com
This benchmark allows for objective
handle increasingly complex table analy
sessment of its performance across a spe
4.3 Evaluation
Theevaluationprocessinvolvescompari
manually generated ground-truth result
matching criterion [9]. For a match to
output must contain the same columns
record in the system’s output must exac
ground truth, including all values acro
must also contain the same number of
missing or extra entries. This strict m
just similar, but identical in structure a
agent’soutputsatisfiesallthesecriteria
task is marked as successful; otherwise
performance is then quantified by calc
ratio of successful tasks to the total num
4.4 Results
Wepresentourexperimentresultsonth
ateditsperformanceacrossdifferentlev
2-shot, and 3-shot examples. GoNoGo
examples.
Initially,weassessedGoNoGo’sabili
ing basic operations like filtering or so
increased the complexity by including q
2 difficulties, followed by those incorpor
nally,weevaluatedGoNoGo’sperforman
ing the most complex queries (Level 4),
as filtering, sorting, grouping, and calcu
OurobservationsindicatethatGoNo
effective for solving queries with task d
these tasks without error. For more com

oftware Release Multi-agent System 11
anthreeoperations,potentiallyincluding
queries, requiring multiple advanced op-
egating, for calculating statistics, beyond
complexityallowsustoassessGoNoGO’s
ulty. It helps identify at which point, if
o degrade, and provides insights into its
mplex table analysis tasks.
e evaluation of the GoNoGo’s ability to
ysis tasks, ensuring a comprehensive as-
ectrum of difficulty levels.
ingtheGoNoGosystem’sresultsagainst
ts. The comparison is based on a strict
o be considered successful, the system’s
as the ground truth. Additionally, each
ctly match a corresponding record in the
oss different fields. The system’s output
f records as the ground truth, with no
matching ensures that the output is not
and content to the expected result. If the
whencomparedtothegroundtruth,the
e, it is considered a failure. The model’s
culating the success rate, defined as the
mber of tasks.
heGoNoGosysteminTable1.Weevalu-
velsoftaskdifficultyusing0-shot,1-shot,
achieved high performance with 3-shot
itytohandlethesimplestqueriesinvolv-
orting (Level 1). We then incrementally
queries that combined Level 1 and Level
rating Level 1 to Level 3 difficulties. Fi-
nceonthefullspectrumoftasks,includ-
, which require multiple operations such
ulating statistics.
oGowith3-shotexamplesisparticularly
difficulty up to Level 2 and can handle
mplex tasks involving Level 3 or Level 4

=== Page 12 ===
12 A. Khoee et al.
Table 1. Performance evaluation of the
example queries across different levels of ta
#Examples TaskDifficulty #TotalTasks
1 16
1-2 32
0-shot
1-3 44
1-4 50
1 16
1-2 32
1-shot
1-3 44
1-4 50
1 16
1-2 32
2-shot 1-3 44
1-4 50
1 16
1-2 32
3-shot
1-3 44
1-4 50
difficulties,humaninterventionisrecom
ulations and computations, rather than
5 Threats to Validity
We identify the following threats to the
Limitation of the Created Benchm
specifically created for evaluating th
signed to be comprehensive, it ma
edgecasesencounteredinreal-world
designqueriesandtaskstobeascom
ificationengineerstomitigatesubjec
the limitation remains that it may n
edge case. This limitation could affe
our findings.
Selection of the Foundation Model
this case GPT-3.5 Turbo, which is c
studies, might influence the results
GPT-4,GPT-4o,Claude3,orLLaM
and interpretations of the same tas
using GPT-3.5 Turbo and focused o
capabilities. Besides, our framework
different pre-trained models. The de
our conclusions may not hold if ano

GoNoGo system with varying numbers of
ask difficulty.
#Success #Failed Performance
3 13 18.75%
6 26 18.75%
9 35 20.45%
11 39 22%
15 1 93.75%
27 5 84.37%
32 12 72.72%
34 16 68%
16 0 100%
31 1 96.87%
38 6 86.36%
41 9 82%
16 0 100%
32 0 100%
41 3 93%
45 5 90%
mmendedtoperformthenecessarymanip-
relying solely on the automated system.
e validity of our study:
mark Our study relies on a benchmark
he system. While this benchmark is de-
ay not cover all potential scenarios and
dapplications.Effortshavebeenmadeto
mprehensiveaspossiblebyinvolvingver-
ctiveness.However,despitetheseefforts,
not capture every potential scenario and
ect the generalizability and robustness of
l Thechoiceofthefoundationmodel,in
considered a widely used LLM in recent
s. Different foundation models, such as
MA3,mayyieldbetterperformancelevels
sks. However, we limited the project to
on improving its reasoning and planning
k is flexible and can be easily applied to
ependency on a single model means that
other model were used.

=== Page 13 ===
GoNoGo: So
6 Related Work
The application of tabular data in mach
ranging from few-shot learning for dat
automation.
Integrating LLM with tabular data
[4]. Most foundation models are not tra
for them to process and interpret this t
issue, pre-training LLMs using tabular
twocommonlyadoptedoptions.[16]des
LLM training, and [19] provided guideli
fine-tuning LLMs.
Inparticular,recentliteraturehasse
self-supervised learning (SSL) approach
SSL for non-sequential tabular data (S
predictive, contrastive, and hybrid lear
such as automatic data engineering and
[30]introducesTapTap,anoveltablepr
prediction and generates synthetic tabl
introducesTabulardataPre-Trainingvia
enables training-free generalization acro
izing data representations through dista
across these works is the enhancement
novative pre-training and SSL techniqu
methodologies and application focuses,
to improving model generalization and
TabularFoundationModels(TabFMs),
on diverse tabular datasets to excel in
learning with scarce data.
Pre-training aims to enhance LLMs
general. However, it does not necessar
cific tasks. On the other hand, fine-tunin
potential for enhancing tabular data m
duced TableLLM, a robust 13-billion-p
tabulardatainreal-worldofficescenario
reasoning process extensions and cross
ing existing general-purpose and tabula
andfew-shottabulardataclassification
andproblemdescriptions,achievingsup
learning methods and even strong basel
dressed question answering over hybrid
LLaMA 2 using a step-wise pipeline, res
both prior fine-tuned models and large
benchmarks. [24] focused on applying L
enhancing LLM capabilities through ex

oftware Release Multi-agent System 13
hine learning holds significant potential,
ta analysis to end-to-end data pipeline
a presents several substantial challenges
ained on tabular data, making it difficult
type of data effectively. To mitigate this
data or fine-tuning on specific tasks are
scribeddifferentphasesandstrategiesfor
ines for enterprises who are interested in
eenagrowinginterestinpre-trainingand
hes using tabular data. [21] emphasizes
SSL4NS-TD), categorizing methods into
rning, and discussing application issues
d cross-table transferability. In contrast,
re-trainingmethodthatenhancestabular
les for various applications. Finally, [26]
aMeta-representation(TabPTM),which
oss heterogeneous datasets by standard-
ance to prototypes. The common theme
t of tabular data handling through in-
ues, though they differ in their specific
ranging from generating synthetic data
manipulation capabilities. [29] proposes
leveragingapre-trainedLLMfine-tuned
instruction-following tasks and efficient
s’ capability of handling tabular data in
rily improve their performance on spe-
ng pre-trained LLMs have demonstrated
manipulation on specific tasks. [31] intro-
parameter model designed for handling
os.Inparticular,TableLLMincorporates
s-way validation strategies, outperform-
ar-focused LLMs. [12] explored zero-shot
bypromptingLLMswithserializeddata
periorperformanceovertraditionaldeep-
lines like gradient-boosted trees. [34] ad-
d tabular and textual data, fine-tuning
sulting in TAT-LLM, which outperforms
e-scale LLMs such as GPT-4 on specific
LLMs to predictive tasks in tabular data,
xtensive training on annotated tables.

=== Page 14 ===
14 A. Khoee et al.
Industrial considerations Oneknowniss
data verbatim, leading to overfitting. [2
generalizationcapability,LLMsperform
duringtrainingcomparedtonew,unsee
wards memorization, necessitating robu
issueisparticularlycriticalforcompanie
tion model has not encountered before,
predict performance on these internal ta
some applications have stringent data
being addressed in the literature [27,6,3
resides within a secure local network, an
inthispaper.Inindustrialsettings,prac
user-centric adaptation, ease of develop
ments, and IT infrastructure limitation
a system that addresses these industria
andexcessiveresourcestypicallyrequire
7 Conclusion
WepresenttheGoNoGo,anLLM-based
line software release decisions in the au
riving insights from real-world data usin
system within our industrial partner’s c
release managers and reducing the num
allowing them to focus on their high-lev
The impact of our system extends
automotive companies manage their sof
and effort required for data analysis wh
ability. This shift allows engineers and
acceleratingtheoveralldevelopmentand
betweenrawdataandactionableinsight
ficient, data-driven software release pra
industrial partner would experience mo
teams and employees, with the decision
prolonged. Pilot users have reported sa
each time they make a decision, highli
efficiency and the industrial partner’s ov
8 Acknowledgement
This work was partially supported by
tems and Software Program (WASP) fu
Foundation.

sueisthatLLMsoftenmemorizetabular
2] highlights that despite their nontrivial
mbetterondatasetstheywereexposedto
endatasets.Thisindicatesatendencyto-
ust testing and validation protocols. This
es’internaldataandtasksthatafounda-
as public benchmarks do not necessarily
asks. In addition, it is worth noting that
privacy policies, a concern increasingly
3]. In our work, we assume that the data
nd we do not address data privacy issues
cticalconstraintssuchasinterpretability,
pment and maintenance, latency require-
ns are crucial. Our objective is to design
al needs without unnecessary complexity
edbypre-trainingandfine-tuningLLMs.
dmulti-agentsystemdesignedtostream-
utomotive industry by analyzing and de-
ng Python code. We have employed this
company, which is significantly assisting
mber of engineers engaged in this process,
vel tasks.
beyond automation, transforming how
ftware release cycles. It reduces the time
hile increasing decision accuracy and reli-
managers to focus on higher-level tasks,
ddeploymentprocessbybridgingthegap
ts,drivingtheindustrytowardsmoreef-
actices. Without GoNoGo in place, our
ore wasted time and effort across various
n-making process becoming significantly
aving approximately 2 hours per person
ighting the system’s positive impact on
overall business goals.
y the Wallenberg AI, Autonomous Sys-
unded by the Knut and Alice Wallenberg

=== Page 15 ===
GoNoGo: So
References
1. Austin,J.,Odena,A.,Nye,M.,Bosma,
Cai, C., Terry, M., Le, Q., et al.: Prog
arXiv preprint arXiv:2108.07732 (2021
2. Bordt,S.,Nori,H.,Rodrigues,V.,Nus
Memorizationandlearningoftabulard
arXiv:2404.06209 (2024)
3. Boudewijn,A.T.P.,Ferraris,A.F.,Pan
K.,Chauvenet,C.R.:Privacymeasurem
artandfutureresearchdirections.In:N
Generation with Generative AI (2023)
4. van Breugel, B., van der Schaar, M.: W
a Research Priority (Jun 2024)
5. Brown, T., Mann, B., Ryder, N., Sub
lakantan,A.,Shyam,P.,Sastry,G.,Ask
learners.Advancesinneuralinformatio
6. Carey,A.N.,Bhaila,K.,Edemacu,K.,
differentially private tabular data. arX
7. Chang, Y., Wang, X., Wang, J., Wu,
Wang,C.,Wang,Y.,etal.:Asurveyon
Transactions on Intelligent Systems an
8. Chen, X., Lin, M., Schärli, N., Zhou, D
debug. arXiv preprint arXiv:2304.0512
9. Chiang,W.L.,Zheng,L.,Sheng,Y.,An
Zhu, B., Jordan, M., Gonzalez, J.E., e
evaluating llms by human preference. a
10. Dagdelen,J.,Dunn,A.,Lee,S.,Walker
Jain,A.:Structuredinformationextrac
models. Nature Communications 15(1)
11. Dyachenko, Y., Nenkov, N., Petrova, M
proaches to cognitive architecture of
Inspired Cognitive Architectures 26, 1
12. Hegselmann, S., Buendia, A., Lang,
TabLLM: Few-shot Classification of Ta
13. Huang,J.,Chang,K.C.C.:Towardsrea
arXiv preprint arXiv:2212.10403 (2022
14. Khot,T.,Trivedi,H.,Finlayson,M.,Fu
A.:Decomposedprompting:Amodula
preprint arXiv:2210.02406 (2022)
15. Liu,P.,Yuan,W.,Fu,J.,Jiang,Z.,Hay
predict:Asystematicsurveyofprompt
ACM Computing Surveys 55(9), 1–35
16. Patil, R., Gudivada, V.: A review of cu
large language models (llms). Applied
17. Rahimi, A., Veisi, H.: Integrating mo
languageembeddingsforfew-shotinten
Conference on Electrical Engineering (
18. Valmeekam, K., Marquez, M., Sreedh
ningabilitiesoflargelanguagemodels-
Information Processing Systems 36, 75

oftware Release Multi-agent System 15
,M.,Michalewski,H.,Dohan,D.,Jiang,E.,
gram synthesis with large language models.
1)
shi,B.,Caruana,R.:Elephantsneverforget:
datainlargelanguagemodels.arXivpreprint
nfilo,D.,Cocca,V.,Zinutti,S.,DeSchepper,
mentsintabularsyntheticdata:Stateofthe
NeurIPS2023WorkshoponSyntheticData
Why Tabular Foundation Models Should Be
bbiah, M., Kaplan, J.D., Dhariwal, P., Nee-
kell,A.,etal.:Languagemodelsarefew-shot
onprocessingsystems33,1877–1901(2020)
Wu,X.:Dp-tabicl:In-contextlearningwith
Xiv preprint arXiv:2403.05681 (2024)
, Y., Yang, L., Zhu, K., Chen, H., Yi, X.,
nevaluationoflargelanguagemodels.ACM
nd Technology 15(3), 1–45 (2024)
D.: Teaching large language models to self-
28 (2023)
ngelopoulos,A.N.,Li,T.,Li,D.,Zhang,H.,
et al.: Chatbot arena: An open platform for
arXiv preprint arXiv:2403.04132 (2024)
r,N.,Rosen,A.S.,Ceder,G.,Persson,K.A.,
ctionfromscientifictextwithlargelanguage
), 1418 (2024)
M., Skarga-Bandurova, I., Soloviov, O.: Ap-
autonomous intelligent agent. Biologically
130–135 (2018)
H., Agrawal, M., Jiang, X., Sontag, D.:
abular Data with Large Language Models
asoninginlargelanguagemodels:Asurvey.
2)
Fu,Y.,Richardson,K.,Clark,P.,Sabharwal,
arapproachforsolvingcomplextasks.arXiv
yashi,H.,Neubig,G.:Pre-train,prompt,and
tingmethodsinnaturallanguageprocessing.
(2023)
urrent trends, techniques, and challenges in
Sciences 14(5), 2074 (2024)
odel-agnostic meta-learning with advanced
ntclassification.In:202432ndInternational
(ICEE). pp. 1–5. IEEE (2024)
haran, S., Kambhampati, S.: On the plan-
-acriticalinvestigation.AdvancesinNeural
5993–76005 (2023)

=== Page 16 ===
16 A. Khoee et al.
19. VM, K., Warrier, H., Gupta, Y., et al
guidelines and recommendations. arXiv
20. Wang, L., Ma, C., Feng, X., Zhang, Z
Chen, X., Lin, Y., et al.: A survey on
agents. Frontiers of Computer Science
21. Wang, W.Y., Du, W.W., Xu, D
on self-supervised learning for non-
arXiv:2402.01204 (2024)
22. Wang, X., Wei, J., Schuurmans, D., L
Zhou,D.:Self-consistencyimprovescha
arXiv preprint arXiv:2203.11171 (2022
23. Wei, J., Wang, X., Schuurmans, D., Bo
D., et al.: Chain-of-thought prompting
Advances in neural information proces
24. Yang, Y., Wang, Y., Sen, S., Li, L., L
Language Models for Predictive Tabula
25. Yao,S.,Zhao,J.,Yu,D.,Du,N.,Shafra
ergizingreasoningandactinginlangua
(2022)
26. Ye,H.J.,Zhou,Q.,Zhan,D.C.:Trainin
ular data via meta-representation (202
27. Ye, J., Du, M., Wang, G.: DataFram
DataFrame Question Answering Witho
28. Yoon,J.,Feldt,R.,Yoo,S.:Intent-drive
languagemodelagents.In:2024IEEEC
and Validation (ICST). IEEE (2024)
29. Zhang, H., Wen, X., Zheng, S., Xu, W
learning on tabular data. arXiv preprin
30. Zhang,T.,Wang,S.,Yan,S.,Li,J.,Liu
ers models for tabular prediction. arXi
31. Zhang, X., Zhang, J., Ma, Z., Li, Y., Z
Zhang-Li,D.,Yu,J.,Zhao,S.,Li,J.,T
Manipulation by LLMs in Real Office
32. Zhang, Z., Yao, Y., Zhang, A., Tang, X
Wang,R.,Liu,G.,etal.:Ignitinglangu
chain-of-thought reasoning to languag
(2023)
33. Zhou, D., Schärli, N., Hou, L., Wei, J
Cui, C., Bousquet, O., Le, Q., et al.:
reasoning in large language models. ar
34. Zhu,F.,Liu,Z.,Feng,F.,Wang,C.,L
LanguageModelforDiscreteReasoning

l.: Fine tuning llm for enterprise: Practical
v preprint arXiv:2404.10779 (2024)
Z., Yang, H., Zhang, J., Chen, Z., Tang, J.,
n large language model based autonomous
18(6), 186345 (2024)
D., Wang, W., Peng, W.C.: A survey
-sequential tabular data. arXiv preprint
Le, Q., Chi, E., Narang, S., Chowdhery, A.,
ainofthoughtreasoninginlanguagemodels.
2)
osma, M., Xia, F., Chi, E., Le, Q.V., Zhou,
g elicits reasoning in large language models.
ssing systems 35, 24824–24837 (2022)
Liu, Q.: Unleashing the Potential of Large
ar Tasks in Data Science (2024)
an,I.,Narasimhan,K.,Cao,Y.:React:Syn-
agemodels.arXivpreprintarXiv:2210.03629
ng-freegeneralizationonheterogeneoustab-
23)
me QA: A Universal LLM Framework on
out Data Exposure (2024)
enmobileguitestingwithautonomouslarge
ConferenceonSoftwareTesting,Verification
W., Bian, J.: Towards foundation models for
nt arXiv:2310.07338 (2023)
u,Q.:Generativetablepre-trainingempow-
iv preprint arXiv:2305.09696 (2023)
Zhang, B., Li, G., Yao, Z., Xu, K., Zhou, J.,
Tang,J.:TableLLM:EnablingTabularData
Usage Scenarios (2024)
X., Ma, X., He, Z., Wang, Y., Gerstein, M.,
uageintelligence:Thehitchhiker’sguidefrom
ge agents. arXiv preprint arXiv:2311.11797
J., Scales, N., Wang, X., Schuurmans, D.,
Least-to-most prompting enables complex
rXiv preprint arXiv:2205.10625 (2022)
Li,M.,Chua,T.S.:TAT-LLM:ASpecialized
goverTabularandTextualData(Feb2024)

Paper:Optimizing RAG Techniques for Automotive Industry PDF Chatbots.pdf
=== Page 1 ===
Optimizing RAG Techniques for Automotive Ind
Locally Deployed Ollama Models
Optimizing RAG Techniques Based on Locally Deployed
A Case Study with Locally Deployed Ollama Models
Fei Liu *
China Automotive Technology & Research Center, liufei@cata
Zejun Kang
China Automotive Technology & Research Center, kangzejun@
Xing Han
China Automotive Technology & Research Center, hanxing@c
With the growing demand for offline PDF chatbots in automotive indu
of large language models (LLMs) in local, low-performance settings
enhancing Retrieval-Augmented Generation (RAG) techniques for p
locally deployed Ollama models.
Based on the Langchain framework, we propose a multi-dime
implementation. Our method addresses key challenges in automotive
technical specifications. We introduce improvements in PDF processi
to the unique characteristics of automotive industry documents. Add
pipelines and an agent supporting self-RAG based on LangGraph best
To evaluate our approach, we constructed a proprietary dataset com
technical reports and corporate regulations. We compared our opti
baseline across three datasets: our automotive industry dataset, QReC
in context precision, context recall, answer relevancy, and faithfulnes
industry dataset.
Our optimization scheme provides an effective solution for deploying
specific needs of PDF chatbots in industrial production environmen
information processing and intelligent production in the automotive
* Place the footnote text for the author (if applicable) here.

dustry PDF Chatbots: A Case Study with
Ollama Models
arc.ac.cn
@catarc.ac.cn
catarc.ac.cn
ustrial production environments, optimizing the deployment
s has become increasingly important. This study focuses on
processing complex automotive industry documents using
ensional optimization approach for Ollama's local RAG
e document processing, including multi-column layouts and
ing, retrieval mechanisms, and context compression, tailored
ditionally, we design custom classes supporting embedding
t practices.
mprising typical automotive industry documents, including
imized RAG model and self-RAG agent against a naive RAG
CC, and CoQA. Results demonstrate significant improvements
ss, with particularly notable performance on the automotive
g local RAG systems in the automotive sector, addressing the
nts. This research has important implications for advancing
industry.

=== Page 2 ===
CCS CONCEPTS • Computing methodologies • Artificial intellige
generation
Additional Keywords and Phrases: Automotive Industry, Langc
1 INTRODUCTION
1.1 Research Background
The automotive industry is undergoing a significant digital tra
technical documentation for various processes [1]. This sh
control, all of which now heavily depend on efficient informat
technical documents, often in PDF format, has created a pr
question-answering capabilities in industrial settings [3].
Large Language Models (LLMs) have emerged as powerful
remarkable abilities in tasks such as document understandi
shown potential in handling the complex, domain-specific l
However, the application of LLMs in industrial environments
computational resources and data privacy [5].
Among the various techniques developed to enhance LLM p
has gained significant attention [6]. RAG combines the gene
retrieval, allowing for more accurate and contextually relev
Lewis et al., has shown superior performance in generating
traditional models [7].
The implementation of RAG techniques in the automotiv
challenges:
The application of RAG techniques in the automotive indus
1. Document Complexity: Automotive technical docume
column formats and complex tables. These structura
document processing methods [8].
2. Data Privacy: The automotive industry deals with hig
designs and manufacturing processes. This necessita
company's infrastructure, without relying on external c
3. Resource Constraints: Many industrial environments
constraint requires the development of optimized, lig
standard hardware [10].
4. Domain Specificity: The automotive sector employs a
Generic language models often lack the specific knowle
queries about automotive processes and specifications

ence • Natural language processing • Natural language
chain, self-rag, PDF Processing, RAG, Ollama
ansformation, with an increasing reliance on complex
hift encompasses design, manufacturing, and quality
tion management systems [2]. The growing volume of
ressing need for advanced information retrieval and
l tools in natural language processing, demonstrating
ing and question answering [4]. These models have
language often found in automotive documentation.
s presents unique challenges, particularly in terms of
performance, Retrieval-Augmented Generation (RAG)
erative capabilities of LLMs with external knowledge
vant responses. This approach, initially proposed by
g specific, diverse, and factual language compared to
ve industry, however, faces several industry-specific
stry presents unique challenges:
ents often feature intricate layouts, including multi-
al elements pose significant challenges for standard
ghly confidential information related to proprietary
ates solutions that can operate securely within the
cloud services [9].
operate with limited computational resources. This
ghtweight models capable of running efficiently on
vast array of specialized terminology and concepts.
edge required to accurately interpret and respond to
[11].

=== Page 3 ===
5. Real-time Performance: In fast-paced manufacturing
process relevant information is crucial. This necessita
capable of operating under time constraints [12].
The open-source large language model service framework
deploy LLMs in low-performance environments [13]. This f
resource constraints faced in industrial settings. However, i
documentation processing remains an area ripe for exploratio
As the automotive industry continues to evolve, particularly
the complexity and volume of technical documentation are
underscores the importance of developing robust, efficient, an
specific needs of the automotive sector [15].
The intersection of these technological advancements a
opportunity for research [16]. By addressing the particular ne
and local LLM deployment, there is potential to significan
automotive engineering and manufacturing processes [17].
1.2 Research Status and Gaps
Recent advancements in RAG techniques have shown promi
which uses predicted next-sentence content to proactivel
introduced FILCO, a method for identifying and filtering usefu
approaches demonstrate the potential for more context-awar
as those found in automotive engineering.
The concept of self-reflective RAG, as explored by Asai e
enhance the quality and factual accuracy of LLMs through on
This approach could be especially valuable in the automotiv
information are paramount.
In the domain of optimizing RAG for specific industries
retrieval method that is particularly relevant for the auto
structures. Similarly, the work of Siriwardhana et al [22], on i
datasets offers insights that could be applied to the vast rep
manufacturing.
The open-source large language model service framework
deploy LLMs in low-performance environments [23], Burga
improving accessibility [24], These developments in local
automotive industry's need for on-premises, resource-efficien
Recent work by Wang et al [25], on on-device language m
potential applications in integrating RAG systems with existi
environments. This could lead to more seamless integration of
industrial processes.
The challenge of processing complex PDF documents, a
automotive industry, has been addressed by several research

g environments, the ability to quickly retrieve and
ates high-performance information retrieval systems
k Ollama has gained attention for its ability to rapidly
framework offers potential solutions to some of the
its application in the context of RAG for automotive
on and optimization.
y with the advent of electric and autonomous vehicles,
e expected to increase further [14]. This evolution
nd secure information retrieval systems tailored to the
and industry-specific challenges presents a unique
eeds of the automotive industry in the context of RAG
ntly enhance information access and utilization in
ise in various domains. Jiang et al. proposed FLARE,
ly retrieve relevant information [18]. Wang et al.
ul contexts to improve generation quality [19]. These
re retrieval in complex document environments, such
et al [20], introduces a novel framework designed to
on-demand retrieval and a self-reflection mechanism.
ve context, where precision and accuracy in technical
s, Rajpathak et al [21], proposed a domain-adaptive
omotive sector's unique terminology and document
improving retrieval efficiency in large-scale industrial
positories of technical documentation in automotive
k Ollama has gained attention for its ability to rapidly
an et al. developed RamChat, an AI chatbot aimed at
l LLM deployment are particularly relevant to the
nt solutions.
models for function calling of software APIs presents
ing software infrastructure in automotive production
f AI-powered information retrieval within established
a common format for technical specifications in the
hers. Lin et al [26], proposed an advanced PDF parsing

=== Page 4 ===
technique that could be adapted to handle the multi-column l
documentation. Furthermore, the work of Bensch et al [27
documents offers promising approaches for dealing with the v
In the realm of domain-specific language understanding
language models for specialized industries provides valuable i
for automotive terminology and concepts. This is complem
recognition in technical documents, which could enhance t
contexts.
The integration of RAG with other AI methodologies has a
RAG with reinforcement learning, as explored by Belhadj et al
retrieval systems capable of handling the diverse query
production.
Privacy and security concerns, which are paramount in t
context of RAG by researchers such as Zeng et al [31], who
could be crucial for protecting proprietary automotive design
The challenge of maintaining coherence in long-form text g
automotive queries, has been tackled by researchers like Borg
dependencies in language models could enhance the quality o
Recent advancements in few-shot learning, as demonstrate
rapidly adapting RAG systems to new automotive subdom
retraining. This could be particularly valuable in the fast-evol
The application of RAG in multilingual settings, as explored
automotive companies dealing with documentation in multipl
generation could facilitate more efficient knowledge sharing a
In the domain of optimizing retrieval mechanisms, the rese
potential improvements in the speed and accuracy of informa
fast-paced automotive production environments.
The challenge of handling numerical data and calculatio
performance metrics, has been addressed by researchers lik
symbolic mathematics with neural language models could enh
quantitative automotive data.
However, despite these advancements, there remains a si
unique challenges of implementing RAG systems in the autom
offline environments.
The significance of this research lies in:
1. Providing an effective optimization scheme for local R
environments, addressing key challenges in document p
2. Exploring the application of self-RAG in offline, industry
calling implementations for domain-specific tasks.
3. Contributing to the advancement of intelligent info
potentially improving efficiency and accuracy in technic

layouts and intricate tables often found in automotive
7], on information extraction from semi-structured
varied formats of automotive technical literature.
g, the research of Faysse et al [28], on fine-tuning
insights that could be applied to tailoring RAG systems
mented by the work of Kumar et al [29], on entity
the precision of information retrieval in automotive
also shown promise. For instance, the combination of
l [30], could lead to more adaptive and context-aware
types encountered in automotive engineering and
the automotive industry, have been addressed in the
proposed privacy-preserving retrieval methods that
ns and processes.
generation, often necessary when addressing complex
geaud et al [32], whose work on improving long-range
of responses in automotive RAG applications.
ed by Izacard et al [33], with GPT-3, offer potential for
mains or emerging technologies without extensive
lving landscape of automotive technology.
d by Ahmad et al [34], is especially relevant for global
le languages. Their work on cross-lingual retrieval and
across international teams.
earch of Su et al [35], on dense retrieval methods offers
ation lookup, crucial for real-time query resolution in
ons, often present in automotive specifications and
ke Noorbakhsh et al. [36], whose work on integrating
hance the precision of RAG systems when dealing with
ignificant gap in research specifically addressing the
motive industry, particularly in resource-constrained,
RAG deployment of Ollama in automotive industrial
processing and information retrieval.
y-specific scenarios, offering new insights into function
ormation processing in automotive manufacturing,
ical document analysis and query resolution.

=== Page 5 ===
1.3 Research Objectives and Significance
Given the identified challenges and research gaps, this stud
scheme for applying RAG technology with Ollama in local, lo
Our specific research objectives include:
• Proposing a PDF file processing method optimized for
multi-column layouts and complex tables.
• Developing an advanced RAG system based on the Lang
BM25 retrievers to build an efficient context compressi
• Designing an intelligent agent that supports self-RAG an
Ollama's response generation in automotive-specific sc
• Evaluating the proposed system using a proprietary d
public datasets, to demonstrate its effectiveness in real
The significance of this research lies in:
• Providing an effective optimization scheme for local R
environments, addressing key challenges in document p
• Exploring the application of self-RAG in offline, industry
calling implementations for domain-specific tasks.
• Contributing to the advancement of intelligent info
potentially improving efficiency and accuracy in technic
This research builds upon and extends existing work in sev
• The potential of RAG systems to support decision-ma
design and manufacturing, has been explored by resear
RAG for few evidences-based reasoning could be adapt
automotive engineering.
• Recent developments in efficient transformer archite
Reformer, offer potential for deploying more powerful
industrial environments.
• The integration of visual information with text-based
opportunities for enhancing RAG systems to handl
automotive documentation.
By addressing these research objectives and building upon
significantly enhance the applicability and effectiveness of RAG
transforming how technical information is accessed, proce
manufacturing processes.

dy aims to develop a multi-dimensional optimization
ow-performance automotive industry environments.
automotive industry documents, capable of handling
gchain framework, introducing reranking models and
ion pipeline.
nd exploring a function calling mechanism to enhance
cenarios.
dataset of automotive industry documents, alongside
l-world industrial applications.
RAG deployment of Ollama in automotive industrial
processing and information retrieval.
y-specific scenarios, offering new insights into function
ormation processing in automotive manufacturing,
ical document analysis and query resolution.
veral key areas:
aking processes, a critical application in automotive
rchers such as Gamage et al [37]. Their work on using
ted to support complex decision-making scenarios in
ectures, such as the work of Zhuang et al [38], on
RAG models within the computational constraints of
d retrieval, as explored by Chen et al [39], presents
le technical diagrams and schematics common in
n recent advancements in the field, this study aims to
G technologies in the automotive industry, potentially
essed, and utilized in automotive engineering and

=== Page 6 ===
2 MATERIALS AND METHODS
2.1 Foundation
Our research builds upon the Langchain framework and Ollam
the automotive industry. We began by constructing a pre
Langchain's components, which we then optimized for proces
Figure 1 illustrates the key components of this system. Thi
capabilities for various file formats, efficient text splitting, a
vector store. The basic framework includes:
Vector Store Document Loader Text Splitter
(Chroma) Documents (PDF) (RecursiveC
Retriever
Figure 1: Basic RAG Architecture for Auto
• Document Loading: Utilizing Langchain's Loader class
directories, simulating the document structure in autom
• Text Chunking: Implementing an embedded tokenizat
chunks, optimized for technical specifications and
documentation.
• Vector Storage: Encoding text chunks into semantic vec
creating an indexed text retriever tailored for automoti
• Dialogue Generation: Employing Langchain's Convers
retrieved context, generating responses using the locall
This foundational setup serves as the baseline for our s
specific challenges in automotive document processing and in
2.2 PDF File Processing Optimization
To address the unique challenges posed by automotive ind
processing method combining PDFMiner and Tabula libraries
2.2.1 Overview of PDFMiner and Tabula
PDFMiner is a Python library used for extracting information
images, metadata, and structural information from PDF docu
level APIs to satisfy different levels of requirements. Automo

ma model, adapting them to meet the specific needs of
eliminary retrieval-based chatbot framework using
ssing automotive technical documents.
is architecture integrates advanced document loading
and a robust retrieval mechanism using the Chroma
Embeddings
CharacterTextSplitter) (OllamaEmbeddings) Query
LLM (Ollama) ConversationalRetrievalChain
Response
omotive Document Processing.
s to recursively load PDF documents from specified
motive manufacturing environments.
tion model to split documents into fixed-length text
nd multi-column layouts common in automotive
ctors and storing them in the Chroma vector database,
ive terminology and concepts.
sationalRetrievalChain to process user queries and
ly deployed Ollama model.
subsequent optimizations, each designed to address
nformation retrieval.
dustry documents, we developed an enhanced PDF
s.
n from PDF documents. It is capable of extracting text,
uments. PDFMiner provides both high-level and low-
otive technical documents often feature multi-column

=== Page 7 ===
layouts and complex diagrams. We implemented a custom algorithm using PDFMiner's extract_pages function to
accurately extract content while preserving the logical flow of information:
1. Page Segmentation: We analyze each page to identify distinct content regions, including text columns,
diagrams, and tables.
2. Content Ordering: Implementing a left-to-right, top-to-bottom reading order algorithm to ensure proper
sequencing of extracted information.
3. Diagram Extraction: Utilizing PDFMiner's image extraction capabilities to preserve technical diagrams crucial
for understanding automotive specifications.
Tabula is a Java library used for extracting tabular data from PDF files. It provides a Python wrapper, making it
more convenient to use Tabula in Python. Tabula can automatically detect table boundaries and convert tabular
data into DataFrame objects, facilitating subsequent data analysis and processing.
2.2.2 Multi-column Layout and Table Information Recognition Optimization
Tables in automotive documents often contain critical data such as part specifications, test results, or compliance
information. Our approach uses Tabula's read_pdf function with custom parameters like Algorithm 1:
ALGORITHM 1: Extract Text and Tables from PDF to Markdown
write_2_md(input, output)
pages = extract_pages(input)
open output for writing as out
for page_num, page in enumerate(pages, start=1), do
elements = [e for e in page if isinstance(e, LTTextContainer)]
tables = tabula.read_pdf(input, pages=page_num, multiple_tables=True)
mid_line = (max(e.bbox[2] for e in elements) + min(e.bbox[0] for e in elements)) / 2
left = [e for e in elements if e.bbox[0] < mid_line]
right = [e for e in elements if e.bbox[0] >= mid_line]
sort left by -e.bbox[1]
sort right by -e.bbox[1]
for col in [left, right], do
for e in col, do
cleaned_text = clean_text(e.get_text())
write cleaned_text + "\n" to out
end
end
for table in tables, do
write pd.DataFrame(table).to_markdown(index=False) + "\n" to out
end
write "\n\n" to out
end

=== Page 8 ===
end
1. Table Detection: Implementing heuristics to identif
considering common formats used in the industry.
2. Data Extraction: Converting recognized tables into stru
between data points.
3. Contextual Integration: Seamlessly integrating extrac
document coherence.
When integrating text and table information, we first writ
layout recognition algorithm into the Markdown file in the or
each page, we convert the table information recognized on th
file. By doing so, we can ensure that the content order in the ge
PDF file, and the table information can be correctly embedded
To illustrate the effectiveness of this approach, let's exa
process for a complex academic paper layout. Figure 2 shows a
features a challenging two-column layout with embedded tab
the corresponding Markdown output after processing with ou

fy table structures within automotive documents,
uctured DataFrame objects, preserving relationships
cted table data with surrounding text to maintain
te the text information extracted by the multi-column
rder of appearance. Then, after the text information of
hat page into Markdown format and write it into the
enerated Markdown file is consistent with the original
d in the corresponding positions.
amine two figures that demonstrate the conversion
a sample page from the original PDF document, which
bles and various formatting elements. Figure presents
ur optimized method.

=== Page 9 ===
Figure 2: Sample page from original PDF document. (https://arxiv.org/pdf/1804.07821)

=== Page 10 ===
Figure 3: Corresponding M
As we can see, our method successfully preserves the stru
capturing both the textual content and tabular data. The two
Markdown format, maintaining the logical flow of informati
syntax, ensuring they remain easily readable and can be furth
Through this approach, we can effectively combine the fun
optimized PDF processing method significantly improves the
from complex automotive documents, providing a solid found
2.3 Optimization of Advanced RAG Based on Langchain
To enhance the RAG system's performance for automot
optimizations to the Langchain-based implementation. We int
Building upon the groundwork laid in previous sections, w
retriever using EnsembleRetriever in Langchain, assigning d
accurate retrieval. Then, a custom class is designed to integra
pipeline, further enhancing the retrieval and generation quali
2.3.1 Overview of BGE Reranker Model and BM25 Retriever
A reranker model is a general semantic vector model used to
to prioritize automotive-relevant information in retrieved con
large as the reranker model. BGE (BAAI General Embedding)
of Artificial Intelligence (BAAI), specifically optimized for Chin

Markdown output.
uctural integrity of the original document, accurately
o-column layout is seamlessly converted into a linear
ion. Tables are properly formatted using Markdown
her processed or rendered as needed.
nctionality of the PDFMiner and Tabula libraries. This
accuracy and completeness of information extraction
dation for subsequent RAG processes.
tive industry applications, we introduced several
troduce the BGE reranker model and BM25 algorithm.
we first combine the BM25Retriever with the default
different weights to achieve more comprehensive and
ate the reranking model into the context compression
ity of the model.
optimize the ranking of retrieval results. It can adapt
ntexts. In this study, we employ BAAI/bge-reranker-
is a reranker model proposed by the Beijing Academy
nese queries [40].

=== Page 11 ===
BM25 (Best Matching 25) is a classic bag-of-words retriev
the term frequency-inverse document frequency (TF-IDF) sco
retriever can quickly and efficiently filter out the most query
We introduce this traditional relevance assessment method
strengthen the effectiveness of the RAG retriever.
2.3.2 Building the Context Compression Pipeline and Custom
To optimize the context information processing of the RAG
DocumentCompressorPipeline that is pecifically tailored f
collection retrievers mentioned earlier, we also introduce:
• EmbeddingsRedundantFilter: An embedding-based r
from the retrieval results.
• LongContextReorder: Optimizes the order of context in
and procedures.
• BgeRerank: A custom class that inherits from BaseDocu
for the BGE model is relatively limited, the purpose of d
reranker model into the pipeline. This custom class can
The following Algorithm 2 is the pseudocode for the BgeR
ALGORITHM 2: B
BgeRerank(documents, query)
initialize model = CrossEncoder(model_name)
doc_list = list(documents)
_docs = [d.page_content for d in doc_list]
model_inputs = [[query, doc] for doc in _docs]
scores = model.predict(model_inputs)
results = sorted(enumerate(scores), key=lambda x: x[1], revers
final_results = []
for r in results, do
doc = doc_list[r[0]]
doc.metadata["relevance_score"] = r[1]
append doc to final_results
end
return final_results
By overriding the compress_documents method, the BGE
query and documents. The documents are then sorted based o
as the final compression results. This custom class design c
Langchain, allowing us to flexibly incorporate it into the pipel

val algorithm that evaluates relevance by calculating
ore between the query and documents [41]. The BM25
y-relevant documents from a large-scale text corpus.
d in combination with the reranker model to further
Class Design
model, we construct a context compression pipeline
for automotive technical content. In addition to the
redundancy filter to remove redundant information
nformation, prioritizing key automotive specifications
umentCompressor. Since Langchain's official support
designing this class is to seamlessly integrate the BGE
n improve relevance scoring for automotive queries.
Rerank class:
BgeRerank
se=True)[:top_n]
model is used to calculate the relevance between the
on their scores, and the top N documents are selected
compensates for the insufficient support for BGE in
line structure.

=== Page 12 ===
In summary, the innovative aspects of this section inclu
retriever, building the context compression pipeline, and seam
through the custom BgeRerank class. This pipeline significan
information, ensuring that the most pertinent automotive tec
2.4 Optimization of Advanced RAG Based on Langchain
In the previous section, we completed the basic design of the R
applications and constructing end-to-end intelligent system
complex, multi-step problem of querying PDF profiles, w
manufacturing processes, we have developed an advanced Se
2.4.1 Overview of SELF-RAG
Self-Reflective Retrieval-Augmented Generation (SELF-RAG) i
and factual accuracy of LLMs through on-demand retrieval an
Unlike traditional RAG methods, SELF-RAG endows LLMs w
1. On-demand Retrieval: The LLMs autonomously determi
external knowledge base based on the input it receives
2. Self-Reflection: The LLMs evaluates and reflects upon b
content, thereby improving the quality and reliability o
The training process of SELF-RAG consists of two stages:
1. Offline Critic Model Training: An independent critic mo
tokens are inserted into the LLMs' output to guide its se
2. Generative Model Training: The LLMs is fine-tuned
retrieved documents. This enables the LLMs to unde
reflection into its generation process.
During inference, the LLMs dynamically decides whether t
the task at hand. It also leverages the retrieved information
quality output. For instance, in tasks demanding factual accur
relevant information, while in more open-ended tasks, it may
2.4.2 Agent Design Supporting Self-RAG
Considering this, based on Langchain, we designed an intell
utilize Self-RAG technology to answer user questions. Ag
LangGraph and LangChain ecosystems to achieve a modular a
The core of the AgenticRAG class is the create_graph me
acyclic graph (DAG). The workflow consists of multiple nodes
answering process. The nodes are connected by directed edg
main components in the AgenticRAG class are as follows:

ude: introducing the BGE reranker model and BM25
mlessly integrating BGE into the Langchain framework
ntly enhances the quality and relevance of retrieved
chnical details are presented to the language model.
RAG system. However, integrating LLMs into practical
ms still present numerous challenges. To address the
which is common in automotive engineering and
elf-RAG agent based on the LangGraph framework.
is a novel framework designed to enhance the quality
nd a self-reflection mechanism [42].
with the following capabilities:
ines whether to retrieve relevant information from an
s.
both the retrieved information and its own generated
of its output.
odel is trained to generate "reflection tokens". These
elf-reflection process.
using a corpus that includes reflection tokens and
erstand and utilize these tokens, incorporating self-
to retrieve information based on the requirements of
and the self-reflection mechanism to generate high-
racy, the LLMs is more inclined to retrieve and utilize
y prioritize creativity and rely less on retrieval.
ligent Agent class called AgenticRAG, which aims to
genticRAG combines various components from the
and scalable question-answering system.
ethod, which defines a workflow based on a directed
s, each responsible for a specific task in the question-
ges, forming a complete question-answering flow. The

=== Page 13 ===
• GraphState: Represents the current state of the graph,
generated answer, and chat history.
• Node: Represents a step or task in the question-ans
performs specific operations, and returns the updated s
We designed the AgenticRAG class to handle sophisticate
Figure 4:
Figure 4: Flowchart of Self-RAG Agent Im
1. Retrieve Node: Optimized to fetch relevant informatio
industry-specific terminology and concepts.
2. Grade Documents Node: Evaluates retrieved docume
considering factors like technical accuracy and applicab
3. Generate Node: Produces responses tailored to au
specifications and industry standards searched from do
4. Transform Query Node: Refines queries to better capt
improving retrieval accuracy in subsequent iterations.

, including the user's question, retrieved documents,
swering process, accepts the current state as input,
state.
ed automotive-related questions. Key components as
mplementation via LangGraph.
on from automotive technical documents, considering
ents based on their relevance to automotive queries,
bility to specific manufacturing processes.
utomotive industry needs, incorporating technical
ocuments.
ture the intent behind automotive-specific questions,

=== Page 14 ===
AgenticRAG uses conditional judgment logic to determine
example, based on the scoring results from the Grade Docum
or rewrite the question; simultaneously, based on the qualit
determines whether to regenerate, rewrite the question, or ou
The design of AgenticRAG fully reflects modularity and sca
process into multiple independent nodes, each node focus
understand, debug, and maintain. At the same time, since the n
be easily inserted into the existing workflow, supporting the e
2.4.3 Function Calling Design for Optimizing Ollama Output in
Function calling is a powerful technique that significantly en
[43]. By integrating external functions with LLMs, specialized
model, resulting in more accurate, coherent, and informativ
learning capabilities of LLMs, enabling them to adapt to new
reasoning and computation.
However, most of the relevant work has focused on
implementation for optimizing Ollama callbacks, especiall
provides ollamafunction.bind to call functions, further resea
enhance the agent's capability in handling automotive-spec
ollamafunction.bind, called ChatFunction. It inherits from t
__call__ methods. The main features of ChatFunction are as A
ALGORITHM 3: C
ChatFunction(persona, lang, retry)
inputProp = Property(type=INPUT, desc=InputDesc())
outputProp = Property(type=OUTPUT, desc=OutputDesc())
props = [inputProp, outputProp]
params = Parameter(props=props, required=[input, output])
initialize BaseFunction(name=ChatFuncName(), desc=ChatFun
end procedure
call(args)
output = args[output]
input = args[input]
if IsEmpty(output) or IsEmpty(input), do
raise ValueError(MissingArgMessage())
end
detail = GetPromptByRetry(retry)
persona = GetPersonaString(lang)
history = GetHistoryString(input)

the direction of the question-answering process. For
ments Node, it decides whether to generate an answer
ty of the answer generated by the Generate Node, it
utput the final result.
alability. By dividing the complex question-answering
ses on a specific task, making the system easier to
nodes pass information through states, new nodes can
extension and optimization of functionality.
n RAG Scenarios
nhances the output quality of LLMs in RAG scenarios
d logic and algorithms can be employed to guide the
ve responses. This approach leverages the few-shot
w tasks while mitigating their inherent limitations in
standard transformer-based LLMs, with a lack of
ly in RAG scenarios. Although Langchain officially
arch on this method is currently scarce. Therefore, to
ecific tasks, we designed a custom class adapted to
the BaseFunction class and overrides the __init__ and
Algorithm 3:
ChatFunction
ncDesc(), params)

=== Page 15 ===
current = GetCurrentString(input)
prompt = Format(detail, persona, history, current)
respTool = LookupTool(ChatResponseEnhancer())
return {
tool: respTool,
tool_input: {
response: output,
query: prompt
}
}
end procedure
GetPromptByRetry(retry)
if retry = 0, do
return GetBriefPrompt()
else if retry = 1, do
return GetMediumPrompt()
else
return GetDetailedPrompt()
end
end function
The initialization accepts three parameters: the AI assist
preference language, and retry count retry_count.
Two properties are defined: query_input and output, rep
description, language instructions, and conversation history
ensures that the model is provided with the necessary backgro
responses based on the specified role characteristics and lang
The constructor of the parent class BaseFunction is c
parameter list.
When invoked, it accepts an arguments dictionary containi
According to the retry count retry_count in the self-ra
detail_prompt is dynamically adjusted to modify prompts ba
depth of technical detail required.
The query_input for the next round is constructed by encod
detail level requirement, and current conversation history. T
context, crucial for addressing multi-step automotive process
A dictionary is returned, containing the tool field (specifyin
(containing the optimized response and updated query_inp
continue optimizing based on the current results and state, fo

tant's personality description personality, language
presenting the complete input (including personality
y) and the AI assistant's response, respectively. This
ound knowledge for each retry, enabling it to generate
guage style.
called, passing the function name, description, and
ing two required parameters: output and query_input.
ag Agent in 3.3.2, the level of detail in the answer
ased on the complexity of automotive queries and the
ding the personality description, language preference,
To maintain awareness of the ongoing conversation
ses or complex diagnostic queries.
ng the callback function name) and the tool_input field
put), allowing the next round of callback requests to
orming a closed-loop self-improvement process.

=== Page 16 ===
The innovation of ChatFunction lies in its full utilization
optimizing the response effectiveness in the RAG scenario
improves the agent's ability to handle complex automotive q
can guide users through the efficient acquisition of knowledge
3 RESULTS
3.1 Overview of the RAGAS Performance Evaluation Framewo
RAGAS (Retrieval Augmented Generation Assessment Suit
assessing the performance of RAG models. It provides a series
with a particular focus on the impact of information retrieval
RAGAS include:
• Context Precision: Measures the precision of relevant
results.
• Faithfulness: Evaluates the faithfulness of the generat
the consistency between the generated content and the
• Answer Relevancy: Assesses the relevance of the ge
answers are on-topic and meet the requirements of the
• Context Recall: Measures the coverage of relevant con
much key information is captured.
We adopt RAGAS as the evaluation framework to compare a
The quantitative metrics provided by RAGAS enable us to obje
models in terms of contextual information utilization an
references for model selection and optimization.
3.2 Experimental Results and Analysis
3.2.1 Experimental Scenario Design
In this paper, we select two public datasets, QReCC [44], and C
the experimental data sources. The QReCC dataset contains 10
knowledge text, with questions presented in the form of multi-
multi-domain dialogues, each based on a given text and consis
The self-constructed dataset is a automotive industry prop
a leading automotive manufacturer. This dataset includes:
• Technical specifications and design documents
• Manufacturing process guidelines
• Quality control procedures
• Corporate regulations and standards

n of Ollama's JSON mode callback function potential,
o. This customized function call mechanism greatly
queries, provide technically accurate information, and
e common to automotive design and manufacturing.
ork
te) is a comprehensive evaluation framework for
of metrics to quantify the quality of generated results,
l on the generation process. The evaluation metrics in
t contextual information contained in the generated
ted results to the original contextual information, i.e.,
e original information.
enerated answers to the questions, i.e., whether the
e questions.
ntextual information in the generated results, i.e., how
and analyze the performance of different RAG models.
ectively evaluate the strengths and weaknesses of the
nd generated content quality, providing important
CoQA [45], and introduce a self-constructed dataset as
0,000 questions, each corresponding to a background
-turn dialogues. The CoQA dataset contains over 8,000
sting of multiple question-answer turns.
prietary dataset compiled from internal documents of

=== Page 17 ===
Due to the confidential nature of these documents, we can
this dataset represents the core focus of our study, reflect
processing.
While the self-constructed dataset serves as our primary
crucial reasons:
1. Structural Similarity: The question-answer pairs in QRe
designed test cases for the self-constructed dataset. Th
of our model's performance across different domains.
2. Conversational Nature: Both QReCC and CoQA feature m
dependent queries often encountered in automotive en
3. Diverse Domain Coverage: These datasets cover a wi
generalization capabilities beyond the automotive dom
4. Benchmark Comparability: As widely used public data
system against other state-of-the-art models in a reprod
5. Confidentiality Compliance: By using these public data
discuss and compare results without compromising sen
6. Robustness Testing: The inclusion of these datasets help
for automotive applications, do not compromise perfor
Considering that our research aims at the requirements of
model, we first translate the knowledge or link information
convert it to PDF format. This step ensures the consistency o
real application scenarios and facilitates the evaluation of t
optimization schemes in practice. The self-constructed data
already in PDF format.
After data preparation, we design or directly utilize a numb
content from these datasets as test cases. Here, we take a set
an example, given a background text:
“John is a boy who likes to play outside. After school, he a
The following is a set of multi-turn question-answering ba
“Q: What did John do after school?
A: John went to the park after school.
Q: Who did he meet at the park?
A: He met his friends at the park.”
We designed our experiments to evaluate the performance
• Naive RAG (Baseline)
• Advanced RAG (Our Optimized Model)
• Self-RAG Agent (Baseline)
• Self-RAG Agent (Our Proposed Agent with Custom Func

nnot provide detailed statistics or examples. However,
ting real-world challenges in automotive document
y testbed, we included QReCC and CoQA for several
eCC and CoQA share a similar format with our custom-
his structural consistency allows for a fair comparison
multi-turn dialogues, mirroring the complex, context-
ngineering and manufacturing processes.
ide range of topics, helping us evaluate our model's
main.
asets, QReCC and CoQA enable us to benchmark our
ducible manner.
asets alongside our proprietary data, we can openly
nsitive corporate information.
ps demonstrate that our optimizations, while tailored
rmance on general conversational tasks.
f PDF dialogue chatbots and uses the BGE reordering
n in the QReCC and CoQA datasets into Chinese and
of experimental data with complex PDF documents in
the performance of different RAG models and their
aset does not require additional processing as it is
ber of question-answer pairs with contextual memory
t of question-answer pairs from the QReCC dataset as
always goes to the park to meet his friends.”
ased on this background text:
e of four systems:
ction Calling)

=== Page 18 ===
For each dataset, we created test sets comprising:
• 500 question-answer pairs from the self-constructed da
• 500 pairs from QReCC
• 500 pairs from CoQA
These test sets were carefully curated to ensure a balan
complex technical questions, mirroring real-world usage scen
3.2.2 Optimization Effects of Langchain-based RAG
Figure 5: Performance Comparison of Naive RAG vs. Advanced RAG w
Table 1: Comparative Analysis of Naive RAG vs. Advanced RAG wit
Datasets Metrics QReCC
Naive RAG Answer Relevancy 0.782
Faithfulness 0.81
Context Precision 0.845
Context Recall 0.831
Advanced RAG Answer Relevancy 0.811
Faithfulness 0.847
Context Precision 0.839
Context Recall 0.842

ataset
nce of simple queries, multi-turn conversations, and
narios in the automotive industry and beyond.
with Custom Context Compression Pipeline across Datasets.
th Custom Context Compression Pipeline across Datasets
CoQA Self-constructed dataset
0.772 0.759
0.803 0.803
0.838 0.847
0.824 0.822
0.829 0.817
0.85 0.832
0.841 0.836
0.811 0.835

=== Page 19 ===
According to the Figure 5 and Table 1, experimental resu
optimization approach achieves certain improvements on som
By introducing the BGE reordering model and BM25 retrie
the optimized RAG model improves context precision by 0.
constructed dataset, respectively. The context recall also in
constructed dataset, but decreases by 1.6% on the CoQA dat
model shows some improvements in capturing question-relev
However, the optimized model exhibits 3.7%, 7.4%, and 7
well as 4.6%, 5.9%, and 3.6% boosts in faithfulness on QReCC
These results underscore the effectiveness of our optimiza
and queries. The Advanced RAG model also showed improv
notably superior, particularly in dealing with multi-step techn
3.2.3 Optimization Effects of Langgraph-based Self-RAG Agen
Figure 6: Performance Comparison of Self-RAG Agent vs. Self-RA
Table 2: Comparative Analysis of Self-RAG Agent vs. Self-RAG
Datasets Metrics QReCC
Answer Relevancy 0.839

ults show that the proposed Langchain-based RAG
me metrics compared to the naive RAG model.
ever, and constructing a context compression pipeline,
.7%, 0.4%, and 1.3% on the QReCC, CoQA, and self-
ncreases by 1.3% and 1.6% on the QReCC and self-
taset. These results indicate that while the optimized
vant background knowledge, it is not always the case.
7.6% relative improvements in answer relevancy, as
C, CoQA, and self-constructed dataset, respectively.
ations in handling complex automotive documentation
vements, but the Self-RAG Agent's performance was
nical queries common in automotive applications.
nt
AG Agent with Custom Function Calling across Datasets.
Agent with Custom Function Calling across Datasets
CoQA Self-constructed dataset
0.821 0.83

=== Page 20 ===
Datasets Metrics QReCC
Self-RAG Faithfulness 0.847
Agent Context Precision 0.864
Context Recall 0.851
Self-RAG Answer Relevancy 0.852
Agent with Faithfulness 0.859
custom function Context Precision 0.861
calling Context Recall 0.871
According to the Figure 6 and Table 2, evaluation results sho
improvements over the naive RAG model on most metrics ac
naive RAG by 7.3%, 6.3%, and 9.4% in answer relevancy, 4.6%
in context precision, and 2.4%, 2.1%, and 3.3% in context r
respectively. The superior performance on most metrics demo
and self-verification mechanism in enabling more targeted an
Furthermore, by introducing the custom function calling m
RAG agent obtains additional 9.0%, 10.2%, and 13.3% gains i
in faithfulness, 1.9%, 5.3%, and 3.0% improvements in contex
context recall on the three datasets compared to the naive
adjusting question and context inputs to the Ollama model ba
generate more accurate, informative, and coherent responses
This performance demonstrates that our optimizations e
excelling in domain-specific tasks. The consistent improve
successfully balances domain-specific optimization with gene
4 DISCUSSION
Our innovative approach to handling complex automotive que
RAG process flow with custom function calling, applied to an
showcases the integration of our custom ChatFunction wit
dynamically adjusts the detail and focus of responses based o
process illuminates the system's capability to iteratively refin
in the context of specialized automotive knowledge.

CoQA Self-constructed dataset
0.858 0.847
0.866 0.867
0.841 0.849
0.851 0.86
0.86 0.857
0.882 0.872
0.87 0.86
ow that the self-RAG agent obtains more significantly
cross the three datasets. Specifically, it surpasses the
%, 6.8%, and 5.5% in faithfulness, 2.2%, 3.3%, and 2.4%
recall on QReCC, CoQA, and self-constructed dataset,
onstrates the effectiveness of the proposed self-asking
nd reliable context retrieval and answer inference.
mechanism that optimizes the Ollama output, the self-
in answer relevancy, 6.0%, 7.1%, and 6.7% increases
xt precision, as well as 4.8%, 5.6%, and 4.6% boosts in
RAG model. These results validate that dynamically
ased on conversation states can effectively guide it to
s that better satisfy user needs.
enhance general conversational AI capabilities while
ement across datasets suggests that our approach
eral language understanding.
eries is exemplified in Figure 7, which depicts the Self-
Anti-lock Braking System (ABS) query. This diagram
thin the Self-RAG framework, demonstrating how it
on the system's self-assessment and retry count. The
ne its answers, ensuring high relevance and accuracy

=== Page 21 ===
«Example»
«
1. User Query
3. Retri
2. Document
Retrieval
Explain ABS working principle ABS prevents wheel lo
and safety advantages
«Example»
6. Initial Answer
Self-RAGLoop
ABS prevents wheel lock,
improves safety ABS reduces braking d
«Example»
9. Optimized Answer
«Highlight» «Highlight»
8. Self-reflection 7. Quality ABS prevents wheel lock,
and Optimization Assessment uses sensors and ECU,
reduces braking distance
by 10-20%
Custom Function Calling (ChatFunction):
- Adjusts detail based on retry_count 10.
- Integrates personality and language Outp
- Optimizes for user needs
Figure 7: Optimized Self-RAG Process Flow with
When comparing performance across datasets, we observ
automotive applications, they also showed improvements on
• The most significant improvements were on the AID, al
• Performance gains on QReCC and CoQA, while smaller, w
approach.
• The Self-RAG Agent showed the most consistent perform
to various query types and domains.
These results validate our approach of using diverse datasets
optimizing for automotive applications, the improvements se
fundamental aspects of information retrieval and generation,

«Example»
ieved Fragments
ock... ABS components...
«Highlight» «Highlight»
4. Relevance 5. Generate
Scoring Initial Answer
distance...
Final
put
h Custom Function Calling - examples.
ved the fact that while our models were optimized for
the QReCC and CoQA datasets:
ligning with our focus on automotive applications.
were still substantial, indicating the robustness of our
mance across all datasets, highlighting its adaptability
s for evaluation. While our primary focus remains on
een across datasets suggest that our methods enhance
benefiting both specialized and general applications.

=== Page 22 ===
5 DISCUSSION
This study presents a comprehensive approach to optimizing
specifically focusing on PDF chatbots deployed in local, low-
critical challenges in processing complex automotive docume
5.1 Key Contributions
• Enhanced PDF Processing: We developed a novel met
handle multi-column layouts and complex tables p
significantly improves information extraction accuracy
• Advanced RAG Optimization: Our Langchain-based RAG
context compression pipeline, demonstrates subst
automotive-specific information.
• Self-RAG Agent Design: The proposed AgenticRAG, en
shows superior performance in handling complex, mul
manufacturing processes.
• Cross-Domain Effectiveness: While optimized for a
improvements in general conversational AI tasks, as e
datasets.
5.2 Implications for the Automotive Industry
Our research has significant implications for the automotive s
1. Improved Information Access: The optimized PDF
information for engineers, technicians, and other stakeh
2. Enhanced Decision Making: By providing more accurat
can support better decision-making in design, manufac
3. Resource Efficiency: The ability to deploy these
environments addresses the industry's needs for data p
5.3 Limitations and Future Work
While our study demonstrates significant advancements, ther
1. Expanding Domain Coverage: Future work could focus
automotive sub-domains, such as electric vehicle techn
2. Real-Time Performance Optimization: Further resea
performance in resource-constrained industrial environ
3. Multi-Modal Integration: Incorporating the ability to p
in technical diagrams and schematics could greatly enh
4. Longitudinal Study: A long-term study in real automotiv
the system's impact on operational efficiency and decis
5. Ethical and Privacy Considerations: As the system dea
explore advanced methods for ensuring data privacy an

RAG techniques for automotive industry applications,
-performance environments. Our research addresses
entation and responding to industry-specific queries.
thod combining PDFMiner and Tabula to effectively
prevalent in automotive technical documents. This
y from industry-specific PDFs.
G system, featuring a custom retriever ensemble and
tantial improvements in retrieving and utilizing
nhanced with a custom function calling mechanism,
lti-step queries typical in automotive engineering and
automotive applications, our approach also shows
evidenced by performance gains on QReCC and CoQA
sector:
chatbot can greatly enhance access to technical
eholders in the automotive industry.
te and contextually relevant information, our system
cturing, and quality control processes.
advanced capabilities in low-performance, local
privacy and resource constraints.
re are areas for further research:
s on adapting the system to cover a broader range of
nology or autonomous driving systems.
arch is needed to enhance the system's real-time
onments.
process and respond to queries about visual elements
hance the system's utility.
ve manufacturing settings could provide insights into
sion-making processes.
als with proprietary information, future work should
nd ethical use of AI in industrial settings.

=== Page 23 ===
In conclusion, this research represents a significant step forwa
techniques to the specific needs of the automotive indus
capabilities and the practical constraints of industrial enviro
transformation of the automotive sector. The demonstrated
information retrieval and query resolution pave the way for m
systems in automotive manufacturing and engineering.
REFERENCES
[1] C. Llopis-Albert, F. Rubio, and F. Valero. 2021. Impact Of Digital Transfor
Social Change 162 (2021), 120343. https://doi.org/10.1016/j.techfore.2
[2] D. G. Schniederjans, C. Curado, and M. Khalajhedayati. 2020. Supply Ch
International Journal of Production Economics 220 (2020), 107439. http
[3] A. Zahra and M. Saeedeh. 2021. Text-Based Question Answering From Info
Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 1
[4] M. Shanahan. 2024. Talking about Large Language Models
https://doi.org/10.1145/3631338
[5] M. Mozes, X. He, B. Kleinberg, and L. D. Griffin. 2023. Use of LLMs for Illici
preprint arXiv:2308.12833 (2023).
[6] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, M. Wang, and H
Models: A Survey. arXiv preprint arXiv:2312.10997 (2023).
[7] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M
Augmented Generation for Knowledge-Intensive NLP Tasks. In Advances
[8] S. Raja, A. Mondal, and C. V. Jawahar. 2022. Visual Understanding of Com
IEEE/CVF Winter Conference on Applications of Computer Vision. 2543-2
[9] M. Krichen. 2023. Formal Methods and Validation Techniques for Ensu
https://doi.org/10.3390/electronics14030666
[10] H. Liu, M. Galindo, H. Xie, L. Wong, H. Shuai, Y. Li, and W. Cheng. 2024. Lig
Survey. arXiv preprint arXiv:2404.07236 (2024).
[11] V. D. Viellieber and M. Aßenmacher. 2020. Pre-trained language models as
arXiv:2012.02558 (2020).
[12] M. Ghaleb, H. Zolfagharinia, and S. Taghipour. 2020. Real-time production
job arrivals and machine breakdowns. Computers & Industrial Engineeri
[13] J. B. Gruber and M. Weber. 2024. rollama: An R package for using g
arXiv:2404.07654 (2024).
[14] R. Hussain and S. Zeadally. 2019. Autonomous Cars: Research Results, Issu
21, 2 (2019), 1275-1313. https://doi.org/10.1109/COMST.2018.286936
[15] Q. Ai, T. Bai, Z. Cao, Y. Chang, J. Chen, Z. Chen, Z. Cheng, S. Dong, Z. Dou, F.
Z. Ren. 2023. Information Retrieval meets Large Language Models: A str
(2023), 80-90. https://doi.org/10.1016/j.fmre.2023.06.009
[16] M. Krafft, L. Sajtos, and M. Haenlein. 2020. Challenges and Opportunities
Journal of Interactive Marketing 51 (2020), 1-8. https://doi.org/10.1016
[17] D. Amalfitano, V. De Simone, R. R. Maietta, S. Scala, and A. R. Fasolino. 2
testing processes: An automotive industrial experience. Jo
https://doi.org/10.1002/smr.2171
[18] Z. Jiang, F. F. Xu, L. Gao, Z. Sun, Q. Liu, J. Dwivedi-Yu, Y. Yang, J. Callan
Proceedings of the 2023 Conference on Empirical Methods in Natural Lan
[19] Z. Wang, J. Araki, Z. Jiang, M. R. Parvez, and G. Neubig. 2023. Learning to
arXiv:2311.08377 (2023).
[20] A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi. 2023. Self-RAG: Learnin
preprint arXiv:2310.11511 (2023).
[21] D. Rajpathak, Y. Xu, and I. Gibbs. 2020. An Integrated Framework For Au
Effective Fault Detection And Isolation In Automotive Domain
https://doi.org/10.1016/j.eswa.2020.103338
[22] S. Siriwardhana, R. Weerasekera, E. Wen, T. Kaluarachchi, R. Rana, and S

ard in applying advanced natural language processing
stry. By bridging the gap between cutting-edge AI
onments, our work contributes to the ongoing digital
improvements in handling complex, domain-specific
more intelligent, efficient, and responsive information
rmation On The Automotive Industry. Technological Forecasting and
2020.120343
hain Digitisation Trends: An Integration of Knowledge Management.
ps://doi.org/10.1016/j.ijpe.2019.07.001
ormation Retrieval And Deep Neural Network Perspectives: A Survey.
11, 6 (2021), e1412. https://doi.org/10.1002/widm.1412
s. Communications of the ACM 67, 2 (2024), 68-79.
it Purposes: Threats, Prevention Measures, and Vulnerabilities. arXiv
H. Wang. 2023. Retrieval-Augmented Generation for Large Language
M. Lewis, W. Yih, T. Rocktäschel, S. Riedel, and D. Kiela. 2020. Retrieval-
s in Neural Information Processing Systems, Vol. 33. 9459-9474.
mplex Table Structures from Document Images. In Proceedings of the
2552.
uring Automotive Systems Security. Electronics 14, 3 (2023), 666.
ghtweight Deep Learning for Resource-Constrained Environments: A
s knowledge bases for Automotive Complaint Analysis. arXiv preprint
n scheduling in the Industry-4.0 context: Addressing uncertainties in
ing 123 (2020), 105031. https://doi.org/10.1016/j.cie.2020.105031
generative large language models through Ollama. arXiv preprint
ues and Future Challenges. IEEE Communications Surveys & Tutorials
60
Feng, S. Gao, J. Guo, X. He, Y. Lan, C. Li, Y. Liu, Z. Lyu, W. Ma, J. Ma, and
rategic report from Chinese IR community. Fundamental Research 4
for Marketing Scholars in Times of the Fourth Industrial Revolution.
6/j.intmar.2020.06.001
2019. Using tool integration for improving traceability management
ournal of Systems and Software 151 (2019), e2171.
n, and G. Neubig. 2023. Active Retrieval Augmented Generation. In
nguage Processing. 7969-7992.
o Filter Context for Retrieval-Augmented Generation. arXiv preprint
ng to Retrieve, Generate, and Critique through Self-Reflection. arXiv
utomatic Ontology Learning From Unstructured Repair Text Data For
n. Expert Systems with Applications 123 (2020), 103338.
S. Nanayakkara. 2022. Improving the Domain Adaptation of Retrieval

=== Page 24 ===
Augmented Generation (RAG) Models for Open Domain
https://doi.org/10.3390/electronics11203388
[23] S. Yin, C. Fu, S. Zhao, K. Li, X. Sun, T. Xu, and E. Chen. 2023. A Survey on M
(2023).
[24] C. Burgan, J. Kowalski, and W. Liao. 2024. Developing a Retrieval Augmen
Models (LLM) and LangChain Framework. IEEE Access 96 (2024). https:/
[25] B. Wang, G. Li, and Y. Li. 2023. Enabling Conversational Interaction with
Annual ACM Symposium on User Interface Software and Technology. Art
[26] D. Lin. 2024. Revolutionizing Retrieval-Augmented Generation with Enh
(2024).
[27] O. Bensch, M. Popa, and C. Spille. 2021. Key Information Extraction From
International Conference on Deep Learning Theory and Applications. 47-
[28] M. Faysse, G. Viaud, C. Hudelot, and P. Colombo. 2023. Revisiting Instruct
Proceedings of the 2023 Conference on Empirical Methods in Natural Lan
[29] A. Kumar and B. Starly. 2021. FabNER: information extraction from ma
recognition. Journal of Intelligent Manufacturing 33 (2021), 2393-2407. h
[30] D. Belhadj, A. Belaïd, and Y. Belaïd. 2023. Improving Information Extrac
variational Graph Auto-Encoder. In Document Analysis Systems. 113-129
[31] S. Zeng, J. Zhang, P. He, Y. Xing, Y. Liu, H. Xu, J. Ren, S. Wang, D. Yin, Y. Chan
in Retrieval-Augmented Generation (RAG). arXiv preprint arXiv:2402.168
[32] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G.
Guy, J. Menick, R. Ring, T. Hennigan, S. Huang, L. Maggiore, C. Jones, A.
Simonyan, J. W. Rae, E. Elsen, and L. Sifre. 2022. Improving Languag
arXiv:2112.04426 (2022).
[33] G. Izacard, P. Lewis, M. Lomeli, L. Hosseini, F. Petroni, T. Schick, J. Dwivedi-
with Retrieval Augmented Language Models. Journal of Machine Learning
[34] S. R. Ahmad. 2024. Enhancing Multilingual Information Retrieval in Mixed
Multicultural Enterprise. arXiv preprint arXiv:2401.01511 (2024).
[35] W. Su, Y. Tang, Q. Ai, Z. Wu, and Y. Liu. 2024. DRAGIN: Dynamic Retriev
Language Models. arXiv preprint arXiv:2403.10081 (2024).
[36] K. Noorbakhsh, M. Sulaiman, M. Sharifi, K. Roy, and P. Jamshidi. 2023. P
arXiv preprint arXiv:2110.03501 (2023).
[37] G. Gamage, N. Mills, D. De Silva, M. Manic, H. Moraliyage, A. Jennings, a
Decision Support in Net-Zero Emission Energy Systems. In 2024 IEEE Pow
(ISGT). 1-6. https://doi.org/10.1109/ISGT58387.2024.10471952
[38] B. Zhuang, J. Liu, Z. Pan, H. He, Y. Weng, and C. Shen. 2023. A survey on
International Conference on Computer Vision. 6823-6831.
[39] W. Chen, H. Hu, X. Chen, P. Verga, and W. W. Cohen. 2022. MuRAG: Multim
over Images and Text. In Proceedings of the 2022 Conference on Empiric
[40] S. Xiao, Z. Liu, P. Zhang, and N. Muennighoff. 2023. C-Pack: Packaged R
arXiv:2309.07597 (2023). https://doi.org/10.48550/arXiv.2309.07597
[41] V. Karpukhin, B. Oğuz, S. Min, L. Wu, S. Edunov, D. Chen, and W. Yih. 2020
Proceedings of the 2020 Conference on Empirical Method
https://doi.org/10.18653/v1/2020.emnlp-main.550
[42] A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi. 2023. Self-RAG: Learnin
preprint arXiv:2310.11511 (2023). https://doi.org/10.48550/arXiv.2310
[43] W. Chen, Z. Li, and M. Ma. 2024. Octopus: On-device language model for
(2024). https://doi.org/10.48550/arXiv.2404.01549
[44] R. Anantha, S. Vakulenko, Z. Tu, S. Longpre, S. Pulman, and S. Chappidi
Question Rewriting. In Proceedings of the 2021 Conference of the North
Human Language Technologies. https://doi.org/10.18653/v1/2021.naac
[45] S. Reddy, D. Chen, and C.D. Manning. 2019. CoQA: A Conversational Q
Computational Linguistics 7 (2019), 249-266. https://doi.org/10.1162/t

Question Answering. Electronics 11, 20 (2022), 3388.
Multimodal Large Language Models. arXiv preprint arXiv:2306.13549
nted Generation (RAG) Chatbot App Using Adaptive Large Language
//doi.org/10.1109/ACCESS.2024.3359176
Mobile UI using Large Language Models. In Proceedings of the 36th
ticle 432, 17 pages. https://doi.org/10.1145/3586183.3606716
hanced PDF Structure Recognition. arXiv preprint arXiv:2401.12599
m Documents - Evaluation And Generator. In Proceedings of the 3rd
-53. https://doi.org/10.5220/0010517700470053
tion Fine-tuned Model Evaluation to Guide Industrial Applications. In
nguage Processing. 9033-9048.
anufacturing process science domain literature using named entity
https://doi.org/10.1007/s10845-021-01867-z
ction from Semi-structured Documents Using Attention Based Semi-
9. https://doi.org/10.1007/978-3-031-41682-8_8
ng, and J. Tang. 2024. The Good and The Bad: Exploring Privacy Issues
893 (2024).
van den Driessche, J. Lespiau, B. Damoc, A. Clark, D. de Las Casas, A.
Cassirer, A. Brock, M. Paganini, G. Irving, O. Vinyals, S. Osindero, K.
ge Models by Retrieving from Trillions of Tokens. arXiv preprint
-Yu, A. Joulin, S. Riedel, and E. Grave. 2023. ATLAS: Few-shot Learning
g Research 24 (2023), 251:1-251:43.
d Human Resources Environments: A RAG Model Implementation for
val Augmented Generation based on the Information Needs of Large
Pretrained Language Models are Symbolic Mathematics Solvers too!.
and D. Alahakoon. 2024. Multi-Agent RAG Chatbot Architecture for
wer & Energy Society Innovative Smart Grid Technologies Conference
n efficient training of transformers. In Proceedings of the IEEE/CVF
modal Retrieval-Augmented Generator for Open Question Answering
cal Methods in Natural Language Processing. 5558-5570.
Resources To Advance General Chinese Embedding. arXiv preprint
0. Dense Passage Retrieval for Open-Domain Question Answering. In
ds in Natural Language Processing (EMNLP). 6769-6781.
ng to Retrieve, Generate, and Critique through Self-Reflection. arXiv
0.11511
r function calling of software APIs. arXiv preprint arXiv:2404.01549
i. 2021. Open-Domain Question Answering Goes Conversational via
h American Chapter of the Association for Computational Linguistics:
cl-main.44
Question Answering Challenge. Transactions of the Association of
tacl_a_00266

Paper:Querying Large Automotive Software Models - Agentic vs Direct LLM Approaches.pdf
=== Page 1 ===
5202
nuJ
61
]ES.sc[
1v17131.6052:viXra
Querying Large Autom
Agentic vs. Direct
Lukasz Mazur Nena
Chair of Robotics, Artificial Chair of Ro
Intelligence and Real-Time Systems Intelligence and
Technical University of Munich Technical Un
Munich, Germany Munich
lukasz.mazur@tum.de nenad.pet
Ansgar Radermacher Robert Ras
Software and Systems Engineering Real-Time Systems,
Universite´ Paris-Saclay Model Based Softw
CEA List Tensor embedded
Palaiseau, France Pollenfeld, Ge
ansgar.radermacher@cea.fr robert.rasche@ten
Abstract—Large language models (LLMs) offer new oppor-
tunities for interacting with complex software artifacts, such
as software models, through natural language. They present
especially promising benefits for large software models that are
difficulttograspintheirentirety,makingtraditionalinteraction
andanalysisapproacheschallenging.Thispaperinvestigatestwo
approaches for leveraging LLMs to answer questions over soft-
waremodels:directprompting,wherethewholesoftwaremodel
is provided in the context, and an agentic approach combining
LLM-based agents with general-purpose file access tools. We
evaluate these approaches using an Ecore metamodel designed
for timing analysis and software optimization in automotive and
embedded domains. Our findings show that while the agentic
approach achieves accuracy comparable to direct prompting,
it is significantly more efficient in terms of token usage. This
efficiency makes the agentic approach particularly suitable for
theautomotiveindustry,wherethelargesizeofsoftwaremodels
makes direct prompting infeasible, establishing LLM agents as
not just a practical alternative but the only viable solution.
Notably,theevaluationwasconductedusingsmallLLMs,which
aremorefeasibletobeexecutedlocally—anessentialadvantage
for meeting strict requirements around privacy, intellectual
property protection, and regulatory compliance. Future work
willinvestigatesoftwaremodelsindiverseformats,exploremore
complex agent architectures, and extend agentic workflows to
support not only querying but also modification of software
models.
Index Terms—Software Model Querying, Agentic LLMs, Au-
tomotive Software, LLMs for Model-Driven Engineering
I. INTRODUCTION
Software modeling is crucial in modern software engineer-
ing, particularly in safety-critical domains like automotive
ThisworkhasreceivedfundingfromtheEuropeanChipsJointUndertaking
underFrameworkPartnershipAgreementNo101139789(HAL4SDV)includ-
ingthenationalfundingfromtheGermanFederalMinistryofEducationand
Research(BMBF)undergrantnumber16MEE00471K.Theresponsibilityfor
thecontentofthispublicationlieswiththeauthors.

motive Software Models:
LLM Approaches
ad Petrovic James Pontes Miranda
obotics, Artificial Software and Systems Engineering
d Real-Time Systems Universite´ Paris-Saclay
niversity of Munich CEA List
h, Germany Palasieu, France
trovic@tum.de james.pontesmiranda@cea.fr
sche Alois Knoll
, Resources, Chair of Robotics, Artificial
ware Eng. Intelligence and Real-Time Systems
d GmbH Technical University of Munich
ermany Munich, Germany
nsor.gmbh knoll@in.tum.de
development, where precise models ensure compliance and
reliability [1]. However, the increasing size and complexity of
thesemodelsposesignificantchallengesforengineersinterms
of access, understanding, and manipulation [2].
Recent advancements in large language models (LLMs) of-
ferpromisingavenuestoassistwithcomplexsoftwaremodels,
leveragingtheircapabilitiesinnaturallanguageunderstanding
andcodegeneration[3].Despitethispotential,thedirectappli-
cationofLLMstostructuredsoftwaremodels,especiallywith
formal languages like PlantUML [4], remains largely unex-
plored [5]. Current research primarily focuses on unstructured
text or code, overlooking the unique challenges of integrating
LLMs with structured models, including format compatibility,
semantic precision, and consistency. Furthermore, the efficacy
of different LLM architectures, such as agentic workflows
versusdirectprompting,inunderstandingandreasoningabout
software models is unclear.
This study investigates and compares agentic LLM work-
flows and direct full-context prompting for querying software
models. We evaluate these approaches on specific, concrete
questions about model structure and semantics, using a repre-
sentative automotive software model.
Our contributions are twofold: an empirical comparison
of LLM-based agentic and direct prompting for software
modelquestionanswering,andinsightsintothefeasibilityand
limitations of current LLM capabilities in this context. These
findings will inform future research on advanced interactions
with software models in model-driven engineering.
Thepaperisstructuredasfollows:Section2reviewsrelated
work. Section 3 details the methodology. Section 4 presents
results and analysis. Section 5 discusses findings. Section 6
addresses threats to validity, and Section 7 concludes with
future work.

=== Page 2 ===
II. RELATEDWORK
A. LLMs in Software and Model-Driven Engineering
LLMs have increasingly been applied in various software
engineering tasks, including code generation, bug detection,
documentation,andsummarization.Theirabilitytounderstand
and generate natural language alongside programming lan-
guages makes them valuable assistants for developers across
the software development lifecycle [3].
Inmodel-drivenengineering(MDE),LLMsareincreasingly
being explored for tasks such as model generation, validation,
and transformation, aiming to improve automation and reduce
manual effort [3]. While software models offer high-level
abstractions of system designs, their structured and formal
natureposeschallengesfornaturallanguagemodels,requiring
specialized input representations and reasoning strategies [6].
A variety of modeling standards are used across domains, in-
cludingUML[7]andEclipseModelingFramework(EMF)[8]
in general software engineering, and AUTOSAR [9] in the
automotive industry. These standards provide precise specifi-
cations of structure and behavior, which are critical in safety-
critical domains governed by standards like ISO 26262, high-
lighting the growing need to integrate AI-assisted techniques
into rigorous development processes [10].
Traditional software modeling tools provide querying, vali-
dation, and transformation capabilities to manage these com-
plex models. EMF and specialized automotive toolchains
support model editing and consistency checks [10] [11]. The
integration of LLMs into such environments has the potential
to enhance these tools by enabling natural language querying,
automated documentation generation, and intelligent assis-
tance during modeling. This intersection of LLM technology
with established software modeling ecosystems remains an
active area of exploration [6].
B. LLM Integration with Structured Software Artifacts
Interfacing LLMs with structured software artifacts such
as models, codebases, or graphs requires specialized archi-
tectural approaches. Unlike plain text, software models are
inherently structured, hierarchical, and often constrained by
formal metamodels, which challenges traditional LLM input
paradigms [12].
One prominent technique to address these challenges
is Retrieval-Augmented Generation (RAG), where external
knowledge bases are queried to retrieve relevant fragments
thataugmenttheLLM’scontext.Thisapproachhelpsmitigate
token-length constraints and context fragmentation, enabling
the LLM to focus on pertinent information without being
overwhelmed by the entire knowledge base [13].
Beyond retrieval-based methods, tool-augmented LLM ar-
chitecturesenablemoresophisticatedworkflows.Theseagents
can perform iterative reasoning, plan multi-step queries, and
invoke external tools or APIs for accessing external data
sources. Agentic approaches combine LLM capabilities with
domain-specific logic and memory management, leading to
improved performance on complex tasks [14] [15]. As tool

usage gains popularity, emerging standards such as the Model
Context Protocol (MCP) [16] and Agent2Agent Protocol
(A2A) [17] are being developed to support scalable and
interoperableagentecosystems.MCPstandardizeshowagents
connecttotools,APIs,andresourcesthroughstructuredinputs
and outputs, while A2A facilitates dynamic, multimodal com-
municationbetweenagents,enablingcollaboration,delegation,
and shared task management.
The balance between single-shot prompting and multi-
turn agentic workflows also influences system capabilities.
While single-shot prompts are simpler and faster, agentic
workflowsprovideenhancedreasoning,planning,andverifica-
tion, but come with higher computational costs and increased
latency [18] [19]. The choice between these architectures
typically depends on the task’s complexity and how well the
agent’s available tools align with the task’s abstraction level.
C. Evaluation of Free-Text LLM Answers
Evaluating open-ended natural language answers from
LLMs is challenging, especially when accuracy, semantic
alignment, and factual grounding are essential. Traditional
lexical matching metrics that focus on the overlap of n-grams
(wordsequences)betweentwotexts,likeBLEUandROUGE,
often fall short when evaluating the quality of responses to
structured or knowledge-intensive queries because they pri-
marily assess surface-level word sequence commonality [20].
While semantic similarity methods, such as bi-encoder and
cross-encoder models, better capture meaning beyond lexical
overlap, they still struggle with evaluating factual accuracy,
logical consistency, and adherence to task-specific constraints
in complex scenarios [21].
LLM-as-a-Judge methods have recently emerged as a flex-
ible and scalable evaluation paradigm, prompting LLMs to
assess the correctness, completeness, and relevance of gener-
atedanswersusingtheirowndomainunderstanding.However,
these models may still hallucinate or misjudge, limiting their
reliability [22]. Human evaluation remains essential for en-
suring validity, particularly for complex reasoning tasks, but
it is resource-intensive and often requires expert reviewers to
assessnuancedcorrectness,adherencetosoftwareengineering
principles, and practical relevance [23].
III. METHODOLOGY
A. Research Questions
This study investigates how LLMs and agent-based archi-
tectures perform on question-answering tasks over complex
softwaremodels,comparingdirectfull-contextpromptingwith
agentic retrieval using external tools.
RQ1: How does the accuracy of an LLM-based agent that
retrieves and processes parts of a large software model using
external tools compare to the accuracy of a reference LLM
thatprocessestheentiremodelwithinitscontextwindowwhen
answering model-related questions?
Thisquestiontargetsthecoretrade-offbetweenfull-context
access and modular, tool-assisted access. It aims to evaluate
whether an LLM-based agent can still produce accurate and

=== Page 3 ===
useful answers to domain-relevant questions despite never
having a complete view of the software model at once. The
answer to this question has significant implications for the
feasibility of using LLM agents in real-world automotive
workflowswheremodelsmaybelarge,distributed,andsubject
to change.
RQ2: How does the token consumption of an LLM-based
agent that incrementally accesses a large software model via
tool support compare to that of an LLM processing the entire
model in a single pass?
Thisquestionaddressestheefficiencyofthetwoapproaches
in terms of token usage, which is especially critical when de-
ploying smaller LLMs with limited context windows. Smaller
models are often the only viable option for local, on-premise
deployment - an increasingly important requirement in the
automotive industry due to strict privacy constraints, intel-
lectual property protection, and regulatory compliance. By
analyzing token consumption, we aim to understand whether
agent-based strategies enable smaller, locally hosted models
to work effectively with large-scale software artifacts.
B. Direct Prompting and Agent-Based Architecture
To evaluate the ability of LLMs to answer questions about
complex software models, we compare two architectures: a
direct LLM call serving as a reference, and a tool-augmented
agent architecture. Both setups are illustrated in Fig. 1, with
example responses shown in Fig. 2 to demonstrate how each
approach processes and answers a question.
1) Reference: Direct Full-Context Prompting: The refer-
ence architecture represents a simple, baseline setup where
the entire software model is placed directly into the LLM’s
context window. The LLM is asked to answer questions in a
zero-shotmanner,withnoexamplesorintermediatereasoning
steps. This approach assumes the model fits into the context
windowoftheevaluatedLLM-anincreasinglylimitingfactor
for larger models, motivating the agentic approach.
The LLM prompt in this setup utilizes the Ecore format [8]
fortheinputmodel,primarilybecauseit’sthenativeformatof
the tool used in our experiments. This choice streamlines the
process by avoiding the need to translate the software model,
even though formats like PlantUML or Mermaid [24] could
also represent class relationships. Ecore, however, provides a
more detailed and inherently tool-compatible representation.
Consequently,thisXML-basedformatrequiresmoretokensto
describethesoftwaremodelthansimpler,text-basedsyntaxes.
Additionally,thepromptexplicitlydirectstheLLMtoanalyze
class relationships thoroughly and to rely exclusively on the
providedcontent,assumingitisacompleteandself-contained
definition.
2) ReAct Architecture: Agent with File Tools: The second
approach uses a tool-augmented agent architecture based on
theReActframework[25],wheretheLLMcanchoosetoissue
tool calls if it determines that the answer cannot be derived
directly. The context window initially contains only the path
to the directory with the software model files, not the model

contentitself.Thissetupallowstheagenttoselectivelyretrieve
and reason over relevant parts of the model on demand.
The agent is equipped with a set of tools adapted from
the SWE-agent framework [26], which simulates an IDE-like
interaction by exposing a windowed view over source files.
Table I lists the tools available to the agent.
Although some tools (list_directory, find_file,
and search_directory) are more relevant for models
distributedacrossmultiplefiles,theywereretainedforconsis-
tency and to enable the reuse of the agent with other software
model datasets. For this experiment, all interactions involved
a single file.
The windowing parameters for file tools were selected
empirically to balance efficiency and context completeness. A
window size of 50 lines with an overlap of 2 lines was used.
This configuration proved effective for the selected software
model, as most type definitions could be captured within one
or two windows, thereby minimizing the need for extensive
scrolling. At the same time, the window size was kept small
enough to maintain low token usage and avoid exceeding the
LLM’s context limits during multi-step reasoning.
The agent was allowed up to 100 iterations per question
to avoid infinite loops while preserving enough flexibility for
complex queries.
The agent prompt followed a similar structure to the refer-
ence setup, stating that the software model is in Ecore format
and emphasizing that the model is complete.
C. LLM Selection and Configuration
This study evaluates LLMs that support tool usage - a
capability essential for agent-based workflows. While direct
prompting can, in principle, use any LLM, we employed the
same tool-capable models for both approaches to ensure a
fair comparison. In line with the privacy and deployment
constraintstypicalintheautomotiveindustry,weconcentrated
on smaller LLMs that are more feasible to run locally or
on secure, private infrastructure. All selected models belong
to the latest two generations of LLM development, offering
enhanced reasoning capabilities and extended context lengths.
We selected GPT-4o mini, GPT-4.1 mini, and o4-mini to rep-
resentOpenAI’scurrentlightweightmodelswithprogressively
improving architecture and performance characteristics, with
o4-mini offering the strongest reasoning performance within
thisgroup.Tobroadentheevaluation,wealsoincludedGemini
2.5 Flash Preview, a fast, tool-capable model from a different
vendor, to assess cross-vendor performance and introduce ar-
chitectural diversity.Table II summarizes theselected models.
In all agent configurations, the temperature parameter was
set to 0.0 to ensure deterministic behavior and maximize
answer reproducibility. The only exception is o4-mini, where
the temperature is fixed at 1.0.
D. Question Dataset Design
As noexistingdatasets aretailored forevaluating LLMson
softwaremodelunderstanding,weconstructedasmall,custom
dataset based on an open-source metamodel in Ecore format

=== Page 4 ===
Fig.1. Evaluationsetupsforsoftwaremodelquestionanswering.(a)DirectLL
relevantmodelpartsbeforeanswering.
TAB
FILETOOLINGCAPABILITIESIN
ToolName
list_directory Listsallfile
find_file Findsall
search_directory Searchesfor
open_file Opensafileatagiv
scroll_up Scrollstheopen
scroll_down Scrollstheopenfil
go_to_line Movesthewindowv
search_file Searchesforater
TABL
LANGUAGEMODELSUSE
ModelName ReleaseDate InputTokenLimit Outp
GPT-4omini 2024-07-18 128,000
GPT-4.1mini 2025-04-14 1,047,576
o4-mini 2025-04-16 200,000
Gemini2.5FlashPreview 2025-04-17 1,048,576
from INCHRON’s am2inc repository [27]. The am2inc tool
facilitates the conversion of AMALTHEA models [28] into
the INCHRON format, which is then utilized by chronSUITE
3.X [29]. AMALTHEA provides an open and unified model
platform for multi-core software and hardware development.
ItssubsequentevolutionintoEclipseAPP4MC[28]hassignif-
icantly broadened its adoption, establishing it as an essential
tool for analyzing and optimizing multi-core embedded sys-
tems, particularly within automotive applications. The am2inc
conversion process is crucial because it filters out extraneous
information irrelevant to timing analysis, thereby streamlining
the model for chronSIM’s specific focus on timing chal-
lenges [30].
The selected metamodel root.ecore is substantial, defining
384 classes and consisting of 13,572 lines. When tokenized
using the OpenAI tokenizer for GPT-4o, this translates to
approximately 118,000 tokens. This token count highlights
that while the model is considerably large and complex,
it remains small enough to fit entirely within the context
windows of modern LLMs - a crucial requirement for our
experiments. Consequently, the selected INCHRON model
serves as a representative example of real-world models used
in the automotive industry for detailed timing analysis and
optimization.

LMcallwithfullmodelinprompt.(b)Agentusingfile-accesstoolstoretrieve
BLEI
NAGENT-BASEDARCHITECTURE
Description
esinadirectoryinatree-styleformat.
fileswithagivennameorpattern.
atermacrossallfilesinthedirectory.
venpath.Optionallyscrollstoaspecifiedline.
filewindowupbyafixednumberoflines.
lewindowdownbyafixednumberoflines.
viewtoaspecificlinenumberintheopenfile.
rmwithintheopenfile(oraspecifiedfile).
LEII
EDINTHEEXPERIMENTS
putTokenLimit KeyCharacteristics
16,384 Compactmultimodalmodelforefficientreasoning.
32,768 High-performancemultimodalreasoningandcoding.
100,000 Lightweightmodelforchain-of-thoughtreasoning.
65,536 Fast,multilingualreasoningandsummarization.
A total of 20 questions were manually created to cover
different reasoning and retrieval patterns, grouped into four
categories:
1) Direct class inspection (5 questions):
Require identifying only the fields (names and types) of
a specified class, without considering inheritance.
2) Single inheritance chain (5 questions):
Requirecollectingfieldsfromaclassanditsbaseclasses
along a single inheritance path.
3) Multiple inheritance chains (5 questions):
Require traversing and aggregating fields across multiple
inheritance paths.
4) Semantic queries (5 questions):
Requireunderstandingthemodelstructureandsemantics
beyond keyword matching.
This dataset enables controlled evaluation of both retrieval-
based and reasoning-intensive tasks, simulating realistic soft-
ware model comprehension needs in automotive software
engineering workflows.
E. Evaluation Criteria
This study evaluates the performance of LLMs and agent-
based architectures in answering questions about a large soft-
ware model, using factual correctness as the primary metric.

=== Page 5 ===
Question:
WhatarethefieldsofFrequencyclass?Providenamesanddatatypesof
onlythisclass,don’tlistfieldsofbaseclasses.
Answer:
(a)
TheFrequencyclasshasthefollowingfieldsdefineddirectly:
1.name:value
-datatype:EDouble(double)
-lowerBound:1
-defaultValueLiteral:1000
2.name:unit
-datatype:FrequencyUnit(enumeration)
-lowerBound:1
-defaultValueLiteral:MHz
(b)
Tool:open_file root.ecore
Observation:
... first 50 lines of the file ...
Tool:search_file Frequency root.ecore
Observation:
Found 8 matches for "Frequency" in
root.ecore:
...
Line 2830: name="Frequency">
...
Tool:goto 2830
Observation:
File: root.ecore (13572 lines total)
...
2828: <eClassifiers
2829: xsi:type="ecore:EClass"
2830: name="Frequency">
...
Answer:
TheFrequencyclasshasthefollowingfields:
1.name:value
-type:EDouble(doubleprecisionfloatingpoint)
-defaultvalue:1000
-description:Thenumericalvalueofthequantity.
2.name:unit
-type:FrequencyUnit(enumeration)
-defaultvalue:MHz
-description:Theunitofthequantity.
Fig.2. Exampleresponsestoamodel-relatedquestionusing(a)DirectFull-
Context Prompting and (b) Agent with File Tools. The agent’s directory-
relatedtoolcallisomittedforclarity.
Factual correctness measures whether the statements in an
LLM-generated answer are objectively true with respect to
the software model [31]. It ensures that the output neither
hallucinates, omits, nor misrepresents key information. In this
context, the software model defines the complete scope of
truth, including components, interfaces, dependencies, and
structural or behavioral constructs described in the Ecore
format.
Duetothenumberandstructureofquestions,aswellasthe
numberofevaluatedsetups,fullhumanevaluationwasdeemed
impractical. Instead, LLMs were used as proxies for scoring
(LLM-as-a-Judge), with manual spot-checking performed for
a randomly selected subset of answers to ensure reliability.
Two complementary scoring methods were used:

a) Per-answerscoring: Eachgeneratedanswerwascom-
pared against a reference answer using a binary judgment,
classified as either correct or incorrect. The accuracy metric
wasthencomputedastheratioofcorrectanswerstototalques-
tions. Evaluations were performed using GPT-4.1 mini with a
structured prompt taken from the LangSmith Hub [32]. The
output format was constrained to structured integer responses,
where a score of 1 indicated correctness and 0 indicated
incorrectness.
b) Per-fact scoring: To capture more nuanced factual
alignment,weemployedtheFactualCorrectnessmetric
provided by Ragas version 0.2.15 [33]. This metric decom-
posesthemodeloutputandthereferenceintoindividualclaims
and applies natural language inference to identify factual
overlap. The same LLM model, GPT-4.1 mini, is used here to
perform the inference.
The evaluation returns precision, recall, and F1 scores,
defined as follows:
TP
Precision= (1)
TP +FP
TP
Recall= (2)
TP +FN
2·Precision·Recall
F score= (3)
1 Precision+Recall
where true positives (TP) refer to claims in the response that
also appear in the reference. False positives (FP) are claims
present in the response but not in the reference, while false
negatives (FN) are claims in the reference that are missing
from the response.
This scoring method enables more granular insight into
partially correct responses and helps differentiate between
omission and hallucination errors.
IV. RESULTSANDANALYSIS
This section presents the experimental results of direct
prompting and agent-based LLM architectures for querying
software models. We evaluated these methods using multiple
LLM variants on a 20-question dataset, focusing on answer
correctness and token efficiency.
A. Correctness Evaluation
Table III presents the factual correctness results of all
evaluated architectures and LLMs. Overall, the direct full-
context prompting setup performed better or comparably for
several models. Notably, Gemini 2.5 Flash and GPT-4o mini
achieved significantly higher accuracy in the reference setup
compared to the agent-based configuration. Gemini 2.5 Flash
reached 80% accuracy in the direct prompting, but only 40%
whenoperatingwithintheReAct-basedtool-augmentedagent.
Similarly, GPT-4o mini’s performance dropped sharply from
45% to 10%. This suggests that these models may struggle
with tool-based reasoning, maintaining coherence across tool
calls, or operating effectively within constrained, windowed
views of the software model.

=== Page 6 ===
In contrast, GPT-4.1 mini and o4-mini maintained high
accuracy (90%) across both setups. Their performance was
especially strong in the agent with file tools architecture,
indicating better capabilities for orchestrating tool use and
reasoning over partial views of the model. These results
support the hypothesis that agent-based setups place greater
demands on a model’s reasoning and memory capabilities,
which smaller or less capable LLMs may not handle well.
Anotherkeyobservationistheprecision-recalltrade-offvis-
ible across models. GPT-4.1 mini in the direct prompting, for
instance, achieved high recall (0.86) but low precision (0.44),
implying a tendency to include more relevant information at
the cost of introducing inaccuracies.
Finally, the relatively high standard deviations in precision,
recall, and F1 score across models (up to ±0.36) suggest
considerable variability in model performance depending on
the specific question type. This highlights the importance of
comprehensive evaluation across diverse question categories
when assessing LLM effectiveness in model understanding
tasks.
B. Token Usage Comparison
To better understand the computational footprint and pro-
cessing patterns of the evaluated setups, we analyzed token
usage across all models and architectures. The results are
summarized in Table IV.
A striking, though not surprising, difference is observed in
the number of prompt tokens between the direct full-context
promptingandtheagentwithfiletools.Directpromptingrelies
oninjectingtheentiresoftwaremodeldirectlyintotheprompt,
resultinginhighprompttokencounts-typicallyrangingfrom
118,000 to over 137,000 tokens on average, depending on
the tokenizer used. In contrast, the agent setup loads context
incrementally via file tools, resulting in dramatically lower
prompt usage—only about 640–780 tokens depending on the
model. This demonstrates that agent-based designs are far
more efficient in managing input context.
In terms of completion tokens, which represent the size of
the final answer, the values are consistently small across all
setups.However,theyareslightlyhigherinthereferencesetup,
likely because the model has access to the entire software
model upfront and can produce more detailed responses. The
agent-based setups produce shorter completions, possibly due
to more focused context windows available at response time.
Reasoning token count offers insight into how models in-
ternallyprocessqueries.GPT-4.1miniandGPT-4ominishow
noreasoningtokens,suggestingtheyproduceanswerswithout
explicit intermediate steps. In contrast, Gemini 2.5 Flash and
o4-miniexhibitsubstantialbuilt-inreasoning.Bothmodelsuse
significantlyfewerreasoningtokensintheagentconfiguration
thanindirectprompting,likelyduetothemodular,tool-driven
context limiting the need for extended internal processing.
Overall,thesefindingsconfirmthatagent-basedapproaches
are significantly more efficient in token usage, especially for
large software models, while still enabling internal reasoning
in models designed for that purpose. They also highlight

that reasoning behaviors vary greatly depending on model
capabilities.
C. Failure Case Analysis
Two main categories of failures were observed during the
evaluation: agent errors, which prevented the model from
producing an answer, and incorrect answers, where the model
made a factually inaccurate response.
Theonlyerrortypeobservedintheagent-basedarchitecture
was a recursive error, occurring when the number of tool-
use iterations exceeded the predefined recursion limit of 100.
These errors prevented the agent from producing any answer,
leading to a failed attempt. Across all evaluations, recursive
errors occurred 15 times when using the agent with file tools.
Two of these cases were attributed to the o4-mini model.
In both instances, the agent repeatedly opened the same file
and interleaved file searches with opening the file at different
lines, continuing this behavior until the iteration limit was
reached. Some search terms appeared arbitrary or incorrectly
chosen, which may point to a misunderstanding of Ecore
syntax. The remaining 13 failures were observed with GPT-
4o mini. In twelve of these, the agent opened a file and
continuously scrolled down until it hit the iteration cap. In
one case, the agent alternated between scrolling down and up
while occasionally invoking find_file with class names,
againwithoutarrivingatacoherentanswer.Allsuchrecursive
errors were treated as incorrect responses and were therefore
assigned a score of 0.0 in the precision, recall, and F1 score
metrics.
Themainobservationfromtheincorrectanswersisthatthe
dominant failure mode across models - especially in tasks in-
volvingclassfieldandinheritancechainextraction-isincom-
plete or prematurely terminated inheritance traversal. Many
agentsstopafteroneortwoinheritancelevels,failingtofollow
the full chain and include all inherited fields, which leads to
missing attributes. Another frequent issue is confusion or in-
consistencyinattributingfieldstothecorrectbaseclass,often
misplacing a field’s origin in the hierarchy. Some answers are
penalized due to minor factual inaccuracies, such as incorrect
data types or multiplicity (e.g., treating a field as a list where
it’s not explicitly typed as such in the model). In cases where
classmembershipquestionsareinvolved(e.g.,busports,event
chainrequirements),modelsoftenovergeneralizebyincluding
additional classes with semantically similar names or nearby
definitions, which, while arguably plausible, deviate from the
ground truth. Notably, models using file tools often exhibit
partialexplorationbehaviors,suchasnavigatingtoaclassbut
notscrollingtoseeallfields,oridentifyingabaseclassbutnot
recursively inspecting further base classes up the inheritance
chain.Thesepatternssuggestthatincorrectanswersoftenarise
not from fundamental misunderstanding but from shallow or
incomplete retrieval and reasoning processes.
V. DISCUSSION
Our results reveal several essential insights. First, the refer-
encearchitecturegenerallyyieldshigherorcomparablefactual

=== Page 7 ===
TABL
FACTUALCORRECTNESSACROSS20QUESTIONSFOREVALUATEDS
Architecture LLMModel Correct Incorrect Accur
Gemini2.5Flash 16 4 8
Direct
GPT-4.1mini 16 4 8
Full-Context
GPT-4omini 9 11 4
Prompting
o4-mini 18 2 9
Gemini2.5Flash 8 12 4
Agentwith GPT-4.1mini 18 2 9
FileTools GPT-4omini 2 18 1
o4-mini 18 2 9
TABL
TOKENUSAGEACROSSEVALUATEDSETUPS.MEANVA
Architecture LLMModel PromptTokens(±SD) Completi
Gemini2.5Flash 137461.4±6.1 174
Direct
GPT-4.1mini 118776.0±5.8 210
Full-Context
GPT-4omini 118776.0±5.8 223
Prompting
o4-mini 118775.0±5.8 15
Gemini2.5Flash 783.3±6.1 1
Agentwith GPT-4.1mini 639.3±5.7 1
FileTools GPT-4omini 642.6±2.1 3
o4-mini 641.8±6.0 5
correctness for most models when the full model fits into the
LLM’s context window. This outcome is intuitive since the
model has complete visibility of the entire software structure
at once, enabling holistic reasoning and direct fact retrieval.
Notably, models such as Gemini 2.5 Flash and GPT-4o mini
exhibited a significant drop in accuracy when constrained to
the agent setup. This suggests that certain LLM variants may
struggle with maintaining state coherence across multiple tool
calls or with reasoning effectively over fragmented, partial
views of the model. Moreover, analysis of incorrect answers
shows that the models frequently failed to choose the most
effective tool (search_file) for the task, instead relying
on a less efficient option (scroll_down).
In contrast, GPT-4.1 mini and o4-mini maintained robust
accuracy (90%) across both architectures, highlighting the
importance of advanced reasoning and memory capabilities
foreffectivetool-assistedmodelcomprehension.Theirsuccess
in the agent setup demonstrates that an LLM capable of
efficiently orchestrating the retrieval and synthesis of partial
information can overcome the limitations imposed by lacking
full context. However, analysis of incorrect answers suggests
that accuracy could be further improved by integrating tools
specifically designed for browsing software models, which
betteraddressthechallengesofpartialexploration,ratherthan
relyingsolelyongeneral-purposefileaccesstools.Thisinsight
has important practical implications for industrial workflows,
where software models often exceed the size limits of even
the largest available context windows.
The observed precision-recall trade-offs provide important
insights. As expected, high recall generally corresponds to
higher overall accuracy in most cases, indicating that models
tend to capture relevant information effectively. However,
overall precision remains relatively low across models, sug-
gesting a common tendency to include extra or occasionally

LEIII
SETUPS:ACCURACY(%),PRECISION,RECALL,F1(MEAN±STD).
racy(%) Precision(±SD) Recall(±SD) F1score(±SD)
80.0 0.70±0.29 0.91±0.25 0.75±0.27
80.0 0.44±0.23 0.86±0.30 0.56±0.23
45.0 0.53±0.23 0.79±0.28 0.61±0.22
90.0 0.59±0.23 0.90±0.24 0.66±0.22
40.0 0.59±0.36 0.68±0.35 0.58±0.36
90.0 0.49±0.23 0.95±0.11 0.61±0.19
10.0 0.19±0.31 0.21±0.35 0.20±0.32
90.0 0.48±0.36 0.85±0.37 0.57±0.35
LEIV
ALUESWITHSTANDARDDEVIATIONSAREREPORTED.
ionTokens(±SD) ReasoningTokens(±SD) TotalTokens(±SD)
4.7±138.8 598.0±328.8 138234.1±404.4
0.0±129.4 0.0±0.0 118986.0±131.5
3.7±164.0 0.0±0.0 118999.7±166.5
50.3±95.1 563.2±291.9 119488.5±355.2
17.6±6.5 282.5±60.6 1083.4±65.5
17.7±1.4 0.0±0.0 656.9±5.8
30.9±4.3 0.0±0.0 673.4±3.6
53.4±9.4 60.4±40.9 755.7±45.4
inaccuratedetails.Strikingtherightbalancebetweenrecalland
precision is especially critical in engineering domains, where
accuracy is paramount and any hallucinations or errors can
mislead developers or compromise system safety.
From an efficiency perspective, agent-based architectures
dramatically reduce prompt token usage by avoiding full
ingestion of large software models. This efficiency gain is
crucialforenablingdeploymentofLLMswithsmallercontext
windows on-premise, addressing automotive industry con-
straints around privacy, intellectual property protection, and
regulatory compliance. Although completion tokens (the size
ofanswers)weresimilaracrosssetups,thereductioninprompt
size directly translates into lower computational costs, faster
responsetimes,andthefeasibilityofmorefrequentoriterative
querying.
VI. THREATSTOVALIDITY
a) Single Model and Format: The study used a single
software model in Ecore format, limited to a single file. This
constrains generalizability, as other models, formats, or multi-
file setups may present different challenges.
b) Limited and Narrow Question Scope: The evaluation
was based on 20 questions focused solely on structural, low-
level aspects (e.g., class fields). It did not assess behavioral
properties or higher-abstraction queries.
c) Answer Validation Limitations: Extra statements gen-
erated by the LLM beyond the expected answers were not
verified for correctness, which may have impacted precision
andrecallmetrics.Additionally,theevaluationreliedonLLM-
basedscoringmethods,potentiallyintroducinginaccuraciesin
answer correctness determination.
d) Fixed Agent Parameters: The agent used a fixed
configuration (e.g., window size, iteration limits), which may
havelimitedadaptabilityorperformanceacrossdifferenttasks.

=== Page 8 ===
VII. CONCLUSIONSANDFUTUREWORK
This study compared direct prompting and agent-based ap-
proaches for answering questions over software models using
LLMs. The agentic approach proved effective with smaller
LLMs,demonstratingthatcompactmodelspossessstrongtool
usage and reasoning capabilities. This improvement makes
sophisticated,retrieval-augmentedagentworkflowsfeasibleon
resource-constrainedsetups.Theresultshighlightthepotential
of such structured approaches for interacting with large soft-
ware artifacts efficiently and accurately.
Future work will explore several directions. First, the ap-
proaches will be evaluated in a broader variety of software
models and formats to assess generalizability. More complex
agent architectures will be investigated to improve reason-
ing capabilities and task coordination, leveraging emerging
standards such as MCP and A2A to enhance tool integration
and agent collaboration. The question set will be expanded,
including queries at different abstraction levels to probe
deeper understanding. Additionally, efforts will be made to
automatically generate model instances from metamodels and
specifications,andtosupporttextualmodificationsofsoftware
models while preserving consistency.
REFERENCES
[1] M. Broy, I. H. Kruger, A. Pretschner, and C. Salzmann, “Engineering
automotive software,” Proc. IEEE, vol. 95, no. 2, pp. 356–373, Feb.
2007.[Online].Available:https://ieeexplore.ieee.org/document/4142919
[2] A.Haghighatkhah,A.Banijamali,O.-P.Pakanen,M.Oivo,andP.Ku-
vaja,“Automotivesoftwareengineering:Asystematicmappingstudy,”
J. Syst. Softw., vol. 128, pp. 25–55, Jun. 2017. [Online]. Available:
https://www.sciencedirect.com/science/article/pii/S0164121217300560
[3] A. Fan, B. Gokkaya, M. Harman, M. Lyubarskiy, S. Sengupta,
S. Yoo, and J. M. Zhang, “Large language models for software
engineering:Surveyandopenproblems,”inProc.IEEE/ACMInt.Conf.
on Softw. Eng. (ICSE), May 2023, pp. 31–53. [Online]. Available:
https://ieeexplore.ieee.org/abstract/document/10449667
[4] “PlantUML.”[Online].Available:https://plantuml.com/
[5] F. Muff and H.-G. Fill, “Limitations of ChatGPT in conceptual
modeling:insightsfromexperimentsinmetamodeling,”inModellierung
2024 - Workshopband. Gesellschaft fu¨r Informatik e.V., Mar. 2024.
[Online].Available:https://dl.gi.de/handle/20.500.12116/43782
[6] J. Di Rocco, D. Di Ruscio, C. Di Sipio, P. T. Nguyen, and R. Rubei,
“On the use of large language models in model-driven engineering,”
Softw. Syst. Model., vol. 24, no. 3, pp. 923–948, Jun. 2025. [Online].
Available:https://doi.org/10.1007/s10270-025-01263-8
[7] “Unified Modeling Language (UML) Specification Version 2.5.1.”
[Online].Available:https://www.omg.org/spec/UML/
[8] “Eclipse Modeling Framework (EMF).” [Online]. Available: https:
//eclipse.dev/emf/
[9] “AUTOSAR (Automotive Open System Architecture).” [Online].
Available:https://www.autosar.org/
[10] K. Vinoth Kannan, “Model-based automotive software development,”
in Automotive Embedded Systems: Key Technologies, Innovations, and
Applications, M. Kathiresh and R. Neelaveni, Eds. Cham: Springer
International Publishing, Apr. 2021, pp. 71–87. [Online]. Available:
https://doi.org/10.1007/978-3-030-59897-6 4
[11] D. Mosquera, M. Ruiz, O. Pastor, and J. Spielberger, “Understanding
the landscape of software modelling assistants for MDSE tools:
A systematic mapping,” Inf. Softw. Technol., vol. 173, p. 107492,
Sep. 2024. [Online]. Available: https://www.sciencedirect.com/science/
article/pii/S0950584924000971
[12] Y. Sui, M. Zhou, M. Zhou, S. Han, and D. Zhang, “Table meets
LLM: Can large language models understand structured table data?
A benchmark and empirical study,” in Proc. 17th ACM Int. Conf.
Web Search Data Mining, ser. WSDM ’24. New York, NY, USA:

Association for Computing Machinery, Mar. 2024, pp. 645–654.
[Online].Available:https://dl.acm.org/doi/10.1145/3616855.3635752
[13] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun,
M. Wang, and H. Wang, “Retrieval-augmented generation for large
language models: A survey,” Mar. 2024, arXiv:2312.10997. [Online].
Available:http://arxiv.org/abs/2312.10997
[14] T. Sumers, S. Yao, K. Narasimhan, and T. Griffiths, “Cognitive
architectures for language agents,” Trans. Mach. Learn. Res., Oct.
2023.[Online].Available:https://openreview.net/forum?id=1i6ZCvflQJ
[15] B. Paranjape, S. Lundberg, S. Singh, H. Hajishirzi, L. Zettlemoyer,
andM.T.Ribeiro,“ART:Automaticmulti-stepreasoningandtool-use
for large language models,” Mar. 2023, arXiv:2303.09014. [Online].
Available:http://arxiv.org/abs/2303.09014
[16] “Model Context Protocol.” [Online]. Available: https://
modelcontextprotocol.io/
[17] “Agent2AgentProtocol(A2A).”[Online].Available:https://google-a2a.
github.io/A2A/
[18] J.Wei,X.Wang,D.Schuurmans,M.Bosma,B.Ichter,F.Xia,E.Chi,
Q.V.Le,andD.Zhou,“Chain-of-Thoughtpromptingelicitsreasoning
in large language models,” in Advances Neural Inf. Process. Syst.,
S.Koyejo,S.Mohamed,A.Agarwal,D.Belgrave,K.Cho,andA.Oh,
Eds.,vol.35. CurranAssociates,Inc.,Nov.2022,pp.24824–24837.
[Online]. Available: https://proceedings.neurips.cc/paper files/paper/
2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf
[19] X. Wang, J. Wei, D. Schuurmans, Q. V. Le, E. H. Chi, S. Narang,
A. Chowdhery, and D. Zhou, “Self-consistency improves chain
of thought reasoning in language models,” in Proc. 11th Int.
Conf. Learn. Represent. (ICLR), Sep. 2022. [Online]. Available:
https://openreview.net/forum?id=1PL1NIMMrw
[20] E. Kamalloo, N. Dziri, C. Clarke, and D. Rafiei, “Evaluating
open-domainquestionansweringintheeraoflargelanguagemodels,”
in Proc. 61st Annu. Meeting Assoc. Comput. Linguistics, A. Rogers,
J. Boyd-Graber, and N. Okazaki, Eds. Toronto, Canada: Association
for Computational Linguistics, Jul. 2023, pp. 5591–5606. [Online].
Available:https://aclanthology.org/2023.acl-long.307/
[21] F. Mustafazade and P. F. Ebbinghaus, “Evaluation of semantic answer
similarity metrics,” Int. J. Natural Lang. Comput., vol. 11, no. 3, pp.
43–57,Jun.2022.[Online].Available:http://arxiv.org/abs/2206.12664
[22] R.Wang,J.Guo,C.Gao,G.Fan,C.Y.Chong,andX.Xia,“CanLLMs
replace human evaluators? An empirical study of LLM-as-a-Judge
in software engineering,” Feb. 2025, arXiv:2502.06193. [Online].
Available:http://arxiv.org/abs/2502.06193
[23] S. Badshah and H. Sajjad, “Reference-guided verdict: LLMs-as-
Judges in automatic evaluation of free-form text,” Aug. 2024,
arXiv:2408.09235.[Online].Available:http://arxiv.org/abs/2408.09235
[24] “Mermaid.”[Online].Available:https://mermaid.js.org
[25] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and
Y.Cao,“ReAct:Synergizingreasoningandactinginlanguagemodels,”
inProc.11thInt.Conf.Learn.Represent.(ICLR),Sep.2023.[Online].
Available:https://openreview.net/forum?id=WE vluYUL-X
[26] J. Yang, C. E. Jimenez, A. Wettig, K. Lieret, S. Yao,
K.Narasimhan,andO.Press,“SWE-agent:Agent-computerinterfaces
enable automated software engineering,” Advances Neural Inf.
Process. Syst., vol. 37, pp. 50528–50652, Dec. 2024. [Online].
Available: https://proceedings.neurips.cc/paper files/paper/2024/hash/
5a7c947568c1b1328ccc5230172e1e7c-Abstract-Conference.html
[27] “INCHRON’s am2inc Ecore model.” [Online]. Available: https:
//github.com/inchron/am2inc/blob/main/EcoreModels/root.ecore
[28] “EclipseAPP4MC.”[Online].Available:https://eclipse.dev/app4mc/
[29] “chronSUITE from INCHRON.” [Online]. Available: https://www.
inchron.com/chronsuite/
[30] “INCHRON’s APP4MC / Amalthea Importer.” [Online]. Available:
https://www.inchron.com/amalthea/
[31] Y. Wang, M. Wang, M. A. Manzoor, F. Liu, G. N. Georgiev, R. J.
Das,andP.Nakov,“Factualityoflargelanguagemodels:Asurvey,”in
Proc.Conf.EmpiricalMethodsNaturalLang.Process.,Y.Al-Onaizan,
M. Bansal, and Y.-N. Chen, Eds. Miami, Florida, USA: Association
forComputationalLinguistics,Nov.2024,pp.19519–19529.[Online].
Available:https://aclanthology.org/2024.emnlp-main.1088/
[32] “LangSmith Hub Prompt: Evaluation for RAG answer accuracy
vs a reference.” [Online]. Available: https://smith.langchain.com/hub/
langchain-ai/rag-answer-vs-reference
[33] “Ragas.”[Online].Available:https://docs.ragas.io/en/v0.2.15/

Paper:Explicating Tacit Regulatory Knowledge from LLMs to Auto-Formalize Requirements for Compliance.pdf
=== Page 1 ===
Explicating Tacit Regulatory Knowl
Requirements for Complia
ZhiyiXue1,Xiaohong
1ShanghaiKeyLaboratoryofTrustworth
2DishuiLakeInternationalSoftwareEngin
52275902017@stu.ecnu.edu.cn, {x
Abstract
Compliance testing in highly regulated do-
mainsiscrucialbutlargelymanual,requiring
domainexpertstotranslatecomplexregulations
intoexecutabletestcases.Whilelargelanguage
models(LLMs)showpromiseforautomation,
theirsusceptibilitytohallucinationslimitsre-
liableapplication. Existinghybridapproaches
mitigatethisissuebyconstrainingLLMswith
formalmodels,butstillrelyoncostlymanual
modeling. To solve this problem, this paper
proposesRAFT,aframeworkforrequirements
auto-formalizationandcompliancetestgenera-
tionviaexplicatingtacitregulatoryknowledge
frommultipleLLMs. RAFTemploysanAdap-
tivePurification-Aggregationstrategytoexpli-
catetacitregulatoryknowledgefrommultiple
LLMsandintegrateitintothreeartifacts: ado-
mainmeta-model,aformalrequirementsrepre-
sentation, and testability constraints. These
artifacts are then dynamically injected into
prompts to guide high-precision requirement
formalization and automated test generation.
Experimentsacrossfinancial,automotive,and
power domains show that RAFT achieves
expert-levelperformance,substantiallyoutper-
formsstate-of-the-art(SOTA)methodswhile
reducingoverallgenerationandreviewtime.
1 Introduction
Inhighlyregulateddomainssuchasfinance,auto-
motive,andenergy,softwarecompliancetestingis
crucial to ensure adherence to regulations, indus-
trystandards,andinternalpolicies(Badrzadehand
Halley,2014;Tabanietal.,2019;Xueetal.,2024b;
Zhangetal.,2025). Failuresincompliancecanlead
toseveresafetyincidents,regulatorypenalties,and
substantialfinanciallosses(Wikipediacontributors,
2014;Sivakumaretal.,2024). Despiteitsimpor-
tance,compliancetestinginpracticeremainspre-
dominantlymanual. Domainexpertsarerequired
tointerpretlengthyandcomplexregulatorytexts
andtranslatethemintoexecutabletestcases. This
1
6202
naJ
41
]ES.sc[
1v26790.1062:viXra

ledge from LLMs to Auto-Formalize
ance Test Case Generation
gChen1,MinZhang2
hyComputing,ECNU,Shanghai,China
neeringInstitute,ECNU,Shanghai,China
xhchen,zhangmin}@sei.ecnu.edu.cn
processislabor-intensiveanderror-prone,making
itsautomationakeyfocusofindustrydevelopment
(CastellanosArdilaetal.,2022;Jainetal.,2025).
Existingautomatedsolutionsfaceatrade-offbe-
tweenmodelingcostandgenerationreliability. Tra-
ditionalmodel-basedapproachesrelyonexplicitly
constructedmodels,graphs,orformalrepresenta-
tionsfortestgeneration(Wangetal.,2020;Stefani
etal.,2025;Zyberajetal.,2025;Yangetal.,2025).
Whilepreciseandcontrollable,theseapproachesre-
quiresubstantialupfrontexperteffort,limitingtheir
scalabilitytootherregulatorydomains. Incontrast,
LLM-basedmethodsreducemanualeffortbygen-
erating tests directly from regulatory texts or via
multi-agent workflows (Castellanos Ardila et al.,
2022;Boukhlifetal.,2024;Korraproluetal.,2025;
Hasanetal.,2025;Masudaetal.,2025). However,
their probabilistic nature leads to hallucinations
and low interpretability, hindering their adoption
inregulation-criticalsettings.
To reconcile this tension, hybrid test genera-
tionframeworkshavecombinedmodel-driventech-
niques with LLM-based generation (Xue et al.,
2024b;Chenetal.,2024;Sunetal.,2025;Liuetal.,
2025;Shresthaetal.,2025). Intheseapproaches,
LLMs translate natural language regulations into
predefined formal requirements, which constrain
generationandmitigatehallucinations. However,
the representation of these requirements still re-
quires substantial manual definition and mainte-
nancebydomainexperts;whenthedomainshifts
(e.g., from finance to automation), they must be
re-engineered,resultinginhighmaintenancecosts.
Automatingrequirementsformalizationitselfis
themostdirectwaytobreakthisdeadlock, butit
demandsregulatoryknowledgeondemand. Hence,
theparadigmmustmovefrom“manualmodeling”
to “automatic knowledge explication”. Modern
LLMs,havingundergonelarge-scalepre-training,
alreadyencodeawealthoftacitregulatoryknowl-
edge,yetitremainsimplicitandunstructured. Only
1

=== Page 2 ===
byunlockingandformalizingthisknowledgeinto
explicit,verifiableartifactscanweenabletest-case
generationthatisbothreliableandscalable.
Inthispaper,weproposeRAFT,anovelframe-
work for Requirement Auto-Formalization and
compliance Test generation via explicating tacit
regulatoryknowledgefrommultipleLLMs. RAFT
introducesadedicatedRegulatoryKnowledgeEx-
plicationphase,inwhichanAdaptivePurification-
Aggregationstrategyisemployedtoextractandfor-
malizethreeknowledgeartifactsfromLLMs: ado-
mainmeta-model,aformalrequirementsrepresen-
tation,andtestabilityconstraints. Together,these
artifactsestablishacoherentconceptualandlogi-
calfoundationpriortoprocessingindividualregu-
latory texts. Building upon these knowledge arti-
facts,RAFTperformsknowledge-injectedprompt-
ing during the Prompt and Test Case Generation
phase. Theextractedartifactsaredynamicallyin-
corporatedintopromptsasstructuralandsemantic
constraints,guidingtheLLMtoformalizeregula-
tionsintoprecise,interpretablerequirementsthat
canbetransformedintohigh-qualitytestcases.
RAFTpromotesLLMsfrom“TextTranslators”
to“KnowledgeArchitects”. Byexplicitlyextract-
ing and injecting tacit regulatory knowledge, the
frameworkdramaticallybooststhecontrollability,
interpretability, and reliability of LLM-driven re-
quirementsformalizationandcompliancetesting,
deliveringafullyautomatedandscalablesolution.
We conducted a comprehensive evaluation on
RAFT.Inthefinancialdomain,itachievedexpert-
levelperformancewithanaverage91.7%F1and
86.5% business scenario coverage, outperform-
ing SOTA methods by up to 34.7%, while reduc-
ingthetotalgenerationandreviewtimefrom5.7
hours or even 2 weeks to just 2.5 hours. Abla-
tion studies confirm that each explicated knowl-
edge artifact, as well as the proposed Adaptive
Purification-Aggregationstrategy,isessentialfor
high-qualitytestgeneration. Furthermore,RAFT
demonstrates strong cross-domain generalizabil-
ity, achieving average F1 scores of 92.7% and
87.2% in the automotive and power domains, re-
spectively. Our code and data are available at
https://github.com/1767675261/RAFT.
Ourcontributionsaresummarizedasfollows:
(1) KnowledgeEnhancedRequirementsformal-
ization and Test Generation: We propose
RAFT, a framework that automatically expli-
cates regulatory knowledge from LLMs and
injectsitintothetestgeneration,shiftingcom-
2

pliancetestingfromexpert-drivenmodelingto
knowledge-drivenautomation.
(2) RegulatoryKnowledgeExplication: Wede-
fine and extract three reusable, explicit arti-
facts,includingdomainmeta-model,formalre-
quirementsrepresentation,andtestabilitycon-
straints, turning originally implicit and frag-
mentedtacitregulatoryknowledgeintoverifi-
ableandcross-domainportableassets.
(3) Knowledge-ConstrainedPrompting: Wede-
viseapromptingschemethatdynamicallyem-
bedsthethreeartifactsasstructuredconstraints
intheprompt,enablingLLMstoproducepre-
cise,regulation-compliantoutputswithoutre-
training,balancingaccuracyandgenerality.
2 RelatedWork
Thissectionreviewspriorworkonautomatedtest
casegeneration,focusingonhowregulatoryknowl-
edgeisrepresentedandutilized.
Model-BasedTestGeneration. Model-basedtest-
ingintroducesexplicitintermediategraphsorfor-
malmodelsfortesting. Representativeexamplesin-
cludecontrol-flowgraphsforpathcoverage(Yang
et al., 2025), System Graphs converted into ex-
ecutable tests (Zyberaj et al., 2025), and formal
ODD or rule models for safety-critical systems
(Stefanietal.,2025;Xueetal.,2024b). Whilecon-
trollable,thesemethodsdependheavilyonmanu-
allyconstructedmodelsthatarecomplexandlabor-
intensive,limitingscalability(Xueetal.,2024a).
LLM-Based Test Generation. Recent studies
leverageLLMsormulti-agentsystemstogenerate
testcases. Prompt-basedmethodsproducetestin-
putsorstructuredteststeps(Wangetal.,2025;Ko-
rraproluetal.,2025),whilemulti-agentpipelines
emulate human testing workflows (Milchevski
et al., 2025) or extract testing strategies prior to
generation(Masudaetal.,2025). Domain-specific
fine-tuninghasalsobeenexplored(Boukhlifetal.,
2024;Hasanetal.,2025). Whiletheseapproaches
reducemanualeffort,theirrelianceonprobabilistic
outputsleadstohallucinationsandinstability,limit-
ingtheirapplicabilityinhighlyregulateddomains
(Zhangetal.,2024;Korraproluetal.,2025).
Hybrid Frameworks. Hybrid approaches com-
bineformalrepresentationswithLLM-basedgen-
eration to balance controllability and flexibility.
Examples include integrating LLMs with struc-
turedtestscenariosinfinancialsoftware(Xueetal.,
2024b;Liuetal.,2025),combiningontologiesand
2

=== Page 3 ===
R e g u la to ry D o c u m e n ts
& H isto ric a l T e st C a ses
L L M 1
D o m a in ① L L M 2
M e ta -M o d e l
… C o n str u c tio n
L L M n
In je c t
K n o w le d g e - ④In
je c ted P ro m p t
G en e r a tio n
P ro m p t
T e m p la te
P ro m p tin g T h eo ries
an d T ech n iq u es
∩
D
R e g u la to r y K n o w
R A G …
K n o w le d g e
R e q u ire m e n ts ②
o m a in -S p e c ific R e p re sen ta tio n
M e ta-M o d e l F o r m a liza tio n
F o rm a l
R e q u ire m e n ts
G e n e ra tio n P ro m p t
T e sta b ility R e g u la to ry
D e te rm in a tio n & D o c u m e n t
R e fin e m e n t P ro m p t
P r o m p t a n d T e st
Figure1: Theregulatoryknowledgeexplicationandinject
learning-basedmethodsforBIMcompliancecheck-
ing (Chen et al., 2024), and guiding LLMs with
retrieval-augmented generation or predefined re-
quirement templates (Sun et al., 2025; Shrestha
etal.,2025). Althoughtheseapproachesmitigate
hallucinationsbyconstrainingthegenerationspace,
they still rely on hand-crafted modeling, leaving
regulatory knowledge statically engineered and
thuslimitingscalabilityandadaptability.
3 TheRAFTApproach
3.1 RegulatoryKnowledgeandOverview
To achieve fully automated test case generation
based on a hybrid framework, it is necessary to
automatetheconversionofregulatorydocuments
intoformalrequirements. Accomplishingthisgoal
requiressatisfyingtwoprerequisites: first,clarify-
inghowrequirementsshouldbeexpressed;second,
confirmingthattherequirementsaretestable.
Regardingthequestionof“howtorepresentre-
quirements”,wefocusontwoaspects: thecomposi-
tionofrequirementelementsandtheformoftheir
expression. Accordingly, the representation pro-
cessisdividedintotwostages: first,extractingkey
requirement elements to construct a requirement
metamodel; and then completing the formal re-
quirementsrepresentationbasedonthismodel. In
parallel,wedefinetestabilityconstraintstoidentify
testablerequirements. Ultimately,wederivethree
core types of regulatory knowledge: the domain
meta-model M, the requirements representation
R,andthetestabilityconstraintsT.
After the regulatory knowledge is formed, it
3

w le
…
s
y
t C
d g e E x p lic a tio n
L L M s
K n o w le d g e
∪ R e q u ire m e n ts
R e p re se n ta tio n …
F o r m a l ⑤
R e q u ire m e n ts G en erate
G en e r a tio n R efin e
T e sta b ility ⑥D
ete rm in a tio n
& R e fin e m e n t
L L M
a se G e n e r a tio n
C o n se n su s-B a sed
A d a p tiv e P u rific a tio n -
A g g re g a tio n M e c h a n ism
K n o w le d g e
T e sta b ility ③ ∪ T e stab ility
C o n str a in ts … C o n stra in ts … S p e c ific a tio n
V erify
S y n tax &
F eed b ack S em an tic C h eck er
L L M
S c e n a r io ⑦&
T e st C a se
G en e r a tio n
T e st C a ses
tion-drivenframeworkforfullyautomatedtestgeneration.
can be systematically embedded into a prompt-
basedframeworktoguideLLMsintwokeytasks:
converting natural-language clauses into formal
requirements and automatically generating exe-
cutabletestcases. Tothisend,weproposeRAFT
(Figure 1), a two-phase approach that ensures se-
mantic consistency and testability by combining
knowledgeexplicitationwithpromptengineering:
PhaseI:RegulatoryKnowledgeExplicitation.
Thedomainmeta-modelM,therequirementsrep-
resentation R, and the testability constraints T
fromregulatorydocumentsandexistingtestcases
toestablishastructuredknowledgesystem.
PhaseII:PromptandTestCaseGeneration.
Injecttheexplicatedknowledgeintoprompttem-
platestosteertheLLMsthroughsequentialrequire-
mentformalizationandtestcasegeneration,result-
inginanend-to-endautomatedworkflow.
3.2 RegulatoryKnowledgeExplication
Challengesinexplicatingregulatoryknowledge
from LLMs. The core objective of this phase is
toobtainthethreeknowledgeassets: thedomain
meta-modelM,therequirementsrepresentationR,
and the testability constraints T. We decompose
the process into three extraction steps, all imple-
mentedusingLLMs. Toassessthefeasibilityofau-
tomatedregulatoryknowledgeexplication,wecon-
ductedpreliminaryexperimentsusingSOTALLMs
to construct these assets with direct instructions.
Theresultsrevealedtworecurringchallenges:
(1) Granularity and Structural Inconsistency.
LLMsoftenfailtoidentifyanappropriatelevel
ofabstraction,leadingtomissingelementsor
3

=== Page 4 ===
inconsistentstructuralrepresentations.
(2) HallucinationandOutputVariability. Gen-
eratedstructuresmaybeungroundedorunsta-
bleacrossruns,hinderingtheconstructionof
reliableregulatoryknowledge.
To address these issues, we propose two cor-
responding solutions: a Chain-of-Thought (CoT)
(Wei et al., 2022) enhanced with Retrieval Aug-
mented Generation (RAG) (Lewis et al., 2020)
promptingmethod,andamulti-LLM-basedAdap-
tivePurification-Aggregationstrategy.
CoT & RAG Prompting. This mechanism con-
strainsLLMreasoningalongfourdimensions: (1)
Task Orientation, framing the task as explicit re-
constructionoftacitregulatoryknowledge;(2)Hi-
erarchicalDecomposition,enforcingastructured
whole-to-part reasoning process tailored to each
knowledge type; (3) Granularity Constraint, re-
stricting the level of detail to what is necessary
forthetargetartifact;and(4)RetrievalGrounding,
incorporatingregulatorydocumentsandhistorical
test cases to reduce hallucinations. This prompt
framework is applied to Steps ①, ②, and ③, with
task-specificadaptations.
AdaptivePurification-Aggregation. Thekeyidea
is to apply reconciliation mechanisms tailored to
differentknowledgetypes,reflectingtheirdistinct
structuralandsemanticcharacteristics. Specifically,
In Step ①, the domain meta-model requires both
structural integrity and parsimony (Evans, 2004).
WethereforeintroduceaK-Purificationoperation,
whichtreatsindividualLLMoutputsasnoisyob-
servations and extracts a stable meta-model core
viamajorityconsensus:
Definition:K-Purification
Let M = {M ,M ,...,M } be the meta-
1 2 N
modelsgeneratedbyN independentLLMs. Given
aconsensusthresholdK (1 < K ≤ N),thefinal
meta-modelMisdefinedas:
N N
(cid:91) (cid:88)
M={e∈ M | I(e∈M )≥K} (1)
i i
i=1 i=1
whereedenotesmeta-modelelementsandI(·)isthe
indicatorfunction.
WesetN = 3andK = 2inourimplementation,
retainingmajority-supportedelementstosuppress
stochastic hallucinations from individual LLMs,
whilegroupinglow-frequencyelementsas“Others”
topreservecoverageofregulatorysemantics.
In Steps ② and ③, the primary risk shifts from
structuralnoisetoinformationomission(Chomsky,
4

Figure2: Meta-modelforthefinancedomain.
2002). Sincemissingregulatorylogicortestability
constraintscanunderminedownstreamcorrectness,
we adopt an Aggregation strategy that prioritizes
logicalcompletenessoverfrequency:
Definition:Aggregation
Givenformalrequirementsrepresentations{R }N
i i=1
andtestabilityconstraints{T }N fromN LLMs,
j j=1
aggregationisperformedvia:
N N
(cid:91) (cid:91)
R= R , T = T (2)
i j
i=1 j=1
WithN = 3,thisstrategyminimizesomission
risk by aggregating all inferred regulatory logic
andconstraints. Overall,theAdaptivePurification-
Aggregation strategy mitigates hallucination and
divergenceinsingleLLMsbyenforcingstructural
rigorinmeta-modelconstructionandlogicalcom-
pletenessinrequirementsrepresentationformaliza-
tionandtestabilityconstraintsspecification.
ExampleofExplicatedRegulatoryKnowledge.
Weillustratetheexplicatedregulatoryknowledge
usingthefinancedomain,employingGPT-5(Ope-
nAI, 2025), Grok-4 (xAI, 2025), and DeepSeek-
R1 (Guo et al., 2025). The financial meta-model
M is expressed as PlantUML, consisting of 14
f
core elements (e.g., TradingVariety, Price) orga-
nized into a three-layer hierarchy in PlantUML
(Team, 2025), as shown in Figure 2. By explic-
itlyseparatingPreconditions,Operations,andEx-
pected Results, the meta-model provides a verifi-
ablecausalstructureandconsolidatesvagueregu-
latoryconceptsintorepresentativedomainentities.
GroundedinM ,thefinancerequirementsrep-
f
resentation R defines a library of domain sym-
f
bolsandaBNF-based(Backusetal.,1960)formal
syntax. AsexemplifiedinFigure3,requirements
follow a structured IF–THEN logic composed of
KEY–OP–VALUEclausesconnectedbylogicalop-
erators,whereKEY isstrictlyalignedwithentities
in M to ensure semantic consistency, VALUE
f
4

=== Page 5 ===
Rule 1: For securities block trading, a "block" shall be at least 10,000 shares or a
quantity of stock having a market value of $200,000 or more.
Rule 2: A NYSE Bonds GTD Order is eligible for execution in the Core Bond
Trading Session only. A designation for any other trading session but the Core Bond
Trading Session will be cancelled.
Requirement1.1
IFAction= Trade ANDTradingMethod= Block Trading ANDTradingVariety=
Security ANDQuantity= 10,000 shares or more ORPrice= $200,000 or more
THENResult = Succeed
Requirement2.1
IFTradingMarkey= NYSE ANDTradingVariety= Bond ANDOperationPart= GTD
Order ANDAction= execute ANDTime= Core Bond Trading Session
THENResult= Succeed
Requirement2.2
IFTradingMarkey= NYSE ANDTradingVariety= Bond ANDOperationPart= GTD
Order ANDAction= execute ANDTime!=Core Bond Trading Session
THENResult= Failure
Figure3: Anexampleof2regulatoryrulesfromNYSE
(Exchange,2025d)andtheirrequirementrepresentation.
specifies the corresponding instance, and OP de-
notestheoperatorthatdefinestheirrelations.
BasedonR ,financetestabilityconstraintsT
f f
arespecifiedasOCLconstraints(Group,2014)cov-
eringfiveaspects,includingStructuralComplete-
ness,ElementDeterminism,ActionExecutability,
ResultObservability,andRuleNon-Conflict. For
example,Rule1inFigure3satisfiesallconstraints
andisthereforetestable,whereasRule2isdeemed
untestable due to the non-deterministic element
“corebondtradingsession”.
3.3 PromptandTestCaseGeneration
Thisphasefocusesontransformingregulatoryrules
intoexecutabletestcasesthroughformalizingre-
quirements. There are four steps: Prompt Gen-
eration, Requirements Formalization, Testability
Determination&Refinement,andfinallyTestCase
Generation. Thepromptsusedandformalizedreg-
ulatoryknowledgeartifactsinthissectionarepro-
videdinAppendicesA.1andA.2,respectively.
Knowledge-InjectedPromptGeneration. InStep
④,wedesigntwospecializedpromptsthatdynam-
icallyinjecttheexplicatedknowledgeartifactsinto
thegenerationprocess,asshowninFigure4:
(1) Formal Requirement Generation Prompt
(P ). This prompt embeds the domain sym-
R
bollibraryandtherequirementsrepresentation
syntax from R into a zero-shot template, con-
strainingtheLLMtogenerateformalIF–THEN
requirements. Byenforcingthesegrammatical
constraints,allgeneratedsymbolsandrelations
arestrictlygroundedinR.
(2) Testability Determination & Refinement
Prompt (P ). This prompt incorporates con-
T
straints from T as fine-grained evaluation cri-
teria. Eachtestabilityconstraintisassessedin-
dependently across all requirements, enabling
thedetectionofsubtlelogicalgapsthatholistic
R eg u la to r y K n o w le d g e P ro m p t T e m p la te
G en e ra te S tru c tu re d R eq u ire m e n t [S Y S T E M R O L E ]
B a se d o n th e F o llo w in g D e fin itio n : Y o u are a p ro fe ssio n a l re g u la to ry
S y m b o ls te stin g e x p e rt. Y o u r ta sk is to …
D o m a in S y m b o ls: A cto r, T im e , … [D E F IN IT IO N / C O N S T R A IN T ]
D y n a m ic ② C o m p a riso n S y m b o ls: … {d y n a m ic _ k n o w le d g e }
S y n ta x K n o w le d g e [S T E P -B Y -S T E P R E A S O N IN G ]
R u le ::= "IF " < P re co n d itio n > In je c tio n F o llo w th e C o T p ro c e ss:
"A N D " < O p e ra tio n > "T H E N " 1 . T a sk B re a k d o w n :
< E x p e c te d O u tc o m e> 2 . R e a so n in g P ro c e ss:
P re co n d itio n ::= … 3 . D r a ft A n sw e r:
4 . S e lf-C r itiq u e :
P ro m p tin g T h e o r ie s P ro m p t ① 5 . R efin e d A n sw e r:
P ro m p t T e m p la te T e m p la te
6 . F in a l O u tp u t:
T a sk D e co m p o sitio n D e sig n
[IN P U T / O U T P U T F O R M A T ]
C h a in -o f-T h o u g h t
> In p u t:
S e lf-C ritiq u e & R e fin e
> O u tp u t:
… …
Figure4: Dynamicknowledgeinjection-basedprompt
generationforFormalRequirementGeneration.
judgmentsmaymissduetolongcontext.
FormalRequirementGenerationandTestabil-
ityDetermination&Refinement. InStep⑤,P
R
is used to guide an LLM to generate formal re-
quirements from regulatory documents within a
Verification-Feedback-Refinementloop. TheBNF
syntax of R is first converted by an LLM into
Xtext-compliantgrammar,whichXtextthenuses
toautomaticallyconstructachecker. Allgenerated
requirementsareiterativelyvalidatedagainstthis
checkerandcorrectedbytheLLM.
In Step ⑥, the generated formal requirements
are assessed against all testability constraints by
instructinganLLMwithP . Violationstriggertar-
T
getedrefinementattemptsbytheLLM,including
completingmissingelements,concretizingabstract
expressions,andsoon. Requirementsthatremain
logically inconsistent, unrefinable, or purely de-
scriptiveareexcludedforexpertreview.
We evaluated this process on 19 financial reg-
ulatory documents using GPT-5, Grok-4, and
DeepSeek-R1, with expert feedback establishing
ground truth. The performance of our approach
was high, achieving token-wise and word-wise
Precision/Recall/F1 of 91.6%/87.7%/89.0% and
89.8%/85.3%/86.8%,respectively. Testabilityas-
sessmentshowedthat 77.6% ofrequirements are
automatable, with fewer than 5% requiring man-
ual intervention, indicating that it can effectively
identifytestablerulesandminimizehumaneffort.
ScenarioandTestCaseGeneration. InStep⑦,
we integrate testable formal requirements into a
hybridtestgenerationframework,LLM4Fin(Xue
etal.,2024b),whichismostcompatiblewithour
requirements representation, to perform the final
ScenarioandTestCaseGeneration.
Testscenariosarebuiltbyidentifyinginter-rule
5

=== Page 6 ===
dependencies, mapping behavioral elements (Ac-
tion, Status) to activity diagrams and state ma-
chines to form end-to-end business flows. For
eachscenario,concretetestcasesaregeneratedus-
ingstrategiessuchasEquivalencePartitioningand
Boundary Value Analysis (Graham et al., 2006).
Numericalinputsproducepositive,negative,and
boundaryvalues,whilefinitenon-numericalinputs
are exhaustively enumerated, yielding a compact
yetcomprehensivesetoftestcases.
4 ExperimentalEvaluation
To evaluate the performance of RAFT, we con-
ductedacomprehensiveexperimentalstudytoad-
dressthefollowingresearchquestions:
RQ1: Howdoesourapproachperformcompared
withSOTAbaselinesintermsof theeffective-
nessandefficiencyofgeneratedtestcases?
RQ2: What is the contribution of the proposed
AdaptivePurification-Aggregationstrategyand
eachexplicatedregulatoryknowledgeartifactto
thequalityofgeneratedtestcases?
RQ3: HowwelldoesRAFTgeneralizeacrossdif-
ferentregulateddomains?
4.1 ExperimentI:EffectivenessandEfficiency
ofTestCasesGeneration
Thisexperimentevaluatestheoveralleffectiveness
andefficiencyofRAFTinthefinancialdomain.
Competitors. We compare RAFT against three
representativecategoriesofbaselines: (1)Domain
Experts, consisting of three senior testing engi-
neers with 3-5 years of financial experience; (2)
LLM4Fin(Xueetal.,2024b),aSOTAhybridreg-
ulatory test generation framework; and (3) End-
to-End(E2E)LLMs,representedbyGPT-5,Grok-
4,andDeepSeek-R1,whichdirectlygeneratetest
casesfromregulationsusingpromptengineering.
Datasets. Duetothelimitedavailabilityofpublic
datasetswithsufficientnumberandcoverage,we
constructedsixfinancialdatasetsbasedonofficial
regulatory documents from financial exchanges,
pairedwithanonymizedreal-worldtestcasespro-
videdbyindustrypartners. Thedatasetsspanmul-
tiple regulatory frameworks and languages. An
overview is given in Table 1. Notably, Datasets
4 and 5 follow the evaluation setup of LLM4Fin,
butusecompleteregulatorydocumentsinsteadof
10–20manuallyselectedrules,resultinginamore
realisticandchallengingevaluationsetting.
Metrics. Duetostrictsecurityconstraintsinfinan-
6

Table1: Detailsofthesixfinancialevaluationdatasets
for Exp. I. #X means the number of X, Req. means
testablerequirement,andTCmeanstestcase.
Dataset Document #Rule #Req. #TC
NewYorkStockExchangeAuction
1 MarketBidsandOffersRules(Ex- 142 114 927
change,2025c)
TheNasdaqStockMarketOptions
2 289 276 1465
TradingRules(Exchange,2025b)
HongKongStockExchangeTrad-
3 129 292 2128
ingRules(Exchange,2025a)
ShanghaiStockExchangeTrading
4 212 195 682
Rules(Exchange,2023)
Shenzhen Stock Exchange Bond
5 190 167 1389
TradingRules(Exchange,2022)
TokyoStockExchangeBuyingand
6 104 198 1020
SellingRules(Exchange,2025e)
cialinstitutions,executablesystemcodeisunavail-
able. Following prior work (Tufano et al., 2020;
Fatimaetal.,2022),weuseanonymizedreal-world
testcasesadoptedinpracticeasgroundtruth. Effec-
tivenessisevaluatedusingPrecision,Recall,and
F1withtheadoptedtestcases,aswellasBusiness
ScenarioCoverage(BSC)(Xueetal.,2024b)toas-
sessregulatoryrequirementcoverage. Efficiencyis
measuredbyTimeConsumptionandTokenUsage.
Wereportthetimerequiredforregulatoryanalysis
(ifapplicable),testgeneration,andexpertreviewto
achieve100%correctness. ForLLM-basedmeth-
ods,weadditionallyreportpromptandcompletion
tokenusageandthecorrespondingmonetarycost.
ExperimentalProcedure. Eachofthesixdatasets
was provided to the three domain experts, who
manuallyauthoredcompliancetestcases. ForE2E
LLMs, prompts were designed following SOTA
promptengineeringpractices(seeAppendixA.3).
LLM4Finwasexecutedfullyautomaticallyusing
itsdefaultconfiguration. ForRAFT,testcaseswere
generatedfollowingtheworkflowdescribedinSec-
tion 3. Reported results for domain experts are
averagedacrossthethreeindividuals,whileresults
forE2ELLMsandRAFTareaveragedovermulti-
plerunsusingGPT-5,Grok-4,andDeepSeek-R1.
ExperimentalResults. Theeffectivenessresults
aresummarizedinTable2. Domainexpertsachieve
thehighestperformance,whileRAFTattainscom-
parableresultsandsubstantiallyoutperformsallau-
tomatedbaselines. Acrossthesixdatasets,RAFT
balances precision and recall, achieving an aver-
age F1 of 91.7% and BSC of 86.5%, improving
overLLM4Finby34.7%and18.2%,respectively.
LLM4Fin underperforms due to its reliance on
smallerBERT-basedmodelswithlimiteddomain
knowledge, which hinders its ability to capture
complexandimplicitregulatorylogic. Incontrast,
6

=== Page 7 ===
Table2: ComparisonofPrecision(%),Recall(%),F1(%)
generatedbyExperts,LLM4Fin,End-to-endLLMs,and
Experts LLM4Fin
Datasets
Pre. Rec. F1 BSC Pre. Rec. F1
1 83.7 96.3 89.6 90.0 80.3 70.2 74.9
2 90.8 91.5 91.1 85.3 52.2 72.8 60.8
3 95.1 98.9 96.9 92.3 74.3 77.0 75.6
4 93.5 93.7 93.6 81.1 59.9 82.1 69.3
5 97.3 96.0 96.6 89.1 61.2 87.7 72.1
6 94.3 97.1 95.7 86.1 83.7 41.8 55.7
Average 92.4 95.6 93.9 87.3 68.6 71.9 68.1
Variance 18.9 5.6 7.7 13.2 132.8 215.2 54.6
Figure 5: Comparison of the time consumption on
knowledge explication (Exp.), test generation (Gen.),
andexpertreview(Rev.) onprocessingthesixdatasets.
E2E LLMs suffer from hallucinations, reasoning
errors, and output instability, resulting in lower
accuracyandcoverage. AlthoughRAFTexhibits
slightlyhighervariancethanhumanexpertsdueto
itsrelianceonprobabilisticLLMoutputs,itsvari-
anceismarkedlylowerthanthatofE2ELLMsand
LLM4Fin,demonstratingthattheproposedmulti-
LLMAdaptivePurification-Aggregationstrategy
effectivelymitigateshallucinationandrandomness.
Efficiencyresults,showninFigure5andTable3,
furtherhighlightthepracticaladvantagesofRAFT.
TestgenerationbydomainexpertsandLLM4Fin
requires substantial manual effort, ranging from
5.7 hours to 2 weeks. In contrast, RAFT signifi-
cantlyreducesend-to-endtime,achievinga2.3×
speedupoverdomainexpertsandmorethana134×
speedup over LLM4Fin. Even compared to E2E
LLMs,RAFTprovidesa156%speedup,primarily
becauseitshigh-accuracytestcasesreduceexpert
review time from 2–4 hours to approximately 1
hour. Fromacostperspective,RAFTisalsomore
economical,asitemphasizesprompttokensover
expensivecompletiontokens. AlthoughLLM4Fin
minimizestokenusagethroughlocaldeployment,
thisadvantagecomesattheexpenseofreducedtest
qualityduetolimitedmodelcapacity.
Conclusion: RAFT achieves expert-level effec-
tiveness,significantlyimprovingefficiencyandre-
ducingcost,demonstratingitspracticalityforreal-
worldregulatorycompliancetesting.
7

),andBusinessScenarioCoverage(BSC,%)oftestcases
RAFTonthesixevaluationdatasets.
End-to-endLLMs RAFT
BSC Pre. Rec. F1 BSC Pre. Rec. F1 BSC
78.1 7.1 41.0 11.8 32.2 95.0 95.8 95.4 90.2
76.6 8.2 21.1 11.7 29.8 85.0 84.4 84.7 88.4
79.4 11.9 33.6 16.8 42.2 96.9 93.4 95.0 91.1
72.8 27.0 46.7 33.6 40.0 79.1 98.7 87.8 83.1
83.7 25.4 49.8 33.2 38.0 95.4 97.4 96.4 89.5
48.6 19.1 36.5 24.6 31.0 92.1 89.7 90.9 76.9
73.2 16.4 38.1 21.9 35.5 90.6 93.2 91.7 86.5
131.7 62.2 88.3 83.8 22.4 41.4 24.0 18.6 25.0
Table 3: Comparison of the average token usage and
monetarycostforeachLLM-basedapproach.
Method PromptTokens CompletionTokens Cost($)
LLM4Fin 227.3K 114.8K 0
E2ELLM 115.8K 1328.6K 12.34
RAFT 1047.0K 128.3K 2.84
4.2 ExperimentII:AblationStudy
ExperimentalDesign. Weevaluatethenecessity
ofexplicatedregulatoryknowledgebycomparing
thefullRAFT,includingmeta-modelM,require-
mentsrepresentationR,andtestabilityconstraints
T, against three degraded variants: (1) w/o T,
which generates test cases without filtering non-
testablerequirements;(2)w/oM&R,whichgen-
eratestestcasesdirectlyfromrulesaftertestability
assessment;and(3)w/oall: whichreliesonE2E
LLMswithoutexplicitregulatoryknowledge.
To assess the proposed Adaptive Purification-
Aggregationstrategy,wefurthercomparethefull
RAFT using GPT-5, Grok-4, and DeepSeek-R1
withvariantsthatperformknowledgeexplication
using them separately. All datasets, metrics, and
proceduresfollowExperimentI.
Experimental Result. As shown in Figure 6, re-
movingT causesanotableprecisiondropof33.6%
due to noise introduced by non-testable require-
ments. RemovingbothMandRleadstoamore
severedegradation,withF1decreasingby66.5%,
indicating that LLMs struggle to capture regula-
torysemanticsandimplicitlogicwithoutexplicit
guidance. The poorest performance of the no-
knowledgevariantconfirmsthatintegratingM,R,
andT isessentialforhigh-qualitytestgeneration.
Figure 7 shows that the Adaptive Purification-
Aggregationstrategyconsistentlyoutperformsthe
single-LLMvariants. WhileindividualLLMsare
prone to hallucination, resulting in incomplete
knowledge explication and degraded test quality,
the consensus-based strategy aggregates comple-
mentary insights to produce more precise and ro-
bustregulatoryknowledge,therebyimprovingthe
7

=== Page 8 ===
Figure6: Impactofregulatoryknowledgecomponents(M,R,T)onthequalityofgeneratedtestcases.
Figure7: ComparisonbetweenourAdaptivePurification-Aggregationstrategy(RAFT(M))andindividualLLMs
(RAFT(I))onknowledgecoverage(KC)andmetricsofgeneratedtestcases.
Table4: Detailsofthefiveevaluationdatasetsonauto-
motiveandpowerdomainsforExp. III.
Dataset Domain Document #Rule #Req. #TC
2025NewJerseyDriverManual
7 47 427 1570
(Commission,2025)
RoadTrafficSafetyLawofPRC
8 Automotive 171 613 2124
(China,2021)
Cambodian Road Traffic Law
9 93 808 3132
(Cambodia,2018)
EN50549-1:2019(Standardiza-
10 75 362 703
Power tion,2019) Figure8: Averageperformanceoftestcasesgenerated
11 GB/T19964-2024(China,2024) 189 195 1311
byourapproachacrossthreeindustrialdomains.
qualityofgeneratedtestcases.
Conclusion: Explicit regulatory knowledge (M, mains,withvariancebelow20inmostcases. These
R, T) is essential for effective compliance test resultsindicatethattheproposedregulatoryknowl-
generation,andtheproposedAdaptivePurification- edgeexplicationandtestgenerationapproachgen-
Aggregationstrategyfurtherenhancesitthrougha eralizeswellacrossdiverseregulatorycontexts.
morecomprehensiveknowledgeexplication. Conclusion: Beyondthefinancialdomain,RAFT
maintains high performance in both automotive
4.3 ExperimentIII:MethodGeneralizability
andpowerdomains,demonstratingitsstrongcross-
Experimental Design. We evaluate the general- domaingeneralizability.
izability of RAFT in the automotive and power
domains. Fivedatasetswereconstructed,covering 5 Conclusion
three traffic regulations and two power grid stan-
dards, each paired with real-world industrial test Inthispaper,weproposeRAFT,aframeworkthat
cases,assummarizedinTable4. Togetherwiththe automaticallyexplicatestacitregulatoryknowledge
financial datasets from Experiment I, this evalua- fromLLMsintostructuredartifactstodrivehigh-
tionspansthreeregulateddomains. qualitytestcasegeneration. Experimentalresults
ExperimentalResults. Theresultsareshownin across financial, automotive, and power domains
Figure8. RAFTdemonstratesconsistentlystrong demonstratethatRAFTachievesexpert-leveleffec-
performance across all 11 datasets. In the auto- tiveness,highefficiency,andstrongcross-domain
motive and power domains, it achieves average generalizability. Byshiftingfrommanualmodel-
F1/BSCscoresof92.7%/87.2%and94.3%/82.3%, ingtoknowledge-drivenautomation,ourapproach
respectively, comparable to those in the financial providesascalableandreliablesolutionforcom-
domain. Itsperformanceremainsstableacrossdo- pliancetestinginhighlyregulateddomains.
8

=== Page 9 ===
Limitations
DependenceontheQualityandCoverageofEx-
ternal Knowledge Sources. Although the pro-
posed framework supplies knowledge for LLMs
byincorporatingregulatorydocumentsandhistor-
icaltestcasesthroughRAG,itsperformancestill
dependsonthequality,completeness,andrepresen-
tativenessoftheseexternalknowledgesources. In
domainswhereregulationsareambiguous,rapidly
evolving, or insufficiently documented, the ex-
tracteddomainmodelsandrequirementsrepresen-
tations may be incomplete or biased, thereby af-
fecting downstream test generation. Addressing
this limitation requires continuous maintenance
and supplementation of the knowledge base, and
mechanisms for detecting and resolving gaps or
inconsistenciesinregulatoryknowledge.
Limited Formal Guarantees on Model Sound-
ness and Completeness. While the collective
wisdomstrategyandmodel-basedgenerationim-
provecontrollabilitycomparedtoend-to-endLLM
approaches, the automatically constructed meta-
modelsandrequirementsrepresentationslackfor-
malguaranteesofsoundnessorcompletenesswith
respecttotheoriginalregulations. Subtleseman-
tic nuances, implicit assumptions, or exceptional
regulatoryclausesmaystillbepartiallyorinaccu-
ratelycaptured. Asaresult,humanexpertreview
remainsnecessary,especiallyforsafety-criticalor
legallysensitivescenarios. Futureworkcouldex-
ploreintegratingformalverificationtechniquesor
regulation-specific logical formalisms to further
strengthenthetheoreticalguaranteesofthegener-
atedmodelsandtestcases.
References
John W Backus, Friedrich L Bauer, Julien Green,
CharlesKatz,JohnMcCarthy,AlanJPerlis,Heinz
Rutishauser, Klaus Samelson, Bernard Vauquois,
JosephHenryWegstein,and1others.1960. Report
onthealgorithmiclanguagealgol60. Communica-
tionsoftheACM,3(5):299–311.
BabakBadrzadehandAndrewHalley.2014. Challenges
associatedwithassessmentandtestingoffaultride-
throughcomplianceofvariablepowergenerationin
australiannationalelectricitymarket. IEEETransac-
tionsonSustainableEnergy,6(3):1160–1168.
MohamedBoukhlif,NassimKharmoum,MohamedHa-
nine, Mohcine Kodad, and Souad Najoua Lagmiri.
2024. Towards an intelligent test case generation
framework using llms and prompt engineering. In
9

InternationalConferenceonSmartMedical,IoT&
ArtificialIntelligence,pages24–31.Springer.
Royal Government of Cambodia. 2018. Cambodian
roadtrafficlaw. https://library.ncdd.gov.kh/
detail/148.
JuliethPatriciaCastellanosArdila,BarbaraGallina,and
FaizUlMuram.2022. Compliancecheckingofsoft-
wareprocesses: Asystematicliteraturereview. Jour-
nalofSoftware: EvolutionandProcess,34(5):e2440.
NanjiangChen,XuhuiLin,HaiJiang,andYiAn.2024.
Automated building information modeling compli-
ance check through a large language model com-
bined with deep learning and ontology. Buildings,
14(7):1983.
National Standardization Management Com-
mittee of China. 2024. Gb/t 19964-2024
technical requirements for connecting photo-
voltaic power station to power system. https:
//openstd.samr.gov.cn/bzgk/std/newGbInfo?
hcno=40D8691DFD7EC3CBA423CCBA65D262F3.
Standing Committee of the National Peo-
ple’s Congress of China. 2021. Road traf-
fic safety law of the people’s republic of
china. https://flk.npc.gov.cn/detail?
id=ff8081817ab231eb017abd617ef70519.
NoamChomsky.2002. Syntacticstructures. Walterde
Gruyter.
New Jersey Motor Vehicle Commission. 2025. 2025
new jersey driver manual. https://www.nj.gov/
mvc/pdf/license/drivermanual.pdf.
EricEvans.2004. Domain-drivendesign: tacklingcom-
plexity in the heart of software. Addison-Wesley
Professional.
Hong Kong Stock Exchange. 2025a. Hong
kong stock exchange trading rules. https:
//www.hkex.com.hk/-/media/HKEX-Market/
Services/Rules-and-Forms-and-Fees/Rules/
SEHK/Whole_SEHK_c.pdf.
Nasdaq Stock Exchange. 2025b. The nasdaq
stock market options trading rules. https:
//listingcenter.nasdaq.com/RuleBook/
Nasdaq/rules/Nasdaq%20Options%203.
New York Stock Exchange. 2025c. New york
stock exchange auction market bids and of-
fers rules. https://nyseguide.srorules.com/
rules/09013e2c8553e79b.
NewYorkStockExchange.2025d. Nyserules. https:
//nyseguide.srorules.com/rules.
Shanghai Stock Exchange. 2023. Shanghai
stock exchange trading rules. https://www.
sse.com.cn/lawandrules/sselawsrules/
stocks/exchange/c/10118395/files/
ae39775817cd4a7183159cd0f1547e26.docx.
9

=== Page 10 ===
Shenzhen Stock Exchange. 2022. Shenzhen stock
exchange bond trading rules. https://docs.
static.szse.cn/www/lawrules/rule/bond/
bonds/trade/W020220127631859244722.pdf.
Tokyo Stock Exchange. 2025e. Tokyo
stock exchange buying and selling rules.
https://resource.lexis-asone.jp/jpx/
rule/tosho_regu_201305070003001.html.
Sakina Fatima, Taher A Ghaleb, and Lionel Briand.
2022. Flakify: Ablack-box,languagemodel-based
predictorforflakytests. IEEETransactionsonSoft-
wareEngineering,49(4):1912–1927.
DorothyGraham, ErikvanVeenendaal, IsabelEvans,
andRexBlack.2006. Foundationsofsoftwaretest-
ing: ISTQBcertification. CengageLearning.
Object Management Group. 2014. Object constraint
language(ocl),version2.4. http://www.omg.org/
spec/OCL/2.4.
Daya Guo, Dejian Yang, Haowei Zhang, Junxiao
Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shi-
rongMa,PeiyiWang,XiaoBi,and1others.2025.
Deepseek-r1: Incentivizingreasoningcapabilityin
llms via reinforcement learning. arXiv preprint
arXiv:2501.12948.
NavidBinHasan,MdAshrafulIslam,JunaedYounus
Khan,SanjidaSenjik,andAnindyaIqbal.2025. Au-
tomatic high-level test case generation using large
languagemodels. In2025IEEE/ACM22ndInterna-
tionalConferenceonMiningSoftwareRepositories
(MSR),pages674–685.IEEE.
JiviteshJain,NivedhithaDhanasekaran,andMonaDiab.
2025. Fromcomplexitytoclarity: Ai/nlp’srolein
regulatorycompliance. InFindingsoftheAssocia-
tionforComputationalLinguistics:ACL2025,pages
26629–26641.
Brahma Reddy Korraprolu, Pavitra Pinninti, and
YRaghuReddy.2025. Testcasegenerationforre-
quirements in natural language-an llm comparison
study. In Proceedings of the 18th Innovations in
SoftwareEngineeringConference,pages1–5.
PatrickLewis,EthanPerez,AleksandraPiktus,Fabio
Petroni,VladimirKarpukhin,NamanGoyal,Hein-
richKüttler, MikeLewis, Wen-tauYih, TimRock-
täschel,and1others.2020. Retrieval-augmentedgen-
erationforknowledge-intensivenlptasks. Advances
inneuralinformationprocessingsystems,33:9459–
9474.
KaiboLiu,ZhenpengChen,YiyangLiu,JieMZhang,
MarkHarman,YudongHan,YunMa,YihongDong,
Ge Li, and Gang Huang. 2025. Llm-powered test
casegenerationfordetectingbugsinplausiblepro-
grams. InProceedingsofthe63rdAnnualMeetingof
theAssociationforComputationalLinguistics(Vol-
ume1: LongPapers),pages430–440.
10

Satoshi Masuda, Satoshi Kouzawa, Kyousuke Sezai,
HidetoshiSuhara,YasuakiHiruta,andKunihiroKu-
dou. 2025. Generating high-level test cases from
requirements using llm: An industry study. arXiv
preprintarXiv:2510.03641.
Dragan Milchevski, Gordon Frank, Anna Hätty,
BingqingWang,XiaoweiZhou,andZheFeng.2025.
Multi-step generation of test specifications using
largelanguagemodelsforsystem-levelrequirements.
In Proceedings of the 63rd Annual Meeting of the
AssociationforComputationalLinguistics(Volume
6: IndustryTrack),pages132–146.
OpenAI.2025. Chatgpt. https://chatgpt.com/.
AbhishekShrestha,Bernd-HolgerSchlingloff,andJür-
genGroßmann.2025. Lessismore:Guidingllmsfor
formalrequirementandtestcasegeneration. InInter-
nationalConferenceonCybersecurityandArtificial
IntelligenceStrategies,pages366–383.Springer.
Mithila Sivakumar, Alvine B Belle, Kimya Khakzad
Shahandashti,OluwafemiOdu,HadiHemmati,Segla
Kpodjedo, Song Wang, and Opeyemi O Adesina.
2024. Icame, isaw, icertified: someperspectives
on the safety assurance of cyber-physical systems.
arXivpreprintarXiv:2401.16633.
European Electrotechnical Committee for Standard-
ization. 2019. En 50549-1:2019 requirements
for generating plants to be connected in parallel
with distribution networks - part 1: Connec-
tion to a lv distribution network - generating
plants up to and including type b. https:
//standards.iteh.ai/catalog/standards/
clc/948bd277-da91-40c7-b7e0-bbf561035638/
en-50549-1-2019.
ThomasStefani,JohannMaximilianChristensen,Ak-
shayAnilkumarGirija,SiddharthaGupta,UmutDu-
rak,FrankKöster,ThomasKrüger,andSvenHaller-
bach. 2025. Automated scenario generation from
operationaldesigndomainmodelfortestingai-based
systems in aviation. CEAS Aeronautical Journal,
16(1):197–212.
Jingyun Sun, Zhongze Luo, and Yang Li. 2025. A
compliancecheckingframeworkbasedonretrieval
augmented generation. In Proceedings of the 31st
InternationalConferenceonComputationalLinguis-
tics,pages2603–2615.
HamidTabani,LeonidasKosmidis,JaumeAbella,Fran-
ciscoJCazorla,andGuillemBernat.2019. Assess-
ingtheadherenceofanindustrialautonomousdriv-
ingframeworktoiso26262softwareguidelines. In
Proceedingsofthe56thAnnualDesignAutomation
Conference2019,pages1–6.
PlantUMLTeam.2025. Plantuml. https://plantuml.
com.
Michele Tufano, Dawn Drain, Alexey Svyatkovskiy,
ShaoKunDeng,andNeelSundaresan.2020. Unit
testcasegenerationwithtransformersandfocalcon-
text. arXivpreprintarXiv:2009.05617.
0

=== Page 11 ===
ChunhuiWang,FabrizioPastore,ArdaGoknil,andLi-
onel C Briand. 2020. Automatic generation of ac-
ceptancetestcasesfromusecasespecifications: an
nlp-basedapproach. IEEETransactionsonSoftware
Engineering,48(2):585–616.
WenhanWang,ChenyuanYang,ZhijieWang,Yuheng
Huang,ZhaoyangChu,DaSong,LingmingZhang,
AnRanChen,andLeiMa.2025. Testeval: Bench-
markinglargelanguagemodelsfortestcasegener-
ation. InFindingsoftheAssociationforComputa-
tionalLinguistics: NAACL2025,pages3547–3562.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,
and1others.2022. Chain-of-thoughtpromptingelic-
its reasoning in large language models. Advances
inneuralinformationprocessingsystems,35:24824–
24837.
Wikipedia contributors. 2014. General motors ig-
nition switch recalls. https://en.wikipedia.
org/wiki/General_Motors_ignition_switch_
recalls.
xAI.2025. Grok. https://grok.com.
ZhiyiXue,LiangguoLi,SenyueTian,XiaohongChen,
PingpingLi,LiangyuChen,TingtingJiang,andMin
Zhang.2024a. Domainknowledgeisallyouneed:
Afielddeploymentofllm-poweredtestcasegenera-
tioninfintechdomain. InProceedingsofthe2024
IEEE/ACM 46th International Conference on Soft-
wareEngineering: CompanionProceedings,pages
314–315.
ZhiyiXue,LiangguoLi,SenyueTian,XiaohongChen,
Pingping Li, Liangyu Chen, Tingting Jiang, and
MinZhang.2024b. Llm4fin: Fullyautomatingllm-
powered test case generation for fintech software
acceptancetesting. InProceedingsofthe33rdACM
SIGSOFTInternationalSymposiumonSoftwareTest-
ingandAnalysis,pages1643–1655.
ZhenzhenYang,ChenhuiCui,TaoLi,RubingHuang,
Nan Niu, Dave Towey, and Guo Shikai. 2025.
Llmcfg-tgen: Using llm-generated control flow
graphs to automatically create test cases from use
cases. arXivpreprintarXiv:2512.06401.
Quanjun Zhang, Ye Shang, Chunrong Fang, Siqi Gu,
Jianyi Zhou, and Zhenyu Chen. 2024. Testbench:
Evaluating class-level test case generation capa-
bility of large language models. arXiv preprint
arXiv:2409.17561.
Shunran Zhang, Zhengmin Jiang, Ming Sang, Yunjie
Han, Huiyun Li, and 1 others. 2025. A compre-
hensive survey on driving compliance assessment
methodologiesforautonomousvehicles. IEEEIntel-
ligentTransportationSystemsMagazine.
Denesa Zyberaj, Lukasz Mazur, Nenad Petrovic,
PankhuriVerma,PascalHirmer,DirkSlama,Xiang-
weiCheng,andAloisKnoll.2025. Genai-basedtest
casegenerationandexecutioninsdvplatform. arXiv
preprintarXiv:2509.05112.
11

A Appendix
A.1 PromptDesigninOurFramework
A.1.1 Meta-modelConstruction
The prompt design theories and techniques used
for constructing financial meta-models from reg-
ulatory texts and test cases have been detailed in
Section 3.2. It integrates role-based instructions,
structural constraints, and staged outputs to sup-
port the abstraction of domain knowledge into a
formal and test-oriented representation. External
financial regulations and test cases are provided
assupplementaryknowledgetoenhancesemantic
completeness.
Thespecificpromptsappliedareshownbelow.
Theproposedpromptdesignhasbeenempirically
validated across multiple domains, including fi-
nance, automotive, and energy, and evaluated on
diverseLLMssuchasGPT,Grok,andDeepSeek,
demonstratingitsdomain-agnosticnatureandinde-
pendencefromspecificmodelimplementations.
You are a software requirements modeling and testing
expert. I will provide two types of inputs:
1. A domain rule document;
2. Corresponding partial test cases.
Your task is to construct a **domain meta-model** for
the rules of the domain. The meta-model should
describe the syntax of rules in a class diagram-style
tree structure. The construction of the meta-model
must be completed in two steps: first, extract and
confirm rule elements (15-20 leaf elements); second,
based on these elements, build a three-layer
meta-model and establish relationships between these
elements and Precondition, Operation, and
ExpectedResult.
Please strictly follow the following specifications
and output format: strict, complete, and
machine-readable:
### Meta-Model Construction Specifications (Must be
followed)
1. **Overall Structure**
* The meta-model should be a tree structure in
class diagram style (classes and relationships only,
without attributes or methods).
* Must adopt a three-layer structure: top layer (1
node) -> middle layer (fixed 3 nodes) -> bottom layer
(n leaf nodes).
* The top-layer node is fixed as `Rule` (single
class).
* The middle layer is fixed as three classes: `
Precondition`, `Operation`, `ExpectedResult`.
* The bottom layer consists of minimal rule
elements (leaf nodes).
2. **Leaf Node (Rule Element) Requirements**
* Must be testable, quantifiable, and concrete rule
elements.
* The total number of elements must be around 15.
High-frequency/core elements are listed individually;
semantically overlapping elements are merged;
scattered low-frequency elements are merged into a
general leaf `Others`. Note: Precondition, Operation,
and ExpectedResult should all include `Others`.
* Leaf nodes should be attributes (keys), and must
not include specific values or examples (e.g., "
interest rate" is correct, "annual interest rate 5%"
is incorrect).
1

=== Page 12 ===
* Preferably extracted from test cases and
supplemented by rule documents. Elements presented in
test cases as ``RuleElement1/RuleElement2'' should be
merged as a single element.
* Elements should be reusable within the domain and
cover common elements across different domain rule
documents.
3. **Relationships**
* Relationship types and applicable scenarios:
* `contains` - composition relationship of
middle-layer nodes to bottom-layer elements
* `constrains` - constraint relationship of
elements to nodes/other elements
* `dependsOn` - prerequisite relationship of
elements at runtime
* `triggers` - operation triggering expected
result
* Other relationships
* Every relationship must be labeled with its name
in PlantUML.
* Bottom-layer elements can only establish
relationships with one of the three middle-layer nodes
, and the relationship type must match the element's
semantics. Carefully consider whether each rule
element belongs to Precondition, Operation, or
ExpectedResult.
4. **Two-Step Output Requirements**
* **Step 1 - Rule Element List**: Output a list of
approximately 15 leaf classes (class names in
UpperCamelCase), each with a semantic description
within 10 words.
* **Step 2 - Meta-Model**: Construct a complete
three-layer class diagram in PlantUML:
* Top layer `Rule`;
* Middle layer `Precondition`, `Operation`, `
ExpectedResult`;
* Bottom layer directly referencing the leaf
classes from Step 1, without renaming.
* In Step 2, clearly indicate the direction and
type of all relationships, ensuring a tree hierarchy
and logical consistency.
5. **Naming and Style**
* All class names use UpperCamelCase (e.g., `
AccountStatus` rather than `account_status`).
* Class bodies remain empty (class name only).
* Relationship names use lowercase verbs (e.g., `
contains`, `triggers`).
### Output (Mandatory)
* The rule element list should be output as a numbered
list; the meta-model should be output as PlantUML
code.
* The number of leaf nodes must be strictly around 15;
the leaf class names in Step 1 and Step 2 must match
exactly (including capitalization).
* If you are unsure of which elements to include,
refer to the keys in the test cases. Elements must be
concise, representative, and high-frequency. For
example, only one Actor should exist as a primary
entity; having X Actor, Y Actor, etc., would be too
repetitive.
A.1.2 RequirementsRepresentation
Formalization
RequirementRepresentationFormalizationdefines
aformal,machine-readablerequirementrepresenta-
tionthatcapturestheessentialsemanticsofdomain
ruleswhileenablingconsistentparsinganddown-
streamanalysis. Givennatural-languagerules,ex-
ample test cases, and a domain meta-model, this
step formalizes informal requirements into a for-
malrepresentationthatbridgesfree-textspecifica-
tionsandexecutableartifacts,withoutyetenforcing
testabilityconstraints.
12

Theformalizedrequirementrepresentationcon-
sistsoftwocorecomponents: SymbolsandSyntax.
Symbolsdefinethevocabularyandsemanticroles
ofelementsusedinrequirementexpressions,while
Syntaxspecifiesthehierarchicalstructureandcom-
position rules for combining these elements into
well-formedrequirements. Thisrepresentationis
domain-agnosticandindependentofanyspecific
modelinglanguageortestingframework,enabling
reuseacrossdifferentregulatorydomainsandLLM
backends.
You are a software requirements modeling expert.
Your task is to define a formal requirement
representation language for describing domain rules in
a structured and machine-readable form.
This representation aims to formalize natural language
rules or requirement documents so that they can be
consistently parsed, analyzed, and used as a basis for
further validation and testing.
### Input
You will receive the following three types of input:
1. **Rule/Requirement Document** - natural language
descriptions of domain rules or system behavior;
2. **Test Cases** - example test cases that illustrate
the intended behavior of some rules;
3. **Meta-Model Syntax Structure** - defining the core
elements of rules and their hierarchical
relationships.
### Task Objective
Based on the above inputs, define a complete formal
Requirement Representation.
The language definition includes two parts:
**Symbols** and **Syntax**.
### **Symbol System**
* Based on the given meta-model, define the types of
symbols used in the language and their scope,
including:
* Logical Symbols
* Comparison Symbols
* Domain Symbols
* Clearly specify the syntactic position and semantic
role of each type of symbol.
### **Syntax**
* Based on the given meta-model, define the core
components of the language and their hierarchical
composition rules;
* The value of each element should be a string or
number, not an enum;
* Use formal BNF to define the language structure;
* The syntax should be simple and explicit, while
supporting complex rule expressions (e.g., AND/OR/NOT,
nested conditions, composite actions);
* Condition, Action, and ExpectedOutcome should follow
consistent structural patterns.
### **Output Requirements**
Please output:
1. The formal definition of Symbols and Syntax;
2. A complete definition of the requirement
representation;
3. **An example** showing how a natural language rule
is transformed into an instance of this representation.
### Meta-Model (PlantUML Representation)
{}
2

=== Page 13 ===
A.1.3 TestabilityConstraintsSpecification
Testability Constraint Specification defines a set
ofexplicitconstraintsovertheformalizedrequire-
mentrepresentationtodeterminewhetherarequire-
mentistestable. Thisstepfocusesonidentifying
structural, semantic, and data-related conditions
thatmustbesatisfiedforarequirementtosupport
automatedtestgenerationandverification.
Testability constraints are specified indepen-
dently of requirement syntax and are applied as
avalidationlayerovertheformalrequirementrep-
resentation. These constraints capture necessary
conditionssuchasobservability,determinism,in-
putcompleteness,andverifiableoutcomes,andare
formalizedusingOCLtoenableautomatedcheck-
ing.
You are a software testing and requirements validation
expert.
Your task is to define a set of formal testability
constraints for a given formal requirement
representation.
These constraints are intended to determine whether a
requirement instance is testable, i.e., whether it can
be unambiguously verified and used for automated test
generation.
### Input
You will receive:
1. **Formal Requirement Representation Definition** -
including Symbols and Syntax.
### Task Objective
Based on the above inputs, define a comprehensive set
of **Testability Constraints**.
### **Testability Constraints**
* Identify the necessary and sufficient conditions for
a requirement to be testable, considering:
* Completeness of conditions and actions;
* Observability and verifiability of expected
outcomes;
* Absence of ambiguity or underspecification;
* Compatibility with available test inputs and
outputs.
* Formalize these constraints using **OCL** over the
requirement representation model.
### **Output Requirements**
Please output:
1. A complete set of testability constraints expressed
in OCL;
2. A clear explanation of each constraint and its
rationale;
3. **An example** demonstrating how a formalized
requirement is checked against these constraints and
classified as testable or non-testable.
### Formal Requirements Representation
{}
A.1.4 FormalRequirementGeneration
This section presents formal requirement genera-
tion,whichtransformsnaturallanguagerulesinto
formal,testablerequirementsbasedonthetestable
13

requirements representation. The task is guided
by prompts specifying the expert role, task ob-
jective, inputs, output format, and language con-
straints. While earlier methods required model
training(Xueetal.,2024b),modernlargelanguage
models can achieve strong results using prompt
engineeringwithfew-shotexamplesalone. Anex-
amplepromptinthefinancialdomainisprovided
below.
You are a software requirements modeling and testing
expert, proficient in requirements engineering, formal
modeling, and test case generation. You are familiar
with testable requirements representation, which can
accurately represent rules described in natural
language as formal requirements that are executable,
verifiable, and testable.
### Task Description
I will provide one or more rules described in natural
language, and your task is to convert them into the
Testable Requirement Language.
### Input
1. Definition of the Testable Requirement Language (
provided below).
2. Natural language rules to be converted, provided
one at a time in multiple interactions.
### Output
Formal Requirements
### Generation Requirements
1. The output testable requirements must conform to
the elements and syntax of the representation, and
must not exceed the defined scope.
2. If a rule can be interpreted in multiple ways,
provide the best expression.
3. TRL must accurately express the meaning of the rule
and fully include all elements of the rule; nothing
should be omitted.
4. Only output the testable requirement; do not output
extra content, and do not evaluate testability at
this step (this will be handled by other tools later).
### Testable Requirement Language Definition
#### Symbol Definition
{}
#### Syntax Definition
{}
#### Other Requirements
1. Generally, strictly follow the defined symbols and
syntax when writing testable requirements.
2. Except for cases requiring modulo calculations, all
expressions must follow the key-op-value triple
format; binary, quadruple, or quintuple formats are
prohibited.
3. Must accurately express the rule meaning and fully
include all elements (subject, verb, object, events,
and domain-specific elements); redundancy is allowed,
omission is not.
4. Do not overuse parentheses; use only when necessary
(e.g., with or, not).
5. Remain faithful to the original text; only words
present in the original text may appear. No invented
words are allowed.
### Examples
* Example 1
* Input: Unless otherwise specified by the exchange,
the bond trading submission quantity shall comply
with the following requirements: (1) for matching
execution, the bond cash submission quantity shall be
100,000 yuan or multiples thereof; for sales of less
than 100,000 yuan, submit in a single order; for
general pledged repo of bonds, the submission quantity
shall be 1,000 yuan or multiples thereof; (2) for
3

=== Page 14 ===
click execution, the submission quantity shall be
100,000 yuan or multiples thereof; (3) for inquiry or
competitive purchase execution, the submission
quantity shall be no less than 100,000 yuan and in
multiples of 1,000 yuan; (4) for negotiated execution,
the bond cash submission quantity shall be no less
than 1,000 yuan and in multiples of 100 yuan; general
pledged repo submission quantity shall be 1,000 yuan
or multiples thereof.
* Output:
```
rule 1
if TradingInstrument = Bond and TradingMethod =
MatchingExecution and BondType = CashBond and Quantity
% 100000 == 0
then Result = Success
rule 2
if TradingInstrument = Bond and TradingMethod =
MatchingExecution and BondType = CashBond and Action =
Sell and Balance < 100000 and Action =
SingleSubmission
then Result = Success
rule 3
if TradingInstrument = Bond and TradingMethod =
MatchingExecution and BondType = GeneralPledgedRepo
and Quantity % 1000 == 0
then Result = Success
rule 4
if TradingInstrument = Bond and TradingMethod =
ClickExecution and Quantity % 100000 == 0
then Result = Success
rule 5
if TradingInstrument = Bond and (TradingMethod =
InquiryExecution or TradingMethod =
CompetitivePurchase) and Quantity >= 100000 and
Quantity % 1000 == 0
then Result = Success
rule 6
if TradingInstrument = Bond and TradingMethod =
NegotiatedExecution and BondType = CashBond and
Quantity >= 1000 and Quantity % 100 == 0
then Result = Success
rule 7
if TradingInstrument = Bond and TradingMethod =
NegotiatedExecution and BondType = GeneralPledgedRepo
and Quantity % 1000 == 0
then Result = Success
```
* Example 2
* Input: If both parties agree to a manual method,
and the client wishes to continue participating in the
next period on the repo maturity date, they shall
re-issue the initial order to the securities company.
* Output:
```
rule 1
if Actor = BothParties and Action = Agree and
Constraint = ManualMethod and Actor = Client and Time
= RepoMaturityDate and Action = WishToContinue and
OperationPart = NextPeriodTrade and OperationTarget =
SecuritiesCompany and Action = Issue and OperationPart
= InitialOrder
then Result = Success
```
A.1.5 TestabilityDetermination
Thissectioncoverstestabilitydetermination,which
evaluateswhetherarequirementsatisfiesspecified
testabilityconstraints. Usingfew-shotprompts,the
modelreceivesanaturallanguagerule,itsformal
requirement,andasingleconstraintperevaluation.
The process checks constraints iteratively: if the
constraint is satisfied, it proceeds to the next; if
not,itstops. Thisleverageslargelanguagemodels’
reasoningwithoutadditionaltraining.
14

You are a software requirements modeling and testing
expert, specialized in evaluating whether a natural
language rule and its formalized requirement
constitute a testable requirement.
Now, you need to determine whether a given rule is a
**Testable Requirement**.
The rule inputs include:
1. Natural Language Rule
2. Formalized Rule
You need to assess whether the rule meets both
requirement validity and testability criteria, and
output:
* `True` (testable requirement) or `False` (
non-testable or non-requirement)
* If `False`, provide a brief explanation.
### **Input Format**
For example, a rule in natural language:
The trading system shall complete matching within 5
seconds after receiving a valid order.
Its corresponding formalized expression:
```
rule 1
if Actor = TradingSystem and Event = ReceivedOrder and
Time = within5s and Action = CompleteMatching
then Result = Success
```
### **Evaluation Criteria**
{}
### **Output Format**
Output `true` or `false` to indicate whether the rule
is a testable requirement.
If the rule is not testable, provide a one-sentence
explanation.
### **Reasoning Strategy (Thinking Sequence)**
1. First, determine if it is a requirement (exclude
background, definitions, etc.).
2. Then, check each of the five testability
constraints one by one.
3. If all are satisfied, output `True`; otherwise,
output `False`.
4. The explanation should be concise and focused on
verifiability.
### **Some Intuitive Guidelines**
1. Statements like ``may'' are considered acceptable,
as doing or not doing does not affect testability
determination.
2. All elements of a testable requirement must be
deterministic; expressions such as ``other'', ``unless
otherwise specified'', or ``submission time (instead
of a specific 9:00-10:00)'' are not allowed.
3. Testable requirements cannot contain references (e.
g., Article A, previous chapter, or earlier rules).
4. The formalized rule has already undergone some
testability processing and is more testable than the
original text. Evaluation mainly focuses on whether
the formalized rule meets testability requirements;
the natural language text serves as a reference.
Note: All testability determinations use strict OCL
constraint patterns. No contextual assumptions are
made; the judgment is based on pure textual-level
testability (must be independent and directly
verifiable).
### **Example**
#### Input:
When the system receives a user payment instruction,
it should immediately deduct the corresponding account
balance and return the transaction result status.
```
rule 1
if Actor = System and Event =
ReceivedUserPaymentInstruction and Action = Deduct and
OperationPart = AccountBalance and Action = Return
and OperationPart = TransactionResultStatus
then Result = Success and ResultStatus =
TransactionSuccess
```
#### Output:
4

=== Page 15 ===
true
A.2 ExtractedRegulatoryKnowledgeforthe
FinancialDomain
Thischapterpresentsthedomainmeta-modeland
thetestablerequirementsrepresentationforthefi-
nancialdomain.
A.2.1 Meta-Model
@startuml
skinparam defaultFontSize 20
skinparam ranksep 20
skinparam nodesep 20
class TradingRule
class Condition
class Operator
class Indicator
class Parameter
class Action
class Signal
class RuleSet
class PositionSizingRule
class RiskManagementRule
class EntryRule
class ExitRule
TradingRule *-- Condition : conditions
TradingRule *-- Action : actions
TradingRule -- RuleSet : part of
RuleSet *-- TradingRule : contains
Condition *-- Operator
Condition *-- Indicator
Condition *-- Parameter
Action -- Signal
EntryRule --|> TradingRule
ExitRule --|> TradingRule
PositionSizingRule --|> TradingRule
RiskManagementRule --|> TradingRule
@enduml
A.2.2 FormalRequirementsRepresentation
### Symbols:
* Logical Symbols:
* and, or, not
* implicate
* Comparison Symbols
* =, !=, >, >=, <, <=, in
* Domain Symbols
* Precondition: Actor, TradingInstrument,
TradingMarket, Time, Constraint, Event
* Action: Action, TradingDirection, TradingMethod,
Quantity, Price, OperationPart, Status
* ExpectedResult: ResultStatus, Result
### Syntax:
```BNF
Rule ::= "IF" <Precondition> "AND" <Operation> "THEN"
<ExpectedOutcome>
Precondition ::= <AtomicPrecondition> | <
CompoundPrecondition>
AtomicPrecondition ::= <PreconditionElement> <
Comparator> <Value>
CompoundPrecondition ::= "(" <Precondition> ")"
| <Precondition> "AND" <
Precondition>
| <Precondition> "OR" <
Precondition>
15

| "NOT" <Precondition>
Operation ::= <AtomicOperation> | <CompoundOperation>
AtomicOperation ::= <OperationElement> <Comparator> <
Value>
CompoundOperation ::= "(" <Operation> ")"
| <Operation> "AND" <Operation>
| <Operation> "OR" <Operation>
| "NOT" <Operation>
ExpectedOutcome ::= <AtomicOutcome> | <CompoundOutcome
>
AtomicOutcome ::= <ResultElement> <Comparator> <Value>
CompoundOutcome ::= "(" <ExpectedOutcome> ")"
| <ExpectedOutcome> "AND" <
ExpectedOutcome>
PreconditionElement ::= "Actor" | "TradingInstrument"
| "TradingMarket"
| "Time" | "Event" | "Constraint"
OperationElement ::= "Action" | "TradingDirection" | "
TradingMethod"
| "Quantity" | "Price" | "
OperationPart" | "Status" | "Constraint"
ResultElement ::= "ResultStatus" | "Result" | "
Constraint"
Comparator ::= "=" | "!=" | ">" | "<" | ">=" | "<=" |
"in"
Value ::= <StringLiteral> | <NumberLiteral> | <
BooleanLiteral> | <TimeLiteral> | <TimeRangeSet>
StringLiteral ::= "\"" [^"]* "\""
NumberLiteral ::= [0-9]+ ("." [0-9]+)?
BooleanLiteral ::= "true" | "false"
TimeLiteral ::= "\"" [0-9]{2} ":" [0-9]{2} (":" [0-9
]{2})? "\"" // Support minutes and seconds
TimeRange ::= <TimeLiteral> "-" <TimeLiteral>
TimeRangeSet ::= "[" <TimeRange> ("," <TimeRange>)*
"]" // Example: [10:00-12:00,13:00-14:00]
```
A.2.3 TestabilityConstraints
1. Structural Completeness: Condition, Action, and
Result must be non-empty
context Rule
```OCL
inv StructuralCompleteness:
not self.Precondition.oclIsUndefined() and
not self.Operation.oclIsUndefined() and
not self.ExpectedResult.oclIsUndefined()
```
2. Deterministic Rule Elements: Precondition,
Operation, and ExpectedResult elements must be
concrete and deterministic
```OCL
context Rule
inv RuleElementDeterministic:
self.Precondition->forAll(e | e.concrete() and e.
deterministic())
self.Operation->forAll(e | e.concrete() and e.
deterministic())
self.ExpectedResult->forAll(e | e.concrete() and e.
deterministic())
```
3. Action Executability: Actions must be executable
```OCL
context Rule
inv ActionExecutable:
self.Operation.Action.notEmpty() and
self.Operation.Action.executable()
```
4. Expected Result Observability: Results must be
observable
```OCL
context Rule
inv ExpectedResultObservable:
self.ExpectedResult.Result.notEmpty() and
5

=== Page 16 ===
self.ExpectedResult.Result.observable() "id": 2,
``` ...
5. Unambiguity Outcome: The same precondition and },
operation should not yield conflicting expected ...
results ]
```OCL
context Rule ### Example
inv DeterministicOutcome: #### Input:
Rule.allInstances()->forAll(r2 | An investor who buys bond ETF shares through auction
if r2 <> self and r2.Precondition = self. trading on the same day may sell them on the same day.
Precondition and r2.Operation = self.Operation #### Output:
then r2.ExpectedResult.ResultStatus = self. [
ExpectedResult.ResultStatus {
else true "id": 1,
endif) "Actor": "Investor",
``` "Time": "Same day",
"TradingMethod": "Auction trading",
"Action": "Buy",
"TradingInstrument": "Bond ETF shares",
A.3 PromptUsedforcomparedE2ELLMs "Time2": "Same day",
"Action2": "Sell",
"Result": "Success"
Intheexperiments,wecompareourapproachwith
},
end-to-endLLMsingeneratingtestcasesfromreg- {
"id": 1,
ulatorydocuments. Representativemodels,includ- "Actor": "Investor",
"Time": "Not the same day",
ingGPT-5,Grok-4,andDeepSeek-R1,areselected "TradingMethod": "Auction trading",
as baselines. Task-specific prompts are carefully "Action": "Buy",
"TradingInstrument": "Bond ETF shares",
designedforthemtoelicitthebestperformancein "Time2": "Same day",
"Action2": "Sell",
testcasegeneration. ThepromptsusedinExperi- "Result": "Failure"
},
mentIarepresentedbelow;forExperimentII,the
...
compositionisthesame,exceptfortheapplication ]
domainandtherunningexample.
You are a Financial Requirement Modeling & Testing
Expert, specializing in software requirements
engineering, financial business rule analysis, and
test case generation.
Your task is to generate test cases for the given
financial-domain rules.
### Task Objective
Test Case Generation (only when the rule is testable)
* Based on the natural language rule, generate a set
of high-quality test cases.
* Generation requirements:
1. Content requirements
* Each test case must be a JSON object (map).
* Each test case should include multiple key
elements, such as: actor, time, trading method,
trading instrument, action, operation target, quantity
, price, result, etc. (to be flexibly selected
according to the rule content).
2. Quality requirements
* Test cases must cover both positive (success)
and negative (failure) scenarios.
* Test cases should reflect rule boundaries and
constraint validation.
* Test cases should not be duplicated and must be
representative and distinguishable.
* The output must be strictly in JSON array
format.
* If the rule is not testable and test cases cannot be
generated, do not generate any output.
### Input Format
Input consists of one natural language
financial-domain rule.
### Output Format
Output test cases in JSON format:
[
{
"id": 1,
"TradingInstrument": ...,
"Time": ...,
...
},
{
16

Paper:Generating Automotive Code - Large Language Models for Software Development.pdf
=== Page 1 ===
Generating Automotive Code: Lar
Development and Verificatio
Sven Kirchner1,
Abstract—Developing safety-critical automotive software
presents significant challenges due to increasing system com-
plexity and strict regulatory demands. This paper proposes a
novel framework integrating Generative Artificial Intelligence
(GenAI)intotheSoftwareDevelopmentLifecycle(SDLC).The
framework uses Large Language Models (LLMs) to automate
codegenerationinlanguagessuchasC++,incorporatingsafety-
focused practices such as static verification, test-driven devel-
opment and iterative refinement. A feedback-driven pipeline
ensures the integration of test, simulation and verification for
compliance with safety standards. The framework is validated
throughthedevelopmentofanAdaptiveCruiseControl(ACC)
system. Comparative benchmarking of LLMs ensures optimal
model selection for accuracy and reliability. Results demon-
strate that the framework enables automatic code generation
while ensuring compliance with safety-critical requirements,
systematically integrating GenAI into automotive software en-
gineering. This work advances the use of AI in safety-critical
domains, bridging the gap between state-of-the-art generative
models and real-world safety requirements.
I. INTRODUCTION
Recentadvancementsintheautomotivedomainaredriving
a paradigm shift from hardware-defined to software-defined
intelligent vehicles, where software complexity and safety-
criticalityhaveincreasedsignificantly.Traditionallinearpro-
cesses, such as the V-model or the waterfall model [1],
offer limited flexibility to adapt to dynamically evolving
requirements. As the volume of automotive software grows,
each change in requirements requires extensive changes to
thecodebaseandrepeatedvalidationcycles,increasingboth
development time and cost. As a result, software architects
and developers face increasing challenges in ensuring safety
compliance, especially given the continuous expansion of
regulatory frameworks and standards, which are now reach-
inglevelsofcomplexitythataredifficulttotrackandimple-
mentmanually[2].LargeLanguageModels(LLMs),suchas
Chat GPT-3 [3], have recently shown promise in addressing
this complexity by transforming the role of developers from
codeauthorstoorchestratorsofgenerativepipelines.Instead
of writing all application-level software manually, engineers
can leverage LLMs for automated code generation, using
the same standards that once hindered rapid development as
structured data sources for compliance.
Inthiswork,weproposeanovelframeworkthatintegrates
Generative Artificial Intelligence (GenAI) into the software
1 TechnicalUniversityofMunich,Garching,Bayern,Germany
ThisresearchwasfundedbytheFederalMinistryofEducationandResearch
ofGermany(BMBF)aspartoftheCeCaSproject,FKZ:16ME0800K.
© 2025 IEEE. Personal use of this material is permitted. Permission from
includingreprinting/republishingthismaterialforadvertisingorpromotionalp
orlists,orreuseofanycopyrightedcomponentofthisworkinotherworks.
5202
nuJ
4
]ES.sc[
1v83040.6052:viXra

rge Language Models for Software
on in Safety-Critical Systems
Alois C. Knoll1
development lifecycle (SDLC). By using LLMs in conjunc-
tion with test-driven development (TDD) and static analysis,
our approach enables modular system architectures that can
be rapidly adapted to evolving requirements, while ensuring
compliance with critical safety standards. A core element of
the proposed framework is its focus on software generation
during the test and integration phases, making the LLM
an active participant in the iterative refinement loop. Under
this paradigm, test suites and integration scripts assist the
LLMbyguidingautomatedcodegenerationtomeetspecified
requirements. The automated process reduces the need for
manual recoding and retesting when system requirements
change. Our methodology therefore shifts engineering effort
to the creation of specification artefacts and robust tools,
rather than traditional manual coding. We detail how this
framework improves development speed by minimizing hu-
man intervention in code production and compliance checks
and we illustrate its capabilities with an automotive case
study that demonstrates its ability to save time and reduce
errorrates.Wethereforepresentthefollowingcontributions:
• GenAI-Integrated SDLC: A novel LLM-driven de-
velopment cycle that combines TDD, static analysis
and iterative refinement for safety-critical automotive
software.
• Safety Monitoring Pipeline: A unified framework
for static analysis, formal verification, and automated
integration validation to ensure safety compliance in
automotive software systems.
• LLM Handling: Evaluating the benchmark perfor-
mance of LLMs and optimizing their implementation
for automated code generation and refinement in auto-
motive software development.
• ISO-based ACC Case Study:Validationthroughauto-
matedgenerationofanISO-basedACCsysteminC++,
tested on the CARLA simulator [4].
II. RELATEDWORK
The fundamental principles of software engineering are
based on critical design decisions in software development.
To integrate safety as a priority, a focus on robust design
capabilities can be complemented by effective test and val-
idation methodologies and the use of software verification
tools. This enables GenAI to create scalable and safety-
critical applications while ensuring compliance with auto-
motive standards.
IEEE must be obtained for all other uses, in any current or future media,
purposes,creatingnewcollectiveworks,forresaleorredistributiontoservers
.

=== Page 2 ===
User
Prompt
Software
Requirements Input
Positional
& Tokenization Embedding
Encoding
System Matrix
Specification
M
System
Prompt Se
Fig. 1: Introduction of Attention Mechanism and Transformer
A. Reducing software complexity through design choices
Managing complexity in software engineering requires a
systematicapproachtodesignchoices,aimedatconstraining
degrees of freedom and thereby reducing the likelihood
of errors. Consequently, maintaining logical consistency in
algorithms and flow control becomes essential for verifying
correctness [5]. Structured interactions between the system
and its environment reduce ambiguity and improve inte-
gration [6]. Efficient organization of data underpins perfor-
manceandscalability[7],whilemodulararchitecturesensure
extensibility and adaptability [8]. Test-driven development
integratescorrectnessintothedevelopmentprocess[9],while
computational precision mitigates numerical instability [10].
Dependency management and platform compatibility ensure
consistent behaviour across environments [11]. Addressing
security vulnerabilities is essential for demonstrating system
safety [12], while effectively managing concurrency is criti-
cal for handling dynamic and parallel systems [13].
Design principles and standards provide a formal frame-
work for managing the inherent degrees of freedom in
software development, ultimately enabling the creation of
robust, scalable and extensible systems [8]. Strategically
controlling each degree of freedom minimizes the potential
for error, thereby increasing the overall safety and reliability
of the software.
B. Safety-Critical Software
Safety-critical software requires a systematic approach,
treating programming as an exact science with predictable
and provable behaviour under all conditions [14]. Achieving
this requires careful selection of programming languages,
robust compiler validation and comprehensive verification
and testing methodologies.
C++ is widely used in safety-critical design because of
to its balance of high performance, precise memory control,
anddeterministicresourcemanagement,whichenablesstrict
real-time and reliability constraints to be met. Compiler
validation further strengthens these guarantees by translat-
ing the code correctly. C++ compilers such as GCC and
Clang are highly optimized for performance and reliability,
offering advanced static analysis, code optimization and
diagnostics [15]. Beyond language and compiler choice,
static code analysis is essential to ensure logical consistency

Layer Normalization
Feedforward
... Linear output
Projection Post
code
& Processing
... .txt
Softmax
Multilayer Perceptron
elf Attention Mechanism
Architecture in Large Language Models for Code Generation.
[5]. Tools such as cppcheck for C++ [16] identify memory
leaks, race conditions and guideline violations, significantly
reducing the likelihood of unexpected behaviors. Before
full integration, system behaviour is validated through unit
testing. Frameworks like Google Test [17] verify functional
correctnessbyadaptingtestingpreconditionsandedgecases.
By integrating language safety, certified compilers, static
analysis and rigorous testing, this approach improves cor-
rectness, compliance with safety standards and robustness in
safety-critical applications.
C. Foundations of Requirements Engineering and Software
Development for Automotive Systems
Automotive software development bridges complex safety
and functional requirements with robust code design. A
Software Requirements Specification (SRS) defines both
functional (e.g., system behaviour) and non-functional (e.g.,
performance, security) requirements, guiding the develop-
ment process. Stakeholder alignment is achieved through
use cases, user stories and prototypes, ensuring clarity
and addressing safety from the outset. Safety and quality
standards are central. ISO 26262 [18] defines functional
safety requirements for road vehicles, while Automotive
SoftwareProcessImprovementandCapabilityDetermination
(ASPICE) [19] provides a framework for assessing software
quality and processes. The MISRA guidelines [20] stan-
dardize programming practices, often implemented in C or
C++ for their reliability and performance in safety-critical
systems. Detailed testing, including static analysis and unit
testing, ensures compliance with safety standards. General
requirements align with frameworks like ISO 26262, while
function-specific requirements address unique system needs.
By integrating these principles, automotive software de-
velopment transforms complex requirements into reliable,
maintainable and safety-compliant systems.
D. Integrating Generative AI into Software Engineering
The introduction of the Attention Mechanism revolution-
ized natural language processing, enabling the development
of Large Language Models (LLMs) through the innovative
Transformer Architecture. This architecture facilitates non-
sequential data processing, overcoming the limitations of
earlier recurrent models and introducing greater efficiency
and scalability [21].

=== Page 3 ===
io-Check
Unittest
System Design
Specification
LLM Handler
Requirements Initialize LLM, Prompt Prom
LLM
Engineering & Error Handler Engine
System Behaviour
Specification
Integrati
Monitori
Fig. 2: The code generation architecture consists of three com
module (grey) and the integration testing module (dark blue).
Handler generates executable code that is iteratively refined
functionality.
In the framework illustrated in Figure 1, a given require-
ment provided as textual input is tokenized and processed
through input embeddings, where it is enriched with po-
sitional encodings to preserve the sequential context. The
tokens are then iteratively passed through a stack of self-
attention layers and feedforward multilayer perceptrons.
These mechanisms ensure that the model captures both
localandglobaldependencieswithintheinputrequirements.
Subsequently,theprocessedtokensundergolinearprojection
and post-processing steps to generate the next token in the
sequence. This iterative process enables the generation of
software in the form of coherent and contextually relevant
text. The ability to train or fine-tune foundation models like
llama3 [22] on specific tasks has been further enhanced by
leveraging large-scale datasets. For instance, LLMs such as
thosedesignedforcodegenerationlikeQwen2.5-Coder[23]
benefit significantly from task-specific training datasets. The
performanceofLLMsisheavilyinfluencedbythequalityof
the training data, the design of the prompt and the system
specifications.
An essential aspect of the effective use of LLMs is the
management of the context size, which is inherently limited
by the architecture. To maximize the utility of the available
context,effectivepromptingtechniqueshavebeendeveloped,
ensuring that critical information is succinctly presented
withinthelimitedinputspace.StrategiessuchasZero-shotor
Few-shot Prompting [24], Chain-of-Thought [25] and Role-
based Prompting [26] enable LLMS to generate accurate
and high quality output for a variety of tasks. Combination
with further validation and formal verification methods can
improve the overall quality of the generated code [27].
III. METHOD
To integrate generative AI into the software development
cycle, we propose an approach that combines test-driven
development with previously introduced verification meth-

k Static Code Compiler Structure
Verification Check Check
Static Validation Module
mpt Prompt generated
Preprocessing Application
eering LLM Code
Integration Testing Module
ion Simulation System
ing Environment Software
mponents: the LLM handler (light blue), the static validation
. The user (light yellow) provides specifications and the LLM
d by static checks and integration tests to ensure safety and
ods and static code analysis, ensuring safety through rapid
feedback and consistency.
A. Architectural Design and Software Version Control
The framework illustrated in Figure 2) shows the GenAI
integrated SDLC. User input, including detailed specifica-
tions,servesasthefoundation.TheLLMHandlertransforms
thisinputintoexecutablecodeanditerativelyrefinesitbased
on feedback from subsequent phases. The Static Validation
Module analyzes the generated code for compliance with
safety standards and design principles. Finally, the Integra-
tion Testing Module evaluates the system in a dynamic test
environment, ensuring robust performance and functional
correctness.
Unsafe States
Verified States
I
S
Safe sI
i ss
States I i
I
Fig. 3: Software versions are categorized by safety clas-
sification, progressing through three primary states. The
”Verified State” is achieved upon successful completion of
static testing. ”Safe States” are achieved after meeting static
and integration test criteria. The LLM Handler dynamically
manages the generation of LLMs based on the current state
of the software.
The use of automated code refinement and regeneration
is highly dependent on the software’s current development
stage and version. In safety-critical systems, version control
adherestoamethodologycombiningintegrationmonitoring,

=== Page 4 ===
static code analysis and iterative refinement (Figure 3). The
ultimate objective is to achieve a ”Safe State,” wherein all
predefined functional and safety requirements are satisfied.
Each iteration I involves static analysis managed by the
S
Static Validation module to detect and resolve logical incon-
sistenciesanddesignviolations.Uponsuccessfulcompletion,
the code moves from a static state (sS) to an integration
i
state (sI) within a simulation environment where iterative
i
validation and refinement occurs (I ). Transition to a safe
I
stateisonlyrealizedwhenbothstaticandintegrationcriteria
are conclusively met.
This cyclical process of static and integration iterations
ensures continuous improvement of the software. Each sub-
sequent state builds incrementally upon its predecessor,
anchored in validated safety and integration protocols. Im-
portantly, a new verified state only generated when the
integration phase is successful and all static checks are
resolved,ensuringanuncompromisingcommitmenttosafety
and correctness.
B. LLM based generation: Specification and User Input
User input is given in two distinct classes: System Design
Specification and System Behaviour Specification. The Sys-
tem Design Specification focuses on the inputs and outputs
ofthesystem,usingprecisemathematicallanguagetodefine
algorithmic preconditions and postconditions. The System
Behaviour Specification describes the overall structure and
behaviour of the system. For prompting LLMs, structured
text is provided as input. JSON is a widely used in software
engineering due to its standardization and compatibility.
YAML’s human-readable features, such as whitespace struc-
turing, optional quotes and support for inline comments,
enhanceusabilityandinterpretabilityduringthespecification
phase [28]. To maximize prompt efficiency, JSON is used
for the system design specification, while YAML is used for
thesystembehaviourspecification.Thisdual-formatstrategy
ensures effective context management and optimal use of
prompt space to generate accurate and interpretable output.
The framework integrates zero-shot and few-shot prompt-
ing to optimize LLM performance. Zero-shot prompting
establishes baseline output, followed by iterative few-shot
refinementtoimproveaccuracyandresolveerrors.Thispro-
cess transitions from exploratory prompts to precise adjust-
ments based on output quality. Chain-of-Thought reasoning
improves version control by providing the LLM with the
best prior solution, enabling iterative improvement towards
a safe state, as shown in Figure 3. Role-based prompting
defines the LLM’s role as a ”specialized AI assistant for
safety-criticalautomotivecodegeneration”,ensuringoutputs
are tailored to the framework’s requirements. Each iteration
builds on previous results, driving continuous improvement
and alignment with specifications.
Selecting an appropriate LLM is critical to achieving op-
timal results. We use McEval: Massively Multilingual Code
Evaluation [29], a benchmark designed to evaluate LLM
performance across 40 programming languages, including
Rust and C++, using 16,000 test cases. This provides a

comprehensive framework for evaluating multilingual code
generation. For reasoning and iterative code refinement, we
adopt Aider’s code editing benchmark [30]. It evaluates
precision and consistency in modifying functions, imple-
menting missing functionality and refactoring code from
natural language instructions. By prioritizing editing over
generation,theAiderbenchmarkevaluatestheaccuracyand
consistency of code review and refinement in a variety of
programming challenges, making it critical for frameworks
that require robust iterative development capabilities. We
also include the widely recognized HumanEval benchmark
[31]. Table I summarizes the performance of various large
languagemodelsacrossthesebenchmarks,highlightingtheir
multilingual code generation and iterative refinement ca-
pabilities. We evaluate state-of-the-art open-source LLMs,
including Qwen2.5-Coder-7B-Instruct, Llama-3-8B-Instruct,
DeepSeek-Coder-V2 Lite Instruct [32], DeepSeek-Coder
33B Instruct [33], and CodeStral-22B [34], using GPT-4o
as a benchmark for comparison.
LLMCodeGenerationandRefactoringBenchmark
Aider HumanEval
Model McEval
CodeEditing (0-shot)
Qwen2.5-Coder-7B-I 57.9 60.3 88.4
Llama-3-8B-Instruct 37.6 32.0 62.2
DeepSeek-Coder-V2LI 48.9 54.7 81.1
DeepSeek-Coder33BI 49.6 54.3 79.3
CodeStral-22B 48.1 50.5 78.1
GPT-4o(240513) 54.0 72.9 90.2
TABLEI:Evaluationofstate-of-the-artlargelanguagemod-
els, with all values reported in percentages. McEval results
represent Pass@1 performance, while HumanEval scores
reflect 0-shot capabilities. DeepSeek-Coder-V2 LI denotes
the Lite Instruct variant, DeepSeek-Coder 33B I refers to
the Instruct version, and Qwen2.5-Coder-7B-I indicates the
Instruct variant.
Given the sensitivity of the data and the stringent data
protection requirements in the automotive domain, our use
case necessitates a locally deployable LLM capable of han-
dling complex programming tasks without compromising
data security. Among models with a token size of less
than 10B, Qwen2.5-Coder-7B-Instruct proves as the most
effective option, offering excellent performance while being
the smallest in this category.
OncetheLLMhasgeneratedtheoutput,thenextstepisto
extractthecodeandinstallthenecessarylibraries.Thisphase
includes dependency management, ensuring all necessary
libraries and tools are properly defined and integrated into
the software environment. By automating these tasks, the
framework accelerates the development cycle while main-
taining precision and reliability. This structured approach
to LLM-based generation bridges the gap between user-
provided input and actionable software artefacts.
C. Static Validation Module
Once the code has been extracted from the LLM analysis,
thefirststepintheevaluationprocessisstaticcodeanalysis.

=== Page 5 ===
This phase involves a series of checks to ensure the safety,
functionality and adherence to design specifications of the
generated code. Static code analysis plays a critical role in
identifying potential problems early on, providing a strong
foundationforseamlessintegrationintothemainframework.
To advance to the next state (S) and proceed to integration
testing, the generated software (SW) must successfully pass
aseriesofstaticchecks(c ).Theprocessshownin1involves
i
an iterative cycle of software generation and refinement,
where each iteration systematically resolves errors (E) iden-
tified during the previous analysis. Through this approach,
the software progressively achieves compliance with the
required safety and functional standards, ensuring readiness
for the integration phase.
Algorithm 1 Static Analysis and Error Handling
1: while ∃ss ∈S such that ss ̸=success do
i i
2: SW ←generate code(ss,E)
i
3: for c i ∈C do
4: ss i ←analyze(SW,c i )
5: if ss ==success then
i
6: continue
7: else
8: E ←get error analysis(SW,c i )
9: break
10: end if
11: end for
12: end while
13: S ←run integration monitoring(SW)
The static analysis process consists of several key checks:
It starts with a structure check, which verifies that the
functionnameoftheprimaryfunctionalityisintheappropri-
ate place in the generated code. This ensures compatibility
with the broader framework and establishes a baseline for
integration.
The compilation check in C++ ensures that the code
can be successfully compiled by validating it. The com-
piler performs multiple checks, including syntactic verifi-
cation to enforce correct grammar and semantic analysis
to ensure meaningful execution. Modern compilers employ
sophisticated multi-layered validation mechanisms to detect
type inconsistencies, scope violations and improper memory
usage. This process guarantees both syntactic and semantic
correctness, reinforcing code reliability and robustness in
high-performance computing environments.
Next, the static code style and design check enforces
adherence to established formatting and design principles,
ensuring maintainability and consistency. Tools such as cp-
pcheck for C++ validate compliance with standards such as
MISRA to address stylistic and semantic issues.
Finally, unit testing validates the functional behaviour of
thecode.FrameworkssuchasGoogleTestinC++areusedto
run comprehensive test suites, covering diverse scenarios to
confirm that inputs and outputs align with specified require-
ments. These tests serve as a safety net against regressions

and ensure correctness in future iterations. When using unit
testing as feedback, it is crucial to withhold specific failure
details from the LLM, preventing over-fitting to individual
tests and preserving generalizable behaviour.
Taken together, these steps constitute a rigorous and sys-
tematic approach to static analysis, ensuring that the code
meets the highest standards of safety, compatibility and
reliability, while laying a robust foundation for subsequent
development and integration.
D. Integration Monitoring Module
Monitoring Agent AD System
LLMout LLMin
Software
δ
APIsys
a x ,v x ,x y
Simulation
ψ
27,1m
16,2m5,1m
Fig. 4: The integration monitoring framework consists of
three key components: the monitoring agent, which acts as
a client to the simulation server and has access to ground
truth data; the simulation server, which provides synthetic
sensor and vehicle state information; and the AD system,
whichprovidesanautonomousdrivingsystemthatallowsto
integrate the generated software through clear APIs.
After successfully passing the static analysis phase and
demonstrating full compliance with static safety require-
ments, the generated software is integrated into the Au-
tonomous Driving (AD) system. This integration is achieved
through the use of well-defined and strictly verified Ap-
plication Programming Interfaces (APIs), which have been
validated during the static analysis phase for consistency
with the previously verified software components. These
validated System APIs (API ) ensure a seamless and
sys
robust connection between the generated software and the
broader AD system architecture. The AD system, which
receives both vehicle state information and sensor data from
a simulation environment, consists of the three core com-
ponents of autonomous driving systems: detection, planning
and control. For the detection module, YOLOP [35] is used,
enabling simultaneous semantic segmentation and object
detection, providing essential contextual information. The
CARLA simulator serves as the simulation environment,
generating synthetic sensor data, such as camera feeds, as
showninFigure4.Toenrichtheobjectdetectionwithdepth
information,adepthcameraisintegratedtoprovidedistance
measurements relative to the ego vehicle.

=== Page 6 ===
This data, along with other vehicle states obtained from
the inertial measurement unit (IMU), is transmitted to the
AD system. The integration monitoring framework includes
a monitoring agent (see figure 4) that uses a simple API to
inspect the environment and system behaviour through its
access to the ground truth data from the simulation server.
User-provided system behaviour specifications serve as a
fundamentalelementinthisframework.Thesespecifications
articulatesimplemathematicalfunctionsdesignedtovalidate
vehicle behaviour against pre-defined performance criteria.
The integration process follows a structured timeline that
includes three distinct phases: initialization, data processing
and evaluation. During the initialization phase, multi-
processing is used to simultaneously start the simulation
environment, the monitoring agent, and the automated
driving (AD) system, ensuring that the performance
of the generated function remains unaffected. Once
operational, the integration monitoring system performs
three critical functions: get data from carla server,
process carla data() and
add data to statistics().Attheendofapredefined
integration test duration, the evaluate data() function
is triggered to perform the mathematical validations defined
in the system behaviour specifications. These validations
span a spectrum of criteria, ranging from behavioural
and comfort-related metrics to strict timing requirements.
Upon successful completion of this stage, the generated
software, refined through iterative interactions with the
LLM, achieves the robustness and reliability required
for seamless integration, meeting all safety-critical and
performance criteria.
IV. EVALUATION
To evaluate the proposed framework, we generate a test
function designed to demonstrate its effectiveness in a re-
alistic scenario. Specifically, we select the adaptive cruise
control (ACC) system, a widely studied application in the
automotivedomain.TheACCsystemoffersrobustevaluation
capabilities in simulation and aligns with the stringent ISO
standards, providing a benchmark for the performance and
reliability of our framework.
A. Simulation Environment and Hardware Setup
TheprimaryobjectiveoftheACCsystemistocontrolthe
longitudinal motion of a vehicle. As a critical component of
the control subsystem in autonomous driving systems, the
ACC takes as input the bounding box of the lead vehicle
including distance information and the inertial measurement
unit (IMU) data of the ego vehicle. Using these inputs,
the system calculates the necessary longitudinal motion and
generates throttle and brake commands as outputs. These
interfaces are essential for maintaining the correct vehicle
speed and spacing in dynamic driving conditions. To ensure
seamless integration within the integration system, the AD
system includes additional modules required for vehicle
operation. These include object detection and segmentation
to identify surrounding objects, as well as motion planning

and a lateral control module to ensure coordinated vehicle
maneuvers.Thesimulationenvironmentreplicatesreal-world
drivingscenarios,providingacontrolledyetdynamicsetting
to evaluate the ACC function. The system is tested under
various conditions to validate its robustness, efficiency and
compliance with ISO requirements. The hardware setup for
this evaluation shown in Table II is critical to achieve high-
performance execution and accurate real-time simulation.
HardwareSetupfortheGenerationandTestingModules
CPU AMDRyzen99950X(16x4.3GHz,170W)
GPU 2xNVIDIAGeForceRTX409024GB
RAM 64GBDDR5-5600Vengeance(2x32GB)
TABLE II: To accelerate the development process, we lever-
age a high-performance hardware configuration to run the
LLMlocallyandexecutethealgorithmwithinthesimulation
environment faster than real-time, ensuring efficient experi-
mentation and iterative refinement.
To enhance computational efficiency, we use accelerated
inference techniques to reduce latency and enable faster
processing. Memory management optimizations are also im-
plemented to minimize gaps in GPU memory allocation. By
dynamically growing memory segments, the framework en-
sures efficient utilization of VRAM, reducing fragmentation
and improving stability during prolonged simulations.
B. Requirements Engineering and System Specification
TherequirementsfortheevaluationoftheAdaptiveCruise
Control (ACC) function are derived from a combination
of multiple sources. The primary standard used is ISO
15622[36], which specifies the performance, safety and
functional behaviour requirements for ACC systems. This
standard serves as the foundation for defining the control
strategy and minimum functional requirements of ACC sys-
tems, including parameters such as time gap (τ), clearance
(c) and ego vehicle speed (v).
τ, c
v, a
Fig. 5: ISO 15622 (Intelligent Transport Systems: Adaptive
cruise control systems – Performance requirements and test
procedures) defines the basic control strategy and minimum
functional requirements for ACC systems. The time gap is
introducedasτ,theclearanceascandtheegovehiclespeed
as v.
From this, we derive the requirement that the minimum
clearance should satisfy:
MAX(c ,τ ·v) (1)
min min
In addition, we define a nominal following distance of 10
meters as an optimal balance between safety and driving

=== Page 7 ===
10
8
6
4
2
0
cstructure−check ccompilation−check ccpp−check cio−check
Failed check ci of the Static Iteration Is
snoitaretI
fo
rebmuN
generation 1
generation 2
generation 3
Fig. 6: Across three independent code generation runs using
Qwen2.5-Coder-7B-I, an average of 16.3 iterations were
required to pass all static tests. Structure and compilation
checks failed the least (2 iterations on average). While the
CPP check, including MISRA compliance, took an average
of4.3iterations,themostdemandingphasewasunittesting,
whichrequired8iterationsonaveragetoensurecorrectness.
comfort. In addition, to ensure physically possible driving
manoeuvres, we set the requirement to reduce the maximum
possible acceleration (positive and negative). The maximum
acceleration is therefore defined as:
|a|<5m/s2 (2)
if no emergency brake is applied. The architecture, inter-
faces and operating logic are carefully defined, following
established best practice in control system development.
Generative AI is given controlled access to throttle and
brake APIs, complemented by real-time vehicle state data
and object detection results, enabling seamless integration
with the wider autonomous driving (AD) system. Software
qualityandreliabilityisensuredbyMISRA-compliantstatic
analysis, which facilitates early detection of potential prob-
lems. In addition, preconditions for integration monitoring,
asoutlinedinISO15622,formthefoundationforsubsequent
test phases, ensuring thorough evaluation and compliance
with critical standards.
C. EvaluatingthePerformanceofthegeneratedACCSystem
To analyze the behavior of the LLM across both software
states(Figure3),weevaluateitsabilitytogeneratecodethat
meets the requirements of the verified state (static checks)
and the safe state (combined static and integration checks).
We apply the defined requirement checks and initiate code
generation, running three independent iterations to analyse
andcomparethenumberofattemptsittakestheLLMframe-
worktoproducecodethatsatisfiesthestaticrequirementsof
a given check (Figure 6).
To ensure effective testing, the behaviour of the leading
vehicleisrandomisedduringintegrationmonitoring.Thisap-
proach prevents the LLM from tailoring the generated func-
tiontoaspecificscenario,therebyimprovinggeneralization.
Theresults,showninfigures7and8,demonstrateconsistent
compliance with the defined requirements. The generated
functions maintain the expected vehicle behaviour, and even
under emergency conditions the deceleration remains within
the prescribed safety threshold.

12
10
8
6
4
2
0
0 2 4 6 8 10 12
Time [s]
]m[
ecnatsiD
generation 1
generation 2
generation 3
Fig.7:Thedistancebetweentheegovehicleandtheleading
vehicle over time shows that all three generated functions
maintainaconsistentfollowingdistanceofapproximately10
metres. The behaviour shows only minor differences across
all implementations, with adjustments occurring mainly in
the 8m to 12m range.
6
4
2
0
−2
−4
−6
0 2 4 6 8 10 12
Time [s]
]²s/m[
noitareleccA
generation 1
generation 2
generation 3
Fig. 8: The acceleration profiles over time show the typical
oscillatory behaviour of all the functions evaluated. Notably,
each function adheres to the predefined safety requirement,
ensuring that the braking does not exceed the threshold of 5
m/s².
V. CONCLUSIONANDFUTUREWORK
Thisworkaddressestheproblemofintegratinggenerative
AI into safety-critical automotive software development.
Specifically, this work aims to (1) develop an LLM-driven
software development framework that ensures compliance
withfunctionalsafetyrequirementsand(2)establishastruc-
turedpipelineforvalidationthroughstaticcodeanalysisand
integration monitoring. By using structured specifications,
automated refinement, and iterative validation, the proposed
framework enables efficient and reliable software genera-
tion for safety-critical applications. Using a case study on
adaptive cruise control (ACC) case study, our experiments
demonstrate that the generated functions meet predefined
safetyandperformanceconstraints,maintainingsafefollow-
ing distances and adhering to acceleration limits even in
emergency scenarios.
Futureworkwillextendtheframeworkbyadaptingmathe-
matical guarantees to prove software correctness. Additional
extensions could involve increasing the number and com-
plexity of requirements to better assess the robustness of
variousLLMs,aswellasevaluatingtheirperformanceacross
different automotive functions. Furthermore, the exploration
of system-level AI-driven software design methodologies
could facilitate the development of a structured model that
improvestheintegrationofgenerativeAIintotheautomotive

=== Page 8 ===
software development lifecycle, building upon and refining
the ASPICE standard. Further evaluation in real-world test-
ing will also be critical to validate the effectiveness of the
framework in practical deployment scenarios.
REFERENCES
[1] Roger Pressman. Software Engineering: A Practitioner’s
Approach. 7th ed. USA: McGraw-Hill, Inc., 2009. ISBN:
0073375977.
[2] Alexandru Constantin Serban et al. “A Standard Driven
Software Architecture for Fully Autonomous Vehicles”. In:
2018 IEEE International Conference on Software Architec-
ture Companion (ICSA-C). 2018, pp. 120–127. DOI: 10.
1109/ICSA-C.2018.00040.
[3] TomB.Brownetal.LanguageModelsareFew-ShotLearn-
ers. 2020. arXiv: 2005.14165 [cs.CL]. URL: https:
//arxiv.org/abs/2005.14165.
[4] AlexeyDosovitskiyetal.CARLA:AnOpenUrbanDriving
Simulator. 2017. arXiv: 1711.03938 [cs.LG]. URL:
https://arxiv.org/abs/1711.03938.
[5] Ian Sommerville. Software Engineering. 9th. Boston, MA,
USA: Addison-Wesley, 2011.
[6] Roger S. Pressman. Software Engineering: A Practitioner’s
Approach. 8th. New York, NY, USA: McGraw-Hill, 2014.
[7] AbrahamSilberschatzetal.DatabaseSystemConcepts.7th.
New York, NY, USA: McGraw-Hill, 2020.
[8] Len Bass et al. Software Architecture in Practice. 3rd.
Boston, MA, USA: Addison-Wesley, 2012.
[9] Kent Beck. Test-Driven Development by Example. Boston,
MA, USA: Addison-Wesley, 2003.
[10] Nicholas J. Higham. Accuracy and Stability of Numerical
Algorithms.2nd.Philadelphia,PA,USA:SocietyforIndus-
trial and Applied Mathematics (SIAM), 2002.
[11] MartinFowler.PatternsofEnterpriseApplicationArchitec-
ture. Boston, MA, USA: Addison-Wesley, 2004.
[12] John Viega and Gary McGraw. Building Secure Software:
How to Avoid Security Problems the Right Way. Boston,
MA, USA: Addison-Wesley, 2001.
[13] Nir Shavit and Maurice Herlihy. The Art of Multiprocessor
Programming. San Francisco, CA, USA: Morgan Kauf-
mann, 2012.
[14] Edsger Wybe Dijkstra. A Discipline of Programming. 1st.
USA: Prentice Hall PTR, 1997. ISBN: 013215871X.
[15] Bjarne Stroustrup. The C++ Programming Language. 4th.
Addison-Wesley Professional, 2013. ISBN: 0321563840.
[16] Daniel Marjama¨ki. Cppcheck: A static analysis tool
for C++. 2024. URL: https : / / cppcheck .
sourceforge.io/.
[17] Google. Google Test: C++ Testing Framework. Accessed:
2023-12-10. 2023. URL: https://github.com/
google/googletest.
[18] International Organization for Standardization. ISO 26262:
Road vehicles – Functional safety. Geneva, Switzerland:
ISO, 2018.
[19] VDAQMCWorkingGroup13.AutomotiveSPICEProcess
Assessment Model. Berlin, Germany: German Association
of the Automotive Industry (VDA), 2022.

[20] MotorIndustrySoftwareReliabilityAssociation.MISRAC:
GuidelinesfortheuseoftheClanguageincriticalsystems.
3rd. UK: MISRA, 2012.
[21] AshishVaswanietal.AttentionIsAllYouNeed.2023.arXiv:
1706.03762 [cs.CL]. URL: https://arxiv.org/
abs/1706.03762.
[22] AaronGrattafiorietal.TheLlama3HerdofModels.2024.
arXiv:2407.21783[cs.AI].URL:https://arxiv.
org/abs/2407.21783.
[23] BinyuanHuietal.“Qwen2.5-CoderTechnicalReport”.In:
arXiv preprint arXiv:2409.12186 (2024).
[24] AnnaScius-Bertrandetal.“Zero-ShotPromptingandFew-
Shot Fine-Tuning: Revisiting Document Image Classifica-
tion Using Large Language Models”. In: Pattern Recogni-
tion.SpringerNatureSwitzerland,Dec.2024,pp.152–166.
ISBN: 9783031784958. DOI: 10.1007/978-3-031-
78495-8_10.
[25] ZhuoshengZhangetal.MultimodalChain-of-ThoughtRea-
soning in Language Models. 2024. arXiv: 2302.00923
[cs.CL].
[26] Aobo Kong et al. Better Zero-Shot Reasoning with Role-
Play Prompting. 2024. arXiv: 2308.07702 [cs.CL].
URL: https://arxiv.org/abs/2308.07702.
[27] Merlijn Sevenhuijsen et al. VeCoGen: Automating Genera-
tionofFormallyVerifiedCCodewithLargeLanguageMod-
els. 2025. arXiv: 2411.19275 [cs.SE]. URL: https:
//arxiv.org/abs/2411.19275.
[28] Malin Eriksson and Victor Hallberg. “Comparison between
JSONandYAMLforDataSerialization.”PhDthesis.2011.
URL: https://urn.kb.se/resolve?urn=urn:
nbn:se:kth:diva-130815.
[29] Linzheng Chai et al. McEval: Massively Multilingual Code
Evaluation. 2024. arXiv: 2406.07436 [cs.PL].
[30] Aider-AI. Aider Code Editing Benchmark. https://
github.com/Aider-AI/aider/blob/main/
benchmark/README.md. Accessed: 2025-01-22. 2024.
[31] Mark Chen et al. Evaluating Large Language Models
Trained on Code. 2021. arXiv: 2107.03374 [cs.LG].
[32] DeepSeek-AI etal. DeepSeek-Coder-V2: Breakingthe Bar-
rier of Closed-Source Models in Code Intelligence. 2024.
arXiv: 2406.11931 [cs.SE].
[33] DayaGuoetal.DeepSeek-Coder:WhentheLargeLanguage
ModelMeetsProgramming–TheRiseofCodeIntelligence.
2024. arXiv: 2401.14196 [cs.SE].
[34] MistralAI.Codestral:Hello,World!Accessed:January27,
2025. 2024. URL: https://mistral.ai/news/
codestral/.
[35] DongWuetal.“YOLOP:YouOnlyLookOnceforPanoptic
DrivingPerception”.In:MachineIntelligenceResearch19.6
(Nov. 2022), pp. 550–562. ISSN: 2731-5398. DOI: 10.
1007/s11633-022-1339-y. URL: http://dx.
doi.org/10.1007/s11633-022-1339-y.
[36] International Organization for Standardization. Intelligent
transport systems — Adaptive Cruise Control systems —
Performance requirements and test procedures. 2018. URL:
https://www.iso.org/standard/71515.html.

Paper:LADFA - A Framework of Using Large Language Models and Retrieval-Augmented Generation.pdf
=== Page 1 ===
LADFA: A Framework of Using
Retrieval-Augmented Generati
Analysis in Privacy Policies
HAIYUEYUAN∗,
InstituteofCyberSecurityforSoc
UnitedKingdom
NIKOLAYMATYUNINandALIRAZA,
Honda
SHUJUNLI∗,
InstituteofCyberSecurityforSociet
UnitedKingdom
Privacypolicieshelpinformpeopleaboutorganisations
aspectssuchasdatacollection,datastorage,andsharin
areoftendifficultforpeopletofullycomprehenddue
inconsistentpracticesacrossdifferentsectorsandorga
analysesofprivacypolicies,manyresearchershaves
languageprocessingtechniques,includinglargelangu
studiesutilisedLLMsforextractingpersonaldataflows
ofworkbycombiningLLMswithretrieval-augmented
derivedfromexistingstudies.Thispaperpresentsthe
framework,whichcanprocessunstructuredtextina
constructapersonaldataflowgraph,andconductanaly
Theframeworkconsistsofapre-processor,anLLM-
demonstratedandvalidatedtheeffectivenessandaccu
studythatinvolvedexaminingtenselectedprivacypolic
notingthatLADFAisdesignedtobeflexibleandcust
analysistasksbeyondprivacypolicyanalysis.
CCSConcepts:•Securityandprivacy→Humanan
networksecurityandprivacy;•Informationsyst
AdditionalKeyWordsandPhrases:LargeLanguageM
Privacy,Security,Retrieval-AugmentedGeneration,RAG
ACMReferenceFormat:
Haiyue Yuan, Nikolay Matyunin, Ali Raza, and Shu
LanguageModelsandRetrieval-AugmentedGeneratio
1,1(January2025),43pages.https://doi.org/XXXXXX
∗Correspondingco-authors.
Authors’ContactInformation:HaiyueYuan,h.yuan-221@ken
ofComputing,UniversityofKent,Canterbury,UnitedKingd
Raza,ali.raza@honda-ri.de,HondaResearchInstituteEurop
CyberSecurityforSociety(iCSS)&SchoolofComputing,Un
Permissiontomakedigitalorhardcopiesofallorpartofthi
providedthatcopiesarenotmadeordistributedforprofitorc
fullcitationonthefirstpage.Copyrightsforcomponentsofth
Abstractingwithcreditispermitted.Tocopyotherwise,orre
priorspecificpermissionand/orafee.Requestpermissionsfr
©2025Copyrightheldbytheowner/author(s).Publicationri
ACMXXXX-XXXX/2025/1-ART
https://doi.org/XXXXXXX.XXXXXXX
6202
naJ
51
]IA.sc[
1v31401.1062:viXra

g Large Language Models and
ion for Personal Data Flow
ciety(iCSS)&SchoolofComputing,UniversityofKent,
aResearchInstituteEuropeGmbH,Germany
ty(iCSS)&SchoolofComputing,UniversityofKent,
s’personaldataprocessingpractices,coveringdifferent
ngofpersonaldatawiththirdparties.Privacypolicies
etothelengthyandcomplexlegallanguageusedand
anisations.Tohelpconductautomatedandlarge-scale
studiedapplicationsofmachinelearningandnatural
uagemodels(LLMs).Whilealimitednumberofprior
sfromprivacypolicies,ourapproachbuildsonthisline
dgeneration(RAG)andacustomisedknowledgebase
developmentofLADFA,anend-to-endcomputational
givenprivacypolicy,extractpersonaldataflowsand
ysisofthedataflowgraphtofacilitateinsightdiscovery.
-basedprocessor,andadataflowpost-processor.We
uracyoftheproposedapproachbyconductingacase
ciesfromtheautomotiveindustry.Moreover,itisworth
tomisable,makingitsuitableforarangeoftext-based
ndsocietalaspectsofsecurityandprivacy;Social
tems→WorldWideWeb.
Model,LLM,PrivacyPolicy,TextAnalysis,DataFlows,
G,Framework,AutomotiveIndustry,ConnectedVehicle
ujun Li. 2025. LADFA: A Framework of Using Large
onforPersonalDataFlowAnalysisinPrivacyPolicies.
XX.XXXXXXX
nt.ac.uk,InstituteofCyberSecurityforSociety(iCSS)&School
dom;NikolayMatyunin,nikolay.matyunin@honda-ri.de;Ali
peGmbH,Germany;ShujunLi,s.j.li@kent.ac.uk,Instituteof
niversityofKent,Canterbury,UnitedKingdom.
isworkforpersonalorclassroomuseisgrantedwithoutfee
commercialadvantageandthatcopiesbearthisnoticeandthe
hisworkownedbyothersthantheauthor(s)mustbehonored.
epublish,topostonserversortoredistributetolists,requires
rompermissions@acm.org.
ightslicensedtoACM.
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 2 ===
2
1 Introduction
Privacypoliciesarewidelyusedasameansofin
practicesoforganisations.Theyareconsiderede
howorganisationscollect,share,andmanagepe
terms).Privacypoliciesareoftensubjecttolegalr
Regulation(GDPR)intheEU[55]andtheUK[5
(e.g., the California Consumer Privacy Act (CC
(CPRA)[51]).Whiletheseregulationsmandateor
implementationoftenlacksconsistencyandtran
andsophisticatedlegallanguageusedinprivacy
understandthescaleandscopeofdatacollection
thematall[11,35,54].
Toaddressthesechallenges,someresearchersh
andtransparencytobetterinformandpresentme
learning(ML)andnaturallanguageprocessing(N
facilitatesuchanalyses[1,16,23,41].Morerecent
oflargelanguagemodels(LLMs),severalstudiesh
toautomatetheprivacypolicyanalysisprocessin
36,46,53].
Among all information described in a privac
importanceastheycantelldatasubjectswhatper
andwithwhatthirdpartiesthecollectedperson
andforwhatpurposes.Suchpersonaldataflows
contextualintegrity(CI)theory,proposedbyNi
modelledaspersonaldataflows,whicharegover
suchnormsareactors(includingthesubjectofinf
ofinformation),attributes(i.e.,typesofinforma
referstotheconditionorconstraintsthatgovern
circumstances(e.g.,abusinessshouldonlygivec
warrantorcourtorder)[33].
Theseparametersareessentialtoinformdata
whomitisshared,andforwhatpurposes.Alth
originalCItheory,Nissenbaum[40]laterexplain
contextbuthelpconstituteit.Inthissense,weco
Forthereadabilityandconsistency,werefertop
paperandrefertodataflowsthatincludetheseat
fewstudieshaveexploredmanual[19,65]anda
flowsfromprivacypoliciesandconstructdataflo
tothebestofourknowledge,noexistingstudy
knowledge base to automatically extract compr
theory.
To address the above-mentioned research ga
contributions:
• Novelframework:weproposeanend-to
(shortfor“AFrameworkusingLLMsandR
Policies”),focusingonextractingdataflows
consistsofapre-processor,anLLM-basedp
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
nformingpeopleaboutpersonalprocessingdata
essentialdocumentsthatdetailinformationabout
ersonaldataofpeople(i.e.,datasubjectsinlegal
requirements,suchastheGeneralDataProtection
57]andvariousstate-levelregulationsintheUS
CPA) [52] and the California Privacy Rights Act
rganisationstodisclosespecificinformation,their
nsparency[48,58].Moreover,duetothelengthy
ypolicies,humanreadersoftenstruggletofully
andsharingpracticesoroftenchoosenottoread
haveexaminedprivacypolicyconsistency,clarity,
eaningfulinformationtohumanreaders.Machine
NLP)techniqueshavebeenfrequentlyexploredto
tly,withtheincreasingcapabilitiesandpopularity
haveshownpromisingresultsofleveragingLLMs
nzero-and/orfew-shottrainingcontexts[13,20,
cy policy, personal data flows are of particular
rsonaldataaboutthemwillbecollectedbywhom
naldatawillbeshared,underwhichconditions
scanbeunderstoodasinformationflowsinthe
issenbaum[38].IntheCItheory,privacycanbe
rnedbycontextualnorms.Thekeyparametersof
formation,thesender ofinformation,andrecipient
ation),andtransmissionprinciple[38,39],which
nthepersonaldataflow,restrictingittospecific
customerrecordstothegovernmentifthereisa
asubjectsaboutthepersonaldatacollected,with
hough‘purposes’isnotexplicitlydefinedinthe
nedthatfactorssuchaspurposedonotexistina
onsiderpurposeaspartoftransmissionprinciples.
personaldataflowasdataflowfortherestofthis
ttributesascomprehensivedataflows.Althougha
automaticapproaches[15,63,64]toextractdata
owgraphsforvisualisationandinsightsdiscovery,
yhasutilisedLLMswithRAGandacustomised
rehensive data flows from the perspective of CI
ap, we conducted a study with following main
o-endprivacypolicyanalysisframeworkLADFA
RAGforPersonalDataFlowAnalysisinPrivacy
s,constructingandanalysingdataflowgraphs.It
processor,andadataflowpost-processor.

=== Page 3 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
• Customisedknowledgebase:beyondutil
base for providing useful contextual info
retrieval-augmentedgeneration(RAG)tof
processor.
• Casestudywithevaluation:weconduc
appsfromdifferentoriginalequipmentma
Unlike prior work that evaluated only se
collectiveevaluationofcomprehensivedat
validationwasperformedbythreedomain
Theevaluationresultsshowedstrongagreem
7-Likertscoresbetween6and7formostta
identifyingdatatypesanddataflowsreach
indicatinghighinter-raterreliability.These
understandingunstructuredtexts,andextr
• Insightsdiscovery:thecomparisonofdata
stratedLADFA’scapabilityinanalysingand
that are often difficult to comprehend or
policies.
Therestofthispaperisorganisedasfollows.
provides detailed descriptions of each compone
automatedprivacypolicyanalysis.Section4pres
followedbyadiscussionofsomeidentifiedlimitati
thepaper.
2 RelatedWork
2.1 PrivacyPolicyAnalysisinGeneral
Previousresearchhasindicatedthatasignifican
adequately inform users about data-handling p
analysisconductedin2017highlightedthatappr
theGooglePlayappstoreweremissingaprivac
them(70%)arecapableofprocessingpersonally
study[43]foundthatmostsmartphoneappsdono
thatwereincluded,only18%oftheiOSappscou
fortheAndroidapps(approximately4%).Apartf
relatedtothereadability,presentation,transpar
preventmoreeffectiveandinformativecommun
consumersrarelyreadprivacypoliciesandperceiv
comprehend,resultinginuninformedconsenttod
notonlyundermineusertrustbutalsocomplica
More recently, Ghahremani and Nguyen [19] p
transparencyandcomprehensivenessofprivacy
contextualgapsandambiguitiesbasedontheCIfr
canbeconsideredanalternativetosubjectiveev
a pressing need to automate the process using
large-scalestudiesandfordevelopinganautoma

DataFlowAnalysisinPrivacyPolicies 3
lisingLLMs,wedesignandconstructaknowledge
ormation that allow the framework to leverage
facilitatetheLLM-basedprocessorandthepost-
ctacasestudyontenconnected-vehiclemobile
anufacturers(OEMs)intheautomotiveindustry.
egments of data flows separately, we provide a
taflows.Duetothelackofgroundtruth,manual
nexperts(thefirstthreeco-authorsofthepaper).
mentwiththeLADFA’soutputs,withtheaverage
asks.Gwet’sAC1andpercentageagreementfor
hed0.94and0.82,and0.96and0.86,respectively,
eresultsaffirmLADFA’scapabilityinprocessing,
ractingdataflowsfromprivacypolicies.
aflowgraphsandgraphnetworkanalysisdemon-
discoveringprivacy-andsecurity-relatedinsights
easily overlooked by human readers of privacy
RelatedworkisdiscussedinSection2.Section3
ent of the proposed end-to-end framework for
sentsthedetailsofthecasestudyandtheresults,
ionsinSection5.Finally,thelastsectionconcludes
ntproportionoforganisationsorservicesdonot
practices through privacy policies. A large-scale
roximately50%ofpopularfreeappsavailableon
cypolicy,despitethefactthatalargeportionof
identifiableinformation[27].Similarly,another
otincludeprivacypolicies:fortheprivacypolicies
uldbeaccessed,andaccessibilitywasevenlower
fromsuchaccessibilitychallenges,knownissues
rency,andconsistencyofprivacypoliciesoften
nicationtoconsumers[12,14,43].Consequently,
vethemasoverlycomplex,lengthy,anddifficultto
datapractices[31,41,58,60,65].Suchchallenges
ateregulatorycompliancefororganisations[16].
presented a study to systematically evaluate the
policiesbymanuallyannotatingandidentifying
ramework.Theyarguedthatsuchmanualanalysis
valuationsbyprivacyexperts;however,thereis
g ML and NLP-based approaches, especially for
atedtooltoassisthumanusers.
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 4 ===
4
2.2 AutomatedPrivacyPolicyAnalysis
2.2.1 ML and NLP-based Approaches. In additio
to analyse privacy policy content to evaluate it
frameworksandimproveitsreadability,presentati
andvolumeoftextinprivacypolicies,researche
thatutiliseMLandNLPtechniquesforsuchanal
Severalstudieshaveinvestigatedandconfirme
differentdomains.Fabianetal.[16]developedan
forinformationextractionandreadabilityanaly
popularEnglish-speakingwebsitesandadopted
well-knownmetricforevaluatingreadability.Th
average,thesedocumentsremaindifficultforhu
Srinathetal.[50]presentedthePrivaSeercorpus
995,475webdomains.Thereadabilityanalysiso
suggestinganeedforroughlytwoyearsofUSc
policy.Inanotherstudyontheprivacypoliciesof
averagescoresfromthreeestablishedreadability
SimpleMeasureofGobbledygook(SMOG).There
readinglevelequivalenttothatofacollegestude
comprehendfully.
Suchreadabilityissuesareoftencausedbyco
the content is presented. Numerous studies ha
approaches,includinginnovativevisualrepresen
systems, and summarisation tools, to facilitate
withconsumers.Forinstance,Oltramarietal.[41
combines crowdsourcing, ML and NLP that can
ontology,allowingthedevelopmentofSPARQLq
knowledgebasetoaddressuserprivacy-related
inlarge-scaleprivacypolicyanalysis.Zaeemet
PrivacyCheck,whichutilisestraineddatamining
allowssummarisinganHTML-basedprivacypolic
shortdescriptionsandrisk-levelindications.Simi
framework,Polisis,whichleveragesaprivacy-c
policiesandaneuralnetworkclassifiertoanalyse
practices.Polisiscanautomaticallyassignprivacy
tolearnmoreprivacyinsightsformakingmorein
introducedPriBotbasedonPolisis.Itisthefirstin
policies,offeringconsumersamoredynamicand
Furthermore,BannihattiKumaretal.[3]conduc
cleantextsspecificallyrelatedtoopt-outoptions.T
browserextensiondesignedtohelppeoplebetter
Buietal.[8]presentedanautomatedsystem,PI
extractprivacypractices.Inthesamepaper,afol
datapracticeannotationstohighlighttheextracte
tohelphumanreadersbettercomprehendprivac
Inadditiontotheresearchdirectionsmentioned
ysis,variousstudieshavefocusedonexploringth
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
on to the challenges listed above, it is essential
ts completeness and alignment with regulatory
ion,consistency,andclarity.Giventhecomplexity
ershaveexploredvariousautomatedapproaches
lyses.
edthereadabilityissuesofprivacypoliciesfrom
nautomatedtoolsetthatutilisedNLPtechniques
ysis.Theyexamined50,000privacypoliciesfrom
dtheFlesh-KincaidGradeLevel(FKG)metric,a
hemeanFKGscorewas13.6,indicatingthat,on
umanreaderstocomprehend.Inadifferentstudy,
s,whichcontains1,005,380privacypoliciesfrom
ofthisdatasetyieldedameanFKGscoreof14.87,
collegeeducationtofullygraspatypicalprivacy
mentalhealthapps,Robillardetal.[43]calculated
ymetrics,includingGunningFog,FKG,andthe
esultsrevealthattheselegaldocumentsrequirea
ent,makingthemdifficultfortheaverageuserto
omplexlegallanguageandthemannerinwhich
ave focused on bridging this gap using various
ntations,nudgingtechniques,question-answering
more effective and informative communication
1]proposedPrivOnto,asemanticframeworkthat
n represent annotated privacy policies using an
queriestoextractinformationfromthePrivOnto
questionsandassistresearchersandregulators
al.[67]developedaChromebrowserextension,
classificationmodelsusing400privacypolicies.It
cyandpresentstheresultsasgraphicaliconswith
ilarly,Harkousetal.[23]developedanautomated
centriclanguagemodeltrainedon130Kprivacy
bothhigh-levelandfine-graineddetailsofprivacy
iconstoprivacypolicies,allowinghumanreaders
nformeddecisions.Inaddition,Harkousetal.[23]
nteractivequestion-answeringsystemforprivacy
dengagingwaytounderstandthesedocuments.
ctedastudyleveragingMLalgorithmstoextract
Thisworkfurtherfacilitatesthedevelopmentofa
runderstandtheiropt-outchoices.Morerecently,
I-Extract,whichusesaneuralnetworkmodelto
llow-upuserstudyoninvestigatingtheeffectsof
edprivacypracticesusingPI-Extractwasreported
cypolicies.
daboveonautomatedprivacypolicycontentanal-
heinconsistency,lackofclarity,andmisalignment

=== Page 5 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
ofprivacypolicycontentwiththeregulatoryfram
anautomatedtoolforanalysingprivacypolicies
tionpracticesusingadvancedNLPandontology
largedatasetofprivacypoliciesfromGooglePla
contradictionsandnarrowingdefinitions,highli
etal.[56]usedNLPtechniquesandsupervisedML
andcheckthecompletenessofprivacypolicies.
policiesdiscovered45outof47incompleteissu
proposedacomprehensiveGDPRtaxonomyand
withhierarchicalinformation.Theirextensiveeffo
toenhancetheaccuracyandreliabilityofautoma
2.2.2 LLM-basedApproaches. Incontrasttotrad
oftenrequireextensiveeffortstolabeldataorre
learning, emerging LLMs have proven to be po
particularlyinclassifyingdatapracticesandextrac
manualannotationsortraining.Variousprompt-b
readers navigate complex legal texts in privacy
whichleveragedLLMsusinga“prefixprompt”to
tasks,achievingaverageMacroF1scoresof97%
twoprivacypolicydatasets,respectively.Itsignifi
Salvietal.[46]introducedPrivacyChat,apromp
3.5)toimproveconsumers’comprehensionofp
proposedPAPEL,aframeworkthatleveragesthe
toanalyseandconvertthecriticalaspectsofpriv
findingsdemonstratedthatvariousLLMs,includin
performanceinprivacypolicyanalysistasks.Sligh
the effectiveness and accuracy of LLM-based so
Theyfurtherproposedasetofspecificconfigurati
shouldbeconsideredareplacementfortradition
processing.Morerecently,Chenetal.[13]develo
usingbothpromptengineeringandLoRA(low-r
resultsshowthatsuchclassifierscanoutperform
LLMs(includingGPT-3.5,Llama38B,Qwen1.5
completeness,logicality,andcomprehensibility,t
explanationsfortheclassificationresults.Evalu
LLMscanprovideclearandunderstandablejust
studytoevaluateLLMs’capabilitiestounderstand
TheresultsrevealedthatLLMscouldachieveana
thecorrectanswerrateofhumanuserswasonly
toreplaceuserstudiesfortheevaluationofpriva
LLMshavealsobeenappliedtodiscoverlegaland
within enterprises’ regulatory and operational
training-freemethodthatconsiderpolicyviolati
problemandadoptswhiteningtechniques.Their
ofexamples,yetachievesstate-of-the-artperform
fine-tuningapproaches.

DataFlowAnalysisinPrivacyPolicies 5
meworks.Andowetal.[1]introducedPolicyLint,
sbyidentifyingcontradictorysharingandcollec-
generationtechniques.ApplyingPolicyLinttoa
ay,theyfoundasignificantoccurrenceoflogical
ightingtheissueofmisleadingstatements.Torre
LapproachestodevelopanAIassistanttoclassify
Acasestudyofapplyingthistoolto24privacy
uesagainsttheGDPR.Recently,Tangetal.[54]
ddevelopedacorpusoflabelledprivacypolicies
ortsinevaluatingGDPRconceptclassifiersaimed
atedGDPRcomplianceanalysis.
ditionalMLandNLP-basedmethodologies,which
elyonexistingannotateddatasetsforsupervised
owerful and efficient for privacy policy analysis,
ctingvaluableinsightswithoutrequiringextensive
basedmethodshavebeenexploredtohelphuman
y policies. Tang et al. [53] developed PolicyGPT,
operformcategoricalclassificationanddefinition
%and87%forclassificationtasksusingGPT4on
ficantlyoutperformedpastMLmodels.Similarly,
pt-engineering-basedsystemusinganLLM(GPT-
privacypolicies.Morerecently,Gokniletal.[20]
capabilitiesofLLMsthroughpromptengineering
vacypoliciesintouser-friendlysummaries.Their
ngLLaMAandGPT-3.5/GPT-4,canachieverobust
htlydifferently,Rodriguezetal.[44]demonstrated
olutions for automating privacy policy analysis.
ionsforChatGPTandarguedthatsuchasolution
nalNLPtechniquesforautomatedprivacypolicy
opedLLM-basedprivacypolicyconceptclassifiers
rankadaptation)fine-tuningtechniques,andthe
motherstate-of-the-artclassifiersusingdifferent
57B).ToexploreLLMexplainabilityintermsof
theyalsoappliedpromptengineeringtogenerate
uationbythreehumanannotatorsindicatedthat
tifications.Similarly,Morietal.[36]conducteda
dprivacypoliciescomparedwithrealhumanusers.
accuracyof85.2%ofcomprehensionlevels,while
y63%,demonstratingthepotentialofusingLLMs
acypolicies.Apartfrombenefitingordinaryusers,
dreputationalrisksbydetectingpolicyviolations
frameworks. A recent work by [42] proposes a
iondetectionasanout-of-distributiondetection
rmethodrequirespolicytextandasmallnumber
mancecomparedwithotherLLM-as-a-judgeand
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 6 ===
6
Similar to our work, Xie et al. [63] conducte
to support automated analysis of privacy polic
assessmenttowhatextentagivenprivacypolicy
clause.Anotheroneistoassesspersonalinform
focusingoncategoriesofpersonalinformationco
andsharing,andthethird-partyrecipients.More
etal.[64]developedaframeworkthatperforms
textsegmentation,paragraph-levelclassification
mapping,relationshipextraction,andgraphgener
theirframeworkforreconstructingattributesand
astrainingandtestingdata,applyingknowledge
BERT.Theirgraphgenerationisimplementedus
interactivequeryfeatures.However,thereliance
modernprivacypolicies.Differentfrompaststud
frommultipleexistingstudiestobuildaknowled
policyanalysisfromtheperspectiveofdataflows,
whomitisshared,andforwhatpurposes.
2.2.3 Data Flow Analysis. Although LLMs hav
analyseshasgainedsignificantattentionbecause
complexconceptsinamoreaccessibleandengag
wasPoliCheck,proposedbyAndowetal.[2],w
consistencymodeltoidentifycontradictionsbetwe
policiesandtheactualdatahandlingpracticeso
PoliGraph,aknowledgegraphdesignedtorepr
PoliGraph-ER,fortheautomatedextractionofdata
demonstratedthatPoliGraph-ERoutperformedP
statedandactualdataflows.
Yuanetal.[65]alsoconductedacasestudyo
ofBooking.com,showingsignificantchallenges
capturethedata-sharinglandscape.Thisemphas
approachestoextractingandanalysingdataflow
employedGPT-4asanexampleLLMtoanalyseth
toproducedataentityrelationshipsthatcapturet
datasharing,andtherecipientsoftheshareddata
avehicle-centricdataecosystem.Whiletheprim
LLMsinprivacypolicyanalysis,itneverthelessoff
motivatedthefollow-upworkpresentedinthisp
2.3 IdentifiedResearchGaps
Although LLMs have been used for privacy pol
have not yet been specifically applied to facilita
andconstructionofdataflowgraphs.Onepossi
hallucination[24]thatcancompromiseaccuracy
particularlythoseoriginatingfrompre-training
knowledgegaps[24],makingitchallengingtoe
privacy policy texts. Additionally, privacy polic
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
ed a study of using the Llama-3.1-70B-Instruct
cies, which involves two main tasks. One is the
segmentcoverstherequiredcontentofaspecific
mationpracticesinprivacypolicies,specifically,
ollectsandshares,thepurposesofdatacollection
erecently,andincloserelationtoourwork,Yang
saseriesofoperations,includingprivacypolicy
n,sentence-levelclassification,privacyattribute
ration.Unlikeourapproach,thekeycomponentof
relationshipgraphsreliesontheOPP-115dataset
distillationtechniquesinvolvingGPTmodelsand
singNeo4j,allowingdataflowsvisualisationand
solelyonOPP-115labelsmaynotbesuitablefor
dies,ourworkleveragestaxonomiesandfindings
dgebase,aimingtofacilitateLLM-drivenprivacy
,specifically,whatpersonaldataiscollected,with
ve not been utilised to analyse data flows, such
etheycangreatlyfacilitatethecommunicationof
gingmanner[58].Anearlyeffortinthisdomain
whodevelopedanentity-sensitiveflow-to-policy
eenthedataflowsdescribedinmobileappprivacy
oftheapps.Similarly,Cuietal.[15]introduced
resentdataflows,alongwithanNLP-basedtool,
aflowsfromprivacypolicytexts.Theirevaluation
PoliCheckinidentifyinginconsistenciesbetween
ofextractingdataflowsfromtheprivacypolicy
sinmanuallyreconstructingdataflowstofully
sisestheneedformoreadvancedandautomated
wsinprivacypolicies.Inourpriorwork[66],we
heprivacypoliciesofselectedcarbrands,aiming
thetypesofdatashared,theintendedpurposesof
a.Thiswaspartofabroaderefforttoreconstruct
maryfocusofthatstudywasnottheutilisationof
fferedaglimpseintoLLMs’potentialanddirectly
paper.
licy analysis, as reviewed in Section 2.2.2, they
ate the extraction of comprehensive data flows
iblereasonisthewell-documentedissueofLLM
yandproduceunreliableresults.Hallucinations,
data,canintroducemisinformation,biases,and
extractreliableinformationaboutdataflowsin
cies show significant linguistic variability, with

=== Page 7 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
differentorganisationsusingdifferentterminolo
makingitmorecomplicatedtoconductcomparis
Apromisingapproachtomitigatethesechallen
whichcaneffectivelyminimisehallucinationsc
generative capabilities of LLMs. The RAG appr
sourcesbyconvertingbothknowledgebaseelem
tationscalledembeddings.Thisallowssemantic
informationfromtheknowledgebase,whichist
query.Asaresult,itenhancestheaccuracyandc
OnekeyadvantageofintroducingRAGisthatL
applications,makingthemmoreefficientandada
linguisticvariabilityshownindifferentprivacyp
andunifythegenerativeoutputsofLLMs,enabl
comparativeanalysisandvisualisation.
However,tothebestofourknowledge,nopast
privacypolicyanalysisforextractingstructuredd
whilepriorresearchhasexaminedprivacypolicies
asystematicframeworkforautomatedprocessin
flowsremainslargelyunexplored.
3 TheProposedFramework:LADFA
Pre-processor
Q1: Data Flow Q4: Processing Purpose LLM Screening Agent
Q2: Data Category Q5: Processing Method Personal data
collection/sharing
Desig
K
n
T
S
_
Q
t
d
e
3
a
p
:
t
D
a
A
a
:
t a
D
C
e
o
fi
n
n
s
i
u
ti
m
o
K
e
n
T
r
s
T
_
y
a
c
p
n
o
e
n
d
s
Q
um
ue
e
s
r
tions tnem
geS
tnem
geS
hcae
roF D
N
a
o
t
t
a
r e
flo
le
w
v a
1
n
:
t
Se
Data flow 2: Se
KT_purpose KT_method
Data flow 3: Se
Design Step B: Knowledge Base
Segment 1
Segment 2 LLM Data Consumer Type Agent
Privacy Policy Text
S
S
e
e
g
g
m
m
…e
e
n
n
t
t
3
n KT_consumer Con
P
te
ro
x
m
ts
pt
+ Q3
Module TS (Text Segmentation) Segment + Data flow + RA
Data Flow Post-processor
Data consumer type 1
Data consu…mer type 2
Data consumer type n
Data Parser Graph Generator Analyser
Fig.1. LADFA
Inthissection,weintroduceLADFAforextract
andanalysingdataflowgraphsusingLLMsandR
maincomponents:apre-processor,anLLM-based
pre-processorisresponsiblefor1)definingconcep
aknowledgebase;and3)convertingtheinputpri
LLM-basedprocessoremploysahybridapproach
1Thesourcecodecanbeaccessedfromhttps://github.com/hy

DataFlowAnalysisinPrivacyPolicies 7
ogiesandstructurestodescribesimilarconcepts,
sonanalysesacrossprivacypolicies.
ngesisretrieval-augmentedgeneration(RAG)[28],
causedbyknowledgegapswhilepreservingthe
roach augments LLMs with external knowledge
mentsandusers’queriesintonumericalrepresen-
similaritysearchestoretrievethemostrelevant
thenprovidedtotheLLMalongsidetheoriginal
credibilityofthegenerativeoutputsofLLMs.
LLMsdonotneedtoberetrainedfortask-specific
aptable[18].Inaddition,consideringthediverse
policies,adoptingRAGcanpotentiallyconstrain
lingconsistentformattingformoreeffectiveand
tstudieshaveutilisedLLMswithRAGtoconduct
dataflowsinacomprehensivemanner.Inaddition,
seithermanuallyorwithotherAI-basedmethods,
ngofprivacypoliciestoextractandvisualisedata
LLM-based Processor
LLM Data Flow Agent LLM Data Category Agent
Prompt KT_data Conte P x r t o s mpt +
Segment + Q1 Q2
Segment + Data flow + RAG
ender 1 Data type 1 Receiver 1
Data type 1 Data category 1
ender 2 Data type 2 Receiver 2 Data type 2
ender 3
…
Data type 3 Receiver 3
Data …type 3 D
D
a
a
t
t
a
a
c
c
a…
a
t
t
e
e
g
g
o
o
r
r
y
y
2
n
Data type n
LLM Data Processing Purpose Agent LLM Data Processing Method Agent
Prompt Prompt
AG KT_pur S p e o g se ment + D C a o t n a t e flo xt w s + + Q4 RAG KT_met S ho e d gments + C D o a n ta te f x lo ts w + + Q5 RAG
Processing purpose1 Processing method 1
Processin…g purpose 2 Processin…g method 2
Processing purpose n Processing method n
Aarchitecture
tingdataflowsfromprivacypolicies,constructing
RAG.AsillustratedinFigure1,itconsistsofthree
dprocessor,andadataflowpost-processor.1.The
ptstofacilitatedataflowextraction;2)constructing
ivacypolicyintomachine-readablesegments.The
thatcombinespromptchainingwithLLMagents.
yyuan/LADFA
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 8 ===
8
AsshowninFigure1,eachtextsegmentisproces
witheachsub-componentfocusingonaddressing
theflowofthepromptchain,whilethehighlight
agentneedsdynamicallyaccesstheknowledgeb
thegenerativeoutput.Thedataflowpost-proce
andananalyser,tocollectivelytransform,struc
flowsfromtheLLM-basedprocessor.Notethat
post-processorsaswell,butthispaperfocuseson
mostcomplicatedpartofthewholepipelinesoc
3.1 Pre-processor
Thepre-processorconsistsofthreesub-componen
andBforconstructingrelevantdomainknowledge
Design steps A and B can be processed once a
dynamically.
3.1.1 DesignStepA:PreparingKeyDefinitionsan
keyparametersintheCItheorythatcanaffectu
privacycomprehensions[34].Inthiswork,weaim
hensivedataflowsthroughthelensofCItheory,
tobetteralignwithterminologiesthathavebeenu
protectionregulationssuchastheEU/UKGDPR
throughoutthepaper.
OnekeyparameterintheCItheoryis‘actors’
senderofinformation’,and‘recipientofinformat
anddatareceiver,respectively.The‘subjectofinfo
intheGDPR,whoareusuallytheconsumer/reade
readeristakingactionsonbehalfofotherdatas
data).Notethatthedatasubjectisnotalwaysthe
user’sdatawithathird-party,thedatasenderist
Asmentionedearlier,anotherkeyparameterof
Inthecontextofthiswork,attributesarethetype
to datareceiver. Asreported in[5], personalinf
instance,‘personalidentificationinformation’isth
isasubcategoryof‘personalidentificationinform
aresubcategoriesof‘contactinformation’.Forc
denotethetypeofpersonalinformationdescribed
datatypemayappearasaleafnode(e.g.,nameo
oramid-levelnode(e.g.,demographicdataorlo
privacypolicy.Insummary,theseformsthedata
datasender→datatype→datareceiver indicates
partytoanotherparty.
Furthermore,toalignvariationsofdatatypes
stylesandtosupportconsistentcomparativeana
aimingtofurtherprocessandclassifydatatypes
Existing studies such as [5, 59] and regulations
information,oftenthroughcomplex,multi-layered
asimplifiedthree-leveltypology,intendedsolelyt
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
ssedthroughmultiplesequentialsub-components,
aspecifictask.Dashedlinesinthefigureindicate
ted‘RAG’textsdenoteinstanceswheretheLLM
base,retrieverelevantinformation,andaugment
essorconsistsofadataparser,agraphgenerator,
cture,visualise,andinterprettheextracteddata
itispossibletoleverageLLMsforthepre-and
napplyingLLMstotheanalyserbecauseitisthe
canbenefitthemostfromtheuseofLLMs.
nts:twodesignsteps(Aforpreparingkeyquestions
ebases)andonemodule(TSfortextsegmentation).
and reused thereafter, and Module TS operates
ndKeyQuestions. Asreportedinpreviousstudies,
users’privacyexpectationsandleadtodifferent
mtoanalyseprivacypoliciesandextractcompre-
adoptingitsparameterswithslightmodifications
usedinexistingstudies[5,6,9,59,65,66]anddata
R.Theserefineddefinitionsareusedconsistently
’,whichconsistsof‘subjectofinformation’,‘the
tion’.Here,wereferthelattertwosasdatasender
ormation’inthisstudyisthedatasubjectdefined
erofaprivacypolicy(butnotnecessarilysoifthe
subjects,e.g.,parentsmanagingtheirchildren’s
datasender,e.g.,whenanonlineservicesharesa
theonlineservice.
CItheoryis‘attributes’(i.e.,typesofinformation).
esofpersonalinformationpassedfromdatasender
formation can be categorisedhierarchically,for
hetoplevelcategory,where‘contactinformation’
mation’,and‘phonenumber’and‘emailaddress’
consistencyandreadability,weusedatatype to
dinprivacypolicies.Insuchahierarchystructure,
oremailaddress),arootnode(e.g.,personaldata),
ocationdata),dependingonthewritingstyleofa
flowconceptdiscussedinthispaper.Specifically
sthehowaspecifictypeofdataflowsfromone
appearedinprivacypolicieswrittenindifferent
alyses,weintroducetheconceptofdatacategory,
sbasedonacustomisedandsimplifiedtypology.
s such as the GDPR have categorised personal
dhierarchicalstructures.Inthisstudy,wepropose
tofacilitateanddemonstratetheeffectivenessand

=== Page 9 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
usefulnessoftheproposedframework.Theroot-
data’,thentodifferentiatenodesatremainingleve
andaleafnodeasa‘datatype’.Theterm‘datacateg
categoriesofpersonaldata’.Moredetailsofdevel
paragraph“KnowledgeTypologyforClassifying
weintroducedataconsumertype,dataprocessing
coverthebroadscopethe‘transmissionprinciple
Theconceptofdataconsumertypeisdefinedt
flow.InlinewiththeGDPR’sdefinition,adata
processor.Inthisstudy,ifthedataconsumerisaco
itstypeisconsideredasfirst-party.Ifthedataco
differentcontexts:1)ifitoperateswiththesameo
isanexternalentitysuchasthird-partyservice
third-party.Moredetaileddescriptioncanbefou
IdentifyingDataConsumerType”.
Theconceptofdataprocessingpurposeisintr
behindthedataprocessing.Whiletheconceptis
inGDPR,wedidnotrelyontheregulationtod
study.Instead,wereferredtoexistingstudies[6,9
weestablishedasetofpurposestailoredtothisst
“KnowledgeTypologyforIdentifyingDataProce
Thedataprocessingmethod referstothemeth
bypreviousstudies[59,65],twomaintypesof
study:1)amethodisactivewhenthedataisvol
interactingwiththeservicecoveredbythepriva
isautomaticallycollectedandsharedwithoutus
Moredetaileddiscussioncanbefoundinthepara
ProcessingMethod”.
Tothisend,dataconsumertype,dataprocessi
enhancethecontextofdataflow toformthecom
definitions,webreakdownthecomplextaskof
subtasks,eachofwhichanswersaspecificquestio
questions.
• Q1:Whataretheclaimeddataflowsdescr
receiver collectsadatatypefromadatasen
receiver?
• Q2:Foreachdatatypewithinadataflowi
classifiedasaspecificdatacategory?
• Q3:ForeachdataflowidentifiedinQ1,wh
• Q4:ForeachdataflowidentifiedinQ1,wh
• Q5:ForeachdataflowidentifiedinQ1,wh
ToallowLADFAtogeneratereliableanswers
scopeassociatedwiththesequestionssothatLL
process the input text. To this end, it is import
supportsansweringthesequestionsandfacilitate
3.1.2 DesignStepB:ConstructingTheDomainK
tion3.1.1,particularlyQ2–Q5,weestablishadom

DataFlowAnalysisinPrivacyPolicies 9
-levelnodeoftheproposedtypologyis‘personal
els,werefertoamid-levelnodeasa‘datacategory’
gory’isalignedwiththeGDPR’snotionof‘special
lopingtheproposedtypologyareprovidedinthe
gDataCategories”laterinthissection.Moreover,
gpurpose,anddataprocessingmethod,aimingto
es’oftheCItheory.
tocapturetheroleofdataconsumergivenadata
consumermaybea(data)controllerora(data)
ontroller,whichtypicallyownstheprivacypolicy,
onsumerisaprocessor,itstypewoulddependon
organisation,itisconsideredasfirst-party;2)ifit
provider,thedataconsumertypeisregardedas
undintheparagraph“KnowledgeTypologyfor
roducedtocapturetheintendeduseorobjective
srelatedtothelawfulbases(conditions)defined
derivethedataprocessingpurposeappliedinthis
9,59]thatexaminesprivacypolicies,fromwhich
tudy.Moredetailscanbefoundintheparagraph
essingPurpose”.
hodinwhichpersonaldataisprocessed.Inspired
dataprocessingmethodsareintroducedinthis
luntarilyenteredorgeneratedbytheuserwhile
acypolicy;2)amethodispassivewhenthedata
serinput,sopassivefromtheuser’sperspective.
agraph“KnowledgeTypologyforIdentifyingData
ingpurpose,anddataprocessingmethod further
mprehensivedataflow.Buildingupontheabove
extractingcomprehensivedataflowsintoseveral
on.Inthisdesignstep,weformulatedasetoffive
ribedintheprivacypolicytext,inwhichadata
nder ordatasender sharesadatatypewithadata
identifiedinQ1,canitbefurtherprocessedand
hatisthedataconsumertype?
hatisthedataprocessingpurpose?
hatisthedataprocessingmethod?
stothesequestions,itisimportanttodefinethe
LMscanhavebettercontextstounderstandand
tant to establish a domain knowledge base that
estheconstructionofcustomisedprompts.
KnowledgeBase. ToaddressquestionssetinSec-
mainknowledgebasecomposedoffourknowledge
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 10 ===
10
typologies,eachtailoredtoaspecificquestion.T
mentedandencodedintovectorrepresentationsu
databasetosupporttheretrievalphaseoftheR
behaviourstogenerateoutputsthataremorecon
Tothisend,weadopteddefinitionsandexamp
OPP-115dataset[59],thepersonalinformationt
case study [6], a study of data-usage purposes
previousstudies[65,66],tobuildthedomainknow
knowledgebaseisreferredtoasKB,whichconsi
Theyrepresentknowledgetypologiesfordatacate
anddataprocessingmethod,respectively.Table
derivedusingexistingstudies.Intheremainder
studiescontributetotheconstructionoftheknow
Table1. Summaryofhowmultiplesourceswere
Source
OPP-115[59]
Personalinformationtaxonomy[5]
dataprocessingpurposescasestudy[6]
Data-usagepurposesinmobileapps[9]
Dataflowreconstructionusingaprivacypolicy
Vehicle-centricdataecosystem[66]
KnowledgeTypologyforClassifyingDataCategor
𝐾𝑇 𝑑𝑎𝑡𝑎 for processing and classifying data categ
introducethree-leveltypology,withtheroot-lev
Ourfocusisondefiningtheremaininglevels.W
constructtheknowledgetypology,andthenfurt
taxonomies[5]andfindingsfromthework[66].
OPP-115datasetisacollectionof115websitep
fine-graineddatapractices[59].Itwasreleased
forprivacypolicyresearch.Thedatasetdefines
bydetaileddescriptionsandillustrativeexamples
maincategories,includingFinance,Health,Contac
OnlineActivities,UserProfile,IPAddressesandDev
Information,SurveyData,GenericPersonalInform
The work conducted by Belen Saglam et al. [
was perceived across different domains. They a
governmental legislation/regulations, privacy p
articles,andproducedaseriesofhierarchicalper
top-leveloverview).AsshowninTable2,somed
[5]areconsistentlyidentifiedfrommultiple(i.e.,a
PersonalIdentificationInformation,FinancialInform
Judgements,SexLife&SexualOrientation,andC
representcommondatacategoriesindependentof
inthepersonalinformationtaxonomies,thefirstf
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
Thedomainknowledgebaseissubsequentlyseg-
usinganembeddingmodel,thenstoredinavector
RAGapproach.ThiscanalsohelpgroundLLMs’
nsistentandlessvariable.
plesfrommultipleexistingstudies,includingthe
taxonomystudy[5],adataprocessingpurposes
in mobile apps [9], and findings from our own
wledgebase.Fortherestofthepaper,thedomain
istsofKT ,KT ,KT ,andKT .
data consumer purpose method
egory,dataconsumertype,dataprocessingpurpose,
1summariseshowknowledgetypologieswere
rofthissection,wedescribehoweachofthese
wledgetypologiesinmoredetails.
usedtoconstructthefourknowledgetypologies
KT KT KT KT
data consumer purpose method
✓ ✓ ✓ ✓
✓
✓
✓
y[65] ✓ ✓ ✓
✓ ✓
ries. Inthispart,weintroducehowweconstructed
gories to address Q2. As mentioned earlier, we
velrepresentedbyasinglenode,‘personaldata’.
WeusetheOPP-115dataset[59]asabaselineto
therrefineandexpanditusingthepersonaldata
privacypolicieswithmanualannotationsof23,000
in2016andhasbecomeawidelyusedresource
tendatapracticecategories,eachaccompanied
s.TheOPP-115datasetcoverpersonaldatain16
ct,Location,Demographic,PersonalIdentifier,User
viceIDs,CookiesandTrackingElements,Computer
mation,Other,andUnspecified.
[5] investigates how personal data evolved and
analysed data from multiple sources, including
policies of applications, and academic research
rsonalinformationtaxonomies(seeTable2fora
datacategoriesidentifiedfordifferentdomainsin
atleastthree)datasources,includingDemographic,
mation,HealthInformation,CriminalRecords/Court
CommunicationDatacategories,suggestingthese
fdomaincontext.Amongthesecategoriesdefined
fourcategoriesarepresentintheOPP-115dataset,

=== Page 11 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
butusingslightlydifferentterminologies.Forcons
IdentityIdentifier,Finance,andHealthareconside
Table2. Firstordersystemofcategorisationofpersonal
Categories Government App(H
Demographic ✓ ✓
PersonalIdentificationInformation ✓ ✓
FinancialInformation ✓ ✕
HealthInformation ✓ ✓
JudicialData ✓ ✕
CriminalRecords/CourtJudgements ✕ ✓
SexLife&SexualOrientation ✕ ✓
TechnicalDeviceInformation ✕ ✓
CommunicationData ✕ ✓
Property/AssetsInformation ✕ ✕
SecurityData ✕ ✕
✓:Thedatacategoryisidentifiedfromthecorrespondingdatasou
✕:Thedatacategoryisnotidentifiedfromthecorrespondingdata
H:Health,F:Finance
Inaddition,CommunicationData,asdefinedin[
includingUserOnlineActivities,UserProfile,IPAd
Elements.Toavoidredundancy,IPAddresses,De
mergedintoonesinglecategory,OnlineIdentifier.
replaceComputerInformation,aimingtocoverabr
tablets).Furthermore,becausetheSecurityDataca
areabsentintheOPP-115dataset,BiometricInfo
nodeofinKT .
data
Moreover,ourpreviousstudy[66]identifiedgo
centricdata-sharingecosystems,particularlyco
legalauthoritiessuchascourtsandlawenforceme
Records/Court Judgements category listed in Tab
mid-levelnodeofKT .
data
Following the same practice of refining and
66],KT includesthefollowingdatacategorie
data
Finance,Health,Location,PersonalIdentityIdentifi
Information,UserOnlineActivities,UserProfile,Cri
Information, Survey data, Other, and Unspecified
categoryisaccompaniedbyatextdescriptionand
illustrativeexamplesbelongingtothecorrespon
leafnodesaremainlyderivedfrom[5,59,65]and
isshownbelow:
Rootnode:Personaldata
Mid-levelnode:Location
Description:Geo-locationinformation(e.g
granularity,whichmayincludeexactlocat
Leafnodes:Locationdata,GlobalPosition
history, Global System for Mobile commu
MobileTelecommunicationsService(UMT

DataFlowAnalysisinPrivacyPolicies 11
sistencyandsimplification,Demographic,Personal
eredasmid-levelnodesofKT .
data
linformationtaxonomiesfromdifferentdatasources[5]
H) App(F) Academicpaper(H) Academicpaper(F)
✓ ✓ ✓
✓ ✓ ✓
✓ ✕ ✓
✕ ✓ ✕
✕ ✕ ✕
✓ ✓ ✓
✓ ✓ ✓
✕ ✓ ✕
✓ ✓ ✓
✓ ✕ ✓
✕ ✓ ✕
urce.
asource.
[5],overlapswithseveralOPP-115datacategories,
ddressesandDeviceIDs,andCookiesandTracking
eviceIDs,andCookiesandTrackingElementsare
.Additionally,DeviceInformationwasincludedto
roaderrangeofmoderndevices(e.g.,smartphones,
ategoryin[5]includesbiometricattributes,which
ormationwasincorporatedasanothermid-level
overnmentalbodiesasimportantpartsinvehicle-
oncerningdatacollectionandsharinginvolving
entagencies.ThiscloselyalignswiththeCriminal
ble 2, which is therefore considered as another
merging results using different sources [5, 59,
es(i.e.,mid-levelnodes:Demographics,Contact,
fier,OnlineIdentifier,DeviceInformation,Biometric
iminalRecords/CourtJudgements,GenericPersonal
d. Apart from Other and Unspecified, each data
dalistofdatatypes(i.e.,leafnodes)thatserveas
ndingdatacategory.Itisworthnotingthatthese
darenotexhaustive.AnexamplebranchofKT
data
g.,auser’scurrentlocation)regardlessof
tion,ZIPcode,orcity-leveldata.
ningSystem(GPS)locationdata,Location
unications (GSM) location data, Universal
TS)locationdata.
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 12 ===
12
It has been well documented that, LLMs can
promptingcomparedtozero-shotprompting,with
becomingcomparablewithfine-tuningapproach
anarrayofdatatypescanfurtherenhanceLLM
examplestosupportfew-shotprompting.Tosupp
typologyisencodedinJSONformat2.Thesame
typologiespresentedintherestofthesection.
KnowledgeTypologyforIdentifyingDataConsum
dataconsumertypeandaddressQ3,weappliedth
KT .Thefocusisondefiningmid-levelan
consumer
twomaindataconsumertypesarefirst-partyand
nodes.Todefinethem,weadoptedthefollowing
• First-partycollectionanduse:‘Privacypra
company/organisationowningthewebsiteor
• Third-partycollectionanduse:‘Privacypr
ordatacollectionbythirdparties.Athird-p
first-partycompanyororganisationthatow
Togeneralisethesedefinitionsbeyondwebsit
descriptionandintroducenon-exhaustivelistsof
ofKT .Theseleaf-nodesareinformedbypr
consumer
whichidentifiedvariousfrist-partyandthird-par
demonstratesthestructureofKT :
consumer
Rootnode:Dataconsumertype
Mid-levelnode:FirstParty
Description: A first party is the entity, su
collectsandusespersonaldatafromindivid
plication/service’sactualnamewouldbeo
firstparty.
Leafnodes:We,Us,Thiswebsite,Thiscom
company,Ourorganisation,Ourservice.
Knowledge Typology for Identifying Data Pro
KT )asatwo-leveltypology,withtheroot-l
purpose
the overarching objective of data processing. T
nodeswithcorrespondingdescriptionsthatspecif
Fewexistingstudieshavespecificallyfocusedon
policies.BhatiaandBreaux[6]recruitedhumanan
218datapurposeannotations.Theiranalysisiden
ServicePurpose,LegalPurpose,CommunicationP
VaguePurpose.Buietal.[9]developedahierarchi
neuraltextclusteringwithcontextualisedword
similarmeaningsinalargepolicycorpus.Theh
purposes and 16 low-level purposes (see Table
descriptionsof11purposes,includingBasicServic
Marketing,Analytics/Research,Personalisation/Cu
2KnowledgetypologiesencodedinJSONcanbeaccessedfrom
9899585ce868ace61b
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
perform better on various tasks with few-shot
hfew-shotprompting’sperformanceinsomecases
hes[7].Includingsuchdescriptivetextalongside
performancebyprovidingrelevantcontextand
portthisaswellastheimplementationofRAG,the
approachisappliedtotheremainingknowledge
merType. Fortheknowledgetypologytoidentify
hesamehierarchicalstructureasKT todevelop
data
ndleafnodes.AsintroducedinSection3.1.1,the
third-party,whichareconsideredasthemid-level
gdefinitionsfromtheOPP-115dataset:
acticedescribingdatacollectionordatausebythe
rmobileapp’,and
racticedescribingdatasharingwiththirdparties
partyisacompanyororganisationotherthanthe
wnsthewebsiteormobileapp.’
tesandmobileapps,weslightlychangethetext
ffirst-partyandthird-partyentitiesasleaf-nodes
riorstudiesonexaminingprivacypolicies[65,66],
rtyentities.Asanexample,thefollowingbranch
uch as a website or company, that directly
duals/customers.Thecompany/website/ap-
oftenusedasindicationofexistenceofthe
mpany,Thisorganisation,Ourwebsite,Our
ocessing Purpose. With respect to Q4, we define
levelnoderepresentedbyasinglenodecapturing
Then the focus is on developing an array of leaf
fydistinctpurposes,derivedfromexistingstudies.
nexaminingdataprocessingpurposesinprivacy
nnotatorstostudyfiveprivacypolicies,producing
ntifiessixcategoriesofdataprocessingpurposes:
Purpose,ProtectionPurpose,MergerPurpose,and
icaltaxonomyofdatausagepurposesbyapplying
embeddingstogrouppurposeclausesthathave
hierarchicaltaxonomyconsistsoffourhigh-level
3). The OPP-115 dataset [59] includes detailed
ce/Feature,AdditionalService/Feature,Advertising,
ustomisation,ServiceOperationandSecurity,Legal
mhttps://osf.io/ab23w/overview?view_only=23e83d260dcf41

=== Page 13 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
Requirement,Merger/Acquisition,Other,andUnspe
threerecruitedlawexpertsusingatop-downapp
Table3. Thehierarchicaltaxonom
High-level Low-l
Production Provid
Improv
Person
Develo
Manag
Manag
Proces
Securi
Marketing Custom
Marke
Promo
Provid
Person
Genera
Legality Genera
Other Other
Bycomparingalltheexistingsetsofpurposes
largelyreflectedintheOPP-115definitions.How
suchasMerger/AcquisitionandAnalytics/Researc
taxonomyproposedin[9].Moreover,thedefinition
briefandoverlapsubstantiallywiththoseinthe
orourpreviousstudies[65],variouspersonaldat
mediaintegrationwithwebsites/apps.Weobserve
in[6,8,59].
Consideringalltheobservationsandgiventhe
purposesinOPP-115,weadoptedthissetasthep
Integration explicitly added as an additional lea
nodesofdataprocessingpurposesincludingBasi
Advertising,Marketing,AnalyticsorResearch,Perso
and Security, Legal requirement, Merger/Acquisi
KT ispresentedbelow:
purpose
Rootnode:Dataprocessingpurpose
Leafnode:Advertising
Description:Toshowadvertisementsthata
targeted,orothergeneraladvertisingactiv
Itisworthnotingthatthedataprocessingpurp
lawfulbases(conditions)undertheGDPR,noris
thispurpose.Nevertheless,comparingexistingca
GDPRisaninterestingtopicforfutureresearch,

DataFlowAnalysisinPrivacyPolicies 13
ecified.Thesepurposesweremanuallycreatedby
proach.
myofdata-usagepurposesin[8]
level
deservice
veService
naliseService
opService
geService
geAccounts
ssPayments
ity
merCommunication
etingAnalytics
otion
deAd
naliseAd
alMarketing
allegality
purposes
s,wefoundthatthosedefinedin[6]and[9]are
wever,certainpurposesintheOPP-115dataset,
ch,arenotexplicitlycapturedinthehierarchical
nsprovidedbyBhatiaandBreaux[6]arerelatively
othertwosources.Additionally,asnotedinone
taareoftencollectedandsharedtoenablesocial
edthatthispurposeisabsentfromthecategories
ebroaderyetfine-grainedsetofdataprocessing
primaryleafnodesofKT withSocialMedia
purpose
af node in this study. In total, there are 10 leaf
icServiceorFeature,AdditionalServiceorFeature,
onalisationorCustomisation,OperationalIntegrity
ition, and Unspecified. An illustrative branch of
areeithertargetedtothespecificuserornot
vities.
posespresentedherearenotintendedtocoverall
stheaimtoproduceacomprehensivedatasetfor
ategorisations/taxonomieswithdefinitionsinthe
however,itisoutofthescopeofthiswork.
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 14 ===
14
KnowledgeTypologyforIdentifyingDataProces
findingsfrom[65]anddefinitionsintheOPP-115
typology.SimilartoKT ,KT isstruct
purpose method
nodeandasetofleafnodeswiththecorrespondin
reportedin[65]identifiedtwoprimarymethods
ThisfindingalignswiththedefinitionsintheO
andunspecifieddataprocessingmodes.Inthese
activelyprovidetheirdatawhileusingtheservic
andusethatoccurspassivelyandautomatically
‘explicit’isoftenassociatedwithconsentintheco
andavoidconfusion,wedecidedtousetheterms
nodesKT .Toillustrate,onebranchofKT
method me
Rootnode:Dataprocessingmethod
Leafnode:Active
Description:acompanyororganizationg
andintentionallyprovides.Thisinvolvesi
suchasfillingoutawebform,creatingana
toanewsletter.Explicitdatacollectiontypi
theinformationbeingprovidedandofteni
3.1.3 Module TS for Text Segmentation. Severa
html2textPythonpackage[47],supportautoma
ever,thesetoolsareeitherspecialisedforextracti
tablecontentsand(nested)bulletpoints.Wehave
use tables and nested bullet points for its conte
Existingsolutionsmaynoteffectivelyconvertsuc
forfurtheranalysis.Consideringthis,acustomi
package3 was developed for automatic text seg
followingmainsteps:I)removingelementsassoc
<head>,<footer>,<style>,<script>);II)proce
Algorithm1toproduceaninitiallistofsegments;
whereeachtableisonesegment;andIV)forseg
associatedheadingorparagraph,andmergingth
segment(SeeFigure5inSection6foranexampl
3.2 LLM-basedProcessor
TheLLM-basedprocessoradoptsamixedappro
Inthecontextofpromptingtechniquesforgener
promptengineeringtechniqueistodecomposeta
tosequentiallypromptinganLLMwithasubtask
prompt[61].Additionally,RAGplaysacrucialrole
relevantexternalknowledge.Accordingtothetax
in the context of GenAI can be classified as age
asanindependenttool.AsillustratedinFigure
segmentsequentiallythroughmultiplesub-comp
onespecificquestionoutlinedinSection3.1.1.T
3https://pypi.org/project/beautifulsoup4/
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
ssingMethod. TohelpaddressQ5,wemainlyuse
5datasetasreferencestocompletetheknowledge
turedasatwo-leveltypology,withasingleroot
ngdescriptions.Amanualprivacypolicyanalysis
ofdataprocessing:explicitandimplicitmethods.
OPP-115dataset,whichdefinesexplicit,implicit,
edefinitions,explicitreferstocaseswhereusers
ce/website,whileimplicitreferstodatacollection
withoutactiveuserinvolvement.Sincetheterm
ontextoftheGDPR,toensureclarity,consistency,
sActive,Passive,andUnspecified asthethreeleaf
isshownbelow:
ethod
gathersinformationthatauserknowingly
instanceswhereusersactivelyinputdata,
account,makingapurchase,orsubscribing
icallyrequirestheusertobefullyawareof
involvestheirdirectconsent.
al existing tools, such as ASDUS [37] and the
atictextsegmentationofHTMLdocuments.How-
ingtop-leveltitlesonlyorstrugglewithhandling
eobservedthatmanyprivacypoliciesfrequently
ent, e.g., for outlining data processing practices.
chHTMLcontentintomeaningfultextsegments
isedpipelineutilisedtheBeautifulsoup4Python
gmentation of an HTML page. It consists of the
ciatedwithheading,footer,style,andscripts(i.e.,
essingallnon-<table>HTMLelementsfollowing
;III)extractingtablecontentswiththeirheadings,
gmentsthatcontainbulletpoints,identifyingthe
hemwiththeassociatedbulletpointstoformone
le).
oachthatutilisespromptchainsandLLMagents.
rativeartificialintelligence(GenAI),aneffective
asksintoseveralsubtasks.Promptchainingrefers
kandthenusingitsresponseasinputforthenext
einimprovingthemodeloutputsbyincorporating
xonomiesreportedinasurvey[49],RAGsystems
ents when considering the retrieval component
1,theLLM-basedprocessorprocesseseachtext
ponents,witheachoneresponsibleforanswering
Thedashedlinesbetweenthesub-componentsin

=== Page 15 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
Algorithm1Thealgorithmforextractingandpr
1: segments←∅ ⊲(Initialiseanemptylist)
2: forallelement∈FindAllTags(html)do
3: ifelement∈{p,h1,h2,h3,h4,h5,li,ol,ul}then
4: ifFindParents(element,{ol,ul})=∅then
5: segments=Process(element,segments)
6: endif
7: endif
8: endfor
Figure1representtheuseofpromptchaintechniq
thatthecorrespondingsub-componentfunction
3.2.1 LLMScreeningAgent. Assumethatasingle
𝑇 ={𝑇 𝑖}𝑛
𝑖=1
.Notallsegmentsareaboutpersonal
mainobjectiveofthissub-componentistofilter
relevantonestothenextsub-component.
3.2.2 LLMDataFlowAgent. Ifatextsegment𝑇
sub-component (i.e., LLM data flow agent) to ex
formulated,asillustratedinEq.(1)basedonmul
definedinSection3.1.1,andasetofpredefinedan
LLMgenerateoutputsanddeterminetheirform
example.
𝑃flow =PromptGene
𝑖

DataFlowAnalysisinPrivacyPolicies 15
rocessingnon-<table>contentofanHTMLpage
1: functionProcess(element,segments)
2: ifFindParent(element)≠tablethen
3: ifelementispthen
4: text←ExtractTextWithout<a>(element)
5: iftext≠∅then
6: Appendtexttosegments
7: endif
8: elseifelementin{h1,h2,h3,h4,h5}then
9: text←ExtractText(element)
10: iftext≠∅then
11: Append“*”+text
12: endif
13: elseifelementisliandanotinelementthen
14: ifelementcontainsnoatagsthen
15: ifelementhasnestedliststhen
16: text←FlattenNestedLists(element)
17: else
18: text←ExtractText(element)
19: endif
20: iftext≠∅then
21: Append“−”+text
22: endif
23: endif
24: elseifelementin{ul,ol}then
25: forallchildinFindChildren(element)do
26: segments=Process(child,segments)
27: endfor
28: endif
29: endif
30: result←Join(segments,END_OF_LINE)
31: returnresult
32: endfunction
ques,whereasthehighlighted‘RAG’textsindicate
asLLMagents.
eprivacypolicy𝑇 consistsof𝑛textsegments,i.e.,
ldatacollectionanddatasharingpractices.The
routirrelevanttextsegmentsandpassonlythe
𝑇 𝑖 passesthescreeningphase,itisfedintothis
xtract data flows. A customised prompt𝑃flow is
𝑖
ltipleinputs,includingthegiven𝑇 𝑖,questionQ1
nsweringrules𝑅 .Here,𝑅 regulateshowan
flow flow
mat.PleaseseeFigure6inSection6foraprompt
eration(𝑇 𝑖 ,Q1,𝑅 flow ) (1)
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 16 ===
16
ThenLLMprocessestheprompt𝑃flowandgene
𝑖
where𝑂flowcontains𝑚individualdataflows,i.e.
𝑖
𝑂flow =LLM
𝑖 g
Iftherearemorethanonedatasenderordata
flowswillbegeneratedforeachuniquepairofd
consistsofadatasenderDS𝑗,adatatypeDT𝑗,an
𝐹 𝑖,𝑗 = (cid:0) DS𝑖,𝑗 ,DT𝑖,𝑗 ,DR𝑖
Ifeitherthedatasenderorreceiverisunknown,
fieldempty.Insuchcases,weusetheplaceholders
inoneoftwopartialtuples (cid:0) ⊥,DT𝑖,𝑗 ,DR𝑖,𝑗 (cid:1) or (cid:0) D
3.2.3 LLM-RAGAgents. Tofurtheranalysedata
identify:1)datacategory,2)dataconsumertype,3
method.TheretrievalphaseoftheRAGapproachi
typologyandthenretrieveinformationthatisrel
literature,avarietyoftermshavebeenusedtodes
totheretrievedinformationasretrievedcontexts
asadditionalcontexts[28],whileothersdenoteth
backgrounds[45].Fortheclarityandsimplicity,h
contexts.
EachLLM-RAGagentperformsaseriesofsimi
(1) AspartoftheRAGprocess,thetaskistore
toagiventextsegmentandasingledata
onsemanticsimilarity.Thistaskcanbere
top-𝑘 retrievedknowledgecontexts,wher
retrieval is carried out using the VectorI
embedthequeryandcomparesitagainstth
Section3.1.2.Bydefault,thesimilarityisc
retrievedknowledgecontextsmostseman
practice,weuseasemanticscorethreshold
only contexts with a score greater than 0
meetsthisrequirement,itissolelyusedin
threshold,thetoptwoareincluded.Ifnoco
isused.KT𝑙 representsthedomainknowl
𝑙 ∈ {data,consumer,method,purpose} cor
inSection3.1.2.𝐹 𝑖,𝑗 representstheextract
suggeststhatnotallLLM-RAGagentstake
process.Oneexampleofusingonlypartofa
IdentifyingDataCategory”.Inaddition,𝑇
ad
oneexampleofusing𝑇 isdetailedinthe
adj
method”ofthissub-subsection).
KCX𝑖,𝑗 =Retrieve
4LlamaIndexisadataframeworkspecialisedforbuildingapp
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
eratesstructuredoutputs𝑂flowasshowninEq.(2),
𝑖
.,𝑂
𝑖
flow ={𝐹 𝑖,𝑗}𝑚
𝑗=1
.
(cid:16) (cid:17)
𝑃flow (2)
generate 𝑖
areceiverforaidentifieddataflow,multipledata
datasenderanddatareceiver.Eachdataflow𝐹
𝑗
ndadatareceiverDR𝑗.
𝑖,𝑗 (cid:1), ∀𝑗 ∈ {1,...,𝑚} (3)
,weinstructtheLLMtoleavethecorresponding
symbol⊥torepresentthemissingvalue,resulting
DS𝑖,𝑗 ,DT𝑖,𝑗 ,⊥ (cid:1) .
aflows,wedevelopasetofLLM-RAGagentsto
3)dataprocessingpurpose,and4)dataprocessing
involvesidentifyingthecorrespondingknowledge
levanttoagivenquery.AcrosstheRAGandLLM
scribetheretrievedcomponent.Somestudiesrefer
[25],othersdescribetheretrievedtextdocuments
heretrievedsnippetsascontexts[26]orcontextual
herewecalltheretrievedinformationknowledge
ilartasksthatcanbegeneralisedasthefollowing:
etrieveknowledgecontextsthataremostrelevant
flowfromthesetofextracteddataflows,based
epresentedinEq.(4).Here,KCX𝑖,𝑗 representsthe
rethevalueof𝑘 isdynamicallydetermined.The
IndexRetriver module of LlamaIndex [32]4 to
hestoredknowledgeembeddingsasdiscussedin
computedviacosinesimilarity,ensuringthatthe
nticallyalignedwiththequeryareprioritised.In
dof0.6toretrieveknowledgecontexts,therefore,
0.6 are selected. If a single knowledge context
ntheprompt.Iftwoormorecontextssatisfythe
ontextexceeds0.6,theonewiththehighestscore
ledgetypologyselectedfortheretrieval,where
rresponds to the knowledge typologies defined
teddataflowdescribedinSection3.2.2,where∗
eacompleteddataflowasinputintheretrieving
adataflowisdetailedintheparagraph“Agentfor
representsoptionaladjacenttextsegments(e.g.,
dj
paragraph“AgentforIdentifyingdataprocessing
(cid:16) (cid:17)
e KT𝑙 ,𝐹 𝑖 ∗ ,𝑗 ,𝑇 𝑖 ,𝑇 adj (4)
plicationsusingLLMs

=== Page 17 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
(2) Oncetherelevantknowledgecontext(s)is/ar
as formulated in Eq. (5). The prompt is co
originaltextsegment𝑇 𝑖,andtheretrieved
isselected,where𝑝 ∈ {2,...,5}toguideth
LLM’soutputformat.
𝑃 𝑖,𝑗 =PromptGenerat
(3) Thegeneratedprompt𝑃 𝑖,𝑗 isthenpassedto
output𝑂 𝑖,𝑗,asdefinedinEq.(6).
𝑂 𝑖,𝑗 =LLM g
To distinguish different LLM-RAG agents, w
Eqs.(4),(5),and(6)intheremainingpartofthes
AgentforIdentifyingDataCategory. First,this
identifieddataflow𝐹 𝑖,𝑗,atextsegment𝑇 𝑖,andt
toretrieveknowledgecontext(s)KCXdata.Theret
𝑖,𝑗
Eq.(4),withthenotationssubstitutedaccording
Then, a customised prompt 𝑃data is dynamic
𝑖,𝑗
context(s)KCXdata,𝑅,alongwiththedatacategor
𝑖,𝑗
onEq.(5)accordingly.SeeFigure7inSection6f
LLMtakesthecustomisedprompt𝑃dataandgene
𝑖,𝑗
(i.e.,𝑂data).
𝑖,𝑗
AgentforIdentifyingDataConsumerType. The
thedataconsumertypeofagivendataflow𝐹 𝑗 is
thesameRAGapproach,thecontextretrieverta
toretrievetherelevantknowledgecontext(s)KC
constructedandpassedtoanLLMtoidentifyas
AgentforIdentifyingDataProcessingPurpose. T
foragivendataflow𝐹 𝑖,𝑗.Usingthesameapproa
KT purpose andagiventextsegment𝑇 𝑖 areusedt
whichisthenusedtofacilitatethepromptgenerat
whichidentifiesthedataprocessingpurposefor
AgentforIdentifyingDataProcessingMethod. A
methodcanbecategorisedasactive,passive,oru
determiningthedataprocessingmethodismorech
textualcontext.Preliminaryexperimentsindicate
theprevioussegment𝑇 𝑖−1 andthenextsegmen
Hence,theretrievaltaskcanbereformulatedwith
follows:
KCX 𝑖 m ,𝑗 ethod =Retrieve (cid:0)𝐹 𝑖
Similar to the above two agents, only the retrie
similarityisused.Thepromptandoutputgenera
previoussections.Thefinaloutputofthisagenti
Insummary,byprocessing𝑛privacypolicyte
an𝑛 setsofoutputs𝑂.Eachset𝑂 𝑖 includes𝑚 s

DataFlowAnalysisinPrivacyPolicies 17
reretrieved,acustomisedprompt𝑃 𝑖,𝑗 isgenerated,
onstructed using multiple inputs, including the
contexts,KCX𝑖,𝑗.Additionally,onequestionQ𝑝
hepromptformulation.Furthermore,𝑅regulates
tion (cid:0)𝑇 𝑖 ,KCX𝑖,𝑗 ,Q𝑝,𝑅(cid:1) (5)
otheLLMforinference,producingonestructured
generate
(𝑃 𝑖,𝑗) (6)
we use different superscripts in the notations of
section.
sLLM-RAGagenttakesthedatatypeDT𝑖,𝑗 ofan
theknowledgetypologyofdatacategoryKT ,
data
trievingprocessfollowsthesameformulationas
tothoseintroducedabove.
cally augmented using the retrieved knowledge
risationquestionQ2.Thiscanbeformalisedbased
foranexampleofgeneratedprompt.Finally,the
eratesonestructuredoutputforthedatacategory
eobjectiveofthisagentistodeterminewhether
afirst-party,third-party,orundefined.Following
akes𝐹 𝑖,𝑗,𝑇 𝑖,andknowledgetypologyKT
consumer
CXconsumer.Acustomisedprompt𝑃consumeristhen
𝑖,𝑗 𝑗
singledataconsumertype(i.e.,𝑂consumer).
𝑖,𝑗
Thisagentdeterminesthedataprocessingpurpose
ach,theassociateddomainknowledgetypology
purpose
toretrievetheknowledgecontext(s)KCX ,
𝑖,𝑗
tion.TheoutputofthisLLM-RAGagentis𝑂purpose
,
𝑖,𝑗
thegivendataflow.
AsdescribedinSection3.1.2,thedataprocessing
unspecified.Unlikeotheragentsdescribedabove,
hallenging,asitoftendependsonthesurrounding
edthatincorporatingadjacenttextsegments,i.e.,
nt𝑇 𝑖+1 ,canhelpimproveclassificationaccuracy.
hminorchangestoEquation4andrepresentedas
𝑖,𝑗 ,𝑇 𝑖−1 ,𝑇 𝑖 ,𝑇 𝑖+1 ,KT method (cid:1) (7)
eved knowledge context with highest semantic
ationprocessesremainedthesameasthoseinthe
isdenotedas𝑂method.
𝑖,𝑗
extsegments,theLLM-basedprocessorgenerates
setsofoutputs,whereeachoneoftheseoutputs
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 18 ===
18
consistsoftheidentifieddataflow,thecorrespo
processingpurpose,anddataprocessingmethod
(cid:26)
(cid:110)
𝑂 = 𝑂 𝑖 = 𝐹 𝑖,𝑗 ,𝑂 𝑖 d , a 𝑗 ta,𝑂 𝑖 c , o 𝑗 nsu
3.2.4 FurtherImplementationDetails. Asmentio
weredevelopedusingLlamaIndex[32].Specifically
embeddingmodel[62]toconverttextualdocume
forretrievalandanalysis.TheexecutionofLLM
languageprocessingunits(LPUs)optimisedfora
compatiblewithLlamaIndexandsupportsvarious
tionintoLADFA.DifferentLLMsweretestedtofi
dataflowextractionagentutilisethellama-3.3-
sibleforidentifyingdatacategoriesusesllama3-
alightweightmodelllama-3.1-8b-instant8 w
bases,i.e.,KT ,KT ,KT .
consumer purpose method
Finally,promptswereconstructionbyfollow
pletionsAPItoensurestructuredandeffectivei
forallLLMs,wesetbothtop_pandtemperatur
andconstraintokenselection,aimingtoproduce
creativity.
3.3 DataFlowPost-processor
Toobtaininsightsfromtheoutputsgeneratedby
prisesthreekeysub-components:adataparser,a
3.3.1 DataParser. Thedataparserisresponsible
thattherawoutputsfromtheLLM-basedproces
andanalysis.Despiteprovidingdetailedinstructio
tenciesandambiguitieswereobservedinthegene
processingstepsarerequired.
Duplicate Data Entries. Redundant entries for
anddatatype)oftenoccurduetovariationsin
abbreviationsandtheircorrespondingfullreprese
couldbeextractedastwodistinctdatareceivers,o
berecognisedasseparatedatatypes.Tomitigat
Pythonpackageinflect9andPython’sremodule10
MisclassificationofDataConsumerTypes. Ing
consumer type given a data flow, where the da
first-partyisinsteadtreatedasathird-party,orv
5https://groq.com/
6https://console.groq.com/docs/model/llama-3.3-70b-versatil
7https://console.groq.com/docs/model/llama3-70b-8192,this
modelavailablewhenweconductedtheexperiment.Itisdep
8https://console.groq.com/docs/model/llama-3.1-8b-instant
9https://pypi.org/project/inflect/
10https://docs.python.org/3/library/re.html
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
ondingdatacategory,dataconsumertype,data
d.ThesecanberepresentedformallyinEq.(8).
(cid:111)𝑚
(cid:27)𝑛
umer,𝑂purpose,𝑂method
(8)
𝑖,𝑗 𝑖,𝑗
𝑗=1
𝑖=1
onedearlier,embedding,indexing,andretrieval
y,theembeddingusestheBAAI/bge-small-en-v1.5
entsintovectorrepresentationsthataresuitable
inferenceissupportedbyGroq5,whichprovides
acceleratingAIinferencetasks.TheGroqAPIis
sopen-sourceLLMs,facilitatingseamlessintegra-
findthebestones(s).Thescreeningagentandthe
-70b-versatilemodel6,whiletheagentrespon-
-70b-8192model7.Forcomputationalefficiency,
wasusedfortasksinvolvingsmallerknowledge
wingtheformatrequiredbytheGroqChatCom-
interactionswiththeselectedLLMs.Inaddition,
retobe0.5,aimingtoreducesamplingvariance
ebalancedoutputsthatfavourconsistencyover
ytheLLM-basedprocessor,thiscomponentcom-
agraphgenerator,andananalyser.
efordatacleaninganddisambiguation,ensuring
ssorarerefinedforsubsequentgraphgeneration
onstoLLMsforstructuringtheiroutput,inconsis-
erateddata.Toaddressthesechallenges,additional
r the same data (e.g., data sender, data receiver,
pluralandsingularformsorinconsistenciesin
entations.Forinstance,‘customers’and‘customer’
or‘vehicleidentificationnumber’and‘vin’might
tethisissue,rule-basedapproachesutilisingthe
0areappliedtostandardiseentityrepresentations.
general,LLMsmayincorrectlyclassifythedata
ata consumer type that should be classified as a
viceversa.Forinstance,inourcasestudyofOEM
le
smodel,with70Bparameters,wasthemostup-to-datelarge
precatednowintheGroqplatform.

=== Page 19 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
privacypolicies(Section4),weobservedcasesw
datareceivertocollectandprocesspersonaldata
incorrectlycategorisedasathirdpartyratherthan
morein-depthanalysis,thedataparseranalysest
andassignsappropriateattributesthroughatwo
(1) Alistoffirst-partykeywords,including‘we
theNLPpackagespaCy11isusedtoextract
fromagiventext(i.e.,datareceiver/sende
predefinedfirst-partykeywordsorthenam
additionally,ifapossessivemodifierispre
orthenameoftheorganisation,theattribu
receiver/sender.Otherwise,theattribute‘th
(2) Weintroducetheconceptofa‘user-party’a
datasenders.FollowingasimilarNLPapp
ofkeywordsincluding‘you’,‘user’,and‘c
relevantdatasenders.
Byimplementingthisapproach,thedataparse
datasendersandreceivers.Inturn,thisenableam
ofagivendataflow.AsdepictedinTable4,data
representedbythreedistinctcases,whiledataflo
thesimilarpattern.Fortheclarityandconsistenc
third-partydataflowsfortherestofthispaper.
Table4. Dataflowscasesunder
First-partydataflow:
(User-party)datasender→dataty
(First-party)datasender→dataty
(Third-party)datasender→dataty
Third-partydataflow:
(User-party)datasender→dataty
(First-party)datasender→dataty
(Third-party)datasender→dataty
Incompletedataflows:
datasender→datatype→?
?→datatype→datareceiver
?→datatype→?
Moreover,previousresearch[58,65]indicated
howdataarecollected,towhatextent,andwith
weinstructedtheLLMdataflowagent,asdescr
datareceiverasunknownentitiesifthetextseg
processed or who is responsible for the data pr
incompletedataflows.Incompletedataflowscons
11https://spacy.io/

DataFlowAnalysisinPrivacyPolicies 19
whereanOEM’smobileappwasidentifiedasa
a,andthecorrespondingdataconsumertypewas
nasafirstparty.Toaddressthisissueandsupport
thedatasenderandthedatareceivercollectively
o-stepprocess:
e’,‘us’,‘app’,and‘website’,weregenerated.Then,
ttherootandthepossessivemodifier(ifpresent)
er).Iftheextractedroottextmatchesanyofthe
meoftheorganisationowningtheprivacypolicy,
esentandalsomatchesakeywordfromthelist
ute‘first-party’isassignedtotheassociateddata
hird-party’isdesignated.
asanotherattribute,whichappliesspecificallyto
proachmentionedabove,butwithadifferentset
customer’,weassigned‘user-party’attributesto
erenrichesthesemanticrepresentationsofboth
morerefinedclassificationofdataconsumertype
flowswithfirst-partydataconsumertypecanbe
owswiththird-partydataconsumertypefollow
cy,werefertotheseasfirst-partydataflowsand
rdifferentdataconsumertypes
ype→(First-party)datareceiver
ype→(First-party)datareceiver
ype→(First-party)datareceiver
ype→(Third-party)datareceiver
ype→(Third-party)datareceiver
ype→(Third-party)datareceiver
dthatprivacypoliciesoftenfailtoclearlyspecify
whomtheyareshared.Tocapturesuchinsights,
ribedinSection3.2.2,toleavethedatasenderor
gmentdoesnotexplicitlyspecifywhosedataare
rocessing, respectively. We define such cases as
sistsofthreedistinctcases,asillustratedinTable4,
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 20 ===
20
whereaquestionmarkrepresentsanunknowne
moregranularanalysisandaddsinterpretability
3.3.2 Graph Generator. The graph generator is
intoagraph-basedmodel,whichcanbeformalise
betweendifferententities(i.e.,datasender,dataty
describedasG = (V,E),whereV ={V𝑖}
𝑖
𝑀
=1
an
setof𝑁 edges,respectively.EachnodeV𝑖 repre
differentattributesareencodedwithdifferentco
colours,eachrepresentingadifferentdataproce
generatorissupportedbythePythonpackagesn
3.3.3 Analyser. Theanalyserextractsandrepor
standingoftheprocessedprivacypolicydata.I
thenetworkgraphconstructedintheGraphGe
data flows between different entities, and 2) ou
comparisons across different privacy policies, id
discovery.Furtherdetailsonthespecificstatistics
section.
4 ACaseStudyfortheAutomotiveIndustr
AdvancementsinAI,theInternetofThings(IoT
theautomotiveindustry,enablingconnectedve
theintegrationofelectroniccontrolunits(ECUs)
amountsofvehicleandpersonaldata.Theexten
themodernvehicleecosystem[29,66]raisessign
ArecentreviewpublishedbyMozilla[10]claim
HaveEverReviewedforPrivacy”.Thisreviewpre
majorautomotiveoriginalequipmentmanufactu
rangeofdatacollectedandsharedbymostautom
doneusingprivacypoliciesasthemaindatasou
misleadingnatureofthecomplexlanguageusedi
wedecidedtousetheautomotiveindustryasaca
LADFAinautomatingprivacypolicyanalysis.
Inthissection,wefirstoutlinethemethodolo
in Section 4.1, followed by a description of the
experimentalresultsarepresentedanddiscussed
4.1 Datasets
WiththeadvancementofIoTandAItechnologie
servicesthroughmobileapplications.Thesemobi
assistanceanduserexperience.Eachmobileapp
consumersofitsdata-handlingpractices.Tosyste
theseservices,weimplementedthefollowingincl
policies:
12https://networkx.org/
13https://pyvis.readthedocs.io/
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
entity.Theseenhancementsallowustoconducta
tothefollow-upanalysis.
s responsible for converting the processed data
edasadirectedgraphdescribinghowdataflows
ype,anddatareceiver).Thegraphcanbeformally
ndE ={E𝑗}𝑁
𝑗=1
representasetof𝑀 nodesanda
esentsoneentity,anddifferententitytypeswith
olours.EdgesinG canbevisualisedindifferent
essingpurpose.Theimplementationofthegraph
networkX12andpyvis13.
rtsvariousstatisticstofacilitateadeeperunder-
Itmainlyreportsresultsofanalysesbasedon1)
enerator,whichrepresentstherelationshipsand
utputs of the LLM-based processor. This allows
dentification of common patterns, and insights
sandtheirimplicationsarepresentedinthenext
ry
T),and5G/6Gtechnologieshaverevolutionised
ehicleservicesandautonomousdrivingthrough
)andsensorsthatcollect,process,andsharevast
nsivescaleofdatacollectionandsharingwithin
nificantprivacyandsecurityrisksforconsumers.
medthat“CarsAretheWorstProductCategoryWe
esentsanin-depthdatapracticesanalysisfor25
urers(OEMs)worldwide,revealingtheextensive
motiveOEMs.Theworkcarriedoutwasmanually
urces,anditalsohighlightedtheambiguityand
inprivacypolicies.Inspiredbythispublicreview,
asestudytotesttheeffectivenessandefficiencyof
ogyforselectingprivacypoliciesasthedataset
e evaluation process in Section 4.2. Finally, the
dinSection4.3.
es,manymodernvehiclesofferconnectedvehicle
ileappsoffervariousfeaturestoenhancedriving
shouldhaveadedicatedprivacypolicytoinform
ematicallyanalysetheprivacypoliciesgoverning
lusionandexclusioncriteriaforselectingprivacy

=== Page 21 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
(1) Theprivacypolicymustbepublishedforaco
theUK.Thisselectioncriterionismotivated
requirementsgoverningdataprotection(e.
tocomparablestructuresandcontentanda
(2) Theprivacypolicymustbespecificallyan
vehiclemobileapp.Iftheidentifiedpolicy
toitsOEM’swebsitegeneralprivacypolicy,
focusesonthedatahandlingpracticesofus
vehiclemobileapp.
(3) Thetextoftheprivacypolicymustbeemb
providedasalinkeddocumentinformats
otherformats,thecustomisedtext-segmen
alsothedominantformatformostofpriva
Inadditiontotheabovecriteria,automotiveO
inaccessibleprivacypolicylinkswereexcluded
aninitialreferenceforselectingprivacypolicies
inclusionandexclusioncriteria.Theselectedpri
privacypolicyissavedasasingleHTMLfile.
Table5. ListofOEMsandtheirassoc
OEM Link
Honda MyHonda+
Kia KiaConnect
Audi AudiPrivacyPolicy
Hyundai HyundaiBluelinkEurope
Ford FordPass
4.2 Evaluation
Duetothelackofgroundtruthdatasets,weusedm
correctnessofLADFA.Thefirstthreeco-authors
asdomainexperts,whereeachindependentlyev
framework based on given text segments of a
generatessixoutputscorrespondingtothedataty
dataprocessingpurpose,anddataprocessingme
bases,asdescribedinSection3.1.2weresharedw
evaluation.Foreachoutput,theevaluatorwasinst
1:Stronglydisagree,2:Disagree,3:Somewhatdisa
agree,6:Agree,7:Stronglyagree)toverifyitsre
knowledgebasesasreferences.
Fortheevaluationexperiment,werandomlys
derivedfromtheanalysisoftheMyHonda+app’s
witheachtuplecontainingsixtasks,amounting
ThemainreasonsforchoosingMyHonda+are
14Thedatasetcanbeaccessedfromhttps://osf.io/zgacu/overv

DataFlowAnalysisinPrivacyPolicies 21
onnectedvehiclemobileappavailableintheEUor
dbythefactthatlegalframeworksandregulatory
.g.,theEU/UKGDPR)arecloselyaligned,leading
allowingsystematiccross-policyanalysis.
ndsolelydedicatedtotheassociatedconnected
foraconnectedvehiclemobileappwasidentical
y,itwasexcluded.Sincethegeneralprivacypolicy
singtheOEM’swebsiteratherthantheconnected
beddedwithinanHTMLpageratherthanbeing
ssuchasPDForWord.WhileLLMscanprocess
ntationpipelineisoptimisedforHTML,whichis
acypolicies.
OEMsandtheirassociatedappswithbrokenor
fromthestudy.UsingtheMozillastudy[10]as
s,wefurtherrefinedourdatasetbyapplyingthe
ivacypolicies14arelistedinTable5,whereeach
ciatedconnectedvehiclemobileapps
OEM Link
Lexus LexusLink+
Nissan NissanConnectServices
Vauxhall MyVauxhall
Polestar Polestar
Renault MyRenault
manualvalidationtoevaluatetheeffectivenessand
ofthisstudyparticipatedintheevaluationwork
valuatedtheoutputsgeneratedbytheproposed
privacy policy. For each text segment, LADFA
ype,datacategory,dataflow,dataconsumertype,
ethod.Inaddition,thecorrespondingknowledge
withallevaluatorsasreferencestofacilitatethe
tructedtogiveascoreusinga1-7Likertscale(i.e.,
agree,4:Neitheragreenordisagree,5:Somewhat
elevance,correctness,andclarityusingthegiven
sampledapproximately40%ofthetotaloutputs
sprivacypolicy.Thisresultedin150outputtuples,
gtoatotalof900evaluationtasksperevaluator.
asfollows:1)itproducesthehighestnumberof
view?view_only=ee487642d88f4ce1a14473b8402d4762
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 22 ===
22
extracteddataflows(seeSection4.3formorede
textincludesdiverseformats,includingtables,bu
robustandvariedevaluationset.
Table6. Evaluationscoresbythreeevaluators
Evaluator DataType DataCategory DataFlow DataConsu
1 6.74(0.87) 6.11(1.35) 6.27(1.21) 6.19(
2 6.97(0.29) 5.62(1.95) 6.52(1.25) 6.58(
3 6.95(0.25) 5.29(2.06) 6.02(1.55) 6.29(
Table6presentsasummaryoftheevaluation
evaluators.Overall,theresultsdemonstratethat
withtheLLMs’outputs,withmostaveragescor
and‘DataFlow’scoresreceivedconsistentlyhig
rangedfrom6.27to6.97,withrelativelylowstan
confidenceinLADFA’sabilitytoidentifyandcl
variationswereobservedintheevaluationofthe‘
particular,Evaluator3assignedanoticeablylower
category.Similarly,the‘Datacategory’taskrece
Evaluators2and3(5.62and5.29,respectively).
Theobserveddisparitiescouldbecausedby1
anddataprocessingpurposesmaybelessrobusto
definitionswithintherelevantknowledgebases
ambiguous,resultingindifferentinterpretations
highlighttheneedtoimproveLADFA’sperforma
knowledgebases.Nevertheless,theconsistently
confirmtheproposedframework’soveralleffect
informationfromunstructuredprivacypolicytex
Table7. Gwet’sAC1andpercentageagreementusi
Metric DataType DataCategory DataFlow DataC
7-Likertscale
Gwet’sAC1 0.85 0.37 0.51
Percent.Agreement 0.89 0.43 0.59
Transformed3-categoryscale
Gwet’sAC1 0.94 0.56 0.82
Percent.Agreement 0.96 0.59 0.86
Moreover,itisessentialtoexaminetheinter-ra
themanualverificationresults.Sinceweobserve
wheretraditionalmetricssuchasCohen’skappa
(ICC) might fail to reflect consensus among rat
percentageagreementsinthisstudy[21,22].G
reliability,andthepercentageagreementmeasure
metrics,thevaluerangesfrom0to1,where1ind
Because the results were evaluated using a 7
subtledifferencesinagreementsanddisagreemen
assessment,itnaturallyreducesthelikelihoodo
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
etails);and2)thestructureoftheprivacypolicy
ulletpoints,andnarrativeparagraphs,providinga
(meanwithstandarddeviation),7-Likertscale
umerType DataProcessingPurpose DataProcessingMethod
(1.39) 6.62(1.07) 6.78(0.93)
(1.20) 6.28(1.40) 6.58(1.10)
(1.58) 4.60(1.93) 5.92(1.48)
scoresacrossthesixtasksassessedbythethree
tevaluatorsgenerally“agree”or“stronglyagree”
resbetween6and7.Specifically,the‘DataType’
ghratingsacrossallevaluators.Themeanvalues
ndarddeviations,indicatingstrongandconsistent
lassifytheseelementscorrectly.However,slight
‘DataCategory’and‘DataProcessingPurpose’.In
raveragescoreof4.60(SD=1.93)forthepurpose
eivedtheloweraveragescore,particularlyfrom
1)LADFA’scapabilitytoclassifydatacategories
ormoreambiguousincertaincontexts,and2)the
susedfortheseclassificationsmaybeinherently
betweenhumanevaluatorsandtheLLMs.These
anceandtheneedtobetterdefineandconstruct
yhighscoresacrossmostevaluationdimensions
tivenessinextractingstructuredandmeaningful
xts.
ing7-Likertscaleandtransformed3-categoryscale
ConsumerType DataProcessingPurpose DataProcessingMethod
0.56 0.21 0.56
0.66 0.33 0.66
0.83 0.48 0.79
0.86 0.53 0.83
aterreliabilitymetrictoobtainmoreinsightsinto
edthattherecouldbehigh-agreementsituations
coefficientandIntraclassCorrelationCoefficient
ters [17, 21], we used both Gwet’s AC1 and the
Gwet’sAC1isastatisticalmeasureofinter-rater
estherawconsensusamongevaluators.Forboth
dicatesperfectagreement.
7-point Likert scale, it was designed to capture
nts.Whilethisgranularityisvaluableforin-depth
ofreachingexactagreementsamongevaluators.

=== Page 23 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
Nevertheless, the agreement metrics based on t
Table7,theoverallagreementforthe‘DataTyp
andacorrespondingpercentageagreementof0.8
agreementwasmoremoderateforothertasks.Fo
ProcessingMethod’,Gwet’sAC1scoresrangedb
above0.58,suggestingareasonablelevelofalign
Purpose’showedthelowestagreement,withGw
Tobettermeasureagreementatabroaderlevel,
ingthe7-pointLikertscaleintoa3-categoryscale
4to2(neutral),and5–7to3(agreement).Thissc
differencesinevaluators’responsesandproduc
AsshowninTable7,weobserveanimproveme
‘DataType’and‘DataFlow’haveGwet’sAC1sco
ingpercentageagreementsabove0.86,indicatin
LADFA’soutputs.TheGwet’sAC1andpercentag
ProcessingMethod’wereapproximately0.8,sug
Althoughthescoresfor‘DataCategory’and‘Data
20%, the agreements were relatively low compa
whileevaluatorsmaydifferonspecificlevelsof
effectivenessandaccuracyoftheproposedframe
policydocumentsandextractingcomprehensive
4.3 AnalysisofResults
Weaimtoillustratehowinterpretationandanaly
togenerateinsightsofpotentialprivacyconcerns
theconvenienceandclarity,weuseOEMs’nam
section.
Table8. Summaryofdat
Audi Ford Honda Hyundai
Edges 84 198 510 79
First-partynodes 5 11 6 13
Third-partynodes 22 33 51 19
User-partynodes 2 3 3 3
Datatypesnodes 22 73 177 14
4.3.1 AnalysisofDataFlowGraphs. Werepresen
analysis.Table8presentsthedescriptivestatistic
themobileapps’privacypoliciesofdifferentOEM
contains510edgesandmorethan200nodes.Inc
moderatelysmallernetworks,withthenumbero
Kia, and Lexus have relatively simpler network
networks. Figure 2 presents a comparison betw
network (Renault) to illustrate the network stru
analysis15.Inthevisualisation,pink,yellow,and
15Allgeneratednetworkgraphscanbeviewedfromhttps://o
402d4762

DataFlowAnalysisinPrivacyPolicies 23
the raw scores remain promising. As shown in
pe’isparticularlyhigh,withGwet’sAC1at0.85
889,indicatingastrongconsensus.However,the
or‘DataFlow’,‘DataConsumerType’,and‘Data
between0.5and0.56,withpercentageagreement
nment.The‘DataCategory’and‘DataProcessing
wet’sAC1at0.37and0.21,respectively.
wealsoappliedascoretransformationbycollaps-
e:scoresof1–3weremappedto1(disagreement),
coringschemecouldreducesensitivitytominor
ceamorerobustmeasureofgeneralagreement.
entinbothmetricsacrossalltasks.Forinstance,
oresof0.94and0.82,respectively,andcorrespond-
ngstrongagreementsonthegeneralvalidityof
geagreementfor‘DataConsumerType’and‘Data
ggestingstrongagreementsbetweenevaluators.
aProcessingPurpose’improvedbyapproximately
ared with other tasks. The results suggest that,
agreement,thereisabroaderconsensusonthe
ework’scapabilityinanalysingcomplexprivacy
dataflows.
ysiscanbeconductedfromdifferentperspectives
sthatmightotherwisebehiddenorneglected.For
mesinsteadofmobileappnamesthroughoutthis
taflownetworkstatistics
Kia Lexus Nissan Polestar Renault Vauxhall
93 61 201 151 8 176
4 2 9 4 2 16
16 17 42 14 0 23
2 1 3 3 1 1
32 15 64 64 4 35
ntdataflowsasgraphsandconductgraph-based
csofthedataflowgraphnetworksextractedfrom
Ms.Hondahasthemostcomplexnetwork,which
contrast,Ford,Nissan,Polestar,andVauxhallhad
ofedgesrangingfrom170to270.Audi,Hyundai,
k structures, whereas Renault has the smallest
ween a complex network (Honda) and a simpler
uctures derived from automated privacy policy
dgreennodesrepresentthird-party,user-party,
osf.io/zgacu/overview?view_only=ee487642d88f4ce1a14473b8
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 24 ===
24
andfirst-partyattributednodes,respectively.Fo
user-party, and first-party nodes, respectively, i
blueboxesrepresentdifferenttypesofdata.Dar
classifications.
(a)
Fig.2. Comparisonbetween(a)acomplexdataflown
and(b)asimpledataflownetworkderivedfromMyR
By taking a closer look at specific nodes as i
directional nature of the network graph, indica
entities.Forinstance,athird-partynode‘yourc
including‘Androidlogcat’,‘drivehistory’,‘USB
‘WiFistation’/footnoteThisistheexactwording
theactualmeaningisWiFistationID.,and‘GPS
Additionally,Figure3(a)showsatableoftheraw
demonstratingthatourmethodcanaccurately
content.
Moreover,tosystematicallycomparenetworks
networkmetrics,includingbetweenness,closenes
toptennodeswiththehighestscoresacrossallap
andvisualisation,weusedistinctcolourstorepre
notingthatwechosenottomergeornormalisen
example,thenodes‘We’and‘Us’aresemantica
data’.Weretainedthemintheiroriginalwordin
minimisetheriskofmisclassificationthatmaya
Toretainsuchrawformalsoallowsustodirect
forcross-validation.Nevertheless,toaddresspot
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
orsimplicity,thesearereferredtoasthird-party,
in the rest of this paper. The nodes in the light
rkblueisusedtoannotatenodeswithunknown
(b)
networkderivedfromMyHonda+app’sprivacypolicy
Renaultapp’sprivacypolicy
illustrated in Figure 3(b), the arrows reflect the
ating the direction of how data flows between
car’sdisplayaudio’wouldshareanarrayofdata,
Bdeviceinformation’,‘mobiledeviceID’,‘VIN’,
gusedintheprivacypolicy.Weunderstandthat
Sinformation’toathird-partynode‘Panasonic’.
wtextoriginallyappearingintheprivacypolicy,
extractgranularinformationfromHTMLtable
andobtainamorecomprehensiveunderstanding,
ss,anddegreecentrality,werecomputed,andthe
ppsarelistedinTable9.Tofacilitatetheanalysis
esentdifferentcategoriesofnodes.Itisalsoworth
nodesthatsharethesamesemanticmeaning.For
allyequivalent,asare‘Personaldata’and‘Your
ngtopreservefidelitytothesourcetextandto
ariseduringsuchmerging/normalisationprocess.
tlyloopupeachnodeintheprivacypolicytext
tentialissuesofsemanticoverlapping,weadded

=== Page 25 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
Processing activity: What information is Lawful
Why we use your collected? proces
information?
To provide you with Drive history, VIN, Android The pr
your display audio log cat, Mobile device ID, necess
functionality Wi-Fi station, GPS ongoin
information, USB device manag
information facilitat
contrac
(a
android lo
drive hi
usb device in
mobile de
your car’ display audio
vin
wifi sta
gps infor
(b
Fig.3. Exampleofconvertingtablecontenttodat
additionalattributes,includingfirst-party,third-p
explainedearlierinSection3.3.1.
Betweenness Centrality. Betweenness centrali
theshortestpathsbetweenothernodesandisof
network.AsshowninTable9,thetoptennodes
consistentlyincludefirst-partynodes(e.g.,OEMs
‘User’)anddatanodesformostapps.Theonlyexc
third-party service providers such as ‘Vodafone
Nissanhas‘Ourpartner’asathirdpartynodeini
ofthird-partyserviceprovidersinFord’sandNis
Overall,the‘Personaldata’/‘Personalinformati
9/10apps’toptenlists.The‘VIN’nodealsoappea
data’and‘VIN’actascriticalbridgesacrossdiffere
specificsensitivedatatypesthatareworthnoticin
cardnumber’forHonda,biometricdata‘Voicereco
information’forLexus,andhealthdata‘Medica
thesedatainrelationtobetweennesscentrality
andtheirbridgingrolesinassociateddataflown
ClosenessCentrality. Closenesscentralitymea
the network, highlighting its role in the inform
colouredstackedbarsacrossallapps,Kiaappears
nodesofclosenesscentralityarethird-partynod

DataFlowAnalysisinPrivacyPolicies 25
l basis of Where is the Specific retention
ssing information periods
collected from?
rocessing is From your Panasonicwill only
sary for the car’s display retain this data for the
ng performance, audio period of the
gement and investigation to
tion of our identify and resolve
ct with you the fault.
a)
og cat
istory
nformation
evice id
panasonic
n
ation
rmation
b)
taflowsillustratedinpartofadataflownetwork
party,anduser-party,tocollectionpartynodes,as
ity measures the extent to which a node lies on
ftenconsidereda“bridge”orintermediaryinthe
swiththehighestbetweennesscentralityscores
snames,‘We’,‘Us’),user-partynodes(e.g.,‘You’,
ceptionsareFordandNissan,whereFordincludes
e’ and the ‘Roadside assistance provider’, while
itstoptennodes.Thisimpliesthesignificantrole
ssan’sdataflownetwork.
ion’nodehadthehighestfrequency,appearingin
aredinmorethanhalfofallapps.Both‘personal
entdataflownetworks.Moreover,therearesome
ng.Forinstance,thefinancedata‘Masked/partial
ording’forKia,personalidentifiabledata‘Identity
alpersonaldata’forNissan.Thesignificanceof
highlightsthescaleofsensitivedataprocessing
networks.
asureshowcloseanodeistoallothernodesin
mation transmission of a network. By reviewing
stohaveadistinctpattern,asmostofitstopten
des,wherenodes,suchas‘KiaConnectedGmbH’
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 26 ===
26
(associatedwithGermany),‘CerenceB.V.’(associa
theEU/EEA’indicatetheextensivecross-border
HyundaiandLexussharesimilarpatternsofd
theHyundainetworkgraphincludesnodes,such
locatedintheRepublicofKorea’,‘HyundaiAuto
and ‘Hyundai BluneLink Europe’, that are affili
LexusispartoftheToyotacorporateGroup,an
‘ToyotaFinancialService’,‘ToyotaInsuranceMan
in the list of closeness centrality top ten nodes.
Lexusmighthaverelativelybettercontroloverda
dataprocessingpracticescouldbemoretranspar
involvingmorethird-partyentities.
Itisworthnotingthatmostoftheapps’dataflo
nodes.Forinstance,‘Processorinthirdcountry’,‘T
provider’,and‘ITserviceprovider’areheavilyinv
‘Analytic’,‘Businesspartner’,and‘Subcontracto
‘Google’,‘Ourpartner’,‘RCIFinancialServiceLi
essential third-party nodes in the data flow net
dependenceonthird-partyentitiestotransmitin
onlyexceptionis‘Renault’,whichdoesnothavea
list.Thismayindicateeitheracomparativelymi
provision,orthattheprivacypolicyiswrittenin
DegreeCentrality. Degreecentralityrevealscen
thenumberofdirectconnectionswithinanetwor
centralityindicatesitsdirectionalconnectiontoth
network.Byinspectingthetoptennodesforalla
partynode(e.g.,‘We’,‘Us’,ortheOEM’sname),a
andadata-typenode(e.g.,‘Personaldata’,‘Data’).
centralityandclosenesscentrality,thetoptennod
first-party,third-party,user-party,anddatatypen
acrossallnodetypeswithinthedataflownetwor
Itisworthnotingthat‘Unknown’nodesappea
Renaultacrossdifferentmetrics.Manualexamina
nodes.Forinstance,forRenault’sdataflows‘Un
→IPaddress→Renault’,theprivacypolicystat
we automatically collect, such as IP address and
ofRenault’swebsitesormobileapplications.”Wh
address’ascategoriesofpersonaldata,itdidnot
withthepolicytext,whichdoesnotexplicitlyst
inferthatthesenderistheuseroftheappordevi
theuser’smachine.However,becausetheinputse
attribution,weadoptaconservativestance:LAD
reflectstheabsenceofcleartextualevidence.Simil
results.Weacknowledgethatwithcarefullytailo
suchimplicitrolesmorereliably,althoughthisr
thetext.Inaddition,wesuggestthatamorerefin
morecross-paragraphcontextmayfurtherimpr
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
atedwiththeNetherlands),and‘Recipientoutside
informationflow.
distributionofnodetypes.Thetoptennodesof
has‘HyundaiMotorCompany’,‘Hyundaientity
oEverEuropeGmbH’,‘HyundaiAutoEverCorp.’,
iated with Hyundai Group. Similar to Hyundai,
ndwecansee‘Toyota’associatednodessuchas
nagement’,and‘ToyotaFinancialService’,appear
. These observations suggest that Hyundai and
ataflowswithintheirnetworksifweassumethat
rentwithinthesamecorporategroupthanthose
ownetworkgraphsareassociatedwiththird-party
Trackingserviceprovider’,‘Webagency’,‘Hosting
volvedinthedataflownetworkofAudi.Similarly,
or’arekeynodesinPolestar’snetwork.‘Dealer’,
imitedtradingasMobilizeFinancialService’are
twork of Nissan. This highlights the significant
nformationwithinthesenetworks.However,the
asinglethird-partynodeappearinginthetopten
inimalrelianceonthird-partyentitiesforservice
nawaythatomitsorobscuressuchdetails.
ntralisedhubs/nodesofthenetworkbycomputing
rk.Tothisend,anodewiththehighestdegreeof
hemostnodes,signifyingitscentralrolewithina
apps,thetopthreenodestypicallyincludedafirst-
auser-partynode(e.g.,‘You’,‘User’,‘Customer’),
.Differentfromtheobservationsforbetweenness
desofdegreecentralityacrossallappsincludeall
nodes,suggestingahighlevelofinterconnectivity
rkgraph.
aramongthetoptennodesforbothPolestarand
ationoftheirprivacypolicieshelpedexplainsuch
nknown→Cookies→Renault’and‘Unknown
tes:“Forinformationrelatingtopersonaldatathat
cookies, a cookie policy is also available on each
hileLADFAcorrectlyidentified‘Cookies’and‘IP
tassignaspecificdatasender.Thisisconsistent
tatethesenderofthedata.Onecouldreasonably
ice,sinceIPaddressesandcookiesoriginatefrom
egmentofthepolicytextdoesnotprovideexplicit
DFA’sclassificationofthesenderas‘Unknown’
larpatternswereobservedinsomeofthePolestar
oredpromptdesign,LLMscouldpotentiallyinfer
requiresbalancinginferencewithstayingtrueto
nedtext-segmentationstrategythatincorporates
rovetheLLM’sability.However,comparedwith

=== Page 27 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalDataFlowAnalysisinPrivacyPolicies 27
Table9. Top10betweenness,closeness,anddegreeofcentralitynetworkmetrics
OEM Metric Top10nodesinDescentorder Distributionofnode
types
Audi BC Personaldata,Us,Data,IPaddress,Information,VIN,Yourdata,IPaddress,Informationaboutcybersecurity
vulnerabilities/incidentorhackerattack,Contactdetail,URLofvisitedwebsites
CC Logfile,Audi,Chatbot,Processorinthirdcountry,Personaldata,Processor,Trackingserviceprovider,Web
agency,Hostingprovider,ITserviceprovider
DC Personaldata,Internetbrowser,Logfile,Data,IPaddress,User,Audi,Chatbot,Us,Yourdata
Ford BC VIN,User,Datausethreshold,VodafoneGlobalEnterpriseLimited(Vodafone),Us,FordSmartMobilityUK
Limited(FSM),Informationthatyouhavepurchasedthesubscription,Roadsideassistanceprovider(RSA),We,
Vehiclelocation
CC Ford,We,FordSmartMobilityUKLimited(FSM),Google,Vehicledata,Us,VIN,Ourauthorizeddealer,Company
ororganisation,Somedata
DC You,Ford,We,User,Vehiclelocation,Us,FordSmartMobilityUKLimited(FSM),Google,Speed,Vehicleinfor-
mation
Honda BC Honda,You,Authenticationcode,Personalinformation,We,Us,VIN,HondaID,Data,Masked/partialcard
number
CC Honda,Data,SoundHound,Authenticationcode,Personalinformation,HondaID,VIN,CustomerID,Us,We
DC You,Honda,Car(viaTCU-TelematicControlUnit),Personalinformation,Us,We,E3MediaLimited,Worldline,
Customer,Manufacturer
Hyundai BC Personaldata,Yourpersonaldata,We,HyundaiMotorCompany,Hyundai,Yourdata,Certainpersonaldata,
VIN,Securityevent-relateddata,Timestampofthegeneratedsecurityevent
CC Dataprocessor,HyundaiMotorCompany,Yourpersonaldata,HyundaientitylocatedintheRepublicofKorea,
Recipientofyourpersonaldata,Cerencesub-processor,HyundaiAutoEverEuropeGmbH,HyundaiAutoEver
Corp.,RepublicofKorea,HyundaiBlueLinkEurope
DC Personaldata,You,Yourpersonaldata,We,Certainpersonaldata,Dataprocessor,HyundaiMotorCompany,
Hyundai,VIN,Securityevent-relateddata
Kia BC Personaldata,Kia,Yourpersonaldata,Log-indata,Locationdata(GPS),Personaldatarelatingtothecontractual
relationship,Communication,Commercialletter,Contactdetail,Voicerecording
CC KiaConnectedGmbH,CerenceB.V.,AutoritédeProtectiondeDonnée,Gegevensbeschermingsautoriteit,Gov-
ernmentauthority,Court,Externaladvisor,RecipientoutsidetheEU/EEA,Similarthird-partythatarepublic
body,Serviceprovider
DC User,KiaConnectedGmbH,Personaldata,Kia,Log-indata,Locationdata(GPS),CerenceB.V.,Autoritéde
ProtectiondeDonnée,Gegevensbeschermingsautoriteit,Voicerecording
Lexus BC Personaldata,Postcode,Address,Personalinformation,Name,Telephonenumber,Emailaddress,VIN,Geo
location,Identityinformation
CC Us,Toyota,Authorisedstaffmember,Affiliateandsubsidiarycompany,ToyotaFinancialService,ToyotaInsur-
anceManagement,ToyotaInsuranceManager,Authorisedretailer,Authorisedrepairer,Personaldata
DC Personaldata,You,Us,Postcode,Address,ToyotaFinancialService,Personalinformation,Authorisedstaff
member,Affiliateandsubsidiarycompany,Memberofourauthorisedretailerandauthorisedrepairernetwork
Nissan BC Personaldata,Us,We,Ourpartner,YourFacebookwebsitebrowsingdata,Anonymisedstatisticaldata,Medical
personaldata,Dataprovideddirectly,Datarelatingtobrowsingourwebsite,Datarelatingtouseofourmobile
application,
CC Nissan,Anyauthoriseddealerorrepairer,Ourfinancialpartner,Us,Personaldata,Dealer,We,NissanAutomotive
EuropeS.A.S,NissanMotor(GB)Limited,NissanAutomotiveS.A.S
DC Personaldata,You,Unknown,Nissan,Anyauthoriseddealerorrepairer,Ourfinancingpartner,Us,Ourpartner,
NissanAutomotiveEuropeS.A.S,We,Dealer
Polestar BC PolestarApp,We,Personaldata,Phonenumber,Emailaddress,Yourinformation,VIN,Location,Contactinfor-
mation,Homeaddress
CC Analytic,We,Customersupport,Vehiclcontrol,Personaldata,Yourinformation,Polestarapp,Polestar,Business
partner,Subcontractor
DC Unkonwn,Analytic,Polestarapp,We,Customer,Personaldata,Customersupport,Vehiclcontrol,Phonenumber,
Emailaddress,
Renault BC Personaldata,Informationthatmakesitpossibletoidentifyyou,IPaddress,Cookie,You,RenaultGroup,Renault
CC RenaultGroup,Renault,Personaldata,Informationthatmakesitpossibletoidentifyyou,IPaddress,Cookie,
You,Unknown
DC You,Personaldata,RenaultGroup,Informationthatmakesitpossibletoidentifyyou,Unknown,IPaddress,
Renault,Cookie
Vauxhall BC Dataprocessor,Personaldata,We,Contactdetail,Ournetwork,Yourdata,Aggregatedinformation,Vehicledata,
Datainferredbyouractivity,Datacollectedbythebrowser
CC Us,StellantisEurope,Partner,We,Carmanufacturer,Thirdselectedpartner,Socialmediaplatform,Programmatic
advertisingplatform,Contactdetail,Ourwebsiteandapplication
DC Data,You,Us,Personaldata,We,Contactdetail,Partner,Yourdevice,StellantisEurope,Socialmediaplatform
BC:BetweennessCentrality,CC:ClosenessCentrality,DC:DegreeCentrality
Colourscheme:Datatypenodes,first-partynodes,third-partynodes,User-partynodes,Unknownnodes
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 28 ===
28
feeding shorter text segments to LLMs, we also
not ideal for extracting fine-grained data flows
senders/datareceiverswithdatatypes.Furtherw
andcontext-awaresegmentationstrategiesthatba
requiredfordetaileddata-flowextraction.
Moreover,asidentifiedinTable8,Renaulthas
Thisisabnormalcomparedtootherapps.Weman
appliesagenericapproachtodescribeitsdatah
whereonlygenerictermssuchas‘personaldata
aboutthetransparencyofitsprivacypolicies,sugg
orlackclarityinexplicitlyexplainingdata-handl
Summary. Overall,graphanalysisbasedonthe
canenhanceourunderstandingofdatacollection
Here,wesummarisetheinsightsobtainedfroms
• Bridgingroleofdatatypesinthedataflo
inmorethanhalfofapps),andspecificsen
Kia’s ‘voice recordings’, Nissan’s ‘medica
highlightingtheirrolesinfacilitatingconn
potentialprivacyrisksifcompromised.
• Third-party service providers’ depend
Vauxhall demonstrate heavy reliance on t
different network metrics, highlighting th
attacksurfaces.
• Cross-borderdatatransmission:Hyund
involvinginternationalentities.Thisraises
dataprotectionstandardsandlegislationam
• Corporate-groupcentralisedcontrol:Hy
control,with60-75%oftheirtop-closeness
heavyrelianceonthird-partyentitiesobse
morestandardiseddatagovernance.
• Transparencygaps:Renaulthas‘Unkno
lists.Withitsgenericapproachofdescribi
associatedprivacypolicy.
4.3.2 DataFlowandDataConsumerTypeAnaly
OEMs,Hondareportedthehighestnumberofda
Renaultreportedonlyfour(asillustratedinFigur
onthenumberofidentifieddataflowsischallen
inwritingstyleandlevelofdetail.Inaddition,h
data processing practices in reality is unknown
privacypolicyasasinglesourceforconductingth
privacypolicymaintainsaconsistentstyleand
frequencies(i.e.,relativeproportions)offirst-pa
Table4inSection3.3.1)acrossdifferentprivacyp
eachprivacypolicy,wecalculatedthefractionof
ofdataflows(valuesbetween0and1).Theresul
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
o noticed that supplying overly lengthy text is
s, as it can incorrectly associate unrelated data
workisthereforeneededtoexploremoredynamic
alancecontextualcompletenesswiththeprecision
onlythreeandfourdatatypenodes,respectively.
nuallyexamineditsprivacypolicy.ForRenault,it
handlingpracticesthroughouttheprivacypolicy,
a’or‘information’areused.Thisraisesconcerns
gestingthattheprivacypoliciesmaybeambiguous
lingpractices.
centralityofbetweenness,closeness,anddegrees
nandsharingpracticesstatedinprivacypolicies.
suchnetworkanalysesasfollows:
ownetwork:‘Personaldata’and‘VIN’(appearing
nsitivedata(e.g.,Honda’s‘maskedcardnumbers’,
al data’) exhibit high centrality of betweenness,
nectionsamongentitiesaswellasamplifyingthe
dencies: Audi, Ford, Nissan, Kia, Polestar, and
third-party partners/service providers based on
he complex accountability chains and potential
dai,Kia,andLexusshowcross-borderdataflows
sprivacyconcernswhentherearemismatchesin
mongdifferentregions.
yundaiandLexusdisplaytighterintra-organisational
nodesbeingaffiliatedentities.Differentfromthe
ervedinotherapps,thiscouldpotentiallyenable
own’nodesindifferentnetworkmetrics’topten
ingdataflows,itreflectsthetransparencyofits
ysis. AsshowninTable10,amongallautomotive
ataflows(asillustratedinFigure2(a)),whereas
re2(b)).Assessingprivacypracticessolelybased
ngingbecauseprivacypoliciesvarysignificantly
howwellaprivacypolicyalignswithitsactual
n. We acknowledge the limitations of using the
heanalysisalone.However,ifweassumethateach
structurethroughout,analysingthenormalised
arty,third-party,andincompletedataflows(see
policiescanstillprovidemeaningfulinsights.For
feachdataflowtyperelativetothetotalnumber
ltsaredepictedinTable10.

=== Page 29 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
Table10. Dataflowstatisticsac
Audi Ford Honda Hyunda
Numberofdataflows 56 109 348 65
First-partydataflow
User-partytofirst-party 0.17 0.19 0.38 0.20
First-partytofirst-party 0.04 0.11 0.01 0.25
Third-partytofirst-party 0.00 0.11 0.13 0.00
Total 0.21 0.41 0.52 0.45
Third-partydataflow
User-partytothird-party 0.11 0.36 0.30 0.14
First-partytothird-party 0.36 0.08 0.05 0.35
Third-partytothird-party 0.20 0.06 0.01 0.00
Total 0.66 0.51 0.36 0.49
Incompletedataflow 0.13 0.08 0.12 0.06
Valuesunder“Numberofdataflows”areabsolutecounts;allothernumeric
totaldataflowswithinthatOEM’sprivacypolicy.
Acrossalldataflows,eachappfollowsasimila
flowsisfromuser-partynodestofirst-partynodes
nodestofirst-partynodes.Overall,morethanhalf
hadanormalisedfrequencygreaterthan0.50ofth
Ford,Hyundai,Kia,andNissanhadvaluesaroun
evenlowerproportionsoffirst-partydataflows.
Noclearpatternemergedforthird-partydatafl
Vauxhall,Polestar)haveahigherproportionofda
whileothers(i.e.,Audi,Hyundai,andKia)havem
Overall,Audi,Ford,Kia,Lexus,andNissanhad
theirdataflowsclassifiedasthird-party,whilethe
forRenault.Moreover,regardingthepercentage
haveasignificantlyhigherproportionthanther
ambiguityintheirprivacypolicies.
To illustrate how such data can be used to g
differentprivacypolicies,weproposeageneralise
weights,aimingtoprovideindicativefiguresthat
intermsofpotentialrisksandtransparency.Th
contributionsofdifferentdataflowtypesandnorm
inEq.(9),thenumeratoroftheequationreprese
giveninstance𝑖,where𝑤 𝑗 istheweightforeachd
forinstance𝑖.Thedenominatoroftheequationc
maximumobservedvaluesofeachdataflowtyp
forthe 𝑗-thdataflowtypeacrossallinstances.F
computedbydividingtherawscorebythemaxim
(cid:205)𝑛
𝑆 norm,𝑖 = (cid:205)𝑛
𝑗=1
Itisworthnotingthattheselectionofdifferen
andjudgment.Theyareintendedforillustrativep
thesechosenweights.Forfirst-partydataflows,c
andterminateatfirst-partynodesareassumedto

DataFlowAnalysisinPrivacyPolicies 29
crossselectedautomotiveOEMs
ai Kia Lexus Nissan Polestar Renault Vauxhall
63 45 141 80 4 142
0.37 0.22 0.33 0.025 0.50 0.31
0.02 0.00 0.01 0.15 0.00 0.10
0.00 0.00 0.11 0.1 0.00 0.10
0.38 0.22 0.45 0.28 0.50 0.54
0.08 0.76 0.26 0.15 0.00 0.41
0.54 0.00 0.24 0.125 0.00 0.01
0.00 0.00 0.01 0.00 0.00 0.03
0.62 0.76 0.51 0.28 0.00 0.45
0.00 0.02 0.04 0.45 0.50 0.01
calvaluesrepresentnormalisedfrequenciesofeachdataflowtyperelativetothe
arpattern,wherethemajorityoffirst-partydata
s,whereasonlyasmallfractionisfromthird-party
fofthedataflowsinHonda,Renault,andVauxhall
heirdataflowsclassifiedasfirst-party.Incontrast,
nd0.40,whileAudi,Lexus,andPolestarshowed
flows.Someapps(i.e.,Ford,Honda,Lexus,Nissan,
ataflowingfromtheuser-partytothethird-party,
moreflowsfromthefirst-partytothethird-party.
morethanhalf(normalisedfrequency<0.50)of
eremainingappsfellbetween0.20and0.50,except
eofincompletedataflow,PolestarandRenault
remainingapps,indicatingpotentialunclearand
gain more comprehensive insights and compare
eddataflowriskscoreusingmax-normalisationof
canbeusedtocomparedifferentprivacypolicies
hescoreiscomputedbysummingtheweighted
malisingthescoretotherange[0,1].Asillustrated
entsthecalculationofarawprivacyscorefora
dataflowtypeand𝑋 𝑗,𝑖 isthecorrespondingvalue
calculatesthemaximumpossiblescoreusingthe
pe,wheremax(𝑋 𝑗)isthehighestvalueobserved
Finally,thenormaliseddataflowriskscorewas
mumpossiblescore:
𝑛
𝑗=1
𝑤
𝑗
·𝑋
𝑗,𝑖
(9)
1 𝑤 𝑗 ·max(𝑋 𝑗)
ntweightsbelowisbasedonourownexperience
purposes,andthesubsequentanalysisdependson
caseswheredataoriginatefromthird-partynodes
posemorerisks,asthedatahandlingpracticesof
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 30 ===
30
third-partyentitieslieoutsidethecontrolofboth
weightedscoresof1foruser-partytofirst-party
2.25forthird-partytofirst-partyflows.Forthir
thefollowingassumption:1foruser-partytoth
flows,and2.25forthird-partytothird-partyflow
incompletedataflowsposeagreaterriskthanbo
weassignaweightof1tooverallscoresoffirst-p
2.25toincompletedataflows.
Table11. Summaryof
APP1 APP2 APP3
Scoreforfirst-partydataflows 0.20 0.52 0.59
Scoreforthird-partydataflows 0.54 0.31 0.24
Overallscore 0.54 0.49 0.47
Itisimportanttoacknowledgethatprivacyisa
fullycapturedusingquantitativeorqualitativeran
evenharmful,ifnotconsideredalongsidebroader
iswhywechosetoanonymiseapps’namesinth
illustratemethodologicalinsightsratherthantos
risks.
AsreportedinTable11,ahigherscorerepres
APP4, APP7, APP9, and APP10 have relatively
between0.43and0.59)thantheirscoresforthird-
andAPP8havehigherriskscoresforthird-party
(i.e.,0.54),followedcloselybyAPP5andAPP6wit
notingthatAPP9hasascoreof0.00,indicatingn
absenceofsuchdataflows.ThisisshowninFigu
broadandlacksthegranularityneededtobetter
practices.
Inaddition,withthecontributionofincomplete
APP8,andAPP9hadthehighestscores,approx
theirhigherpercentageofincompletedataflows,
inprivacypolicies.Thisisalsoinlinewiththe
presentedinSection4.3.1,wheretheyweresing
theirdependencyonthird-partyentitiesandpriv
scoresfortheremainingappsfelljustbelow0.50
orclearerdatahandlingpracticesstatedintheir
4.3.3 DataCategoryandDataProcessingPurpo
basedprocessoristofurtherclassifydatatypes
inknowledgetypology𝐾𝑇 toallowmorein-
data
standsoutwiththehighestnumberofdatatypes
moredatatypes,particularlyincategoriessucha
(18),‘Location’(13),and‘Finance’(17),indicating
trackingandfinancialtransactions.However,A
collectedsignificantlylessdataacrossmostdata-t
categorycontainsdatatypesthatcannotbecatego
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
husersandfirstparties.Toreflectthis,weapply
flows,1.5forfirst-partytofirst-partyflows,and
rd-partydataflows,weapplyweightsbasedon
hird-partyflows,1.5forfirst-partytothird-party
ws.Fortheoverallprivacyscores,weassumethat
oththird-partyandfirst-partydataflows;hence,
partydataflows,1.5tothird-partydataflows,and
fdataflowriskscores
APP4 APP5 APP6 APP7 APP8 APP9 APP10
0.49 0.33 0.19 0.51 0.41 0.43 0.50
0.33 0.44 0.38 0.32 0.17 0.00 0.25
0.48 0.47 0.51 0.47 0.61 0.58 0.49
acomplexandmultifacetedconceptthatcannotbe
nkingsalone.Suchmeasurescanbemisleading,or
legal,organisational,andcontextualfactors.That
hispartoftheanalysis,asitismainlyintendedto
systematicallyandcomprehensivelyrankprivacy
sentshigherdataflow-relatedrisks.APP2,APP3,
higher risk scores for first-party data flow (i.e.,
-partydataflows.Incontrast,APP1,APP5,APP6,
ydataflows,withAPP1havingthehighestrisk
thscoresof0.44and0.38,respectively.Itisworth
nothird-partydataflowrisks,whichisduetothe
ure2,suggestingthattheprivacypolicyisoverly
rinformusersabouttheirgeneraldatahandling
edataflowstotheoverallriskscores,APP1,APP6,
ximatelybetween0.51and0.61.Thisalignswith
,indicatingambiguityandalackoftransparency
observationsobtainedfromthegraphanalysis
gledoutforpotentialprivacyconcernsrelatedto
vacypolicytransparencyissues.Theoverallrisk
0,indicatingthattheseappshaverelativelybetter
privacypoliciesfromthedataflowperspective.
oseAnalysis. OneofthemaintasksfortheLLM-
intodatacategoriesbasedonthedefinitionsset
-depthanalysis.AsdepictedinTable12,Honda
sacrossalmostalldatacategories.Hondacollects
as‘Onlineidentifiers’(25),‘Useronlineactivities’
gitsbroaddataprocessingrelatedtoonlineuser
Audi,Kia,Lexus,Polestar,Renault,andVauxhall
typecategories.Inaddition,the‘Other’datatype
orisedusingtheothercategorieslistedinthetable.

=== Page 31 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
Bymanuallyinspectingthisdatacategory,itm
‘vehicledata’,‘braking’and‘DTC(DiagnosticTr
(e.g.,‘reasonforyourRoadsideAssistancecall’,‘t
Table12. Datacategorydistributiona
DataCategory Audi Ford Honda Hyundai
GenericPersonalInfo 1 5 7 4
PersonalIDIdentifier 1 3 4 0
OnlineIdentifier 2 3 25 0
UserOnlineActivities 9 5 18 0
UserProfile 0 1 1 0
Contact 1 7 8 2
Demographic 0 3 13 2
BiometricInformation 0 0 1 0
Location 1 15 13 0
Finance 0 2 17 0
Health 0 1 0 0
CriminalRecords 0 2 0 0
DeviceInformation 2 6 11 1
Other 7 9 60 5
Certaindatacategories,suchas‘Profile’,‘Biom
nalRecords’,exhibitclearvariationsbetweenapp
apps,includingHonda(i.e.,voicecommand),Kia
soundorimagesfiles),Nissan(i.e.,voicerecordi
Renault(i.e.,informationthatmakesitpossibleto
collectedbyHonda(e.g.,taxcode,paymentcard
mation)andNissan(e.g.,purchasinghistory,pa
ordernumber).‘Health’dataprocessingforNissan
onlycompanythatexplicitlyclaimsacollection
numbersandvehicletheftinformation.Regarding
Hondarecordsinformationabouttheprimaryuse
andVauxhallclaimstheprocessingofgeneralprofi
acrossappspresentedinTable12indicatevarying
policies,withsomeappsexplicitlydetailingspeci
oromitsuchdisclosures.
Furthermore,wewereinterestedinhowdiffer
dataprocessingpurposes.Toachievethis,wehan
collectedandsharedbytwo-thirdsoftheappsa
purposesacrossdifferentdatacategoriescollectiv
categoriesarelinkedtomultiplepurposesofdat
multifunctionalrolethatpersonaldataplaysint
needsandbroaderobjectives.
Amongalldatacategories,‘OperationalIntegri
dataprocessingpurposeacrossmostdatacatego
definition,makingitapplicabletoawiderangeo
‘LegalRequirement’areconsistentlyprominent
‘OperationalIntegrityandSecurity’,thismightme
underpinmuchoftheidentifieddatacategories.

DataFlowAnalysisinPrivacyPolicies 31
mostlycontainsvehicle-relateddata(e.g.,‘speed’,
roubleCode)history’)andotherunspecifieddata
timestampofthegeneratedsecurityevent’).
acrossselectedautomotivecompanies
Kia Lexus Nissan Polestar Renault Vauxhall
3 3 9 5 1 2
2 1 2 1 0 0
3 1 4 7 2 6
2 0 12 7 0 6
0 0 1 0 0 1
2 4 4 5 0 5
0 1 4 5 0 2
2 1 1 0 1 0
10 1 1 8 0 1
0 0 12 5 0 0
0 0 1 3 0 0
0 0 0 0 0 0
2 0 1 9 0 5
6 3 17 10 0 7
metricInformation’,‘Finance’,‘Health’,and‘Crimi-
ps.‘BiometricInformation’iscollectedbymultiple
a(i.e.,voicerecording,voicesamples),Lexus(i.e.,
ingsfromcallsbetweenyouandthedealer),and
oidentifyyou).Abroadrangeof‘Finance’datais
ddata,PAN,cardholdername,transactioninfor-
aymentmethod,discountgranted,orderhistory,
nismedicalpersonaldata.Meanwhile,Fordisthe
of‘CriminalRecords’,includingcrimereference
g‘UserProfile’data,Fordcollectsprofilepictures,
er,Nissancollectsusernamesandprofilingdetails,
filedata.Overall,thedifferencesindataprocessing
glevelsofspecificityandtransparencyinprivacy
ificdatatypes,whileothersremainmoregeneral
rentdatacategoriesareassociatedwithdifferent
nd-pickeddatacategoriesthatwereclaimedtobe
andexaminedthedistributionofdataprocessing
vely.Overall,asshowninFigure4,almostalldata
taprocessingtosomeextent.Thishighlightsthe
theautomotivecontext,servingbothoperational
ityandSecurity’isthemostfrequentlyassociated
ories.Thisispartlyduetoitsgeneralandbroad
ofdataflows.Inaddition,dataprocessingpurpose
tacrossmostofdatacategories.Combinedwith
eanthatlegalandcompliance-basedjustifications
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 32 ===
32 Yuanetal.
1
0.8
0.6
0.4
0.2
0
Conta D ct e s mog D r G a e p e v h n ic i e c e r s i i c nf p o e r r m so a n ti a o l n infor mation Loca O t n io l n ine U id s e e n r t o P ifi n e e l r i r s n o e n a a c l t i i d v e it n ie ti s tyidentifier
noitroporP AdditionalServiceorFeature Advertising
AnalyticsorResearch BasicServiceorFeature
LegalRequirement Marketing
Merger/Acquisition OperationalIntegrityandSecurity
PersonalData SocialMediaIntegration
Fig.4. Distributionofdataprocessingpurposesacrossdifferentdatacategories.
Moreover,multipledatacategoriessuchas‘Contacts’,‘GenericPersonalInformation’,‘Location’,
‘OnlineIdentifier’,‘UserOnlineActivities’and‘DeviceInformation’standoutwithadiversespread,
wheretheyarefrequentlyassociatedwithawiderangeofdataprocessingpurposes,indicatingtheir
multiplerolesinthedataprocessing.Forinstance,‘Contacts’,itsassociationwithmultipledata
processingpurposessuggestsitsdualroleinbothfunctional(i.e.,basicservice,communication)and
business-orienteduses(i.e.,marketingandpromotion).‘Location’,‘DeviceInformation’,‘Online
Identifier’,and‘UserOnlineActivities’showthestronglinktothepurpose‘AnalyticsorResearch’,
reflectingtheiradditionalroleinpossiblebehaviouralprofilingandserviceoptimisation.
The processing of ‘Personal Identity Identifier’ category is commonly linked with purposes
including‘BasicServiceorFeature’,‘LegalRequirement’,‘Marketing’,and‘Merger/Acquisition’,
in addition to ‘Operational Integrity and Security’, indicating the broad scale of sensitive data
processing,andraisingpotentialprivacyconcernsaboutoversharingpersonalsensitivedata.
Ingeneral,mappingdataprocessingpurposestodatacategoriesprovidesinsightintothecollec-
tivebehaviourofdata-handlingpracticeswithintheautomotiveindustry.Thisfurtherconfirms
andraisespotentialconcernsaboutnecessarydataminimisation,excessivedataretention,and
potential secondary use. Moreover, it would be interesting to take privacy policies from other
domainsandconductcross-sectorcomparisonstudies;however,thisisoutofthescopeofthis
paperandcouldbeaninterestingtopicaspartofourfuturework.
4.3.4 Cross-CheckwithAdditionalDataSources. Althoughprivacypoliciesaresubjecttolegal
requirementstodisclosedata-handlingpractices,theextenttowhichtheyprovideaccurateinfor-
mationisunclear.Hence,weneedothersourcesofinformationtocross-checktheresults.Tothis
end,wevisitedtheGooglePlay(i.e.,Android)apps’datasafetysections16andtheAppleiOSapps’
privacylabels17,wherebothrequireappdeveloperstodiscloseinformationaboutmobileapps’
datacollectionanddatasharingpractices.
AsshowninTables13and14inSection6,acrossallselectedmobileapps,disclosuresviaboth
theGooglePlayapps’datasafetysectionsandAppleiOSapps’privacylabelscontradictthedata
16https://support.google.com/googleplay/answer/11416267
17https://developer.apple.com/app-store/app-privacy-details/
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 33 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
practices stated in their associated privacy poli
appcollectsfinancialdataasstatedinitsprivac
Playapp’sdatasafetysectionandAppleiOSap
mobileapp,therearenoticeableinconsistenciesin
Google Play’s app safety section and Apple iOS
doesnotcollectanydataaccordingtoitsApple
ofpersonalinformationarecollectedbasedonit
suggestthat1)mobiledevelopersmaybeneglig
practices;2)thereisalackofaclearunderstand
asignificantdiscrepancyindatasecurityandpr
apps. These observations highlight the difficult
whilealsorevealingtheunreliabilityofGooglePl
privacylabels.Thesignificantdiscrepanciesbetw
theextenttowhichconsumersand,perhaps,eve
andgranularityofdata-handlingpractices.Howev
scopeofthisstudy,butitisworthinvestigatingi
5 LimitationsandFutureWork
Onelimitationofthisworkistheverificationpro
specificallydesignedforextractingdataflowsfro
evaluation.Thisstudyreliedonlyonmanualve
theextractedinformation.Whilethishelpsconfi
inherentlylimitsourabilitytobenchmarktheresu
weplantoutiliseLLMsteamingwithhumanuser
partofourfuturework.Inaddition,weacknowled
canintroducepotentialbiases,whichcouldpoten
thevalidationresults.Toaddressthislimitation
validationstudywithrecruitedhumanparticipant
ItisalsoimportanttoacknowledgethatLLMs
butalsoforthepre-processoranddataflowpost-p
LLMscouldbeutilisedtoassistinrefininginput
discovery.However,inthisstudywerestrictedth
analyserrepresentsthemostcomplexanddema
ofintegratingLLMsareexpectedtobemostpro
focusondemonstratingthefeasibilityandeffecti
Futureresearchcouldexploreandevaluatetheus
framework.
Moreover,weconsiderthattheconstructionof
tationisanotherlimitationofthiswork,sinceth
theresultsgeneratedbytheLLMs.Ourfindings
canleadtoambiguousandincorrectoutputsfro
andpassive/automaticdataprocessingareinher
forhumanreaders,theinterpretationsofthesam
thisend,wewouldrecommendthatknowledgeb
enhanceclarityandimprovethereliabilityofLLM
hallucinations.
AsintroducedinSection3.1.3,LLMsprocess
tasks.Thisapproachmayoverlookcross-paragra

DataFlowAnalysisinPrivacyPolicies 33
icies. For instance, the NissanConnect Services
cypolicy,butitfailstodeclarethisinitsGoogle
pps’privacylabels.Moreover,evenforthesame
ndatacollectionandsharingdisclosuresbetween
S apps’ privacy labels. For instance, Audi’s app
iOSapp’sprivacylabels,whereasseveraltypes
tsGooglePlayapp’ssafetydescription.Thismay
gentinaccuratelyreportingtheirdata-handling
dingoftheregulatorylandscape;and3)thereis
rivacybetweenGooglePlayappsandAppleiOS
ty in verifying the accuracy of privacy policies,
layapps’datasafetysectionsandAppleiOSapps’
weendifferentdatasourcesraiseconcernsabout
endeveloperscantrulyunderstandthefullscope
ver,systematicallyaddressingtheseisbeyondthe
infuturestudies.
ocess.Thelackofanexistingground-truthdataset
omtextpreventsusfromconductingalarge-scale
erificationinvolvinghumanverifierstovalidate
firmandensuretheaccuracyofourmethods,it
ultswithothermethods.Toaddressthislimitation,
rstoco-curatededicatedgroundtruthdatasetsas
dgethatrelyingonthreeco-authorsasevaluators
ntiallyaffectthegeneralisabilityandrobustnessof
n,weareplanningtoconductamoreindependent
tsaspartofourfuturework.
scouldbeemployednotonlywithintheanalyser
processoroftheproposedframework.Forinstance,
tformat,segmentingtext,orenhancinginsights
heuseofLLMstotheanalysercomponent,asthe
andingstageofthepipeline,wherethebenefits
omising.Whilethisdesignchoiceallowedusto
ivenessofLADFA,italsoconstitutesalimitation.
seofLLMstosupporttoothercomponentsofthe
ftheknowledgebasesusedintheRAGimplemen-
heaccuracyoftheseknowledgebasescanaffect
sdemonstratethatvagueoruncleardefinitions
omLLMs.Forinstance,conceptssuchasactive
rentlydifficulttodefinewithgreatclarity.Even
metextbydifferentpeoplewouldbedifferent.To
basesshouldbeco-createdwithdomainexpertsto
Ms’outputswhilealsohelpingtoreducetheriskof
textsegmentssequentiallytocompleteasetof
aph(i.e.,cross-segment)information,potentially
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 34 ===
34
leadingtounreliableorincompleteoutputsfrom
tasksuchasextractingdataflows,feedingthee
1)thelossofgranularitycomparedtoourcurren
segmentsand2)incorrectassociationofunrela
Nevertheless,wewouldliketoemphasisethatwe
byusingparagraph-basedtextsegmentation,add
addingatableheaderrowtoeachtablerowfor
wewouldrecommendthatfurtherresearchisneed
approach with considerations of cross-paragraph
fine-grainedtasksand2)exploreotherapproache
knowledgeaugmentedgeneration(KAG)[30].
Furthermore, our current network graphs of
corporategroupsandthirdparties.Itwouldbeus
withexistingtools(e.g.,NetVizCorpy[4],atoolth
graphsusingWikidata)toenrichandexpandth
morecomprehensiveviewofinter-organisational
wellashelpingvalidatingtheoutputsgenerated
Last but not least, while this work focuses on
industry,theaimistodemonstrateitscapabilitya
usingLLMswithRAG.Wewouldalsoliketohigh
privacypoliciesbutalsogeneralisableandadaptabl
domains.Additionally,manyoftheparts,suchas
bases,andLLM-basedagentsintheproposedfram
taskstoprovidebetterflexibilityandgeneralisability
ofLADFAtodifferenttypesofdocumentsanddi
6 Conclusion
Thispaperreportsourworkondevelopingande
automatingprivacypolicyanalysisusingLLMsa
LLM-basedprocessor,andadataflowpost-proce
convertingandsegmentingHTML-basedtextan
severalLLMagentstoanalyseprivacypolicytext
and3)post-processLLMs’outputsandutilised
privacy-relatedinsights.Todemonstratetheuseful
weconductedacasestudyinvolvingtheanalysis
vehicle mobile apps. The results show that LAD
privacypoliciesandextractkeyinformationtogen
privacyinsightsthatmayrequireconsiderableti
References
[1] BenjaminAndow,SaminYaseerMahmud,WenyuWang
andTaoXie.2019.PolicyLint:InvestigatingInternalPri
the28thUSENIXSecuritySymposium.USENIXAssociatio
ty19/presentation/andow
[2] BenjaminAndow,SaminYaseerMahmud,JustinWhit
Egelman.2020. ActionsSpeakLouderthanWords:En
18https://www.anthropic.com/news/contextual-retrieval
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
mLLMs.However,wefoundthatforagranular
entireprivacypolicyastheinputwouldleadto
ntapproachofsequentiallyfeedingsmallertext
ateddatasenders/datareceiverswithdatatypes.
ealsomadesomeeffortstomitigatethislimitation
dingheadingstobulletpoint-basedsegments,and
additionalcontextualinformation.Inanutshell,
dedto1)determinetheoptimaltextsegmentation
contexts to improve LLMs’ performance on such
esbeyondRAGsuchascontextual-retrieval18 and
f data flows reveal strong connections between
sefultoallowtheproposeframeworktointegrate
hatreconstructsbusiness-to-businessrelationship
hescopeofournetworkanalysisbyprovidinga
ldataflowsextractedfromotherdatasources,as
byLADFA.
n analysing privacy policies for the automotive
andeffectivenessofconductingcomplicatedtasks
hlightthatLADFAisnotonlycapableofanalysing
leforexamininganytext-baseddocumentsforother
sthetextsegmentationtool,domainknowledge
mework,canbeupdatedandcustomisedfordifferent
y.Inourfuturework,wewillexploreapplications
ifferenttasks.
evaluatinganend-to-endframework,LADFA,for
andRAG.LADFAconsistsofapre-processor,an
essor.Itcan1)preprocessprivacypolicytextsby
ndconstructinglocalknowledgebases;2)utilise
tsegmentsandextractcomprehensivedataflows;
dataflowgraphstodiscoverdataprotectionand
lnessandeffectivenessoftheproposedframework,
sofprivacypoliciesfromtenselectedconnected
DFA can effectively and accurately understand
neratecomprehensivedataflows,aswellasreveal
imeforconsumerstoreadandcomprehend.
g,JustinWhitaker,WilliamEnck,BradleyReaves,KapilSingh,
ivacyPolicyContradictionsonGooglePlay.InProceedingsof
on,585–602. https://www.usenix.org/conference/usenixsecuri
taker,WilliamEnck,BradleyReaves,KapilSingh,andSerge
ntity-SensitivePrivacyPolicyandDataFlowAnalysiswith

=== Page 35 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
PoliCheck.InProceedingsofthe29thUSENIXSecuritySy
ix.org/conference/usenixsecurity20/presentation/andow
[3] VinayshekharBannihattiKumar,RogerIyengar,Nami
Cherivirala,MargaretHagan,LorrieCranor,ShomirW
ChoiceinaHaystack:AutomaticExtractionofOpt-Ou
WebConference2020.ACM,1943–1954.doi:10.1145/3366
[4] ZsofiaBaruwa,HaiyueYuan,ShujunLi,andZhenZhu.2
WithWikidata:TheCaseofElectricVehicleIndustry.Glo
1/glob.70029
[5] RahimeBelenSaglam,JasonR.C.Nurse,andDuncanH
evolution.JournalofInformationSecurityandApplicatio
103163
[6] JaspreetBhatiaandTravisD.Breaux.2017.ADataPurp
IEEE25thInternationalRequirementsEngineeringConfer
[7] TomB.Brown,BenjaminMann,NickRyder,MelanieSu
PranavShyam,GirishSastry,AmandaAskell,SandhiniA
RewonChild,AdityaRamesh,DanielM.Ziegler,Jeffrey
Sigler,MateuszLitwin,ScottGray,BenjaminChess,JackC
Sutskever,andDarioAmodei.2020.LanguageModelsa
ConferenceonNeuralInformationProcessingSystems.Cur
s.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac
[8] DucBui,KangGShin,Jong-MinChoi,andJunbumShin.2
inPrivacyPolicies.ProceedingsonPrivacyEnhancingTech
[9] DucBui,YuanYao,KangG.Shin,Jong-MinChoi,andJun
inMobileApps.InProceedingsofthe2021ACMSIGSAC
2824—-2843.doi:10.1145/3460120.3484536
[10] JenCaltrider,MishaRykov,andZoëMacDonald.2023.I
ReviewedforPrivacy. https://www.mozillafoundation.o
worst-product-category-we-have-ever-reviewed-for-pr
[11] FredH.Cate.2010.TheLimitsofNoticeandChoice.IEEE
[12] BaiqiChen,TingminWu,YanjunZhang,MohanBaruw
UnderstandingofPrivacyPoliciesofVirtualPersonalA
ConferenceonComputerandCommunicationsSecurity.A
[13] YuxinChen,PengTang,WeidongQiu,andShujunLi.
PromptEngineering,Fine-TuningandExplainability.12p
[14] CaitlinD.CottrillandPiyushimita‘Vonu’Thakuriah.2013
tolocationprivacyprotection.InternationalJournalofL
093/ijlit/eat014
[15] HaoCui,RahmadiTrimananda,AthinaMarkopoulou,a
AnalysisusingKnowledgeGraphs.InProceedingsoft
1037–1054. https://www.usenix.org/conference/usenixs
[16] BenjaminFabian,TatianaErmakova,andTinoLentz.2
Proceedingsofthe2017InternationalConferenceonWebI
[17] AlvanR.FeinsteinandDomenicV.Cicchetti.1990.High
JournalofClinicalEpidemiology43,6(1990),543–549.d
[18] YunfanGao,YunXiong,XinyuGao,KangxiangJia,Jinl
Wang.2024.Retrieval-AugmentedGenerationforLarge
arXiv:2312.10997[cs.CL]
[19] ShahramGhahremaniandUyenTrangNguyen.2024
contextualintegrityframework.SecurityandPrivacy7,
[20] ArdaGoknil,FemkeB.Gelderblom,SimeonTverdal,S
throughpromptengineeringforLLMs.doi:10.48550/arX
[21] KilemLiGwet.2008. Computinginter-raterreliability
Math.Statist.Psych.61,1(2008),29–48.doi:10.1348/0007
[22] KevinA.Hallgren.2012.ComputingInter-RaterReliabilit
inQuantitativeMethodsforPsychology8,1(2012),23–34

DataFlowAnalysisinPrivacyPolicies 35
ymposium.USENIXAssociation,985–1002. https://www.usen
w
itaNisal,YuanyuanFeng,HanaHabib,PeterStory,Sushain
Wilson,FlorianSchaub,andNormanSadeh.2020. Findinga
utStatementsfromPrivacyPolicyText.InProceedingsofThe
6423.3380262
2025.ConstructingandAnalysingGlobalCorporateNetworks
obalNetworks25,4,Articlee70029(2025),17pages.doi:10.111
Hodges.2022. Personalinformation:Perceptions,typesand
ons66,Article103163(2022),31pages.doi:10.1016/j.jisa.2022.
poseCaseStudyofPrivacyPolicies.InProceedingsofthe2017
rence.IEEE,394–399.doi:10.1109/RE.2017.56
ubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,
Agarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,
yWu,ClemensWinter,ChristopherHesse,MarkChen,Eric
Clark,ChristopherBerner,SamMcCandlish,AlecRadford,Ilya
areFew-ShotLearners.InProceedingsofthe34thInternational
rranAssociatesInc.,Article159,25pages. https://proceeding
c142f64a-Paper.pdf
2021.AutomatedExtractionandPresentationofDataPractices
hnologies2021,2(2021),88–110.doi:10.2478/popets-2021-0019
nbumShin.2021.ConsistencyAnalysisofData-UsagePurposes
ConferenceonComputerandCommunicationsSecurity.ACM,
It’sOfficial:CarsAretheWorstProductCategoryWeHaveEver
org/en/privacynotincluded/articles/its-official-cars-are-the-
rivacy/Accessed:2025-07-27.
ESecurity&Privacy8,2(2010),59–62.doi:10.1109/MSP.2010.84
walChhetri,andGuangdongBai.2023. InvestigatingUsers’
AssistantApplications.InProceedingsofthe2023ACMAsia
ACM,65–79.doi:10.1145/3579856.3590335
.2025. UsingLLMsforAutomatedPrivacyPolicyAnalysis:
pages.doi:10.48550/arXiv.2503.16516arXiv:2503.16516[cs.CL]
3.Privacyincontext:anevaluationofpolicy-basedapproaches
LawandInformationTechnology22,2(2013),178–207.doi:10.1
andScottJordan.2023.PoliGraph:AutomatedPrivacyPolicy
the32ndUSENIXSecuritySymposium.USENIXAssociation,
security23/presentation/cui
2017. Large-scalereadabilityanalysisofprivacypolicies.In
Intelligence.ACM,18–25.doi:10.1145/3106426.3106427
hagreementbutlowKappa:I.Theproblemsoftwoparadoxes.
doi:10.1016/0895-4356(90)90158-L
liuPan,YuxiBi,YiDai,JiaweiSun,MengWang,andHaofen
eLanguageModels:ASurvey.doi:10.48550/arXiv.2312.10997
4. Comprehensiveevaluationofprivacypoliciesusingthe
4,Articlee380(2024),26pages.doi:10.1002/spy2.380
ShukunTokas,andHuiSong.2024. Privacypolicyanalysis
Xiv.2409.14879arXiv:2409.14879[cs.CL]
yanditsvarianceinthepresenceofhighagreement. Brit.J.
711006X126600
tyforObservationalData:AnOverviewandTutorial.Tutorials
4.doi:10.20982/tqmp.08.1.p023
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 36 ===
36
[23] HamzaHarkous,KassemFawaz,RémiLebret,FlorianSch
AnalysisandPresentationofPrivacyPoliciesUsingDeep
USENIXAssociation,531–548. https://www.usenix.org
[24] LeiHuang,WeijiangYu,WeitaoMa,WeihongZhong,Zh
XiaochengFeng,BingQin,andTingLiu.2024. ASurv
Taxonomy,Challenges,andOpenQuestions.ACMTrans
doi:10.1145/3703155
[25] BowenJin,JinsungYoon,JiaweiHan,andSercanO.Arik.
forLongInputsinRAG.doi:10.48550/arXiv.2410.05983
[26] HaileyJoren,JianyiZhang,Chun-SungFerng,Da-Cheng
text:ANewLensonRetrievalAugmentedGenerationSys
[27] SimonLeigh,JingOuyang,andChrisMimnagh.2017
frameworktoevaluateappsforchronicinsomniadis
doi:10.1136/eb-2017-102751
[28] PatrickLewis,EthanPerez,AleksandraPiktus,FabioPe
MikeLewis,Wen-tauYih,TimRocktäschel,SebastianRie
forKnowledge-IntensiveNLPTasks.InProceedingsofthe
Systems,Vol.33.CurranAssociates,Inc.,9459–9474. htt
3230205f780e1bc26945df7481e5-Paper.pdf
[29] YunxuanLi,PascalHirmer,andChristophStach.2023.CV
ConnectedVehicles.InProceedingsofthe2023IEEEInterna
WorkshopsandotherAffiliatedEvents.IEEE,583–588.do
[30] LeiLiang,MengshuSun,ZhengkeGui,ZhongshuZhu,Zh
JinYang,HuaidongXiong,LinYuan,JunXu,ZaoyangW
Chen,andJunZhou.2024. KAG:BoostingLLMsinPro
doi:10.48550/arXiv.2409.13731
[31] ThomasLinden,HamzaHarkous,andKassemFawaz.202
onPrivacyEnhancingTechnologies2020(2020),47–64.d
[32] JerryLiu.2022.LlamaIndex.doi:10.5281/zenodo.1234
[33] NathanMalkin.2023.ContextualIntegrity,Explained:A
(2023),58–65.doi:10.1109/MSEC.2022.3201585
[34] KirstenMartinandHelenNissenbaum.2016. Measu
ConfoundingVariables.ColumbiaScienceandTechnology
[35] AleeciaM.McDonaldandLorrieFaithCranor.2008.Th
PolicyfortheInformationSociety4,3(2008),543–568. h
[36] KeikaMori,DaikiIto,TakumiFukunaga,TakuyaWatan
EvaluatingLLMsTowardsAutomatedAssessmentofP
SymposiumonUsableSecurityandPrivacy.19pages.do
[37] AbhijithAthreyaMysoreGopinath,ShomirWilson,and
forRobustSeparationofSectionTitlesandProseText
EmpiricalMethodsinNaturalLanguageProcessing.ACL,
[38] HelenNissenbaum.2009.PrivacyinContext:Technolog
Press,RedwoodCity.doi:10.1515/9780804772891
[39] HelenNissenbaum.2011.AContextualApproachtoPriv
_a_00113
[40] HelenNissenbaum.2019.ContextualIntegrityUpandD
(2019),221–256.doi:10.1515/til-2019-0008
[41] AlessandroOltramari,DhivyaPiraviperumal,FlorianSch
N.CameronRussell,PeterStory,JoelReidenberg,andN
analysisofprivacypolicies.SemanticWeb9,2(2018),18
[42] OrenRachmil,RoyBetser,ItayGershon,OmerHofma
YuvalElovici,andRomanVainshtein.2025.Training-Fre
inLLMs.doi:/10.48550/arXiv.2512.03994arXiv:2512.039
[43] JulieM.Robillard,TanyaL.Feng,ArloB.Sporn,Jen-AiL
readability,andcontentofprivacypoliciesandtermsof
Article100243(2019),8pages.doi:10.1016/j.invent.2019
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
haub,KangG.Shin,andKarlAberer.2018.Polisis:Automated
pLearning.InProceedingsof27thUSENIXSecuritySymposium.
g/conference/usenixsecurity18/presentation/harkous
hangyinFeng,HaotianWang,QianglongChen,WeihuaPeng,
veyonHallucinationinLargeLanguageModels:Principles,
sactionsonInformationSystem43,2,Article42(2024),50pages.
2024.Long-ContextLLMsMeetRAG:OvercomingChallenges
arXiv:2410.05983[cs.CL]
Juan,AnkurTaly,andCyrusRashtchian.2025.SufficientCon-
stems.doi:10.48550/arXiv.2411.06037arXiv:2411.06037[cs.CL]
7. Effective?Engaging?Secure?ApplyingtheORCHA-24
sorder. BMJMentHealth20,4,Articlee20(2017),7pages.
etroni,VladimirKarpukhin,NamanGoyal,HeinrichKüttler,
edel,andDouweKiela.2020.Retrieval-AugmentedGeneration
e34thInternationalConferenceonNeuralInformationProcessing
tps://proceedings.neurips.cc/paper_files/paper/2020/file/6b49
V-Priv:TowardsaContextModelforPrivacyPolicyCreationfor
ationalConferenceonPervasiveComputingandCommunications
oi:10.1109/PerComWorkshops56833.2023.10150231
houyuJiang,LingZhong,YuanQu,PeilongZhao,ZhongpuBo,
Wang,ZhiqiangZhang,WenZhang,HuajunChen,Wenguang
ofessionalDomainsviaKnowledgeAugmentedGeneration.
20.ThePrivacyPolicyLandscapeAftertheGDPR.Proceedings
doi:10.2478/popets-2020-0004
MoreUsablePrivacyDefinition.IEEESecurity&Privacy21,1
uringPrivacy:AnEmpiricalTestUsingContexttoExpose
yLawReview18,1(2016),176–218.doi:10.7916/stlr.v18i1.4015
heCostofReadingPrivacyPolicies.I/S:AJournalofLawand
http://hdl.handle.net/1811/72839
nabe,YutaTakata,MasakiKamizono,andTatsuyaMori.2025.
PrivacyPolicyUnderstandability.InProceedingsofthe2025
oi:10.14722/usec.2025.23009
NormanSadeh.2018.SupervisedandUnsupervisedMethods
inWebDocuments.InProceedingsofthe2018Conferenceon
,850–855.doi:10.18653/v1/D18-1099
gy,Policy,andtheIntegrityofSocialLife.StanfordUniversity
vacyOnline.Daedalus140,4(2011),32–48.doi:10.1162/DAED
DowntheDataFoodChain.TheoreticalInquiriesinLaw20,1
haub,ShomirWilson,SushainCherivirala,ThomasB.Norton,
NormanSadeh.2018.PrivOnto:Asemanticframeworkforthe
85–203.doi:10.3233/SW-170283
an,NitayYakoby,YuvalMeron,IdanYankelev,AsafShabtai,
eePolicyViolationDetectionviaActivation-SpaceWhitening
994[cs.LG]
Lai,CodyLo,MonicaTa,andRolandNadler.2019.Availability,
fagreementsofmentalhealthapps.InternetInterventions17,
9.100243

=== Page 37 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
[44] DavidRodriguez,IanYang,JoseM.DelAlamo,andNorm
privacypolicyanalysisatscale.Computing106(2024),3
[45] PranabSahoo,AyushKumarSingh,SriparnaSaha,Vinija
SurveyofPromptEngineeringinLargeLanguageModels
arXiv:2402.07927[cs.AI]
[46] RohanCharudattSalvi,CatherineBlake,andMasooda
forFine-GrainedInformationExtractionoverPrivacyP
Conference,iConference2024,Changchun,China,April15–
3-031-57850-2_17
[47] AlirezaSavandandAaronSwartz.2025.html2text:Conve
r3z4/html2text/
[48] FlorianSchaub,TravisD.Breaux,andNormanSadeh.2016
andbestpractices.it-InformationTechnology58,5(201
[49] SanderSchulhoff,MichaelIlie,NishantBalepur,Konstan
Gupta,HyoJungHan,SevienSchulhoff,PranavSandee
ChauPham,GersonKroiz,FeileenLi,HudsonTao,Ash
Rogers,InnaGoncearenco,GiuseppeSarli,IgorGalyn
Anadkat,AlexanderHoyle,andPhilipResnik.2024.TheP
doi:10.48550/arXiv.2406.06608arXiv:2406.06608[cs.CL]
[50] MukundSrinath,ShomirWilson,andC.LeeGiles.20
WebPrivacyPolicies.InProceedingsofthe59thAnnual
the11thInternationalJointConferenceonNaturalLan
doi:10.18653/v1/2021.acl-long.532
[51] StateofCalifornia,USA.2004.CaliforniaOnlinePrivacy
slature.ca.gov/faces/codes_displayText.xhtml?division=
[52] StateofCalifornia,USA.2020.CaliforniaConsumerPriv
ov/faces/codes_displayText.xhtml?division=3.&part=4.&
[53] ChenhaoTang,ZhengliangLiu,ChongMa,ZihaoWu
TianmingLiu,andLeiFan.2023.PolicyGPT:Automate
doi:10.48550/arXiv.2309.10238arXiv:2309.10238[cs.CL]
[54] PengTang,XinLi,YuxinChen,WeidongQiu,Haoch
AComprehensiveStudyonGDPR-OrientedAnalysis
Classifiers.doi:10.48550/arXiv.2410.04754arXiv:2410.04
[55] TheEuropeanParliamentandTheCouncilofTheEurop
ParliamentandoftheCouncilof27April2016onthe
ofpersonaldataandonthefreemovementofsuchdata
Regulation)(TextwithEEArelevance). EUlaw,Offi
lex.europa.eu/eli/reg/2016/679/oj
[56] DamianoTorre,SallamAbualhaija,MehrdadSabetzadeh,L
2020.AnAI-assistedApproachforCheckingtheComple
2020IEEE28thInternationalRequirementsEngineeringC
[57] UKParliament.2018.DataProtectionAct2018.UKlaw.
ted
[58] KarlvanderSchyff,SuzannePrior,andKarenRenaud.2
agenda.Computers&Security146,Article104065(2024)
[59] ShomirWilson,FlorianSchaub,AswarthAbhilashDar
MadsSchaarupAndersen,SebastianZimmeck,Kantha
Norton,EduardHovy,JoelReidenberg,andNormanSa
PolicyCorpus.InProceedingsofthe54thAnnualMeetin
LongPapers).ACL,1330–1340.doi:10.18653/v1/P16-112
[60] ShomirWilson,FlorianSchaub,FrederickLiu,Kanthash
RohanRamanath,PeterStory,FeiLiu,NormanSadeh,a
FromCrowdsourcingtoAutomatedAnnotations. AC
doi:10.1145/3230665
[61] TongshuangWu,MichaelTerry,andCarrieJunCai.2
InteractionbyChainingLargeLanguageModelPrompts
inComputingSystems.ACM,Article385,22pages.doi:1

DataFlowAnalysisinPrivacyPolicies 37
manSadeh.2024.Largelanguagemodels:anewapproachfor
3879–3903.doi:10.1007/s00607-024-01331-9
aJain,SamratMondal,andAmanChadha.2025.ASystematic
s:TechniquesandApplications.doi:10.48550/arXiv.2402.07927
aBahir.2024. PrivacyChat:UtilizingLargeLanguageModel
Policies.InWisdom,Well-Being,Win-Win:19thInternational
–26,2024,Proceedings,PartI.Springer,223–231.doi:10.1007/978-
ertHTMLtoMarkdown-formattedtext. https://github.com/Ali
6.Crowdsourcingprivacypolicyanalysis:Potential,challenges
16),229–236.doi:10.1515/itit-2016-0009
ntineKahadze,AmandaLiu,ChengleiSi,YinhengLi,Aayush
epDulepet,SauravVidyadhara,DayeonKi,SwetaAgrawal,
haySrivastava,HevanderDaCosta,SaloniGupta,MeganL.
nker,DenisPeskoff,MarineCarpuat,JulesWhite,Shyamal
PromptReport:ASystematicSurveyofPromptingTechniques.
021. PrivacyatScale:IntroducingthePrivaSeerCorpusof
MeetingoftheAssociationforComputationalLinguisticsand
nguageProcessing(Volume1:LongPapers).ACL,6829–6839.
yProtectionAct(CalOPPA).USstatelaw. https://leginfo.legi
=8.&chapter=22.&lawCode=BPC
vacyAct(CCPA).USstatelaw. https://leginfo.legislature.ca.g
&lawCode=CIV&title=1.81.5
u,YiweiLi,WeiLiu,DajiangZhu,QuanzhengLi,XiangLi,
edAnalysisofPrivacyPolicieswithLargeLanguageModels.
henMei,AllisonHolmes,FenghuaLi,andShujunLi.2024.
ofPrivacyPolicies:Taxonomy,CorpusandGDPRConcept
4754[cs.CR]
peanUnion.2016.Regulation(EU)2016/679oftheEuropean
protectionofnaturalpersonswithregardtotheprocessing
a,andrepealingDirective95/46/EC(GeneralDataProtection
fficialJournaloftheEuropeanUnion,L119. https://eur-
LionelBriand,KatrienBaetens,PeterGoes,andSylvieForastier.
etenessofPrivacyPoliciesAgainstGDPR.InProceedingsofthe
Conference.IEEE,136–146.doi:10.1109/RE48521.2020.00025
https://www.legislation.gov.uk/ukpga/2018/12/contents/enac
2024.Privacypolicyanalysis:Ascopingreviewandresearch
),14pages.doi:10.1016/j.cose.2024.104065
ra,FrederickLiu,SushainCherivirala,PedroGiovanniLeon,
ashreeMysoreSathyendra,N.CameronRussell,ThomasB.
adeh.2016. TheCreationandAnalysisofaWebsitePrivacy
ngoftheAssociationforComputationalLinguistics(Volume1:
26
hreeMysoreSathyendra,DanielSmullen,SebastianZimmeck,
andNoahA.Smith.2018.AnalyzingPrivacyPoliciesatScale:
CMTransactionsontheWeb13,1,Article1(2018),29pages.
2022. AIChains:TransparentandControllableHuman-AI
s.InProceedingsofthe2022CHIConferenceonHumanFactors
10.1145/3491102.3517582
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 38 ===
38
[62] ShitaoXiao,ZhengLiu,PeitianZhang,NiklasMuenn
ResourcesForGeneralChineseEmbeddings.InProceedin
andDevelopmentinInformationRetrieval.ACM,641–64
[63] QingeXie,KarthikRamakrishnan,andFrankLi.2025.
Scale:AnLLM-BasedAutomatedApproach.InProceed
USENIXAssociation,Article298. https://www.usenix.o
[64] MianYang,VijayalakshmiAtluri,ShamikSural,andAs
LargeLanguageModels.InDataandApplicationsSecurit
DataandApplicationsSecurityandPrivacy,DBSec2025,G
doi:10.1007/978-3-031-96590-6_2
[65] HaiyueYuan,MatthewBoakes,XiaoMa,DongmeiCao,a
fromaCaseStudyofBooking.com.InIntelligentInforma
2023,Proceedings.Springer,52–60.doi:10.1007/978-3-03
[66] HaiyueYuan,AliRaza,NikolayMatyunin,JibeshPatra,a
DataSharingEcosystem.InProceedingsofthe2024IEE
Systems.IEEE,3587–3594.doi:10.1109/ITSC58415.2024.1
[67] RaziehNokhbehZaeem,RachelL.German,andK.Suza
ofPrivacyPoliciesUsingDataMining. ACMTransacti
doi:10.1145/3127519
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
nighoff,DefuLian,andJian-YunNie.2024. C-Pack:Packed
ngsofthe47thInternationalACMSIGIRConferenceonResearch
49.doi:10.1145/3626772.3657878
EvaluatingPrivacyPoliciesunderModernPrivacyLawsat
dingsofthe34thUSENIXConferenceonSecuritySymposium.
org/conference/usenixsecurity25/presentation/xie
shishKundu.2025.AutomatedPrivacyPolicyAnalysisUsing
tyandPrivacyXXXIX:39thIFIPWG11.3AnnualConferenceon
Gjøvik,Norway,June23-24,2025,Proceedings.Springer,23–43.
andShujunLi.2023.VisualisingPersonalDataFlows:Insights
ationSystems:CAiSEForum2023,Zaragoza,Spain,June12–16,
31-34674-3_7
andShujunLi.2024.AGraph-BasedModelforVehicle-Centric
EE27thInternationalConferenceonIntelligentTransportation
10919888
anneBarber.2018.PrivacyCheck:AutomaticSummarization
ionsonInternetTechnology18,4,Article53(2018),18pages.

=== Page 39 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
Appendix
*** Using your personal data with transparency
In the course of its activities, Renault Group collects, uses and stores some of your personal d
the greatest transparency in the processing it performs on the personal data you provide to it
_table_ | Processing activity: Why we use your information? | What information is collected? | Law
| My Honda Plus mobile app | To set up and manage your Honda account, including sending you s
number, Password, Honda ID, which is a unique identifier generated for each Honda account holde
opt to login using the touch ID, voice command or facial recognition features of your phone. We do
in the App | To take steps at your request to enter a contract with you, for the ongoing performanc
unfortunately mean you will not be able to open a Honda account with us., To the extent that the p
legitimate interest to provide you with a good customer experience and to provide you with featur
Fig.5. Exampleofconvertingnon-ta

DataFlowAnalysisinPrivacyPolicies 39
Converting non-table web text to a
text segment
data, i.e. information that makes it possible to identify you. Renault Group intends to ensure
t or on the personal data it collects through the various contacts you may have with it.
Converting table web text to a text
segment
wful basis of processing | Where is the information collected from? | Specific retention periods |
service notifications. | Country, Language, Email address, Address (including postcode), Mobile
er during the registration process, Your device ID which will be linked to your Honda ID where you
o not process your biometric data which remains on your device., Your preferences which you set
ce, management and facilitation of such contract., A failure to provide this information will
processing goes beyond what is necessary for the contract, the processing is necessary for our
res to keep your account secure. | From you (via the App) |
ableandtabletexttotextsegments
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 40 ===
40
Prompt
role:system
content:
[1] YouareanexperttoanalysetheTEXT
[2] If TEXTSEGMENTstartswith_table
tableheading;Treatsecondlineasthet
[3] ReadandunderstandtheTEXTSEGME
toproduceyourresponses:
(aI)ftheTEXTSEGMENTatleastta
informationfromanotherparty,or
toanotherparty,OUTPUTtheext
(bT)heJSONobjectsmustusethefor
{"Output":[{
"data_sender": "",
"data_type": [],
"data_receiver":
}]}
(cR)espondonlywithvalidJSON.
(dE)achdataflowrepresentsoneparty
data_type)fromanotherparty(i.e
sharespersonaldata(i.e.,data_typ
(eF)ordata_types:extractallatomicp
rules: (1) when dealing with sent
themintoindividualdata_typesfo
MUSTappearinTEXTSEGMEN
INCLUDE any other text in the a
deductionoryourexplanation;(4)
DONOTINCLUDEspecificaddre
organisations,orgeographicalinfor
leaveitempty.
(fF)ordata_sender/data_receiver:(1)
bineddata_receiversordata_sende
data_senderforaclearerrepresen
stringMUSTappearinTEXTSE
data_sender is explicitly stated in
empty;(4)ifnodata_receiverisexp
data_receiverempty.
(gO)UTPUTonly“None”forotherun
role:user
content:
TEXTSEGMENT:OnePrivacyPolicy
Fig.6. Prompttemplateforextractingdataflows
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
SEGMENTtoextractdataflows.
e_:Treat|asseparators;Treatfirstlineasthe
tablecontent.
ENTandthenstrictlyfollowthebelowrules
alkaboutonepartycollectsdataorpersonal
rapartysharesdataorpersonalinformation
tracteddataflowsinmultipleJSONobjects.
rmat:
,
[]
y(i.e.,data_receiver)collectspersonaldata(i.e.,
e.,data_sender),oraparty(i.e.,data_sender)
pe)toanotherparty(i.e.,data_receiver).
personaldata(i.e.,data_type)followingthese
tences that have combined data_types, split
oraclearerrepresentation;(2)eachdata_type
NT,anddonotchangethecases;(3)DONOT
answer such as input or query text or your
removePronounsintheidentifiedstrings;(5)
esses,postcodes,emailaddresses,companies,
rmation;(6)ifyoucannotidentifyadata_type,
whendealingwithsentencesthathavecom-
ers,splitthemintoindividualdata_receiveror
ntation;(2)eachdata_senderordata_receiver
EGMENT,donotchangethecases;(3)ifno
n the TEXT SEGMENT, leave data_sender
plicitlystatedintheTEXTSEGMENT,leave
nrelatedscenarios
TextSegment
followingtheGroqChatCompletionsAPIformat

=== Page 41 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalDataFlowAnalysisinPrivacyPolicies 41
Prompt
role:systemcontent:
[1] YouareanexpertincategorisingtheINPUTDATATYPEprovidedbytheuserto
extractkeyinformationaboutdatacollection/sharing.
[2] UsetheTEXTSEGMENTgivenbytheuser,alongwiththeknowledgeandunder-
standingofdatacategoryanddescriptionprovidedintheCONTEXTlisttoperform
thecategorisation.
[3] Pleasestrictlyfollowthebelowruleswhenansweringquestions:
(aO)utputmustfollowtheJSONformatshownbelow.
{"Output": [{
"DataCategory": "data_category",
"DataType": "data_type",
"InputText": "input_text",
}]}
(bR)espondonlywithvalidJSON.
(cD)onotincludeanyothertext(e.g.,inputorquerytext).
(dD)ataCategory is the identified data category defined in CONTEXT. Do not
createnewcategories.
(eD)ataTypeistheINPUTDATATYPE.
(fI)nputTextistheTEXTSEGMENT.
(gO)UTPUTonly"None",ifnocategorycanbefound.
role:usercontent:
[1] INPUTDATATYPE:ExampleDataType
[2] TEXTSEGMENT:PrivacyPolicyTextSegment
[3] CONTEXT:
Datacategory:Datacategory1
Datadescription:Descriptionofdatacategory1
Exampledatatypes:data1,data2,data3,...
[4] CONTEXT:
Datacategory:Datacategory2
Datadescription:Descriptionofdatacategory2
Exampledatatypes:data1,data2,data3,...
Fig.7. PrompttemplateforidentifyingdatacategoriesfollowingtheGroqChatCompletionsAPIformat
,Vol.1,No.1,Article.Publicationdate:January2025.

=== Page 42 ===
42
Table13. Datacollectionandsharingprac
DataCategory Audi Ford Honda Hyund
S C S C S C S C
Location
Approximatelocation
Preciselocation Y
PersonalInfo
Name Y Y Y Y Y
Emailaddress Y Y Y Y Y
UserIDs Y Y Y Y Y
Address Y Y Y Y
Phonenumber Y Y Y
Raceandethnicity
Politicalorreligiousbeliefs
Sexualorientation
Otherinfo Y
FinancialInfo
Userpaymentinfo
Purchasehistory
Creditscore
Otherfinancialinfo
Health&Fitness
Healthinfo
Fitnessinfo
Messages
Emails
SMSorMMS
Otherin-appmessages
PhotosandVideos
Photos
Videos
Audiofiles
Voiceorsoundrecordings
Musicfiles
Otheraudiofiles
Filesanddocs
Filesanddocs Y
Calendar
Calendarevents Y
Contacts
Contacts Y
Appactivity
Appinteractions Y Y Y Y Y
In-appsearchhistory
Installedapps
Otheruser-generatedcontent Y Y
Otheractions
Webbrowsing
Webbrowsinghistory
Appinfoandperformance
Crashlogs Y Y Y Y
Diagnostics Y Y Y Y
Otherappperformancedata
DeviceorotherIDs
DeviceorotherIDs Y Y Y Y Y
S:Datashared
C:Datacollected
,Vol.1,No.1,Article.Publicationdate:January2025.

Yuanetal.
cticesstatedinGoogleappsafetysection
dai Kia Lexus Nissan Polestar Renault Vauxhall
C S C S C S C S C S C S C
Y Y
Y Y
Y Y Y Y Y Y Y Y Y
Y Y Y Y Y Y Y Y Y Y Y
Y Y Y Y Y Y
Y Y Y Y Y
Y Y Y Y Y Y Y Y Y Y
Y Y Y Y
Y
Y Y Y
Y Y Y
Y Y
Y Y Y Y Y
Y Y
Y Y
Y Y Y Y Y Y
Y Y Y Y Y
Y Y
Y Y Y Y Y Y Y Y Y

=== Page 43 ===
LADFA:AFrameworkofUsingLLMsandRAGforPersonalD
Table14. Datacollectionandsharingpract
DataCategory Audi Ford Honda Hyundai
T L N T L N T L N T L N
Location
Preciselocation
Coarselocation Y
Contactinfo
Name Y Y Y
Emailaddress Y Y Y
Phonenumber Y Y Y
Physicaladdress Y Y
Otherusercontactinfo
Healthandfitness
Health
Fitness
Financialinfo
Paymentinfo
Creditinfo
Otherfinancialinfo
Sensitiveinfo
Contacts
Usercontent
Emailsortextmessages
Photosorvideos
Audiodata
Gameplaycontent
Customersupport Y
Otherusercontent
Browsinghistory
Searchhistory
Identifiers
UserID Y Y
DeviceID Y Y
Purchasehistory
Usagedata
Productinteraction Y Y
Advertisingdata
Otherusagedata
Diagnostics
Crashdata Y Y
Performancedata Y Y
Otherdiagnosticdata Y
Surroundings
Environmentscanning
Body
Hands
Head
Otherdatatypes Y
T:“Datausedtotrackyou”
L:“Datalinkedtoyou”
N:“Datanotlinkedtoyou”

DataFlowAnalysisinPrivacyPolicies 43
ticesrepresentedusingAppleprivacylabels
Kia Lexus Nissan Polestar Renault Vauxhall
T L N T L N T L N T L N T L N T L N
Y Y Y Y Y Y
Y Y Y
Y Y Y Y Y
Y Y Y Y Y Y
Y Y Y Y Y
Y Y Y Y
Y Y
Y
Y
Y Y
Y Y Y
Y
Y Y
Y Y Y Y Y Y
Y Y Y Y Y
Y
Y Y Y Y Y Y
Y Y
Y
Y Y Y Y Y
Y Y Y
Y
,Vol.1,No.1,Article.Publicationdate:January2025.

Paper:Knowledge Management for Automobile Failure Analysis Using Graph RAG.pdf
=== Page 1 ===
Knowledge Management
Analysis Using
1st Yuta Ojima 2nd H
Department of System Innovation Faculty of I
School of Engineering and
The University of Tokyo Hokka
Tokyo, Japan Hokk
y ojima@m.sys.t.u-tokyo.ac.jp sakaji@
4th Hiroaki Sakata 5th Kazuya Seki
Chasis Engineering Dept. No.1 Quality Assurance Dept.
Isuzu Motors Limited Isuzu Motors Limited
Tokyo, Japan Tokyo, Japan
Hiroaki Sakata@isuzu.com Kazuya Seki@isuzu.com Y
8th Kazuhiro Aoyama
Department of System Innovation
School of Engineering
The University of Tokyo
Tokyo, Japan
aoyama@race.t.u-tokyo.ac.jp
Abstract—This paper presents a knowledge management sys-
tem for automobile failure analysis using retrieval-augmented
generation (RAG) with large language models (LLMs) and
knowledge graphs (KGs). In the automotive industry, there is
a growing demand for knowledge transfer of failure analysis
fromexperiencedengineerstoyoungengineers.However,failure
events are phenomena that occur in a chain reaction, making
them difficult for beginners to analyze them. While knowledge
graphs, which can describe semantic relationships and structure
informationiseffectiveinrepresentingfailureevents,duetotheir
capabilityofrepresentingtherelationshipsbetweencomponents,
there is much information in KGs, so it is challenging for young
engineers to extract and understand sub-graphs from the KG.
On the other hand, there is increasing interest in the use of
Graph RAG, a type of RAG that combines LLMs and KGs
for knowledge management. However, when using the current
Graph RAG framework with an existing knowledge graph for
automobile failures, several issues arise because it is difficult
to generate executable queries for a knowledge graph database
which is not constructed by LLMs. To address this, we focused
on optimizing the Graph RAG pipeline for existing knowledge
graphs. Using an original Q&A dataset, the ROUGE F1 score
of the sentences generated by the proposed method showed
an average improvement of 157.6% compared to the current
method.Thishighlightstheeffectivenessoftheproposedmethod
for automobile failure analysis.
Index Terms—Graph RAG, Large Language Model, Knowl-
edge Graph, Knowledge Management, Automobile Failure
4202
voN
92
]IA.sc[
1v93591.1142:viXra

t for Automobile Failure
g Graph RAG
Hiroki Sakaji 3rd Tadashi Nakamura
Information Science Chasis Engineering Dept. No.1
Technology Isuzu Motors Limited
aido University Tokyo, Japan
kaido, Japan Tadashi A Nakamura@isuzu.com
@ist.hokudai.ac.jp
6th Yuu Teshigawara 7th Masami Yamashita
Quality Assurance Dept. Technology Strategy Dept.
Isuzu Motors Limited Isuzu Motors Limited
Tokyo, Japan Tokyo, Japan
Yuu Teshigawara@isuzu.com Masami Yamashita@isuzu.com
I. INTRODUCTION
In the Japanese automotive industry, especially truck indus-
try, the necessity of knowledge transfer of failure analysis has
been increasing in recent years, specifically from experienced
engineers to young engineers. There are two main reasons for
this. The first reason is that failure analysis in automobiles is
complex and challenging to address without sufficient experi-
ence. Vehicles are generally recognized as systems composed
of multiple parts, meaning that a failure in one part can
potentially lead to a chain of failures in other components.
Therefore, understanding relationships of parts is crucial to
find out the causal of failure, but this knowledge is mainly
gained by experience not by lectures or textbooks.
The second one is that compared to the past, young en-
gineers now need to address a broader and more specialized
range of failure issues. Japan is currently facing to a prob-
lem of declining birthrate and an aging population, resulting
in a reduced number of young engineers compared to the
past. Moreover, there is growing complexity of automobile
technologies owing to innovations such as CASE (Connected,
Automated, Shared, Electric), Mobility as a Service (MaaS),
and Electric Vehicles, so the burden on each young engineer
has increased.
To address these challenges, a truck company issues and
archives ”failure documents” each time a failure occurs to
ensure the transfer of failure analysis expertise. These doc-

=== Page 2 ===
uments contain details about the conditions of malfunction-
ing vehicles, repair methods, dates, and circumstances, each
organized in separate columns and written in Japanese. For
effective knowledge transfer, it is necessary for young engi-
neers to understand these documents. However, because they
arewritteninnaturallanguage,itisdifficulttocomprehendthe
relationships between critical components in failure analysis.
Tofacilitateunderstandingoftheconnectionsbetweencom-
ponents, it is reasonable to represent these documents in the
formofaknowledgegraph(KG),whichcandescribesemantic
relationships and store structured information and is used for
tackling problems in various domains [1]. Hara et al. [2] has
constructed failure KG from failure documents, but due to
the vast amount of data within failure documents, failure KG
alsobecomescomplexandchallengingforyoungengineersto
comprehend.
Currently, there are some experienced engineers who can
easily search the necessary information from the documents,
and they can provide the information to young engineers.
However, the average age of these engineers is not low, and
the numbers of them are expected to decline in the future.
Additionally, truck failures cause substantial losses to both
Japanesefreightstransportation,wheretruckstransport91.4%
of the total weight of goods moved1, and truck drivers, so
thecompanyhavetodealwiththefailuresquickly.Therefore,
anticipating the retirement of experienced engineers, it is es-
sentialtodevelopasystemthatcanquicklyidentifythecauses
of failures without relying on their experience. Specifically, it
is desirable to construct a system that can critically present
the causes when the fault conditions are inputted.
LargeLanguageModels(LLMs),likeChatGPT[3],demon-
strate remarkable capabilities in various natural language
processing tasks [4], and can response quickly, so they are
expected to be effective for knowledge management of fail-
ure analysis. However, since a vanilla LLM does not retain
domain- or organization-specific information, an approach
calledRetrieval-AugmentedGeneration(RAG)isneeded.This
method answers user questions based on external information
resources, and Graph RAG [5], which is a type of RAG
that combines LLMs and KGs, enables responses to users’
queries based on the information within those graphs. How-
ever, current implementation of Graph RAG faces challenges
in adapting to existing KGs.
In this study, we propose a novel Graph RAG system that
can be applied to existing KGs. In the following section,
we introduce related work, methodology—including current
challenges—and the experiment using ROUGE [6]. Main
contributions of this research are summarized as follows.
• We propose a Graph RAG system that is independent of
the query representation in knowledge graph databases.
• The text generated by the proposed method achieved a
higherROUGEF1scorecomparedtothosegeneratedby
the current Graph RAG and ChatGPT, demonstrating its
effectiveness.
1https://jta.or.jp/wp-content/themes/jta theme/pdf/yusosangyo2023.pdfs

II. RELATEDWORK
A. Failure Knowledge Graph
Hara et al. [2] employed text mining techniques based on
syntactic analysis, including the extraction of co-occurrence
anddependencyrelations,aswellascausalrelationextraction
using the algorithm proposed by Sakaji et al [7]. They con-
structedfailureKG,aknowledgegraphoffailureinformation.
A portion of failure KG is shown in Fig. 1.
Fig.1. FailureKG[2].Thisfigureillustratesthenodesrelatedtotheclutch
node.TheoriginalgraphwascreatedinJapanese,andthedisplayedexcerpts
aretranslatedintoEnglish.Inthisrepresentation,thebluelabelsrepresentthe
statesofthesystem,whilegreenlabelsdenotethecomponentsinvolved.
Each node is labeled as a system, component, part, status,
or other categories by experienced engineers. The meaning
of each node is validated through human involvement. The
relationships obtained from each syntactic analysis are cate-
gorized as weak causal and status relations for co-occurrence,
hierarchical relations for dependencies, and causal relations
for causal relation extraction.
While they demonstrated the ability to extract the inter-
relations of parts involved in a failure, challenges remain
in understanding the resulting network especially for young
engineers,duetovastamountofdata.Therefore,itisessential
to implement the constructed knowledge graph in an applica-
tion that can extract important sub-graphs from the KGs and
generate answers for the question from young engineers.
B. Large Language Model and RAG
The release of ChatGPT by OpenAI [3] has demonstrated
the vast potential of LLMs to generate sentences. These
models can engage in continuous conversations with users
based on chat context and perform complex tasks such as
coding and academic writing [4]. While LLMs can handle a
widerangeofquestions,makingthemvaluableforknowledge
management,theyoftenlackcompany-specificknowledgeand
may occasionally output incorrect information. Consequently,
thereisagrowingneedforthedevelopmentofLLMstailored

=== Page 3 ===
for specific companies. However, unlike previous encoder-
only language models like BERT [8], pre-training LLMs
withspecificdomainknowledgeorup-to-dateinformationhas
become impractical owing to the significant amount of data,
training time, and computational resources required, leading
to extremely high costs. Additionally, contemporary LLMs,
like ChatGPT, are generally offered solely as APIs, rendering
pre-training unfeasible.
As a result, attention has shifted to Retriever-Augmented
Generation (RAG) techniques. Fig. 2 provides an overview of
RAG. This method involves retrieving necessary information
fromexternaldatasources,suchasdocumentdatabases,based
on the user’s prompt and integrating this relevant information
into the LLM’s prompt. This effectively allows the LLM
to incorporate the latest knowledge from specific domains
[9]. When using LLMs offered as APIs, RAG enables the
integrationofinformationwithoutbeinglimitedbytheamount
of data held, while also reducing computational resource
requirements.
Fig.2. OverviewofRAG
C. Graph RAG
Microsoft has proposed a Graph RAG system as a RAG
framework that utilizes knowledge graphs [5]. As Fig. 3
provides, this system consists of two steps.
1) Constructing the Knowledge Graph: Source documents
containing the information to be provided to the LLM
are converted into a KG using the LLM and prompts.
After constructing the KG, the LLM forms graph com-
munities, orclusters, from theentire graph basedon the
numberofrelationshipsderivedfromthedocument.This
process can be viewed as labeling each node.
2) RAG with LLM and KG: First, the Retriever LLM
generates a database query to extract information from
the knowledge graph’s database based on the user’s
query. The LLM then generates an answer using the
retrieved response and the user’s query.
Graph RAG can be viewed as executing a task categorized
into Knowledge Graph-based Question Answering (KGQA),
which focuses on providing answers to user-posed questions
based on the KGs [10]. There are two main approaches
to KGQA: the Semantic Parsing (SP) and Information
Retrieval (IR) based methods [10]. The SP method involves
converting natural language questions posed by users into

Fig.3. OverviewoftheGraphRAG
search queries for the knowledge graph, specifically into
logical symbols, and then generating answers based on the
results obtained from these queries [10]. On the other hand,
theIRmethodinvolvesextractinganunderstandablesub-graph
from the knowledge graph that is related to the question,
reasoning based on this sub-graph, and generating the answer
[10].
In this process, the user’s question is converted into a
searchable query by the LLM, which is then sent to the
knowledge graph database. The LLM generates an answer
based on the information retrieved from the knowledge graph
database.
Additionally, the combination of KGs and LLMs has been
reported to generate more consistent answers and suppress
the generation of misinformation, commonly referred to as
”hallucinations”, compared to other RAG approaches [9].
III. METHODOLOGY
A. Problem Definition
WhenapplyingthecurrentGraphRAGtoautomotivefault
knowledge management, two major challenges emerge. The
first challenge is the difficulty in adapting to existing knowl-
edgegraphs.Aspreviouslymentioned,thecurrentGraphRAG
isbasedontheSPmethod.Itcanbeconsideredthatexecutable
queries can be generated without high-cost training, which is
generally needed [10], as the same LLM is utilized both for
convertingauserqueryq fromthenaturallanguagespacetoa
query q for KG databases in logical symbol space, as well as
forconstructingKGsfromdocuments.Therefore,whileGraph
RAG is effective for KGs constructed by LLM, it remains
unclear whether it can be applied to existing KGs created
using other methods. As stated in II-A, failure KG is difficult
for beginners to comprehend, but it has been confirmed that
the relationships between components during a failure can be
partially extracted. Therefore, in this study, we want to focus
on utilizing this KG as it currently exists. Additionally, the
knowledge graphs in Graph RAG often lack human-validated
meaning, making them insufficient for practical use.
Thesecondchallengeisthattherelationshipsandstructures
described in the knowledge graph are rarely used in answer

=== Page 4 ===
generation. Since Graph RAG operates using the SP method,
the search typically targets the graph’s nodes rather than its
edges, i.e., the relationships. However, automobile failures
involve chains and their structures, making it essential to
use the information from entire sub-graphs containing the
necessary information, rather than focusing on specific nodes.
These challenges primarily arise from the fact that the
current Graph RAG constructs a pipeline based on the SP
method. In response, we propose an IR-based Graph RAG
that is applicable to existing knowledge graphs and is based
on the IR method. While it has been mentioned that the IR
method may lead to an increase in the number of extracted
sub-graphs in response to complex queries, there is potential
to resolve this issue using LLMs.
B. Proposed Method
The following outlines the pipeline of the IR-based Graph
RAG. A schematic diagram is presented in Fig. 4.
Fig.4. OverviewoftheIR-basedGraphRAG
1) Retrieving:Givenauserqueryq,theLLMprocessesthe
inputandretrievesasetofrelatedtermsT byidentifying
relevant automotive issues and faults. Mathematically,
this can be expressed as below:
T =Retrieve (q,p ) (1)
LLM retrieve
where p is the prompt instructing the retrieval of
retrieve
related words.
2) Extracting: Sub-graphs are extracted based on the re-
trievedwords.Thisextractioninvolvesgeneratingarule-
based searchquery that isfree from grammatical errors.
Foreachwordt∈T ,asub-graphG isdefinedassset
t
of relationships, including the node n corresponding to
t
thetargetwordt,alongwiththeedgesE andconnected
t
nodes N . Mathematically, the sub-graph G can be
t t
expressed as:
G =(n ,N ,E ) (2)
t t t t
where n is the target word node, N is the set of nodes
t t
connected to n , and E is the set of edges connecting
t t
n toN ,orN ton .Inotherwords,theserelationships
t t t t
form one-hop chain. Also, the sub-graph G is then
t
represented as sets of text shown in Fig. 5.

3) Filtering: The LLM is used to filter the extracted sub-
graphs,selectingcandidatesthatarerelevanttotheuser’s
question.Thisstepisnecessarybecausemanyedgesare
connectedtospecificwords(suchas“engine”),resulting
in the extraction of numerous unrelated sub-graphs. By
using the LLM, this step mitigates the conventional
issue of an overwhelming number of extracted sub-
graphs when adopting the IR-method for KGQA. Let
G=G ,G ,...,G represent the set of extracted sub-
1 2 n
graphs.TheLLMappliesafilteringfunctionFilter
LLM
that selects a subset G ⊆ G of sub-graphs
filtered
relevant to the query q, which can be expressed as:
G =Filter (G,q,p ) (3)
filtered LLM filter
where p is the prompt containing instructions to
filter
filter the sub-graphs.
4) Reasoning: The final filtered sub-graphs, along with the
user’s question, are given to the LLM as a prompt to
generatethefinalanswer.Ifthenumberofselectedsub-
graphsistoolargeandexceedsthetokenlimitLforthe
prompt,randomsub-graphsareremovedbeforeincluded
in the prompt. This can be expressed as:
G′ =random(G ,L,q,p ) (4)
filtered filtered reason
where p is the prompt used to instruct the LLM
reason
to reason and generate the answer. The final answer a
is then generated by the LLM as expressed below:
a=Reason (G′ ,q,p ) (5)
LLM filtered reason
Fig.5. Examplesofsub-graphrepresentations
C. Evaluation
To evaluate the proposed method, we assess its validity
by creating and using a Q&A dataset to measure the textual
similaritybetweentheresponsesgeneratedbyGraphRAGand
the expected answers. The dataset is generated by providing
the LLM with failure documents and specific instructions as
prompts, resulting in a set of questions and answers related to
malfunction or failure information. To make the content more
practical, the dataset is designed so that the answers involve
the actual component configurations and failure propagation
processes typically analyzed during failure analysis. The sen-
tencesfromfailuredocumentsarecleansedandconvertedinto
grammatically correct and meaningful sentences by the LLM.
This approach is similar to that of Balaguer et al [11].

=== Page 5 ===
Fortheevaluationmetric,weusetheROUGEF1score[6].
We hypothesize that when questions generated from failure
documents and the LLM are input into Graph RAG, which
uses failure KG as the data source, the responses will be
similar to those generated by failure documents and LLM. A
higher ROUGE score indicates greater textual similarity with
the dataset, suggesting that the generated response contains
more of the required information. Therefore, we adopted this
metric for this study.
IV. EXPERIMENT
A. Experiment Setting
In this study, we exclusively used ChatGPT as the LLM.
Specifically, we employed the Azure OpenAI GPT-4o (2024-
07-01) with the temperature parameter set to 0.
We compared three methods: the proposed method, Chat-
GPT, and the current Graph RAG. Both versions of Graph
RAG use failure KG. Because the current Graph RAG adopts
the SP method, we named it SP-based Graph RAG. Addi-
tionally,toimplementSP-basedGraphRAG,weusedlibraries
supported by LangChain and Neo4j2.
InthepromptfortheSP-basedGraphRAG,weincludenot
only the reasoning prompt used in the IR-based Graph RAG
but also an explanatory description of failure KG.
The SP-based Graph RAG was executed once, while the
other two methods were run five times each to calculate
the average score. This approach was chosen because of
the variability in the generated text; when the token limit
was exceeded, relationships are randomly deleted, leading to
fluctuations in the scores.
For the evaluation, we used the F1 scores of ROUGE-1,
ROUGE-2, and ROUGE-L. We computed the ROUGE F1
scores for each set in the dataset, summed them, and then
divided the total by the number of sets.
B. Dataset
failure documents were provided by Isuzu Motors Limited.
For the dataset, we used 43 sets of failure documents that
includedthetermクラッチ(clutch)andcontainedallthenec-
essary information for constructing failure KG. We instructed
theLLMtocreateadatasetofquestionsandanswersrelatedto
the chain of parts or failures. We used GPT-4 (1106-preview)
providedbyAzureOpenAItoconstructthedataset,settingthe
temperature parameter to 0.
C. Results
TheresultsarepresentedinTableI.FortheSP-basedGraph
RAG, five sets of the dataset encountered errors and were
excluded from the evaluation. All errors were attributed to
syntaxissuesinthesearch queriesgeneratedfortheKG,with
successful query generation achieved for only ten sets.
The IR-based Graph RAG demonstrated an average score
improvement of 157.6% compared to the current Graph RAG
and an average improvement of 23.18% over ChatGPT. The
2https://python.langchain.com/v0.2/docs/integrations/graphs/neo4j cypher/

IR-based Graph RAG consistently achieved the highest scores
in all cases, indicating that it contained the most relevant
information for the answers. Conversely, the SP-based Graph
RAG produced very low scores, challenging to consider it a
practicaltext.Furthermore,generatingeffectivesearchqueries
proved to be challenging. Even when queries were success-
fully created, a significant number of syntax errors occurred,
suggesting that this method may not be suitable for use with
existing knowledge graphs.
TABLEI
THEEXPERIMENTRESULTS.
Method ROUGE-1F1 ROUGE-2F1 ROUGE-LF1
ChatGPT 0.3305 0.1483 0.2364
SP-based 0.1538 0.06967 0.1185
IR-based 0.4053 0.1845 0.2896
Additionally, the proposed method outperformed ChatGPT,
clearly demonstrating its capability to extract essential infor-
mation from the failure KG. This indicates that the proposed
approach is more effective for automotive failure knowledge
management compared to existing technologies. Furthermore,
when comparing the average number of tokens in the text
generatedbyChatGPTandtheIR-basedGraphRAG,thelatter
produces fewer tokens (as shown in Table II), suggesting that
it generates more concise text. This may make it easier for
beginners to understand.
TABLEII
THEAVERAGETOKENS.
Method AverageTokens
ChatGPT 530.2
IR-based 320.0
V. DISCUSSION
A. Cause Analysis about Missing Information
Whiletheproposedmethodhasdemonstratedeffectiveness,
the evaluation metric scores remain low, raising concerns
aboutitspracticality.Possiblereasonsforthisincludemissing
information that should be stored in failure KG and the
possibility that the method for extracting and describing sub-
graphs is not appropriate. In this study, we conduct additional
verification of the former issue.
To demonstrate that the amount of information recorded in
failureKGisinsufficient,weproposecomparingthegenerated
answers by adding sentences from failure documents that
formed the basis of failure KG into the prompts. We hypothe-
size that including these sentences in the Reasoning step will
improvetheevaluationmetrics,astheyareexpectedtocontain
more information. Specifically, we add an evaluation method
called IR-based Graph RAG with sentences (mentioned as
”With sentences” in Tables), where sentences from failure
documents that generated the sub-graph are also extracted
in the Filtering step and added as prompts alongside the

=== Page 6 ===
sub-graphs during the Reasoning step. Thus, the following
equation is added to the Filtering step:
S =Extract(G ) (6)
filtered
where S is the set of sentences extracted from failure docu-
ments that generated the sets of sub-graphs G .
filtered
Also, during the Reasoning step, these processes are exe-
cuted:
G′ ,S′ =random(G ,S,L,q,p ) (7)
filtered filtered reason
a =Reason (G′ ,S′,q,p )
with sentences LLM filtered reason
(8)
where S′ are randomly selected sentences to avoid exceed the
token limit L, and a is the generated answer by
with sentences
this method, which was used for evaluation.
Additionally, we include a separate method called IR-based
Graph RAG only sentences (mentioned as ”Only sentences”
in Tables), in which sentences from failure documents are
extracted during the Extracting step, similar to the IR-based
GraphRAGwithdocuments.However,intheReasoningstep,
only these sentences are given as prompts. Therefore, adding
tothepipelineofIR-basedGraphRAG,(6)isexecutedduring
the Filtering step, and the following processes are executed in
the Reasoning step:
S′ =random(S,L,q,p ) (9)
reason
a =Reason (G′ ,S′,q,p )
only sentences LLM filtered reason
(10)
where a is the generated answer used for evalu-
only sentences
ation.
Each method was run five times, and the average ROUGE
F1 score calculated for each run was used. The other ex-
perimental conditions remain the same as in the previously
conducted experiments. The results are shown in Table III.
Based on the results, including both the sub-graphs and
sentences from failure documents in the prompt during the
Reasoning step leads to more accurate output. The scores
of IR-based Graph RAG with sentences were the highest,
showing an average improvement of 8.18% compared to the
proposed method, which can be recognized as a significant
difference. This suggests that the extracted sub-graph alone is
insufficient and that there is missing information that should
be described in failure KG.
TABLEIII
RESULTSOFTHEEXPERIMENTABOUTMISSINGINFORMATION.
Method ROUGE-1F1 ROUGE-2F1 ROUGE-LF1
Withsentences 0.4245 0.2106 0.3060
Onlysentences 0.3940 0.1891 0.2825
Whiletheadditionalexperimentdemonstratedthattherewas
missing information that should have been included in failure
KG. However, there was no significant difference observed
between the IR-based Graph RAG and the IR-based Graph
RAG only sentences. This can be explained by the proportion

of information that LLMs can interpret. Generally, text of
failure documents is considered to provide more information
as a prompt compared to the sub-graphs. However, because
failure documents are written in natural language, they likely
contain a lot of information that could be considered noise.
Therefore, the proportion of interpretable information from
failure documents is likely smaller compared to that of the
sub-graphs by the LLM. Additionally, the difference in the
distribution of interpretable information between the sub-
graphs and failure documents suggests that providing both
sources of information in the prompt results in the highest
score. In summary, these explanations can be represented as
shown in Fig. 6.
Fig. 6. Comparison of the information space provided by sentences versus
sub-graphs
B. Ablation Analysis about the Filtering step
To verify the effectiveness of the Filtering step in the
proposed method, we conducted an ablation analysis. In this
analysis, we removed the Filtering step from the pipelines
and evaluated the ROUGE F1 score. We compare the vanilla
IR-based Graph RAG, IR-based Graph RAG only sentences,
and IR-based Graph RAG with sentences, and use the same
experimentalconditionsasinthepreviousexperiment,andthe
results are shown in Table IV.
TABLEIV
THEABLATIONANALYSISRESULTSOFTHEIR-BASEDGRAPHRAG.
Method ROUGE-1F1 ROUGE-2F1 ROUGE-LF1
Vanilla 0.3882 0.1769 0.2809
Onlysentences 0.3695 0.1713 0.2632
Withsentences 0.3827 0.1885 0.2768
The results garnered indicate an average diminution of
7.077% relative to preceding scores, underscoring the indis-
pensability of the filtering phase within the proposed method-
ology. This implies that the filtering stage in the proposed
approach is not merely a procedural necessity, but a critical
component, given that the selection of pertinent sub-graphs
profoundly influences the precision of the outcomes. Addi-
tionally, it was found that filtering sub-graphs, which had
been pointed out as a challenge in IR methods [10], can be
performed on LLMs without requiring any special training.

=== Page 7 ===
C. Limitation and future works
This study has three major limitations. The first is the
inadequacyofthesub-graphextractionmethod.Inthecontext
of failure events, chains of events are crucial, but this study
extracts only one-hop chain. Future work should explore the
introductionofanalgorithmthatcanextractmulti-hopchains.
For example, it is a possible approach that embedding nodes
or edges using an encoder model like BERT [8], and then
determining which chains in KGs to use for reasoning based
on cosine similarity to the query. This approach is similar to
the method proposed by Saxena et al [12].
The second limitation concerns the evaluation method. In
this study, the dataset was constructed using ChatGPT, and
the evaluation was based on ROUGE F1. However, ROUGE
isintendedforuseinscenarioswherethetargettextisdirectly
used, such as in extractive summarization, and its suitability
forevaluatinggeneratedtextremainsquestionable.Toenhance
thecredibilityoftheevaluations,itisnecessarytoincorporate
human evaluations as well.
The last one is that only a single round of interaction is
conducted during the Reasoning step. In the experiments,
there are some responses that simply include the names
of components without providing deeper explanations. This
is likely due to the attempt to generate an answer within
a single interaction. Recent LLMs support agent systems,
allowing them to act autonomously. These agents can analyze
what information is needed to answer a given query, utilize
provided tools (e.g., databases, web searches) to retrieve the
required information, and perform reasoning based on it [13].
Depending on the prompt, they can autonomously execute
multi-step processes, which enables them to generate more
accurate and contextually appropriate responses.
VI. CONCLUSION
Thisstudydemonstratesthattheproposedmethod,IR-based
Graph RAG, is an effective system for knowledge manage-
ment in automotive failure analysis. It suggests that providing
information in the form of sub-graphs as prompts offers an
interpretable format for LLMs. However, it is important to
note that, that at this stage, it has not yet reached a level
where it can be used directly, and we have identified issues
specifically with the knowledge graph used in Graph RAG.
Inthefuture,weintendtoverifythepracticalityandvalidity
forawiderrangeofeventsbyincreasingthesizeofthedataset.
Additionally, we aim to improve the score accuracy through
prompt engineering as part of our future work.
ACKNOWLEDGMENT
This study was supported by Isuzu Motors Limited.
REFERENCES
[1] B.Abu-Salih,“Domain-specificknowledgegraphs:Asurvey,”Journal
of Network and Computer Applications, vol. 185, p. 103076, 2021.
[Online]. Available: https://www.sciencedirect.com/science/article/pii/
S1084804521000990

[2] S. Hara, H. Ozawa, M. Yamashita, S. Yamada, Y. Sakachi, and
K. Aoyama, “Knowledge management for design development and
maintenance through text mining of product information (knowledge
management for design development and maintenance using product
development history information and product defect response informa-
tion),”Design&SystemsConference,vol.2022.32,p.1201,Jan.2022.
[3] L.Ouyang,J.Wu,X.Jiang,D.Almeida,C.L.Wainwright,P.Mishkin,
C.Zhang,S.Agarwal,K.Slama,A.Ray,J.Schulman,J.Hilton,F.Kel-
ton,L.Miller,M.Simens,A.Askell,P.Welinder,P.Christiano,J.Leike,
and R. Lowe, “Training language models to follow instructions with
humanfeedback,”inProceedingsofthe36thInternationalConference
onNeuralInformationProcessingSystems,ser.NIPS’22. RedHook,
NY,USA:CurranAssociatesInc.,2024.
[4] L. Yang, H. Chen, Z. Li, X. Ding, and X. Wu, “Give us the facts:
Enhancing large language models with knowledge graphs for fact-
awarelanguagemodeling,”IEEETransactionsonKnowledgeandData
Engineering,vol.PP,pp.1–20,072024.
[5] D. Edge, H. Trinh, N. Cheng, J. Bradley, A. Chao, A. Mody,
S. Truitt, and J. Larson, “From local to global: A graph rag
approach to query-focused summarization,” 2024. [Online]. Available:
https://arxiv.org/abs/2404.16130
[6] C.-Y.Lin,“ROUGE:Apackageforautomaticevaluationofsummaries,”
inTextSummarizationBranchesOut. Barcelona,Spain:Associationfor
Computational Linguistics, Jul. 2004, pp. 74–81. [Online]. Available:
https://aclanthology.org/W04-1013
[7] H.Sakaji,S.Sekine,andS.Masuyama,“Extractingcausalknowledge
using clue phrases and syntactic patterns,” in Practical Aspects of
Knowledge Management, T. Yamaguchi, Ed. Berlin, Heidelberg:
SpringerBerlinHeidelberg,2008,pp.111–122.
[8] J.Devlin,M.-W.Chang,K.Lee,andK.Toutanova,“Bert:Pre-training
ofdeepbidirectionaltransformersforlanguageunderstanding,”inNorth
American Chapter of the Association for Computational Linguistics,
2019. [Online]. Available: https://api.semanticscholar.org/CorpusID:
52967399
[9] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai,
J. Sun, M. Wang, and H. Wang, “Retrieval-augmented generation
for large language models: A survey,” 2024. [Online]. Available:
https://arxiv.org/abs/2312.10997
[10] Y.Luo,B.Yang,D.Xu,andL.Tian,“Asurvey:Complexknowledge
base question answering,”in 2022 IEEE 2ndInternational Conference
on Information Communication and Software Engineering (ICICSE),
2022,pp.46–52.
[11] A.Balaguer,V.Benara,R.L.deFreitasCunha,R.deM.Esteva˜oFilho,
T.Hendry,D.Holstein,J.Marsman,N.Mecklenburg,S.Malvar,L.O.
Nunes, R. Padilha, M. Sharp, B. Silva, S. Sharma, V. Aski, and
R.Chandra,“Ragvsfine-tuning:Pipelines,tradeoffs,andacasestudyon
agriculture,”2024.[Online].Available:https://arxiv.org/abs/2401.08406
[12] A.Saxena,A.Tripathi,andP.Talukdar,“Improvingmulti-hopquestion
answeringoverknowledgegraphsusingknowledgebaseembeddings,”
in Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics, D. Jurafsky, J. Chai, N. Schluter,
and J. Tetreault, Eds. Online: Association for Computational
Linguistics, Jul. 2020, pp. 4498–4507. [Online]. Available: https:
//aclanthology.org/2020.acl-main.412
[13] L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang, J. Zhang, Z. Chen,
J. Tang, X. Chen, Y. Lin, W. X. Zhao, Z. Wei, and J. Wen, “A
survey on large language model based autonomous agents,” Frontiers
of Computer Science, vol. 18, no. 6, p. 186345, Mar 2024. [Online].
Available:https://doi.org/10.1007/s11704-024-40231-1

Paper:Measuring design compliance using neural language models - an automotive case study.pdf
=== Page 1 ===
Measuring design compliance u
an automotiv
DhasarathyParthasarathy,CeciliaEkelin
VolvoGroup,Sweden
𝑒
𝑋
Query programs
𝑟
𝑋
𝑒
𝑌
PLM
𝑌 𝑚 𝑒
𝑌
Neural language model trained on source code
Figure1:Overview:Wedemonstrateasystemthatautomatica
automotiveController-Handlerdesignpattern.Theheartofthe
Theassessmentprocesscomparesgeometricalpropertiesofthe
stancesofthepattern.Thecomparisonisthenconvertedintoas
ABSTRACT
Asthemodernvehiclebecomesmoresoftware-defined,itisbe-
ginning to take significant effort to avoid serious regression in
softwaredesign.Thisisbecauseautomotivesoftwarearchitects
relylargelyuponmanualreviewofcodetospotdeviationsfrom
specifieddesignprinciples.Suchanapproachisbothinefficient
andpronetoerror.Inrecentdays,neurallanguagemodelspre-
trainedonsourcecodearebeginningtobeusedforautomatinga
varietyofprogrammingtasks.Inthiswork,weextendtheappli-
cationofsuchaProgrammingLanguageModel(PLM)toautomate
theassessmentofdesigncompliance.UsingaPLM,weconstruct
asystemthatassesseswhetherasetofqueryprogramscomply
withController-Handler,adesignpatternspecifiedtoensurehard-
wareabstractioninautomotivecontrolsoftware.Theassessment
isbaseduponmeasuringwhetherthegeometricalarrangementof
queryprogramembeddings,extractedfromthePLM,alignswith
thatofasetofknownimplementationsofthepattern.Thelevel
ofalignmentisthentransformedintoaninterpretablemeasureof
compliance.Usingacontrolledexperiment,wedemonstratethat
ourtechniquedeterminescompliancewithaprecisionof92%.Also,
usingexpertreviewtocalibratetheautomatedassessment,wein-
troduceaprotocoltodeterminethenatureoftheviolation,helping
eventualrefactoring.Resultsfromthisworkindicatethatneurallan-
guagemodelscanprovidevaluableassistancetohumanarchitects
inassessingandfixingviolationsinautomotivesoftwaredesign.
PROMISE’22,November17,2022,Singapore,Singapore
©2022AssociationforComputingMachinery.
Thisistheauthor’sversionofthework.Itispostedhereforyourpersonaluse.Not
forredistribution.ThedefinitiveVersionofRecordwaspublishedinProceedingsof
the18thInternationalConferenceonPredictiveModelsandDataAnalyticsinSoftware
Engineering(PROMISE’22),November17,2022,Singapore,Singapore,https://doi.org/10.
1145/3558489.3559067.
2202
guA
82
]ES.sc[
1v51231.8022:viXra

using neural language models –
ve case study
AnjaliKarri,JiapengSun,PanagiotisMoraitis
ChalmersUniversityofTechnology,Sweden
𝑒 ,𝑒 -Embeddings of query programs 𝑋,𝑌
𝑋 𝑌
𝑟 -Average offset between controller and handler programs seen in a set of
known instances of the pattern
𝑒 -Embedding of 𝑌expected by 𝑟
𝑌
𝑚–Alignment between expected and actual embedding as a measure of
compliance with the Controller-Handler design pattern
allyassesseswhetherqueryprograms (𝑋,𝑌) complieswiththe
esystemisaneurallanguagemodelpre-trainedonsourcecode.
eembeddingsofqueryprogramswiththatofasetofknownin-
scorethatallowsarchitectstointerpretthelevelofcompliance.
CCSCONCEPTS
• Software and its engineering → Software architectures; •
Computingmethodologies→Naturallanguageprocessing.
KEYWORDS
neuralprogramminglanguagemodels,languagemodelevaluation,
softwaredesignpatterns
1 INTRODUCTION
’Ifyouthinkgooddesignisexpensive,trybaddesign’,goesthe
aphorism.Whilethisobservationcanheadlineanydesigneffort,it
iscertainlyaprimemotivatorinthedesignofsoftware.Verygener-
ally,theprocessofsoftwaredesignattemptstoenvisionasoftware
solutionthatmeetsagivensetofrequirements[14].Theclassic
designprocessachievesthisusingacombinationoftoolsincluding
designprinciples,architecturemodels,interfacespecifications,etc.,
thatparallellyguide,ifnotinstructtop-down,theimplementation
ofthesolution.Meetingcorebusinessrequirementsmaybeitspri-
maryobjective,butsoftwaredesignoftenaspiresfurthertoaddress
severalnon-functionalconcernstoincreasethelikelihoodthatthe
solutionoperatesandevolvessustainably[4].Theexpandedset
ofconcernsinevitablycomplicatesthedesignprocess,whichnow
becomes an act of trading-off concerns in multiple dimensions,
undertheshadowofconstantuncertainty.Inrecentyears,neural
languagemodelspre-trainedonlargesourcecodecorporahave
startedbecomingbuildingblocksforautomatingavarietyofcom-
plexprogrammingtaskslikecodecompletionandprogramrepair
([13] and [25], for example). If such programming tasks, which
oftenrequirenuancedjudgment,canbeautomated,canasimilar
approachbeappliedtoautomatedesigntasks?Inthiswork,we
takeinitialstepstowardsansweringthisquestionbyinvestigating
ausecaseinautomotivesoftwaredesign.

=== Page 2 ===
PROMISE’22,November17,2022,Singapore,Singapore
Needforassistanceinautomotivesoftwaredesign–Themod-
ernvehicleisincreasinglysoftwaredriven.Softwareplaysacentral
roleinrealizingavarietyofin-vehiclefunctionslikepreventive
safety,driverassistance,energymanagement,etc.Notonlyisin-
creasingthefootprintofsoftwareessentialtomeetthegrowing
demandforfunctionality,vehiclemanufacturersareincreasingly
realizingthatwell-designedsoftwareisakeyrequirementtomeet
thisdemandsustainably[20].However,thereareseveralfactors
thatcomplicatethedesignandevolutionofautomotivesoftware.A
strictregulatoryenvironment,decadesoflegacy,complexintegra-
tionchains,thestronginfluenceofnon-functionalconcernslike
safetyandsecurity,andstronghardwarecouplingareprominent
amongthem.Moreover,sincetheautomotiveindustryhasitsroots
intraditionaldisciplineslikemechanicalandelectricalengineering,
knowledgeofprinciplesandpracticesofsoftwareengineeringis
lesswidespread.Therefore,deliveringsoftwareathighcadence,
whileminimizingdesigncompromisesandpreventingmajorthreats
tosustainableevolutionofthecodebase,remainsaformidable
challenge.Currently,theindustryreliesuponexperiencedsoftware
architectstomanuallyassessthecodefordesignviolationsand
intervenewithchangeswhennecessary.Withviolationsfromspec-
ifieddesignbeinginevitableinpractice,oneadvantageofmanual
reviewisthattheexpertisabletoexercisenuanceandjudgment
onwhetheragivenviolationisacceptable.Thedisadvantage,of
course,isthatmanuallyassessingthousandsoflinesofcodeis
effort-intensive.Theintensityofeffortaloneincreasesthelikeli-
hoodthatmajorviolationsareleftundiscoveredandtheoverall
designregresses,withharmfulconsequencesforsystemevolution.
Automaticassessmentofdesign,withlevelsofnuancecompara-
bletoahumanexpert,wouldthereforeprovidevitalassistancein
increasingthespeedandeffectivenessofdesignintervention.
Neurallanguagemodelsforsoftwaredesign–Theapplication
ofneurallanguagemodelsforautomatingprogrammingtasksis
fundamentallybaseduponthenaturalnesshypothesis[1],which
recognizesthatsoftwareisaformofcommunication.NeuralPro-
grammingLanguageModels(PLMs),pre-trainedoncodecorpora,
exploitsuchinfusedelementsofhumancommunicationtolearna
statisticalmodelofprogramming.Suchknowledgeliesatthefoun-
dationofitsabilitytoautomatecomplexprogrammingtasks.In
ourattempttoapplyPLMsforautomatingdesign-relatedtasks,we
startbyconsideringwhetherdesigninformationisalsonaturally
communicatedincode.Generally,programmerschoosetoaugment
self-explanationincodesothatfellow-programmersfinditeasy
toextend.Abasicexplanatorytechniquelikeusingwell-worded
programstatements,inaclearlyevidentsequence,accompanied
bylucidnaturallanguagecommentsclearlyhelpscodeextension
inrelativelylocalscopes.Inparallel,carefullywordingandcharac-
terizingentitieslikemethods,modules,orclasses,andthewaysin
whichtheyrelate,interact,andarepackaged,promotemoreglobal
extension.Infusingsuchexplanation,whichislargelycomplemen-
tarytoprogramlogic,clearlyachievemanyofthesameobjectives
ofatop-downdesignexercise.Infact,theco-evolutionofdesignand
solution–the’codeasdesign’approach–isitselfanaturalbyprod-
uctofusinghigh-levelPLs[26].Putsimply,withsoftwarenaturally
containingalgorithmicandexplanatorychannels,thelatterislikely
toincludeinformationaboutdesign.Thus,irrespectiveofwhetherit

Parthasarathy,etal.
emergesbottom-upasaresultofprogrammingortop-downasare-
sultofadesignprocess,elementsofsoftwaredesignoccurnaturallyin
sourcecode.Giventhat(1)PLMssuccessfullyunderstandstatistical
propertiesofnaturalprogramming,and(2)elementsofdesignoccur
naturallyinsourcecode,wereasonthatPLMspre-trainedonlarge
codecorporaarelikelytounderstandelementsofdesign.Thepurpose
ofthisstudyistobothverifythisreasoningandexploititspotential.
Problemstatement–WeenvisionasystemSthatusesaPLMF
toassesswhetherasetofqueryprograms/files𝑄,drawnfromacor-
pusQ,complieswithadesignpatternDspecifiedforthecorpus.A
score𝑚calculatedbythesystemprovidesameasureofcompliance.
𝑚=S(𝑄, D; F), 𝑄 ⊆Q (1)
Toconstructandevaluatesuchasystem,weposethefollowing
researchquestions.
RQ1–CanthesystemSforassessingdesigncompliancebecon-
structedusinganeurallanguagemodeltrainedoncode?
RQ2–DoestheassessmentimprovewhenthePLMisexplicitly
providedwithinformationrelevanttodesignpatternD?
RQ3–Canthemeasure𝑚becommunicatedinawaythatmakes
iteasyforanarchitecttounderstandthecomplianceof𝑄withD?
Resultsfromourstudy1showthatitisindeedpossibletoconstruct
such a system for measuring design compliance. Such a neural
languagemodelingapproachtoautomaticallyassessdesigncompli-
ancehasthepotentialtoimprovethechancesofquicklyidentifying
(andsubsequentlycorrecting)designviolations,thuspromoting
sustainableevolutionofthecodebasewithincreasedcadence.
2 CHOOSINGACORPUSANDDESIGN
PATTERNFORSTUDY
Wenowdescribe(1)thecorpusQ,fromwhichqueryprogramsare
drawn,and(2)thepatternDagainstwhichtheirdesignisassessed.
TruckApplicationSoftwarecorpus–Inamodernvehicle,the
overallsystemwhichgovernstheautomaticcontrolofin-vehicle
functionsisgenerallyreferredtoastheElectrical/Electronic(E/E)
system([15]).Inthissystem,thebasicunitof(electronic)hardware
istheElectronicControlUnit(ECU).Itistypicallyamicrocontroller-
basedplatformthatbringstogetherthenecessaryelementsofauto-
maticcontrol–thecontrollogic,sensors,actuators,andrelatedI/O.
Software–deployedonECUstorealizethecontrollogic–isour
focushere.Forthisstudy,weuseTruckApplicationSoftware(TAS),
acorpusof∼5kfilesofC-languagecode,thatimplementsin-vehicle
functionalityfortheVolvoGroup’struckplatforms.Principlesof
softwaredesignadoptedinTASstemmainlyfromtheAutomotive
SoftwareArchitecture(AUTOSAR)industrystandard[3].Thebasic
unitofsoftwaredefinedbyAUTOSARistheSoftwareComponent
(SWC),whichisanindependentlydeployableunitoffunctionality.
AtthecoreofeachSWCisasetofCfiles,calledsoftwaremod-
ules,whichcollectivelyrealizethefunctionalityoftheSWC.Upon
deployment,SWCsinteractwitheachothertocollectivelyrealize
controlapplications(Figure2a).Thedecompositionofcontrollogic
intoasetofSWCsisfundamentalforachievingseveralobjectivesof
1Wereleasetheimplementationofourcomplianceassessmentsystemhere.Sincethe
testcorpusQisproprietary,weincludeexamplesthatillustrateitscontent.

=== Page 3 ===
Measuringdesigncomplianceusingneurallanguagemodels
automotivesoftwaredesignincludingthemanagementofcomplex-
ity,separationofconcerns,andthepromotionofreuse.Therefore,
thenotionofaSWCis,defacto,alsothebasictoolforsoftwarede-
signinTAS.Anydesignpatternofincreasedsophisticationadopted
inthiscorpus,buildsupontheideaSWCs.Onesuchdesignpattern,
whichwefocusuponinthisstudy,isdescribedbelow.
0..* 0..*
Use Use
Application SWC Module
1..* 1..*
(a)
0..*
Use
Controller Handler Device
0..* 1
Use Handles
(b)
Figure 2: (a) SWCs collaborating to implement a vehicle
function,(b)Controller-Handlersoftwaredesignpatternfor
automotivecontrolsystems
TheController-Handlerdesignpattern–Letusnowconsider
anexampleapplication2inTAS–roofhatchcontrol–anditsdesign.
Trucksaresometimesequippedwithahatchontheroof,whichthe
drivercancontroltoadjusttheflowofairandtheamountofambi-
entlight.Thehatchisequippedwithmotorsthateffectthiscontrol.
Onedesignprinciple,usedinTAS,toimplementsuchafunctionis
theseparationofthecorelogicforhatchadjustment,theController,
fromthelogicthathandlesthemotors,theHandler.Themainrea-
sonforthisseparationisthattheroof-hatchmotorsarephysically
wiredtospecifichardwarepinsinaspecificECU.Thismeansthat
thehandlerneedstobedeployedonthisparticularECUanduse
thedesignatedpinstocontrolthemotor.Incontrast,theapplica-
tionlogicinthecontrollerisnotboundtoaspecificECU,which
allowsmorefreedomindecidingwhereitcanbedeployed.Since
automotiveECUs(traditionally)arequiteresourceconstrained,this
Controller-Handler(CH)patternoffersawaytoefficientlyutilize
theavailableresources.Moreover,suchhardwareabstractionis
essentialtomakecost-effectiveproductofferings.Atrucktypically
needstosupportahighlevelofproductconfigurationtobeable
tofitavarietyoftransportoperationsandmarketsegments.A
roofhatchcontrolapplicationthatproperlyimplementsCHcan
helpoffertruckswithdifferentvariantsofroof-hatchmotors,each
tunedtomeetacertaincustomerdemand.Havingseparatedthe
applicationlogic,thecontrollercanbereusedoverallthesevariants.
DuetoitsprevalenceinTASwefocusontheCHdesignpattern
inthisstudy.Formally(seeFigure2b),theCHpatternadvocates
theimplementationofanin-vehiclecontrolapplicationusingaset
ofSWCs𝑃 = {𝐶,𝐻
1
,𝐻
2
,...𝐻 𝑁}.Here,theController component
𝐶,implementsthecorecontrollogic,whileHandlercomponents
𝐻
𝑖
,𝑖 =1...𝑁 implementhardware-specificlogic.Inpractice,since
thehandlercomponentsareusuallyindependentofeachother,
the CH design pattern can be defined as applying to each pair
2RefertoroofHatchinthereleasedcodeforanillustration

PROMISE’22,November17,2022,Singapore,Singapore
𝑃 =(𝐶,𝐻 𝑖)ofcontrollerandhandlerSWCsusedtorealizetheover-
allapplication.Apartfromroofhatchcontrol,applicationsinTAS
thatadoptthisdesignpatternincludewasherandwipercontrol,
exteriorlightscontrolandacceleratorpedalcontrol.
WhilethereasoningbehindtheCHpatternisintuitive,compliance
isnotalwaysachievableinpractice.Forinstance,theresponsibility
splitbetweenthecontrollerandhandlermustbeattherightlevelto,
amongotherthings,avoidduplicationoflogicacrosshandlervari-
ants.Roofhatchcontrolincludesspeciallogictoensureelectrical
safetyduringactuation.Placingallofthissafetylogicinthehandler
(andnotjustmotor-specificparts)leadstoduplication.Iftherehap-
penstobeaviolationinsomehandlervariantwhichimplements
moresafetylogicthannecessary,spottingthisisnoteasyforanar-
chitectwhowasnotintimatelyinvolvedinitsdesign.Ontheother
hand,theremaybesufficientcluesintokensusedinthecompro-
misedhandlersourcecodethataneuralPLMmayfindanomalous.
3 CONSTRUCTINGASYSTEMFOR
ASSESSINGDESIGNCOMPLIANCE
HavingfixedthequerycorpusQ asTASandthedesignpattern
D asController-Handlerforthestudy,werestateourobjective.
WeaimtoconstructasystemSthatassesseswhetheranordered
pair𝑄 = (𝑋,𝑌), 𝑋,𝑌 ∈ Q ofSWCscomplywiththeController-
Handlerdesignpattern.ThougheitheroftheSWCsinthispair
canberealizedusingmultiplesoftwaremodules(orprograms),at
thispointitissimplertoconsiderthecasewhereeachSWCis
realizedasoneprogram.Werelaxthisconditionatalaterpoint.
Thefollowingsectionsdescribetheprocessofconstructingthe
complianceassessmentsystemSthatweenvisioninEq.1.
Pre-trainingaPLM–Inthiswork,weconsideraprogram𝑋 =
(𝑡
1
,𝑡
2
,...,𝑡 𝑁) to be a source code file containing a sequence of
tokens. We then define a PLM to be a language representation
modeloftheformF(𝑋 𝑀)→𝑋 pre-trainedasamaskedlanguage
model,firstintroducedinBERT[8].Thecoretaskinpre-training
suchamodelisMaskedReconstruction(MR),showninEq.23.Inthis
task,thePLMisprovidedamaskedprogram𝑋 ,whichproduced
𝑀
byreplacingafractionoftokensin𝑋 withamasktokent.The
modelisthentaskedtorecovertokensinmaskedpositions,asa
resultofwhichitlearnscontextualmeaningsofprograms.
𝑀𝑅(𝑋;F)= F(𝑋 𝑀)[𝑗] ==𝑋[𝑗],
(2)
𝑗 ={𝑖 :𝑡 𝑖 =t,𝑡 𝑖 ∈𝑋 𝑀}
SinceouraimistoassessdesigncomplianceinTASwhichisa
C-languagecorpus,wepre-trainamonolingualPLMonCcode.
Aspre-trainingcorpus P,weuse∼75MfilesofCcodederived
fromtheGitHubpublicdataset4.Themodelisthenpre-trainedby
minimizingtheobjectiveshowninEq.3.Priortobeingfedintoa
PLM,eachprogramistokenizedandsplitfurtherintoasequence
ofsubwordsusingtheBytePairEncoding(BPE)[28]mechanism.
F :=argmin E 𝑋∈P 𝑀𝑅(𝑋; F) (3)
F
TheproceduredescribedinEq.1assesseswhetherasetofprograms
𝑄complieswithadesignpatternD.Practically,however,feeding
anentireprogramintothePLMisanissuebecauseCprograms
3Inpractice,adifferentiablecross-entropylossisused
4https://console.cloud.google.com/marketplace/details/github/github-repos

=== Page 4 ===
PROMISE’22,November17,2022,Singapore,Singapore
tendtobelong.TheaveragelengthofaCprogramis∼5ksubwords
intheGitHubcorpusand∼7ksubwordsintheTAScorpus.The
Transformerarchitecture[32],whichisthemainstayofseveral
previouslyreportedfoundationalPLMslikeCodeBERT[10],istypi-
callyconfiguredtohandleinputsequencesoflength512-1024.This
isbecausethevanillaself-attentionmechanismisofquadraticcom-
puteandmemorycomplexity,whichmakesitimpracticalforlonger
inputsequences.Tobeabletoassesslongprograms,wetherefore
basethePLMF onthemoreefficientReformer[17]architecture.
Combininglocality-sensitive-hashingandreversibleresiduallayers,
theReformerhandleslongsequencesmuchmoreefficiently.By
configuringtheinputsequencelengthto8192,weareabletofeed
around80%ofprogramsintheTAScorpusintotheReformer-based
F intactwithmanageablememoryandcomputationalcomplexity.
Longerprogramsaretruncatedtothislength.TheReformerencoder
F of∼180Mparameterswith6self-attentionlayers(eachwith8
heads)wastrainedfromscratchon16NvidiaTeslaV100GPUs
untiltheMRaccuracyonavalidationsetof5kfilesreached95.12%.
Assessingcompliancebymanualreview–RecallingtheCH
designpatterndescribedinSection2,letusnowconsiderhowahu-
manarchitectwouldassesswhetheraquerypair(𝑋,𝑌)ofprograms
complieswiththispattern.Thearchitectwouldnormallydothisby
reviewingthecode(orthe‘naturalness’)oftheprogramsandassess
whether𝑋and𝑌respectivelyembodycoreprinciplesofacontroller
anditsassociatedhandler.Itis,however,importanttonotethat
theCHpatterndefinesexpectationsjointlyonthepairandnoton
individualprograms.Therefore,astartingpointforthearchitect
wouldbetojuxtaposerelatedpartsfromthepair(sometimesmen-
tally)andthenconducttheassessment.Wefinditusefultoreferto
suchajuxtapositionas𝑋𝑌 –the‘jointness’ofthetwoprograms.It
isonthis–attimesabstract–representationXYthatthearchitect
assesseswhetherprinciplesoftheCHpatternarecompliedwith.In
theexampleofroofhatchcontrol,signsofcomplianceincludethat
theinterfaceforthehandlerisapureabstractionofthehardware
interfaceforthehatchmotors.Thatis,thehandlerdoesnotcontain
extralogice.g.toprotectthemotorsfromoverusage.Thatkind
oflogicwouldbepartofthecontroller.Similarly,thecontroller
shouldmakeuseofthehandlerinterfaceonlytointeractwiththe
motors.Signsofdeviationfromthepatternaretheoppositeofwhat
hasbeendescribed.Thatis,thehandlercontainstoomuchcontrol
logicorthecontrollerinteractsdirectlywiththemotors.Notonlyis
manuallyassessingthejointness𝑋𝑌 forsignsofdeviationdifficult,
thereareseveralfactorsthatcomplicatetheprocessfurther.First,
anyinstanceoftheCHpatterniscertaintocontaincodethatfalls
outsidethepurviewofthepatternitself.Hence,anarchitectwill
havetoidentifyandassesstenetsofthepatterninadilutedcontext.
Second,asarelativelyloosepattern,itcanberealizedinseveral
styles.Anarchitectwouldthereforeneedtojudgewhetheragiven
styleofimplementationislegitimate.Third,itispracticallydifficult
toconstructanidealrealizationagainstwhichthequeryprograms
canbeassessed.Usually,thearchitectreliesonasubjectivemental
modelofthepattern,whichisnotonlydifficulttoexplicitlystate,
butalsoaffectstheobjectivityoftheassessment.Addressingthese
concernsrequiresnuancedjudgment,whichispreciselywhata
humanexpertapplies.InusingaPLMasanalternativetoahuman
expert,wenowdescribehowweaddresssomeoftheseconcerns.

Parthasarathy,etal.
Assessingcomplianceusingprogramembeddings–Themain
toolweuseforPLM-basedcomplianceassessmentistheprogram
embedding𝑒
𝑋
,whichisavectorrepresentationoftheprogram𝑋
thatreflectsitssemanticproperties.Asshownin[24],thereare
differentwaystoextractembeddingsfromcontextuallanguage
models,eachcapturingdifferentaspectsofinformation.Aftersome
trialanderror,weempiricallydecidetousethenormalizedoutput
ofthefinal(6th)layerofF asshownbelow.
F (𝑋)
𝑒 𝑋 = ||F 6 (𝑋)|| (4)
6
ThePLMF ispre-trainedonthemaskedreconstructiontaskonmil-
lionsofprogramexamples.Itisthereforereasonabletoexpectthat
theembedding𝑒 isafairlyrobustrepresentationoftheprogram𝑋
𝑋
andisinsensitivetominorsemanticvariations.Thus,theprocessof
assessingwhether(𝑋,𝑌)complieswiththeCHpatternisdone,not
inthecodespace,butinavectorspaceusingembeddings(𝑒
𝑋
,𝑒 𝑌).
Whilethispairofembeddingssufficientlyrepresenttheprograms
individually,anadditionalrepresentationisneededtoaddressthe
jointperspective𝑋𝑌.Onesimplemodeltocapturethejointnessof
apairofprogramswouldbetheoffsetbetweentheirembeddings.
𝑟 𝑋𝑌 =𝑒 𝑌 −𝑒 𝑋 (5)
Shouldthereexistabenchmarkvector𝑟 thatcapturestherequired
levelofjointnessasprescribedbytheCHdesignpattern,thenthe
assessmentofdesigncompliancereducestocheckingthealign-
mentbetween𝑟 and𝑟 intheembeddingspace.Putotherwise,
𝑋𝑌
if𝑟 servesasaneffectiveoffsetvectorbetweentheembeddingsof
thepairofprograms(𝑋,𝑌),i.e.,ifEq.6issatisfied,thenthispair
comesclosetorealizingtheprinciplesspecifiedbytheCHpattern.
𝑒^𝑌 :=𝑒 𝑋 +𝑟 ≈𝑒 𝑌 (6)
Asnotedearlieramongconcernsinmanualassessment,thereisno
easywaytoconstructanidealrealizationoftheCHpatterninthe
codespace.Thismeansthataccesstoitsembeddingequivalent𝑟
isequallydifficult.Asapracticalalternative,weassesscompliance
withtheaveragerealizationoftheCHpattern,extractedfromaset
ofknowninstances.Thatis,givenaset𝑉 ={(𝐶,𝐻)}𝑁 fromthe
𝑖=1
TAScorpusthatareknowntoimplementtheCHpattern,wedefine
abenchmarkofaveragejointness(Eq.7),thataveragesoffsetvec-
torsfrompairsin𝑉.Ifthisbenchmarkservesasaneffectiveoffset
forqueryprograms(𝑋,𝑌),satisfyingEq.6,thenthispaircomes
closetorealizingtheaverageimplementationoftheCHpatternseen
in|𝑉|knowninstances.Apartfrombeinganintuitiveandpractical
benchmark,bypoolingcommontraitsfromknowninstances,𝑟pro-
videsastrongersignaturefortheCHpatterncomparedtoindividual
instances,wheresignaturesofthepatternarelikelytobediluted.
1 ∑︁
𝑟 := |𝑉| 𝑒 𝐻 −𝑒 𝐶 (7)
(𝐶,𝐻)∈𝑉
AsshownusinganexampleinFigure3,servingasanoffsetvector
from𝑒
𝑋
,if𝑟isabletopredictahandlerembedding𝑒^𝑌 thatisreason-
ablyclosetoitsactualcounterpart𝑒
𝑌
,programs(𝑋,𝑌)arelikelyto
complywiththeCHpattern.Suchclosenessbetween𝑒^𝑌 and𝑒
𝑌
is
easilymeasurableusingthecosinesimilaritybetweenthesetwovec-
tors.Withthismethod,theassessmentsystemfortheCHdesignpat-
ternD,originallyenvisionedasEq.1,canbere-writtenasfollows.

=== Page 5 ===
Measuringdesigncomplianceusingneurallanguagemodels PROMISE’22,November17,2022,Singapore,Singapore
Procedure1:ComplianceassessmentsystemS
𝑚=S((𝑋,𝑌),D; F,𝑉)= 𝑒 𝑌 ·(𝑒 𝑋 +𝑟) (8) Parameters :Testinput(𝑋,𝑌),PLMF,TAScorpusQ,known
||𝑒 𝑌|| 2 ||𝑒 𝑋 +𝑟|| 2 instancesoftheCHpattern𝑉
1 Function𝑀(𝑒 𝐴 , 𝑒 𝐵):
2
𝑚=
||𝑒𝐴
𝑒
||
𝐴
2
.𝑒
||
𝐵
𝑒𝐵||2
return𝑚
3
𝑟 4
FunctionS(𝑋,𝑌;F,𝑉):
𝑒𝑊 𝑒𝑋 /* Note: 𝑒 𝑋 =F 6 (𝑋)/||F 6 (𝑋)|| */
5 𝑟 = |𝑉 1 | (cid:205) (𝐶,𝐻)∈𝑉 𝑒 𝐻 −𝑒 𝐶
𝑒𝑋+𝑟 𝑒𝑌
7
6 𝑐
𝑘
=
=i
[
n
𝑀
de
(𝑒
x
𝑍
of
,
(
𝑒
s
𝑋
ort
+
(𝑐
𝑟
)
)
,
:
𝑀
𝑍
(𝑒
∈
𝑌 ,
Q
𝑒 𝑋
\
+
{𝑋
𝑟)
}
)
]
// rank
𝑒𝑍 8 𝑙=𝑘 ≤0.1∗|Q| // binary assessment of compliance
return𝑘,𝑙
9
𝑚
Figure3:Thealignmentbetweentheactualhandlerembed-
4 EXPERIMENTS
ding𝑒
𝑌
andthepredictedone𝑒 𝑋+𝑟reflectscompliance.Vec-
Thissectiondescribeshowweexperimentwiththesystembased
tors𝑒 𝑊 ,𝑒 𝑍 illustrateembeddingsofprograms𝑊,𝑍 ∈Q
uponparametersidentifiedinEq.8.
Query (𝑋,𝑌) andbenchmarkprograms𝑉 –Theobjectiveof
Usingcosinesimilarityasthemetricmeasure–standardpractice theassessmentprocessistocheckwhetherapairofquerySWCs
forcomparinglanguagemodelembeddings–resultsin−1≤𝑚 ≤1. (𝑋,𝑌)complieswiththeaveragerealizationoftheCHpatternseen
Then,𝑚≈1meansthatthepredictedhandlerembedding𝑒^𝑌 closely inaseparateset𝑉 ofknowninstances.Withthehelpofarchitects
alignswiththatoftheactualhandler𝑒 𝑌 ,indicatingcompliance. whoarefamiliarwiththeTAScorpus,wefirstidentify21known
Thus,asawaytoassesscompliancewiththeCHdesignpattern, instancesoftheCHpatternandcuratethemintoasetV.Next,we
wesubstituteacomplexcodereviewprocesswithavastlysimpler designacontrolledexperimentbyselectingtwotypesofqueries.
comparisonofembeddingsextractedfromaneurallanguagemodel. • The positive query – where the query𝑄+ ∈ V is known to
Easinginterpretationofcompliance–Withcosinesimilarity, beanimplementationoftheCHpatternthatislikelytosatisfy
whileitisclearthat𝑚 = 1and𝑚 = −1indicateperfectcompli- theconditionspecifiedinEq.7.Thebenchmarksetinthiscaseis
anceandnon-compliancerespectively,suchperfectscoresarerare. 𝑉 =V\{𝑄+},whichisallknowninstancesofthepatternexcluding
Scoresinbetween,whicharemostlikelyinpractice,aredifficultto theinstancechosenasthetestinput.
interpret.Inordertoprovideintuitivehuman-readableassessment, • Thenegativequery–wherethequery𝑄− ∈Q\Visknowntonot
weconvertsimilarity𝑚intoarank𝑘.Thediscreterank𝑘means implementtheCHpatternandisthereforeunlikelytosatisfyEq.7.
thatthepredictedhandlerembeddingisthe𝑘𝑡ℎ mostsimilarto Here,thebenchmarkset𝑉 =V includesallknowninstancesof
thatoftheactualhandler,whencomparedtotheembeddingsofall theCHpatternintheTAScorpus.Sinceweexpectnegativequeries
otherprogramsintheTAScorpus.Thebestindicatorofcompliance to perform poorly during the assessment, they help establish a
isarankof𝑘 =1when,amongallprogramsintheTAScorpusQ baselinefortheevaluatingtheaccuracyoftheassessmentprocess.
(excludingthecontroller𝑋)thereisnobetterhandlerthan𝑌forthe ConsiderapairofSWCs(𝐶,𝐻) ∈V,thatisknowntoimplement
controller𝑋,asassessedbythebenchmark𝑟.Conversely,arankof the CH pattern. While it is most straightforward to implement
|Q|−1meansthatthepredictedembeddingisleastsimilarandany eachSWCinthepairasoneprogram,thisisnotalwayspracti-
otherprogramintheTAScorpusisabetterhandlerthan𝑌.Thisis cal.AsshowninFigure2a,someSWCsincludealotoffunction-
theworstindicatorofcompliance.Whiletherankmaybeamore ality in which case it is necessary to split its code into several
interpretablemeasure,itsvalueisnowdependentuponthespread programsorfiles.Practically,therefore,theSWCsareoftheform
ofembeddingsaround𝑒 𝑌 .IntheexampleshowninFigure3,even 𝐶 ={𝐶
1
,𝐶
2
,...,𝐶 𝑀}and𝐻 ={𝐻
1
,𝐻
2
,...,𝐻 𝑁},eachofthembeing
ifthepredictionisreasonablygood,itisofrank𝑘 =2,sincethere implementedusingmultipleprograms.Thiscomplicatestheassess-
isanotherprogram𝑍 ∈Q,whoseembeddingisclosertothatofthe mentprocesssincethesystemSisdesignedonlytohandleapairof
actualhandlerprogram𝑌.Ifthereisconsiderableclusteringinthe programsandnotapairofsets.Asimplewaytocircumventthislim-
closeneighborhoodof𝑒 𝑌 ,thenevenagoodpredictionisunlikelyto itationisto‘unroll’thesetVintoaCartesianproductsetasfollows.
resultinarankcloseto1.Wethereforeuseasimpleruleofthumb,
V∗={(𝑐,ℎ): 𝑐 ∈𝐶,ℎ∈𝐻 : (𝐶,𝐻) ∈V} (9)
whereifthepredictedembeddinglieswithin10%ofembeddings
mostsimilarto𝑒
𝑌
,wedefinetheassessment𝑙 =Truethatthequery ForeveryknowninstanceoftheCHpattern(𝐶,𝐻) ∈V,theprod-
(𝑋,𝑌)complieswiththeCHpattern.Ifthepredictedembeddinglies uctsetV∗pairseachprograminthecontrollerSWC𝐶withevery
amongthoseof90%oftheleastsimilarprograms,welabelthepair programinthehandlercomponent𝐻.Thisprocessresultsinatotal
asnon-compliant.Thediscreterank𝑘,inadditiontoatrue/false of63pairs,whichweuseaslikelyqueriesinourexperiments.By
binaryassessmentofcompliance𝑙,easeshumancomprehensionof drawingqueries𝑄+ ∈V∗,theadvantageisthatweexhaustively
ourPLM-basedprocessofassessingdesigncompliance.Thecom- presentallcombinationsinapairedformthatissuitableforassess-
pleteprocessofcomplianceassessmentisdescribedinProcedure1. mentusingEq.8.Thedisadvantageisthatevenifatthecomponent

=== Page 6 ===
PROMISE’22,November17,2022,Singapore,Singapore
leveleverypair(𝐶,𝐻) ∈VisaknowninstanceoftheCHpattern,
noteverypair(𝑐,ℎ) ∈V∗attheprogramlevelisa‘true’controller-
handlerpairthatimplementselementaryaspectsoftheCHpattern.
ConsideringthatseveralinstancesoftheCHpatternareimple-
mentedusingmultipleprograms,andthattheassessmentsystemis
currentlydesignedtoworkonlywithapairofprograms,weaccept
theriskandloosenthedefinitionoftheCHpattern.Everypairin
theproductsetV∗ isconsideredasatruepairandispresented
asapositivecasefortesting,whilealsobeingusedtocalculate
𝑟.Negativequeries𝑄−aresimplydrawnbypickingtworandom
programsfromTASaslongasneitherofthemappearinV∗.
ThePLMF –Astheheartoftheautomatedcomplianceassess-
mentsystem,theneuralPLMF canbeseenasthemachinecoun-
terpartofahumanarchitectwhoconductsthesameassessment
manually.Withsuchananalogy,wenowreasonaboutthelevelof
informationwithwhichF istrainedanditsrelationtothequality
ofassessment.Themodelpre-trainedusingEq.3onaC-language
corpusextractedfromGitHub–whichwenowdenoteas F𝐴 –
is a C-programming expert. Using this model is akin to asking
ahumanexpertinC-programming,butonewhohasnoexperi-
enceinautomotiveapplicationdesignanddevelopment,toassess
compliance withthe CHpattern. While it isnot impossiblefor
suchanexperttoconductthisassessment,itisreasonablethatan
awarenessofrelevantdomainanddesignconceptswouldeasethe
process.ToaC-programmingexpert,wecontendthatsuchaware-
nesscanbeintroducedinthreestages.Thefirststagewouldbeto
increaseawarenessabouttheautomotive-domain,i.e.thepatternof
tokenusage(itsnaturalness)initsapplicationcode.Secondcomes
design-relatedknowledge,mainlytheconceptofSWCs,whichis
fundamentaltothedefinitionoftheCHpattern.Third,wouldbe
theconceptofcontrollersandhandlers,thesubjectsofassessment.
Like[12],weachievethefirststage–improvingdomain-familiarity
–bysimplycontinuingtopre-train F𝐴 oncodefromTAS.The
secondstagerequiresinducingtheknowledgeofaSWC–aset
ofprogramsthatjointlyrealizefunctionality.Wedothisbyfirst
assemblingaset𝐶 = {(𝐴,𝑃,𝑁)}𝑀 ofprogramsfromTAS,such
𝑖=1
that𝐴and𝑃 belongtothesameSWC,while𝑁 belongstoadif-
ferentSWC.Then,weusethetripletlosstoclusterembeddingsof
programsthatbelongtoaSWC,whilekeepingthoseofprograms
fromdifferentSWCsfurtherapart.Tosimultaneouslyensurethat
thisSWC-basedclusteringdoesnotmajorlydisrupttheembedding
geometry,andtoimpartdomainfamiliarity,wecombinetheMR
taskontheTAScorpuswithSWC-clusteringasshownbelow.
F𝐵 =argminE (𝐴,𝑃,𝑁)∈𝐶 𝑇𝑅(𝐴,𝑃,𝑁; F)+𝑀𝑅(𝐴; F)
F (10)
𝑇𝑅(𝐴,𝑃,𝑁; F)=(||𝑒 𝐴−𝑒 𝑃||2−||𝑒 𝐴−𝑒 𝑁||2)
Theresultingfine-tunedmodelF𝐵 isthusmorefamiliarwithdo-
mainanddesignconceptsrelatedTASincomparisontoF𝐴 .For
thethirdstageofinducingknowledgeaboutcontrollerandhandler
programs,wefollowasimilarapproachofencouragingthePLM
torespectivelyclustertheseprogramsbytype.Toachievethis,we
assemble(1)aset𝐷
𝐶
={(𝐶
1
,𝐶
2
,𝐴)}
𝑖
𝑀
=1
with𝐶
1
and𝐶
2
beingcon-
trollersand𝐴beinganon-controllerprogramfromtheTAScorpus,
and(2)aset𝐷
𝐻
={(𝐻
1
,𝐻
2
,𝐵)}
𝑖
𝑁
=1
,with𝐻
1
and𝐻
2
beinghandler
programsand𝐵beinganon-handlerprogram.Wethenfine-tuneF𝐵
usingthetripletlossonthecombinedset𝐷 =𝐷 𝐶∪𝐷
𝐻
,resultingin

Parthasarathy,etal.
amodelF𝐶 thatisawareoftheconceptofcontrollersandhandlers.
F𝐶 =argminE (𝐴,𝑃,𝑁)∈𝐷 𝑇𝑅(𝐴,𝑃,𝑁; F)+𝑀𝑅(𝐴; F) (11)
F
ByassessingdesigncomplianceusingmodelsF𝐴 ,F𝐵 ,andF𝐶 ,re-
spectivelyrepresentingincreasingawarenessofconceptsrelevant
totheassessment,weanalyzetheinfluenceofsuchawareness.This
assessmentisconductedonanequalnumberofpositive(𝑄+)and
negative(𝑄−)queries.Foreachquery,resultsarecollectedinterms
ofadiscreterankandabinarylabel(seeProcedure1).
5 RESULTS
Theprimarytoolwhichweuseforanalyzingtheresultsarethe
labels𝑙collectedforeachquery.Thisbinarylabelindicateswhether
thequeryhasbeenevaluatedbythesystemStocomplywithorde-
viatefromtheCHpattern.Thecontrolledexperimentusingpositive
andnegativequeries,whichareknowntocomplyanddeviatefrom
thepattern,allowscollectionofresultsofeachofthesecasesinto
lists𝐿+and𝐿−respectively.Thus,truepositive(TP)assessmentsare
thoselabelsin𝐿+thatevaluatetoTrueandfalsenegatives(FN)are
thosethatevaluatetoFalse.Falsepositive(FP)andtruenegative
(TN)assessmentsaresimilarlyidentifiablefrom𝐿−,asshownbelow.
𝑇𝑃 :{𝑙 |𝑙 ==𝑇𝑟𝑢𝑒,𝑙 ∈𝐿+}𝐹𝑁 :{𝑙 |𝑙 ==𝐹𝑎𝑙𝑠𝑒,𝑙 ∈𝐿+}
(12)
𝐹𝑃 :{𝑙 |𝑙 ==𝑇𝑟𝑢𝑒,𝑙 ∈𝐿−}𝑇𝑁 :{𝑙 |𝑙 ==𝐹𝑎𝑙𝑠𝑒,𝑙 ∈𝐿−}
Usingthis,webuildtheconfusionmatrix(Table1)andperformance
metricsoftheassessmentprocess(Table2).Thesemetricshelpus
answertheresearchquestionsposedinourproblemstatement.
Table1:Complianceassessment–confusionmatrix1,2
Prediction(𝑙) F𝐴 F𝐵 F𝐶
Queries
True False True False True False
Positive(𝑄+)-63 22(0.35) 41(0.65) 37(0.59) 26(0.41) 50(0.80) 13(0.20)
Negative(𝑄−)-63 8(0.13) 55(0.87) 7(0.11) 56(0.89) 4(0.06) 59(0.94)
1Confusionmatrixonlabels𝐿+and𝐿−calculatedaccordingtoEq.12
2Fordefinitionofeachlabel𝑙∈𝐿+𝑜𝑟𝐿−refertoProcedure1
Table2:Complianceassessment–performancemetrics
Metric withF𝐴 withF𝐵 withF𝐶
Accuracy 0.611 0.738 0.860
Recall 0.349 0.587 0.790
Precision 0.733 0.840 0.920
F1score 0.473 0.691 0.850
RQ1:assessingdesigncomplianceusingneuralPLMs–Per-
formancemetricsinTable2showencouragingsignsthatasystem
forassessingcomplianceofprograms(𝑋,𝑌)withtheCHdesign
patterncanbeconstructedusinganeurallanguagemodeltrained
onnothingbutsourcecode.Evenwiththemodel F𝐴 ,whichis
pre-trainedpurelyonnon-automotivecode,thesystemiscapable
ofidentifyinginstancesoftheCHpatternwithaprecisionofmore
than0.70.AsalsoseeninTable1,withahighTrueNegativeRate

=== Page 7 ===
Measuringdesigncomplianceusingneurallanguagemodels
(TNR)(0.87),thesystemisparticularlyadeptatcorrectlyidentify-
ingnon-compliantinstancesofthepattern.Themainconcern,seen
fromthesametable,isofcoursetheveryhighFalseNegativeRate
(FNR)of0.65.Thatis,thesystembuiltusingF𝐴 ismisclassifying
amajorityofknowninstancesoftheCHpatternasnon-compliant.
ThehighFNR,inturn,lowerstheaccuracy,precisionandF1score.
Thus,whiletheperformanceofdesigncomplianceassessmentus-
ingF𝐴 isencouraging,itremainsunsatisfactory.Wereasonthat
therearethreemainfactorsthatcouldexplainthehighFNR.The
firstistheproductsetV∗,whichconsidersallpossiblepairsof
programsfromapplicationsthatareknowninstancesoftheCH
pattern.Theintroductionofdoubtfulpairscouldtaintboththe
averagejointnessbenchmark𝑟 andwhetherapositivetestinput
isgenuinelyso.Thesecondreasoncouldbethelackoffamiliarity
withTASdomainanddesigninF𝐴 ,duetowhichprogramembed-
dingsarearrangedinsuchawaythatthebenchmarkvector𝑟 does
notserveasagoodoffset.Thethirdreasoncouldbesomeweakness
inassessmentusingtheaveragejointnessbenchmark𝑟.Results
fromtestingwithmodelsF𝐵 andF𝐶 showsthatitislesslikelyto
beduetoaweaknessintheassessmentapproach.
RQ2: assessment using PLMs with increased knowledge –
Havingbeenpre-trainedonlyusingtheGitHubcorpus,oneweak-
nessinF𝐴 isthatitislessawareofdomainanddesign-relatedspe-
cializationsintheTAScorpus.Thisispreciselywhywetrainmodels
F𝐵 andF𝐶 byexplicitlyprovidingthisinformation.Assessmentus-
ingF𝐵 ,whichlearnsdomain-specificnaturalnessandtheconceptof
SWCsusedintheTAScorpus,leadstoastrongreductionoftheFNR
to0.41.TheconsequentimprovementintheF1scoreto0.7isalso
noteworthy.Thisclearlyindicatesthatinducingtheknowledgeof
SWCsdirectlyleadstoanimprovementinthequalityofassessment.
UsingmodelF𝐶 –whichistrainedtounderstandcontrollerand
handlerprograms–fortheassessmentleadstoyetanotherstrong
reductionintheFNRto0.2,duetowhichtheprecisionandF1score
commendablyincreaseto0.92and0.85respectively.Theclustering
objectives(Eqs.10and11),arethereforelikelytohaveresultedin
anarrangementofembeddingsthatbettersatisfiesEq.7.Theseob-
servationsclearlyindicatethatusingaPLMwithanincreasedlevel
ofawarenessaboutthedomainanditsdesign,resultsinamuch
moreaccurateassessment.Evenwithamarkedimprovementinthe
qualityofassessment,theFNRremainsaconcern.Toanalyzethis,
thereisaneedtogobeyondbinaryassessmenttoafinermethod.
RQ3:easinginterpretationofassessment–Analyzingthebi-
narylabelsofcompliance(𝐿+and𝐿−),usingtheconfusionmatrix
andmetricsderivedfromit,helpsevaluatetheperformanceofthe
assessment system. While this is necessary to build confidence
inthesystem,fromtheperspectiveofanarchitectordeveloper,
itisequallyimportanttounderstandwhy thesystemassessesa
queryascomplyingordeviatingfromtheCHpattern.Sincethis
requiresmuchmorenuancethanabinarylabel,weturntothe
rank𝑘togainafinerinterpretationoftheassessment.Specifically,
weanalyzethedistributionof𝐾+ and𝐾− ofranksrespectively
collectedforpositiveandnegativequeries.Forbrevity,weconfine
ouranalysistothebestperformingsystemthatusesthemodelF𝐶 .
FirstwebeginbyvisualizingthespreadofranksshowninFigure4.
Inspectingthespreadofranksforthepositivecases𝐾+,allowsus
todemarcatethreeintervalsofrankswhereresultscluster.Next,we

PROMISE’22,November17,2022,Singapore,Singapore
samplequeriesfromeachintervalandhavethemassessedbyarchi-
tectswhoarefamiliarwithTAS.Themanualassessmentofsampled
queriesfollowsanapproachsimilartotheonedescribedinSection3.
UsingexpertreviewwecalibratetheresultsofthePLM-basedcom-
plianceassessmentsystemwithineachintervalasdescribedbelow.
Figure 4: Calibrating the results of assessment into inter-
pretableintervalsusingexpertreview
• Interval1(ranks1-100)–Theintervalwhereamajorityofpos-
itivecasescluster,itconsistsmostlyofqueriesthatareassessed
byarchitectstobegoodimplementationsoftheCHdesignpat-
tern.Someareevenjudgedtobetextbookcaseswiththeright
interfaceandresponsibilitysplitbetweencontrollerandhandler
programs.Thebestrankinginstancesinthisintervalarealsothose
whichexhibitbidirectionalexchangeofinformationbetweenthe
twoprograms.Theexchangefollowsstandardpracticeofusing
theAUTOSARRuntimeEnvironment(RTE),seenintheiruseof
RTE_readandRTE_writemethods5.Casesthatperformrelatively
worsewithinthisinterval(rankcloseto100)areobservedtoim-
plementunidirectionalinteraction,wherethecontrolleronlyreads
fromthehandler,whichisperfectlylegitimate.Therefore,expert
reviewgenerallyconsiderstestinputsthatrankinthisintervalto
becompliantwiththeCHpattern,withnoneedforrefactoring.
Thisisfurtherstrengthenedbythefactthatnotasinglenegative
testcaseisrankedbythesystemasbeinginthisinterval.
• Interval2(ranks100-1000)–Expertreviewindicatesthatpositive
queriesinthisintervalshowsubtledeviationsfromthestandard
implementationoftheCHpattern.Onedeviationisthat,whilethe
responsibilitysplitiscorrect,thecontrollerandhandlerprograms
donotinteractdirectlywitheachother.Theactualinteraction,in
thiscase,usuallyhappensthroughsomeotherprograminthecon-
trollerSWC,whichisexcludedduetotheconstraintthatthesystem
operatesonlyonpairsofprograms.Thisis,therefore,notagenuine
violationandresultssimplyduetoalimitationinthesystem.More
significantly,theotherobserveddeviationiswherethereisdirect
interaction,butitdoesnottakeplacethroughtheAUTOSARRTE.
Thisisasubtledeviationwhichcouldbenefitfromrefactoring.The
factthattheassessmentsystemconsistentlyplacessuchcasesinthe
5RefertoroofHatchinreleasedcodeforanexample

=== Page 8 ===
PROMISE’22,November17,2022,Singapore,Singapore
secondintervalisanencouragingobservation.However,thedevia-
tionsobservedbyexpertreviewinthisintervalalsoseemtobechar-
acteristicsobservableinpairsofprogramsthatarenotcontrollers
orhandlers.Forinstance,itisplausiblethatrandomsamplingfrom
therelativelysmallTAScorpusresultsinapairofnon-interacting
programs,oneofwhichcontainssomeapplication-likecodeandthe
othercontainingsomecoderelatedtohardware.Thiscouldexplain
whysomenegativecasesendupbeingrankedinthisinterval.In
general,whenthesystemranksaqueryinthisinterval,itcould
beacandidateforrefactoring.However,itisbestiftheautomated
assessmentismanuallyverifiedtoensurethatitisagenuinecase.
• Interval3(ranks1000-5000)–Veryfewpositivecasesrankinthis
interval.Insomecases,thetestinputimplementsdiagnosticrou-
tines,andnotapplicationlogic.Inothers,thecontrollerprogramis
verysmall,containingonlyafewlinesofcode.Generally,therefore
positivecasesseemtorankinthisintervalbecausetheyaremarked
outlierscomparedtotheaverageCHimplementation.Acausefor
concernarethehandfulofcaseswhicharegenuinefalsenegatives
andare,infact,assessedtobegoodimplementationsoftheCH
pattern.Moreover,aqueryrankedinthisintervalseemstodeviate
fromtheaverageimplementationtosuchanextentthatitisbarely
distinguishablefromrandomqueriesdrawnfromTAS.Aresultin
thisintervalthereforerequiresmanualreviewbyanexpert.
Thus,thegreatestadvantageofthesystemisitsabilitytoidentify
truecompliancewiththeCHpattern.Suchcases,asverifiedby
experts,rankinthefirstinterval.Also,itstendencytoranksubtle
variations–possiblecandidatesforrefactoring–inthesecond
intervalshowsitsabilitymakenuancedjudgments.Findingsuch
deviationsisastrongindicatorofitspracticalutility.Theinconclu-
sivenatureofresultsinthethirdinterval,andthepresenceofsome
negativecasesinthesecond,indicatetheboundariesofthisprocess.
Overallobservations–First,queriesthatfallwithinthefirsttwo
intervalsareremarkablysimilarincharacter,meaningthatobserva-
tionsapplyquiteconsistentlytocaseswithinagiveninterval.This
reflectstheconsistencyofautomatedassessmentusingtheaverage
jointnessbenchmark.Second,thisconsistencyeasespracticaluse
becausewhenaqueryrankswithinaninterval,wehaveareason-
ablygoodideawhythishappens.Thismeansthatanysubsequent
designinterventioncanbepreciselytargetedtorectifysuspected
deviations.Third,thecalibrationprocessmakesitpossibletodecide
theconditionsunderwhichitisnecessaryforanarchitecttointer-
vene.Ranksinthefirstintervaldonotrequirehumanverification,
whilethoseinthesecondand(especially)thirdintervalsneedactive
intervention.Theseobservationsthuspointtotheingredientsof
aprotocolforinterpretingtheresultsand,thus,practicallyusing
thesystem.However,wealsoobserveafewcaveatsintheprocess
whichwenowlist.First,underthecurrentprocess,thebenchmark𝑟
needstoberecalculatedwheneverthereisanewinstanceoftheCH
pattern.Sincethisisnotacomputationallyheavyprocess,wedonot
ratethisasamajorconcern.Analternativewouldbetofix‘golden’
instancesofthepatternsothatthebenchmark𝑟isitselffixed.While
choosingsuchinstances,itisimportanttoensurethatlegitimate
variationsareincluded.Itwouldalsobenecessarytoperiodically
auditthegoldeninstancestoensurethattheyareup-to-datewith
thelatestunderstandingofthepattern.Second,therankingprocess
dependsuponallprogramsintheTAScorpus,meaningthatthe

Parthasarathy,etal.
additionofnewprogramsneedsarecalibrationoftheresults.In
the worst case, the inclusion of a new set of highly specialized
programscouldseverelydisruptthecalibration.However,itisim-
portanttonotethatsuchrisksareinherenttoanybenchmarkthat
isderivedfromanevolvingcorpus.Third,thereisaneedtobetter
understandtherelationshipbetweenpatterncomplianceandrank.
Considerthetestinputwitharankcloseto100(andthusininterval
1),butdeviatesfromthetextbookimplementationbecauseherethe
controlleronlyreadsfrom,anddoesnotwriteto,thehandler.Such
adeviationseemssufficientfor∼100programsintheTAScorpus
tocomeinbetweenthepredictedandactualhandlerembeddings.
Whiletheempiricalcalibrationprocessallowsustocircumventthis,
itisessentialtounderstandthenatureofinterveningprogramem-
beddings.Thisisaninvestigationthatweprioritizeforfuturework.
Overall,resultsfromthisstudydemonstrateapromisingmethod
toconstructanautomatedsystemformeasuringdesignpattern
complianceusingneurallanguagemodelstrainedonsourcecode.
6 DISCUSSION
Relationshipwithembeddingregularities–Thecentralidea
ofourPLM-basedsystemfordesigncompliance,capturedinEq.7,
iswhethertherepresentationofaveragejointness𝑟 servesasan
effectiveoffsetvectorforqueryembeddings(𝑒
𝑋
,𝑒 𝑌).Forthiscon-
ditiontoholdacrossseveralpossiblequeries,theembeddingsof
controllerandhandlerprogramsneedtofollowaspecificpattern
ofarrangement.Thegeometricalrelationshipbetweentheembed-
dingsofsemanticallyrelatedentitieshasbeenthefocusofextensive
studyinneuralnaturallanguageprocessing.Mostfamously,[21]
studiedregularitiesintheembeddingsofwordpairsthatareassoci-
atedbyasimilarconcept.Usingpairsofwords(𝑀𝑎𝑛,𝑊𝑜𝑚𝑎𝑛)and
(𝐾𝑖𝑛𝑔,𝑄𝑢𝑒𝑒𝑛),theword2veclanguagemodelhasbeenshownto
learnembeddingssuchthat𝑒 𝐾𝑖𝑛𝑔−𝑒 𝑀𝑎𝑛+𝑒
𝑊𝑜𝑚𝑎𝑛
≈𝑒
𝑄𝑢𝑒𝑒𝑛
.Ifthe
modelhasaproperunderstandingoftheanalogicalrelationshipbe-
tweenthesepairsofwordsthen,asshownby[21],thesefourword
embeddingsapproximateaparallelogram.Buildinguponthisidea,
[34]showedthatembeddingsofpairsofsentencesthatarerelated
bythesameconceptshowasimilarparallelogramgeometry.Our
entireapproachcanbereinterpretedasexaminingtheembedding
regularitiesofpairs(𝑋,𝑌)ofprogramsthatarerelatedbythesame
concept–theCHdesignpattern.IftheneuralPLMF usedintheas-
sessmentsystemcorrectlyencodesthejointnessthatunderliesthe
CHdesignpattern,embeddingsofpairsofprograms(𝐶 ,𝐻 )and
1 1
(𝐶 ,𝐻 )thatimplementthispatternshouldapproximateaparallel-
2 2
ogram.Inwhichcase,𝑒
𝐶
+(𝑒
𝐻
−𝑒
𝐶
)≈𝑒
𝐻
musthold,whichis
2 1 1 2
aspecialcaseoftheaveragejointnessbenchmarkwithoneknown
patterninstance.Ifthisparallelogramgeometryconsistentlyholds
acrossseveralinstancesofthepattern,theaveragejointnessvector
𝑟naturallyservesasaneffectiveoffsetbetweentheprogramembed-
dingsofanygiveninstance(𝑋,𝑌).Further,sinceregularityisessen-
tialforcomplianceusing𝑟astheoffset,wereasonthatclusteringob-
jectives(Eqs.10and11)strengthensit,improvingthequalityofthe
assessmentprocess.Additionally,[9]formalizedtheideaoftesting
theregularityofonepairofrelatedwordsusingtheaverageoffsetof
otherpairsofsimilarlyrelatedwords–atechniquethattheyreferto
as3CosAvg.Theiruseoftheaverageoffsetcloselyreflectsourcon-
structionoftheaveragejointness𝑟asthebenchmarkforassessment.

=== Page 9 ===
Measuringdesigncomplianceusingneurallanguagemodels
Thefactthatthesystemwedesignfordesigncomplianceassess-
mentisfirmlygroundedinextensivelystudiedpropertiesofneural
languagemodels,inspiresfurtherconfidenceinourapproach.
Thequalityofprogramembeddings–Thesystemweconstruct
forassessingcompliancewithadesignpatternisbuiltuponpro-
gramembeddings,whicharevectorrepresentationsofprograms
extractedfromthePLMF.Thequalityoftheassessmentprocessis
thereforehighlydependentuponthequalityoftherepresentation.
Amongthefactorsthatinfluencethisquality,perhapsthemost
importantistheobjectivethatisusedtotrainthemodel.PLMsused
inourstudyareprimarilytrainedusingthemaskedreconstruction
taskshowninEq.3.ThesimplicityoftheMRtaskisundoubtedlyits
keyadvantage.However,amajorshortcomingoftheBERTmask-
ingrecipeisthat,byuniformlychoosing15%ofthetokenstobe
masked,onlytokensthatarenumericallyabundant–butsemanti-
callylesssignificant(like;)–aremorelikelytobemasked.Inorder
tosuccessfullyreconstructatokenlike;itisoftensufficientto
simplylearnconceptsinalocalscope,likethelikelihoodoftheend
ofastatement.Thus,withthemodelrarelybeingtaskedwithrecon-
structingtokensthataresemanticallysignificant,itislessequipped
tolearnglobalconceptslikedesign.Thiscouldexplainwhythebase
modelF𝐴 ,whichispre-trainedonlyusingMR,performsworst.This
weaknessofMRiswell-documentedinliteratureandseveralinter-
estingalternativeshavebeenproposedthatencouragethemodel
tolearnmoreglobalconcepts.Oneoptionistomodifythemask-
ingrecipelike[29],whichmasksselectedphrasesand[16],which
maskslargerspansoftokens.Anotheroptionistouse[6]and[18],
whichtaskamodeltodetectreplaced,permuted,insertedordeleted
tokens.Astasksthataremorecomplexthanreconstructingsimple
tokens,theyencouragethemodeltogainadeeperunderstandingof
programcontexts.Anotherinterestingalternativeclassoftraining
objectivesarethosethatselectivelyobfuscatetokens.Forinstance,a
de-obfuscationobjectiveproposedby[27]obfuscatesclass,method,
andvariablenamesbeforetaskingthemodeltorecoverthem.Since
thesuccessfulcompletionofthistaskrequiresadeeperandbroader
understandingoftheprogram,theymayleadtoembeddingsthat
arebettersuitedforadesignassessment.Whilewereasonthefine-
tuningobjectivesthatimprovedomainanddesign-relatedaware-
ness(Eqs.10and11)arelikelytoremainimportant,settingatask
thatismorecomplexthanMRmayresultinamuchmorepowerful
basemodelF𝐴 .Weleavethisinvestigationforfuturework.
Trainingbeyondcode–Ourresultsclearlyshowthatitispos-
sibletoconstructasystemforassessingdesigncomplianceusing
PLMstrainedonsourcecode.However,wedonotnecessarilyadvo-
cateacode-onlytrainingapproachforimpartingdesignknowledge.
Inadditiontosourcecode,automotivesoftwareengineering,which
followstheAUTOSARstandard,capturesadditionalengineering
informationusingthestandardARXMLmodelinglanguage.From
theperspectiveofdesignawareness,woulditthereforebehelpful
toexplicitlytrainPLMswithARXMLmodels?Theanswerdepends,
ofcourse,uponwhethersuchmodelsprovideadditionaldesign
awareness.IfmostoftheinformationinARXMLmodelsislikely
tobereplicatedincode,thenusingthemfortrainingisunlikely
toenhancedesignunderstanding.Otherwise,ifdesignmodelsdo
containsomeinformationnotdiscernibleincode,itmayindeedbe
helpfultoadditionallytrainwithsuchinformation.Assessingthe

PROMISE’22,November17,2022,Singapore,Singapore
usefulnessofengineeringinformationinARXMLfordesigncompli-
anceassessmentisaninvestigationthatweleaveforfuturework.
7 RELATEDWORK
Tothebestofourknowledge,ourworkisthefirstattempttoapply
neurallanguagemodelsformeasuringdesigncompliance.Insoft-
wareengineering,ourworkcloselyrelateswiththetaskofdesign
patterndetection.Arecentsurveyofthisarea[33]revealsthat
around20%ofreportedmethodstakeamachinelearningapproach,
mostlyusingclassicalalgorithms.Examplesinclude[30]which
comparespatterninstancesbymodelingthemasgraphs,and[23]
and[22]whichuseartificialneuralnetworkandrandomforest
modelsrespectivelytoclassifypatterninstances.Wereasonthat
thekeyadvantageofouruseofneurallanguagemodelsisthelevel
ofnuancethatitcanapplyforjudgingdesign.ABERT-likePLM,
whichhasbeenshowntolearnnuancedcontextualinformation,
couldbevitalforassessingdesign,wherefirmjudgmentsarerare.
Also,unlikethemajorityfocusonpatterndetection,wedevelop
atechniqueformeasuringcompliancewithagivenpattern,includ-
ingstepstoidentifythesourceofdeviation.Moreover,ourstudy
focusinguponembeddedcontrolsystemswouldalsobeauseful
additiontoanareathatmostlyfocusesonobject-orienteddesign.
AsdiscussedindetailinSection6,ourapproachforcompliance
assessmentcloselyrelatestothepropertyoflinguisticregularityob-
servedinneuralnaturallanguagemodels[21].Mostexperiments,as
surveyedin[2],studythispropertyasawaytoevaluatethequality
ofwordembeddingmodels.Fewofthemapplythispropertyinapre-
dictivesettingbyframingananalogycompletiontaskwhere,given
atriplet(𝐴,𝐵,𝐶),theypredict𝐷suchthat(𝐴,𝐵)and(𝐶,𝐷)areana-
logicalpairs.Studies[11]and[19]approachthistaskrespectively
usingpopularword2vecandGloVeembeddingmodels,while[7]
usessenseembeddingsderivedfromword2vec.Anexampleofthe
propertybeingstudiedinaspecialistdomainis[5]whichfine-tunes
GloVeonacorpusrelatedtoradiology,andusesitsembeddingsfor
theanalogycompletiontask.Similartoourdeparturefromwordem-
beddingmodels,[31]studiesthispropertyinpre-trainedcontextual
neurallanguagemodels.Theworkwesurveycanthereforebeseen
torelatetopartsofourassessmentsystem,butwebuildapipeline
thatnotonlyanalyzesembeddingregularity,butalsointerpretsit
withinthecontextofsoftwareanditsdesign.Indoingso,wealso
tiethepropertyofembeddingregularitiestoaconcreteapplication.
8 CONCLUSIONS
Thisworkdemonstrateshowneurallanguagemodelstrainedon
sourcecodecanbeusedtomeasurewhetherasetofprograms
complywithdesireddesignproperties.Complianceismeasuredby
inspectingthegeometricalproperties–specificallytheregularity–
ofqueryprogramembeddings.Ourworkalsoincludestechniques
tosignificantlyimprovetheaccuracyoftheassessmentbyexplicitly
providingthemodelwithdomainanddesign-relatedinformation.
Experimentsperformedonanautomotivecodecorpusresultina
predictionprecisionof92%.Wealsopresenthowthemodelpredic-
tionscanbeincorporatedintoadesignreviewmethodologyinorder
toprovidevaluablefeedbacktoautomotivesoftwarearchitects.

=== Page 10 ===
PROMISE’22,November17,2022,Singapore,Singapore
ACKNOWLEDGMENTS
This work is partially funded by Chalmers AI Research Center
(CHAIR)projectT4AI.
REFERENCES
[1] MiltiadisAllamanis,EarlT.Barr,PremkumarT.Devanbu,andCharlesSutton.
2018.ASurveyofMachineLearningforBigCodeandNaturalness.ACMComput.
Surv.51,4(2018),81:1–81:37. https://doi.org/10.1145/3212695
[2] AmirBakarov.2018.Asurveyofwordembeddingsevaluationmethods.arXiv
preprintarXiv:1801.09536(2018).
[3] StefanBunzel.2011.AUTOSAR-theStandardizedSoftwareArchitecture.Inform.
Spektrum34,1(2011),79–83. https://doi.org/10.1007/s00287-010-0506-7
[4] LianpingChen,MuhammadAliBabar,andBasharNuseibeh.2013.Characterizing
ArchitecturallySignificantRequirements. IEEESoftware30,2(2013),38–45.
https://doi.org/10.1109/MS.2012.174
[5] TimothyLChen,MaxEmerling,GunvantRChaudhari,YeshwantRChillakuru,
YounghoSeo,ThienkhaiHVu,andJaeHoSohn.2021.Domainspecificword
embeddingsfornaturallanguageprocessinginradiology.Journalofbiomedical
informatics113(2021),103665.
[6] KevinClark,Minh-ThangLuong,QuocV.Le,andChristopherD.Manning.2020.
ELECTRA:Pre-trainingTextEncodersasDiscriminatorsRatherThanGenerators.
In8thInternationalConferenceonLearningRepresentations,ICLR2020,Addis
Ababa,Ethiopia,April26-30,2020.OpenReview.net. https://openreview.net/
forum?id=r1xMH1BtvB
[7] JéssicaRodriguesdaSilvaandHelenadeMedeirosCaseli.2020.Generatingsense
embeddingsforsyntacticandsemanticanalogyforPortuguese.arXivpreprint
arXiv:2001.07574(2020).
[8] JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2019.BERT:
Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstanding,
JillBurstein,ChristyDoran,andThamarSolorio(Eds.).AssociationforCompu-
tationalLinguistics,4171–4186. https://doi.org/10.18653/v1/n19-1423
[9] AleksandrDrozd,AnnaGladkova,andSatoshiMatsuoka.2016.WordEmbed-
dings,Analogies,andMachineLearning:Beyondking-man+woman=queen.
InCOLING2016,26thInternationalConferenceonComputationalLinguistics,Pro-
ceedingsoftheConference:TechnicalPapers,December11-16,2016,Osaka,Japan.
ACL,3519–3530. https://aclanthology.org/C16-1332/
[10] ZhangyinFeng,DayaGuo,DuyuTang,NanDuan,XiaochengFeng,MingGong,
LinjunShou,BingQin,TingLiu,DaxinJiang,andMingZhou.2020.CodeBERT:
APre-TrainedModelforProgrammingandNaturalLanguages.InFindingsof
theAssociationforComputationalLinguistics:EMNLP2020,OnlineEvent,16-
20November2020(FindingsofACL),TrevorCohn,YulanHe,andYangLiu
(Eds.),Vol.EMNLP2020.AssociationforComputationalLinguistics,1536–1547.
https://doi.org/10.18653/v1/2020.findings-emnlp.139
[11] EdouardGrave,PiotrBojanowski,PrakharGupta,ArmandJoulin,andTomas
Mikolov. 2018. Learning word vectors for 157 languages. arXiv preprint
arXiv:1802.06893(2018).
[12] SuchinGururangan,AnaMarasovic,SwabhaSwayamdipta,KyleLo,IzBeltagy,
DougDowney,andNoahA.Smith.2020.Don’tStopPretraining:AdaptLanguage
ModelstoDomainsandTasks.InProceedingsofthe58thAnnualMeetingofthe
AssociationforComputationalLinguistics,ACL2020,Online,July5-10,2020,Dan
Jurafsky,JoyceChai,NatalieSchluter,andJoelR.Tetreault(Eds.).Association
forComputationalLinguistics,8342–8360. https://doi.org/10.18653/v1/2020.acl-
main.740
[13] AbramHindle,EarlT.Barr,ZhendongSu,MarkGabel,andPremkumarT.De-
vanbu.2012. Onthenaturalnessofsoftware.In34thInternationalConference
onSoftwareEngineering,ICSE2012,June2-9,2012,Zurich,Switzerland,Martin
Glinz,GailC.Murphy,andMauroPezzè(Eds.).IEEEComputerSociety,837–847.
https://doi.org/10.1109/ICSE.2012.6227135
[14] ISO/IECTR19759:20152015. SoftwareEngineering—Guidetothesoftware
engineeringbodyofknowledge(SWEBOK).Standard.InternationalOrganization
forStandardization,Geneva,CH.
[15] ShugangJiang.2019. VehicleE/EArchitectureandItsAdaptationtoNew
TechnicalTrends.InWCXSAEWorldCongressExperience.SAEInternational.
https://doi.org/10.4271/2019-01-0862
[16] MandarJoshi,DanqiChen,YinhanLiu,DanielS.Weld,LukeZettlemoyer,and
OmerLevy.2020. SpanBERT:ImprovingPre-trainingbyRepresentingand
PredictingSpans. Trans.Assoc.Comput.Linguistics8(2020),64–77. https:
//transacl.org/ojs/index.php/tacl/article/view/1853
[17] NikitaKitaev,LukaszKaiser,andAnselmLevskaya.2020. Reformer:The
EfficientTransformer.In8thInternationalConferenceonLearningRepresen-
tations,ICLR2020,AddisAbaba,Ethiopia,April26-30,2020.OpenReview.net.
https://openreview.net/forum?id=rkgNKkHtvB
[18] MikeLewis,YinhanLiu,NamanGoyal,MarjanGhazvininejad,Abdelrahman
Mohamed,OmerLevy,VeselinStoyanov,andLukeZettlemoyer.2020. BART:
DenoisingSequence-to-SequencePre-trainingforNaturalLanguageGeneration,

Parthasarathy,etal.
Translation,andComprehension.InProceedingsofthe58thAnnualMeetingofthe
AssociationforComputationalLinguistics,ACL2020,Online,July5-10,2020,Dan
Jurafsky,JoyceChai,NatalieSchluter,andJoelR.Tetreault(Eds.).Association
forComputationalLinguistics,7871–7880. https://doi.org/10.18653/v1/2020.acl-
main.703
[19] SuryaniLim,HenriPrade,andGillesRichard.2021. Classifyingandcomplet-
ingwordanalogiesbymachinelearning.InternationalJournalofApproximate
Reasoning132(2021),1–25.
[20] AndersMagnusson,LeoLaine,andJohanLindberg.2018.RethinkEEarchitecture
inautomotivetofacilitateautomation,connectivity,andelectromobility.In
Proceedingsofthe40thInternationalConferenceonSoftwareEngineering:Software
EngineeringinPractice,ICSE(SEIP)2018,Gothenburg,Sweden,May27-June03,
2018,FrancesPaulischandJanBosch(Eds.).ACM,65–74. https://doi.org/10.
1145/3183519.3183526
[21] TomásMikolov,Wen-tauYih,andGeoffreyZweig.2013.LinguisticRegularities
inContinuousSpaceWordRepresentations.InHumanLanguageTechnologies:
ConferenceoftheNorthAmericanChapteroftheAssociationofComputational
Linguistics,Proceedings,June9-14,2013,WestinPeachtreePlazaHotel,Atlanta,
Georgia,USA,LucyVanderwende,HalDauméIII,andKatrinKirchhoff(Eds.).
TheAssociationforComputationalLinguistics,746–751. https://aclanthology.
org/N13-1090/
[22] NajamNazar,AldeidaAleti,andYaokunZheng.2022.Feature-basedsoftware
designpatterndetection. JournalofSystemsandSoftware185(2022),111179.
https://doi.org/10.1016/j.jss.2021.111179
[23] RoyOberhauser.2020. AMachineLearningApproachTowardsAutomatic
SoftwareDesignPatternRecognitionAcrossMultipleProgrammingLanguages.
InProceedingsoftheFifteenthInternationalConferenceonSoftwareEngineering
Advances.IARIA,27–32.
[24] MatthewE.Peters,MarkNeumann,MohitIyyer,MattGardner,Christopher
Clark,KentonLee,andLukeZettlemoyer.2018.DeepContextualizedWordRep-
resentations.InProceedingsofthe2018ConferenceoftheNorthAmericanChapter
oftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,
NAACL-HLT2018,NewOrleans,Louisiana,USA,June1-6,2018,Volume1(Long
Papers),MarilynA.Walker,HengJi,andAmandaStent(Eds.).Associationfor
ComputationalLinguistics,2227–2237. https://doi.org/10.18653/v1/n18-1202
[25] YewenPu,KarthikNarasimhan,ArmandoSolar-Lezama,andReginaBarzilay.
2016.sk_p:aneuralprogramcorrectorforMOOCs.InCompanionProceedings
ofthe2016ACMSIGPLANInternationalConferenceonSystems,Programming,
LanguagesandApplications:SoftwareforHumanity,SPLASH2016,Amsterdam,
Netherlands,October30-November4,2016,EelcoVisser(Ed.).ACM,39–40.
https://doi.org/10.1145/2984043.2989222
[26] JackWReeves.1992.Whatissoftwaredesign.C++Journal2,2(1992),14–12.
[27] BaptisteRozière,Marie-AnneLachaux,MarcSzafraniec,andGuillaumeLample.
2021. DOBF:ADeobfuscationPre-TrainingObjectiveforProgrammingLan-
guages.CoRRabs/2102.07492(2021).arXiv:2102.07492 https://arxiv.org/abs/2102.
07492
[28] RicoSennrich,BarryHaddow,andAlexandraBirch.2016. NeuralMachine
TranslationofRareWordswithSubwordUnits.InProceedingsofthe54thAnnual
MeetingoftheAssociationforComputationalLinguistics,ACL2016,August7-12,
2016,Berlin,Germany,Volume1:LongPapers.TheAssociationforComputer
Linguistics. https://doi.org/10.18653/v1/p16-1162
[29] YuSun,ShuohuanWang,Yu-KunLi,ShikunFeng,XuyiChen,HanZhang,
XinTian,DanxiangZhu,HaoTian,andHuaWu.2019. ERNIE:Enhanced
RepresentationthroughKnowledgeIntegration. CoRRabs/1904.09223(2019).
arXiv:1904.09223 http://arxiv.org/abs/1904.09223
[30] HannesThaller,LukasLinsbauer,andAlexanderEgyed.2019.Featuremaps:A
comprehensiblesoftwarerepresentationfordesignpatterndetection.In2019
IEEE26thinternationalconferenceonsoftwareanalysis,evolutionandreengineering
(SANER).IEEE,207–217.
[31] AsahiUshio,LuisEspinosa-Anke,StevenSchockaert,andJoseCamacho-Collados.
2021.BERTistoNLPwhatAlexNetistoCV:canpre-trainedlanguagemodels
identifyanalogies?arXivpreprintarXiv:2105.04949(2021).
[32] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,
Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is
AllyouNeed.InAdvancesinNeuralInformationProcessingSystems30:An-
nualConferenceonNeuralInformationProcessingSystems2017,December4-
9, 2017, Long Beach, CA, USA, Isabelle Guyon, Ulrike von Luxburg, Samy
Bengio,HannaM.Wallach,RobFergus,S.V.N.Vishwanathan,andRoman
Garnett(Eds.).5998–6008. https://proceedings.neurips.cc/paper/2017/hash/
3f5ee243547dee91fbd053c1c4a845aa-Abstract.html
[33] HadisYarahmadiandSeyedMohammadHosseinHasheminejad.2020.Design
patterndetectionapproaches:asystematicreviewoftheliterature.Artif.Intell.
Rev.53,8(2020),5789–5846. https://doi.org/10.1007/s10462-020-09834-5
[34] XunjieZhuandGerarddeMelo.2020.SentenceAnalogies:LinguisticRegularities
inSentenceEmbeddings.InProceedingsofthe28thInternationalConferenceon
ComputationalLinguistics,COLING2020,Barcelona,Spain(Online),December
8-13,2020.InternationalCommitteeonComputationalLinguistics,3389–3400.
https://doi.org/10.18653/v1/2020.coling-main.300

Paper:Secure Multifaceted-RAG for Enterprise - Hybrid Knowledge Retrieval with Security Filtering.pdf
=== Page 1 ===
Secure Multifaceted-RAG for Enter
with Securi
GraceByun1,ShinsunLee*1,2,
1EmoryUniversity,2Hy
{grace.byun, shinsun.lee, nayou
Abstract
Existing Retrieval-Augmented Generation
(RAG) systems face challenges in enterprise
settingsduetolimitedretrievalscopeanddata
security risks. When relevant internal docu-
ments are unavailable, the system struggles
to generate accurate and complete responses.
Additionally, using closed-source Large
Language Models (LLMs) raises concerns
about exposing proprietary information. To
address these issues, we propose the Secure
Multifaceted-RAG (SecMulti-RAG) frame-
work, which retrieves not only from internal
documents but also from two supplementary
sources: pre-generated expert knowledge for
anticipated queries and on-demand external
LLM-generated knowledge. To mitigate
security risks, we adopt a local open-source
generator and selectively utilize external
LLMs only when prompts are deemed safe
by a filtering mechanism. This approach en-
hances completeness, prevents data leakage,
and reduces costs. In our evaluation on a
report generation task in automotive industry,
SecMulti-RAG significantly outperforms
traditional RAG—achieving 79.3–91.9%
win rates across correctness, richness, and
helpfulness in LLM-based evaluation, and
56.3–70.4% in human evaluation. This high-
lightsSecMulti-RAGasapracticalandsecure
solutionforenterpriseRAG.
1 Introduction
Retrieval-Augmented Generation (RAG) (Lewis
et al., 2020) has become a powerful tool for AI-
drivencontentgeneration.However,existingRAG
frameworks face significant limitations in enter-
prise applications. Traditional RAG systems rely
heavily on internal document retrieval, which can
lead to incomplete or inaccurate responses when
relevant information is missing. Moreover, lever-
aging external Large Language Models (LLMs)
*Work done while at Emory University as a visiting
scholar.
5202
luJ
71
]LC.sc[
2v52431.4052:viXra

rprise: Hybrid Knowledge Retrieval
ity Filtering
NayoungChoi1,JinhoD.Choi1
yundaiMotorCompany
ung.choi, jinho.choi}@emory.edu
like GPT (OpenAI et al., 2024), Claude (An-
thropic, 2024), or DeepSeek (DeepSeek-AI et al.,
2025) introduces security risks and high opera-
tionalcosts,makingthemlessviableforenterprise
deployment.
To address these challenges, we introduce
SecMulti-RAG framework that optimizes infor-
mation retrieval, security,and cost efficiency. Our
approach integrates three distinct sources: (1)
dynamically updated enterprise knowledge base,
(2) pre-written expert knowledge for anticipated
queries, and (3) on-demand external knowledge,
selectivelyretrievedwhenuserpromptissafe.For
sercurity, we introduce a filtering mechanism that
ensures proprietary corporate data is not sent to
external models. Furthermore, instead of relying
on powerful closed-source LLMs, we use a local
open-source model as the primary generator, se-
lectivelyinvokingexternalmodelsonlywhenuser
promptsarenon-sensitive.
In this paper, we apply SecMulti-RAG to the
Korean automotive industry. Our fine-tuned fil-
ter, retriever, and generation models show strong
performance, ensuring the reliability of our ap-
proach.Onthereportgenerationtask,ourmethod
outperforms the traditional RAG approach in cor-
rectness, richness, and helpfulness, as evaluated
by both humans and LLMs. We also present
adaptable strategies to meet specific environmen-
talneeds,emphasizingitsflexibility.Ourkeycon-
tributionsare:
• Multi-sourceRAGframeworkcombiningin-
ternal knowledge, pre-written expert knowl-
edge,andexternalLLMstoenhanceresponse
completeness.
• Confidentiality-preserving filter to prevent
exposureofsensitivecorporatedatatoexter-
nalLLMs.
• Cost-efficient approach that leverages high-

=== Page 2 ===
qualityretrievaltocompensateforsmallerlo-
calgenerationmodels.
2 RelatedWork
Enhancing Retrieval-Augmented Generation
Many efforts have been made to enhance RAG
systems(Zhouetal.,2024;Gutiérrezetal.,2025).
Jeong et al. (2024) classify user prompts based
on complexity to determine the optimal retrieval
strategy,makingtheirapproachrelevanttoourfil-
tering mechanism for selecting retrieval sources.
Meanwhile, Yu et al. (2023) and Wu et al. (2024)
replacetraditionaldocumentretrievalwithgenera-
tivemodels.Inparticular,Wuetal.(2024)propose
amulti-sourceRAG(MSRAG)frameworkthatin-
tegrates GPT-3.5 with web-based search, making
it the most relevant to our work. In contrast, our
approachretainsinternaldocumentretrievalwhile
integrating pre-generated expert knowledge and
externalLLMs.
Security Risks in LLM As generative models
are widely used, concerns about security and pri-
vacyriskscontinuetogrow.Manystudieshaveex-
plored methods for detecting and mitigating the
leakage of sensitive information (Zhang et al.,
2024; Kim et al., 2023; Hayes et al., 2017; Lukas
et al., 2023). For example, Chong et al. (2024)
present a prompt sanitization technique that en-
hances user privacy by identifying and removing
sensitiveinformationfromuserinputsbeforethey
are processed by LLM services. Our study incor-
porates a user prompt filtering mechanism, ensur-
ingamoresecureretrievalprocess.
3 Method
As shown in Figure 1, our RAG framework con-
sists of three core components: multi-source re-
trieval,aconfidentiality-preservingfilteringmech-
anism,andlocalmodeladaptation.(AppendixA)
1)Multi-SourceRetrieval Unlikeconventional
RAGframeworksthatrelysolelyoninternalstruc-
tured document chunks, our system retrieves in-
formation from three distinct sources: (1) inter-
nal corporate documents, (2) pre-generated high-
quality answers to anticipated queries, and (3)
real-timeexternalknowledgegeneratedbyclosed-
source LLMs. This multi-source retrieval strategy
improvesresponsecompletenessandaccuracy,es-
peciallywheninternaldocumentsareinsufficient.

Figure1:SecMulti-RAGframework
2) Confidentiality-Preserving Filtering Mech-
anism To mitigate the risk of unintended data
leakage when interacting with external closed-
source LLMs, we introduce a query filtering
mechanismthatdetectssecurity-sensitivecontent.
Ifauserqueryisclassifiedascontainingconfiden-
tial information, external retrieval is skipped, and
thesystemgeneratesresponsessolelybasedonin-
ternal documents and pre-curated expert knowl-
edge.Thismechanismensuresdataconfidentiality
whilemaintainingretrievalquality(Section4).
3) Local Model Adaptation Since enterprises
oftenencountersecurityandcostlimitationswhen
usingpowerfulclosed-sourceLLMs,weuseopen-
sourceQwen-2.5-14B-Instruct(Yangetal.,2024)
asourprimarygenerationmodel.Wefine-tunethis
model using domain-specific data to better reflect
the language and knowledge of the Korean auto-
motivedomain.(Section6)
4) End-to-End RAG Pipeline The final sys-
tem consists of a multi-stage pipeline where user
queries are processed through filtering, retrieval,
andgenerationstages.Byintegratinghigh-quality
retrieval with local model adaptation, our frame-
work demonstrates that a well-optimized retrieval
system can compensate for the limitations of
smaller, locally deployed LLMs, making enter-
priseRAGbothscalableandsecure.
4 ConfidentialityFilter
4.1 Dataset
Security-sensitive and general (non-sensitive)
queries were created by Korean automotive engi-
neerswiththeassistanceoftheClaude3.7Sonnet

=== Page 3 ===
Query La
WhatisthereasonbehindtheintroductionoftheIIHS 1
smalloverlapcrashtest,andhowhasitinfluencedve-
hicledesign?
What is the deformation value in the second-row pas- 0
sengercompartmentduetotheupperbendingnearthe
chassis frame fuel tank MTG during HD3 52kph rear
evaluation?
Whyisitnecessarytochangethelocationofthedoor 0
pushingbracket,andwhatistheproblemwiththecur-
rentlocation?
Table 1: Examples of safe and unsafe queries and their
referstosecurity-sensitivequeries,while1referstonon-s
(Anthropic, 2024), accessed through a university-
internal service built on AWS Bedrock1. This
setupprovidessecureaccesstoClaudewithoutex-
posing data to external LLM providers2. Figure 5
in Appendix B.1 illustrates the prompt template
used to construct the query dataset. The prompts
are designed to elicit three types of queries: (1)
general queries that do not pose confidentiality
risks, (2) security-sensitive queries (easy) con-
taining explicit project names, and (3) security-
sensitive queries (hard) that omit project names.
Type (3) queries are particularly challenging to
classify, even for expert engineers, due to the ab-
senceofclearidentifiers.Inadditiontothequeries
and the binary labels (sensitive or non-sensitive),
brief rationales are generated to explain the rea-
soning behind each label. Table 1 presents exam-
plequeries,andTable2summarizesdatastatistics.
Set Safe Unsafe Total
Easy Hard
Train 820 800 720 2,340
Validation 102 100 90 292
Test 103 101 90 294
Table 2: Data split for training and evaluation of the
filtermodel.
4.2 Model
For the filter, we fine-tune a lightweight model,
Qwen2.5-3B-Instruct (Yang et al., 2024), to clas-
sify safe and unsafe queries. The training param-
etersandthepromptusedforthefilteringprocess
aredetailedinAppendixB.
1https://aws.amazon.com/ko/bedrock/
2All Claude 3.7 Sonnet model used in this study—for
data generation and LLM-based evaluation—were accessed
exclusivelythroughthissecureuniversity-internalservice.

abel Reason Type
1 A general question about Generalquery
publiclyavailableteststan-
dardsandtheirimpact.
0 Containsdetailedinforma- Security-sensitive query
tion about structural vul- withprojectnames
nerabilities.
0 Reveals structural design Security-sensitive query
weaknesses. withoutprojectnames
corresponding reasons, translated into English. Label 0
sensitiveones.(Specificvehicletypeisanonymized.)
4.3 Evaluation
As shown in Table 3, we evaluate the filter model
on two subsets: Easy-only (queries with explicit
project names) and Easy&Hard (both with and
withoutprojectnames).Security-sensitivequeries
(class 0) are treated as the positive class, making
recall critical in preventing information leakage
to external LLMs. For easy test cases, the filter
achieves 99.01% recall, indicating strong perfor-
mance with minimal false negatives. When am-
biguous queries is included, accuracy drops to
82.31% and recall to 74.35%, while precision re-
mains high (97.93%), meaning that when it does
flag a query as sensitive, it is highly likely to be
correct. To estimate the upper bound, we conduct
human evaluation on the Easy&Hard set. Expert
annotatorachieves80.95%accuracy,92.99%pre-
cision, and 76.44% recall, highlighting the intrin-
sicambiguityanddifficultyofthetask.
Method TestData Acc% Prec Rec
Easy-only 98.04 97.09 99.01
Filter
Easy&Hard 82.31 97.93 74.35
Human Easy&Hard 80.95 92.99 76.44
Table 3: Evaluation results of the filter model and hu-
man annotators on the test set. Easy-only includes
security-sensitive queries with explicit project names.
Easy&Hard includes both easy (with project names)
and hard (without project names) queries. Human
showsexpert-labeledupperboundperformance.
4.4 Application
In practical deployment, constructing a labeled
dataset of safe and unsafe queries for filter train-
ing can be labor-intensive. To address this, we
proposeaprogressivedeploymentstrategyforthe
confidentiality filter. Initially, the system oper-

=== Page 4 ===
ates without filtering or external retrieval, rely-
ingonlyoninternaldocumentsandpre-generated
expert knowledge. During this phase, real user
queriesarecollectedandlaterlabeledtotrainafil-
termodel,enablingcost-effectiveintegrationover
time. Alternatively, the filter can perform query
rewriting—flagged queries are transformed into
safer versions, allowing secure forwarding to ex-
ternal LLMs. This flexible design supports scal-
able adaptation to organizational privacy and de-
ploymentneeds.
5 Retrieval
This paper focuses on generating reports for
enterprise-level engineering problems. Our re-
trieval system is built upon 6,165 chunked docu-
ments,consistingof5,625chunksfromtheEnter-
prise Knowledge Base and 540 from Pre-written
Expert Knowledge. To prevent data leakage, only
the training subset of the 675 Pre-written Expert
Knowledge documents is included in the retrieval
pool; the remaining 135 keyword–report pairs are
reservedforthefinalevaluationofSecMulti-RAG
(Section7).AlldocumentslistedinTable4arein-
dexed using FAISS (Douze et al., 2025), and our
trainedretrieverretrievesthetopfivemostrelevant
documentsforeachquery.
Type Source File/Page Chunks
TestReport 1,463 4,662
EnterpriseKnowledgeBase MeetingReport 249 882
Textbook 404 81
Pre-writtenExpertKnowledge GoldReport - 540
Total 6,165
Table 4: Overview of chunked documents used in
SecMulti-RAG retrieval. Traditional RAG retrieves
onlyfromtheEnterpriseKnowledgeBase.
5.1 Dataset
5.1.1 EnterpriseKnowledgeBase
For the Enterprise Knowledge Base dataset, we
usethedatasetintroducedbyChoietal.(2025).It
consists of test reports, meeting reports, and text-
books,witheachdocumentsegmentedintomean-
ingfulunitssuchasslides,chapters,orotherrele-
vant sections. QA pairs from the reports and text-
bookareusedtotrainbothretrieverandgeneration
model.SeeTable7inAppendixCfordetails.
5.1.2 Pre-writtenExpertKnowledge
To construct a high-quality knowledge source, a
domain expert in automotive engineering first cu-

rates a list of domain-specific keywords, repre-
sentingexpertise-levelproblems.Usingthesekey-
words,theexpertthengeneratespre-writtenexpert
knowledge using Claude (Appendix D.1, D.2). A
total of 675 keyword–report pairs are partitioned
intotraining,validation,andtestsplitsinan8:1:1
ratio.
5.1.3 ExternalKnowledgefromLLM
After the user query passes the safety filter and
is deemed safe, we use GPT-4o3 to provide on-
demand external knowledge. Specifically, in this
paper, it generates a general-purpose technical
backgrounddocumenttoassistengineersindraft-
ingformalsafetyreports.Thepromptisillustrated
inAppendixE.Thegenerateddocumentisthenin-
dexedintothedocumentpoolforfutureretrieval.
5.2 Retriever
Wefine-tuneBGE-M3(Chenetal.,2024),amul-
tilingual encoder supporting Korean, using QA
and keyword–report pairs (Sections 5.1.1, 5.1.2).
Trainingisdonefor10epochson4×48GBRTX
A6000 GPUs with publicily available code4. For
evaluation, we use all splits (training, validation,
andtest)asthechunkpooltoensuresufficientdata
coverage and mitigate potential biases due to the
smallsizeofthetestset.
5.3 RetrieverEvaluation
Theperformanceoftheretrieverisevaluatedusing
MeanAveragePrecision(MAP@k),whichcalcu-
lates the average precision of relevant results up
to rank k. As shown in Table 5, fine-tuning BGE-
M3 leads to significant improvements, underscor-
ingtheimportanceoftask-specificadaptation.
Model MAP@1 MAP@5 MAP@10
BGE(Vanilla) 0.2855 0.3793 0.3925
BGE(Fine-tuned) 0.5965 0.7027 0.7099
Table5:Comparisonofretrievalperformancebetween
thevanillaandfine-tunedmodelsonourtestdataset.
5.4 DocumentSelectionStrategy
Inthisstudy,werankcandidatedocumentsbyse-
manticsimilarityandapplyaselectionconstraint:
at most one external knowledge is included per
query. GPT-generated documents are limited to
3https://platform.openai.com/docs/models/
gpt-4o
4https://github.com/FlagOpen/FlagEmbedding

=== Page 5 ===
one per query as they provide only general tech-
nical background, and excessive reliance on such
externalcontentmayreducethefactualgrounding
ofresponses.Althoughthisconstraintiscurrently
implementedviaheuristicrules,weaimtodevelop
a learning-based document selection strategy that
jointly considers query characteristics and docu-
mentprovenance.
6 Generation
6.1 Generator
WeuseQwen-2.5-14B-Instruct(Yangetal.,2024)
asourbaselanguagemodel,asitisoneofthefew
multilingualmodelsthatofficiallysupportKorean
whileofferingasufficientcontextlength.Wefine-
tunethemodelusingQApairsintroducedinSec-
tion5.1.1.Hyperparameters,GPUconfigurations,
andthegenerationpromptareinAppendixF.
6.2 Result
Table 6 summarizes the retrieved document
sources and filtering results for the 135 test
queries. All queries retrieved pre-generated ex-
pert knowledge, while 28.1% and 18.5% also re-
trievedGPT-generatedandinternaldocuments,re-
spectively. Among the test queries, 34 are clas-
sified as safe, enabling on-demand GPT genera-
tion. Interestingly, the number of queries retriev-
ingGPT-generateddocumentsslightlyexceedsthe
numberofsafequeries.Thisisbecausepreviously
generated external documents remain in the re-
trieval pool and can still be retrieved for relevant
future queries, even if those queries are classified
as sensitive. This illustrates a key benefit of our
system: as more external knowledge is accumu-
lated over time, the retrieval pool becomes richer,
allowingevensensitivequeriestobenefitfromex-
ternalknowledgewithoutcompromisingsecurity.
Category Count(%)
Pre-writtenknowledgeretrieved 135(100%)
Externalknowledgeretrieved 38(28.1%)
Internaldocumentretrieved 25(18.5%)
filter=1(Safe) 34(25.2%)
filter=0(Security-sensitive) 101(74.8%)
Table6:Distributionofretrieved documenttypes(ap-
pearingatleastonceamongtheTop-5documents)and
filteringoutcomesintheSecMulti-RAG

7 Evaluation
7.1 Method
To evaluate the effectiveness of our approach,
we conduct a qualitative assessment based on
three metrics: Correctness, Richness, and Help-
fulness. We perform pairwise comparisons using
bothLLM-as-a-judge(Zhengetal.,2023)andhu-
man evaluation, comparing responses generated
by Traditional RAG—which retrieves only from
theinternalknowledgebase—withourSecMulti-
RAG, which retrieves from the internal knowl-
edge base, pre-generated expert knowledge, and
on-demand external knowledge. For each metric,
Claude and a human annotator assess which re-
sponse (A or B) is better and record the outcome
asawin,loss,ortie.Tomitigatepositionbiasfrom
the judge LLM, we anonymize the response or-
der by randomly assigning either SecMulti-RAG
or Traditional RAG as response A or B in half of
thecases.ThepromptthatweuseforLLM-based
evaluationisinAppendixG.1.
• Correctnessassessesthefactualconsistency
with the given gold answer. The pre-written
reportsareprovidedasgoldanswers.
• Richness evaluates the level of detail and
completenessintheresponse.
• Helpfulness measures how clear, informa-
tive,andusefultheresponseis.
7.2 Result
Figure2:WinratecomparisonbetweenSecMulti-RAG
andTraditionalRAGacrossevaluationmetrics
Figure 2 presents a comparison of win rates be-
tween the two systems, evaluated by human an-
notatorsandanLLM-basedevaluation.Botheval-
uation sources consistently prefer the outputs of
SecMulti-RAG,particularlyintherichnessmetric.
There is a substantial agreement between human
andLLMevaluationsasinAppendixG.2.

=== Page 6 ===
User Query: Generate report about ‘Occupant Injury Risk –Excessive Should
(See Appendix for detai
Traditional RAG
Top 5 Retrieved from: All from internal doc T
Excessive Shoulder Load in Side Impact: ABC Case Study Excessive
Problem Definition Problem D
In a 32kph 75°side pole crash test, the ABCmodel exhibited excessive excessive shoulder load, •Excessive
primarily due to: exceeding
•Root causes identified:
• • I I n n a su d f e f q ic u ie a n te t o S v A e B r l d a e p s b ig e n t : w p e o e o n r t p h r e o t B e o c d ti y o n P i f l o la r r d R u e m a m r L y o ’s w s e h r o ( u B l / d P e L r R a ) re a a nd the pole, S Lo a w fe e ty r E Im ur p
• Changes in body pulse dynamicscaused by weight reduction in the HEV model. deduction
Safety Impact Non-comp
• Increased shoulder load leads to higher chest/thoracic injury risk, potentially compromising Common P
regulatory compliance and safety ratings. 1.Insufficie
2.Low SAB
Key Technical Findings 3.Door/B-
•The shoulder load in ABC exceeded regulatory targets 4.Vent ho
•Lower B/PLR deformation correlated with higher shoulder loads.
•Higher HeadX valuesindicate reduced engagement between the vehicle structure and the Technical
pole, exacerbating the load issue. • Low SA
• Covera
Test Result Summary (Anonymized) • Door &
| Vehicle Variant | Weight (kg) | Shoulder Load (kN) | B-Pillar Deformation (mm) | Door Deformation (mm) • Vent H
| Summary
|----------------------|-----------------|----------------------------|------------------------------------|--------------------------------- | Vehicle
--| |-----------
| Variant 1 | XXXX | XXXX | Moderate | Moderate | | XX Mode
| Variant 2 | XXXX | XXXX | Moderate |Moderate | | YY Mode
| ABC | XXXX | XXXX | Low | Comparable | | ZZ Mode
Patterns Identified: Improvem
1.Shoulder load was highest in the ABC model. • SAB Op
2.Lower B/PLR deformationcorresponded with higher shoulder load 1.
2.
Improvement Directions 3.
•Redesign SAB shapeto enhance shoulder coverage • Restrai
•Enhance B-pillar structureto increase deformation and overlap area 1.
•Adjust vehicle mass distributionor use alternative structural materials to moderate body • Furthe
pulse behavior 1 2 . .
Traditional RAG
Multi-model Analysis ❌No (focuses on one m
Vent Hole / SAB Pressure Insights ❌Missing
Technical Richness ⚠Moderate
Actionable Engineering Direction ⚠General suggestio
Figure3:ComparisonBetweenTraditionalRAGandSec
tionAnonymized)
7.3 Analysis
While human evaluators tend to assign ‘tie’ la-
bels more frequently than the judge LLM, both
clearly favor SecMulti-RAG across all metrics.
Figure 3 illustrates an example of reports gener-
atedbySecMulti-RAGandTraditionalRAG.
As expected, richness is the most notably im-
proved aspect of our framework, reflecting the
benefit of incorporating diverse documents from
multiple sources. SecMulti-RAG outputs contain
significantly more detailed information, such as
more diverse test cases and technical findings. In
fact, the average length of reports generated by
SecMulti-RAG is 2,660.21 tokens, compared to
1,631.84 tokens from Traditional RAG. In terms
of correctness, both systems generally produce
factually accurate content but occasionally fail to
citethecorrectsourcedocument.Forhelpfulness,
while our approach delivers more comprehensive
reports, Traditional RAG may be more favorable
when the engineer’s intent is to focus on a spe-
cifictestcase,asitsresponsestendtobemorenar-

der Load in Relation to Chest/Thoracic Injuries’based on relevant documents.
led prompt template.)
Secure Multifaceted-RAG
Top 5 Retrieved from: prewritten,external LLM, prewritten, prewritten, internal doc
e Shoulder Load Related to Occupant Chest/Thoracic Injury
Definition
e shoulder load has been repeatedly observed in multiple vehicle models during 32kph side pole crash tests, often
g regulatory thresholds or leaving insufficient safety margins.
plications
ro NCAP / IIHS Crash Safety Ratings:Elevated shoulder loads increase chest/thoracic injury metrics, leading to point
ns in safety evaluations.
pliance with Regulatory Requirements:Shoulder loads exceeding regulatory thresholds compromise compliance.
PatternsObserved Across Test Cases
ent SAB coverage:Inadequate protection in the shoulder area.
B internal pressure → Results in bottom-out phenomena.
-pillar deformation → direct impactforces transmitted to the shoulder
ole size variation → Variability in airbag performance affecting shoulder load.
Findings (Root Cause Analysis)
AB Internal Pressure:Leads to bottom-outphenomena (Observed in: XX Model, YY Model).
age Deficiency:SAB fails to provide sufficient coverage over the shoulder area (ZZ Model)
& B-Pillar Deformation:Increased deformation leads to higher direct impact on the shoulder (BB Model, CC Model).
Hole Specification Variability:Different vent hole sizes and designs affect airbag performance (DD Model, EE Model).
y of Test Results (Anonymized)
Model | Shoulder Load (kN) | % of Regulation Limit | Evaluation Result | Source |
-----------|--------------------------|------------------------------|------------------------|-------------------|
el | XXXX | XXXX | Pass | Report_001 |
el | XXXX | XXXX | Marginal | Report_002 |
el | XXXX | XXXX | Pass | Report_003 |
ment Directions
ptimization
. Adjust vent hole spec
. Improve coverage & pressure
. Modify deployment shape/timing
int System Adjustment
. Enhance seatbelt PT & pelvic pad design
er Testing Required
. SAB Vent Hole Performance Validation:Determines the optimal vent hole size for internal pressure retention.
. Sled Test on Optimized SAB Designs:Evaluates real-world effectiveness of modified SAB parameters.
SecureFusion-RAG
model) ✅Yes
✅Detailed
✅High
ons ✅Prioritized & layered
cMulti-RAG(TranslatedfromKorean;SensitiveInforma-
rowly scoped. This could potentially be mitigated
through prompt tuning. One notable issue is the
occasional generation of Chinese characters, due
to the Qwen model’s Chinese-centric pretraining.
Thisproblemislikelycausedbythelongerdocu-
mentsretrievedbySecMulti-RAG,whichincrease
the context length and make the model more vul-
nerabletogeneratingsucherrors.
8 Conclusion
In this paper, we present SecMulti-RAG for en-
terprise that integrates internal knowledge bases,
pre-generated expert knowledge, and on-demand
external knowledge. Our framework introduces
a confidentiality-aware filtering mechanism that
protects security-sensitive user prompts by by-
passing external augmentation when necessary,
mitigating the risk of information leakage to
closed-source LLMs. In our experiments on au-
tomotiveengineeringreportgeneration,SecMulti-
RAGshowedclearimprovementsoverTraditional
RAG in terms of correctness, richness, and help-
fulness.Itachievedwinratesrangingfrom56.3%

=== Page 7 ===
to 70.4%, as evaluated by human evaluators, out-
performingtraditionalRAGacrossallmetrics.Be-
yond performance gains, our approch is a cost-
efficient, privacy-preserving, and scalable solu-
tion,leveraginghigh-qualityretrievalwithlocally
hostedLLMs.
Limitations
Due to the lack of publicly available Korean-
language datasets in the automotive domain, our
evaluation is limited to the report generation task
based on a relatively small amount of data that
we have constructed ourselves. While this work
isintendedforanindustrytrackanddemonstrates
practical significance, future research could en-
hance the academic impact by showing the scal-
ability of the SecMulti-RAG framework across a
broader range of tasks and domains. In fact, we
have conducted preliminary experiments on engi-
neering question answering tasks beyond report
generation,andobservedthatSecMulti-RAGalso
performswellinthosescenarios,indicatingitspo-
tential. Example responses are provided in Ap-
pendixG.3.
Currently, we apply a heuristic selection con-
straint:atmostoneexternalknowledgedocument
is included per query (Section 5.4). This con-
straint is motivated by our observation that GPT-
generated documents, while useful for providing
general technical background or engineering con-
text, may dilute the factual grounding of system
responses if overused. However, this rule-based
constraint lacks adaptability and may not always
yield optimal document combinations tailored to
diverse query intents. In future work, we aim to
developalearning-baseddocumentselectionstrat-
egythatjointlyconsidersquerycharacteristicsand
document sources, allowing the system to auto-
matically re-rank and select optimal document
combinationstobettermatchthespecificneedsof
eachqueryanddeploymentcontext.
Acknowledgement
We gratefully acknowledge the support of the
Hyundai Motor. Any opinions, findings, and con-
clusions or recommendations expressed in this
material are those of the authors and do not nec-
essarilyreflecttheviewsofHyundaiMotor.

References
Anthropic. 2024. The claude 3 model family: Opus,
sonnet,haiku.
Jianlyu Chen, Shitao Xiao, Peitian Zhang, Kun
Luo, Defu Lian, and Zheng Liu. 2024. M3-
embedding: Multi-linguality, multi-functionality,
multi-granularity text embeddings through self-
knowledge distillation. In Findings of the Associa-
tionforComputationalLinguisticsACL2024,pages
2318–2335,Bangkok,Thailandandvirtualmeeting.
AssociationforComputationalLinguistics.
Nayoung Choi, Grace Byun, Andrew Chung, Ellie S.
Paek,ShinsunLee,andJinhoD.Choi.2025. Trust-
worthy answers, messier data: Bridging the gap in
low-resourceretrieval-augmentedgenerationfordo-
mainexpertsystems. Preprint,arXiv:2502.19596.
ChunJieChong,ChenxiHou,ZhihaoYao,andSeyed
Mohammadjavad Seyed Talebi. 2024. Casper:
Prompt sanitization for protecting user privacy
in web-based large language models. Preprint,
arXiv:2408.07004.
DeepSeek-AI,DayaGuo,DejianYang,HaoweiZhang,
Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao
Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang
Zhang, Xingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou,
Zhihong Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu,
Bing Xue, Bingxuan Wang, Bochao Wu, Bei Feng,
Chengda Lu, Chenggang Zhao, Chengqi Deng,
ChenyuZhang,ChongRuan,DamaiDai,DeliChen,
Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai,
FuliLuo,GuangboHao,GuantingChen,GuoweiLi,
H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang,
Honghui Ding, Huajian Xin, Huazuo Gao, Hui Qu,
Hui Li, Jianzhong Guo, Jiashi Li, Jiawei Wang,
Jingchang Chen, Jingyang Yuan, Junjie Qiu, Jun-
long Li, J. L. Cai, Jiaqi Ni, Jian Liang, Jin Chen,
Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin
Huang,KuaiYu,LeanWang,LecongZhang,Liang
Zhao, Litong Wang, Liyue Zhang, Lei Xu, Leyi
Xia, Mingchuan Zhang, Minghua Zhang, Minghui
Tang,MengLi,MiaojunWang,MingmingLi,Ning
Tian,PanpanHuang,PengZhang,QianchengWang,
QinyuChen,QiushiDu,RuiqiGe,RuisongZhang,
RuizhePan,RunjiWang,R.J.Chen,R.L.Jin,Ruyi
Chen, Shanghao Lu, Shangyan Zhou, Shanhuang
Chen, Shengfeng Ye, Shiyu Wang, Shuiping Yu,
ShunfengZhou,ShutingPan,S.S.Li,ShuangZhou,
Shaoqing Wu, Shengfeng Ye, Tao Yun, Tian Pei,
TianyuSun,T.Wang,WangdingZeng,WanjiaZhao,
WenLiu,WenfengLiang,WenjunGao,WenqinYu,
WentaoZhang,W.L.Xiao,WeiAn,XiaodongLiu,
Xiaohan Wang, Xiaokang Chen, Xiaotao Nie, Xin
Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu
Yang,XinyuanLi,XuechengSu,XuhengLin,X.Q.
Li, Xiangyue Jin, Xiaojin Shen, Xiaosha Chen, Xi-
aowen Sun, Xiaoxiang Wang, Xinnan Song, Xinyi
Zhou, Xianzu Wang, Xinxia Shan, Y. K. Li, Y. Q.
Wang, Y. X. Wei, Yang Zhang, Yanhong Xu, Yao
Li, Yao Zhao, Yaofeng Sun, Yaohui Wang, Yi Yu,
Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He,

=== Page 8 ===
Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma,
Yiyuan Liu, Yongqiang Guo, Yuan Ou, Yuduan
Wang, Yue Gong, Yuheng Zou, Yujia He, Yunfan
Xiong, Yuxiang Luo, Yuxiang You, Yuxuan Liu,
Yuyang Zhou, Y. X. Zhu, Yanhong Xu, Yanping
Huang,YaohuiLi,YiZheng,YuchenZhu,Yunxian
Ma,YingTang,YukunZha,YutingYan,Z.Z.Ren,
ZehuiRen,ZhangliSha,ZheFu,ZheanXu,Zhenda
Xie, Zhengyan Zhang, Zhewen Hao, Zhicheng Ma,
Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zi-
junLiu,ZilinLi,ZiweiXie,ZiyangSong,Zizheng
Pan,ZhenHuang,ZhipengXu,ZhongyuZhang,and
ZhenZhang.2025. Deepseek-r1:Incentivizingrea-
soningcapabilityinllmsviareinforcementlearning.
Preprint,arXiv:2501.12948.
Matthijs Douze, Alexandr Guzhva, Chengqi Deng,
Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel
Mazaré, Maria Lomeli, Lucas Hosseini, and Hervé
Jégou. 2025. The faiss library. Preprint,
arXiv:2401.08281.
BernalJiménezGutiérrez,YihengShu,YuGu,Michi-
hiro Yasunaga, and Yu Su. 2025. Hipporag: Neu-
robiologically inspired long-term memory for large
languagemodels. Preprint,arXiv:2405.14831.
Jamie Hayes, Luca Melis, George Danezis, and Emil-
iano De Cristofaro. 2017. Logan: Evaluating pri-
vacyleakageofgenerativemodelsusinggenerative
adversarialnetworks. ArXiv,abs/1705.07663.
Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju
Hwang, and Jong C. Park. 2024. Adaptive-
rag: Learning to adapt retrieval-augmented large
language models through question complexity.
Preprint,arXiv:2403.14403.
SiwonKim,SangdooYun,HwaranLee,MartinGubri,
Sungroh Yoon, and Seong Joon Oh. 2023. Propile:
Probing privacy leakage in large language models.
Preprint,arXiv:2307.01881.
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio
Petroni, Vladimir Karpukhin, Naman Goyal, Hein-
rich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock-
täschel, Sebastian Riedel, and Douwe Kiela. 2020.
Retrieval-augmented generation for knowledge-
intensive nlp tasks. In Proceedings of the 34th In-
ternationalConferenceonNeuralInformationPro-
cessing Systems, NIPS ’20, Red Hook, NY, USA.
CurranAssociatesInc.
Nils Lukas, Ahmed Salem, Robert Sim, Shruti Tople,
Lukas Wutschitz, and Santiago Zanella-Béguelin.
2023. Analyzing leakage of personally identifi-
able information in language models. Preprint,
arXiv:2302.00539.
OpenAI, Josh Achiam, Steven Adler, Sandhini Agar-
wal, Lama Ahmad, Ilge Akkaya, Florencia Leoni
Aleman, Diogo Almeida, Janko Altenschmidt,
Sam Altman, Shyamal Anadkat, Red Avila, Igor
Babuschkin, Suchir Balaji, Valerie Balcom, Paul
Baltescu, Haiming Bao, Mohammad Bavarian,

Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel
Bernadett-Shapiro,ChristopherBerner,LennyBog-
donoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa
Brakman, Greg Brockman, Tim Brooks, Miles
Brundage, Kevin Button, Trevor Cai, Rosie Camp-
bell, Andrew Cann, Brittany Carey, Chelsea Carl-
son, Rory Carmichael, Brooke Chan, Che Chang,
Fotis Chantzis, Derek Chen, Sully Chen, Ruby
Chen,JasonChen,MarkChen,BenChess,Chester
Cho, Casey Chu, Hyung Won Chung, Dave Cum-
mings, Jeremiah Currier, Yunxing Dai, Cory De-
careaux, Thomas Degry, Noah Deutsch, Damien
Deville, Arka Dhar, David Dohan, Steve Dowling,
Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna
Eloundou, David Farhi, Liam Fedus, Niko Felix,
Simón Posada Fishman, Juston Forte, Isabella Ful-
ford,LeoGao,ElieGeorges,ChristianGibson,Vik
Goel,TarunGogineni,GabrielGoh,RaphaGontijo-
Lopes, Jonathan Gordon, Morgan Grafstein, Scott
Gray, Ryan Greene, Joshua Gross, Shixiang Shane
Gu,YufeiGuo,ChrisHallacy,JesseHan,JeffHarris,
YuchenHe,MikeHeaton,JohannesHeidecke,Chris
Hesse,AlanHickey,WadeHickey,PeterHoeschele,
Brandon Houghton, Kenny Hsu, Shengli Hu, Xin
Hu, Joost Huizinga, Shantanu Jain, Shawn Jain,
Joanne Jang, Angela Jiang, Roger Jiang, Haozhun
Jin, Denny Jin, Shino Jomoto, Billie Jonn, Hee-
woo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Ka-
mali, Ingmar Kanitscheider, Nitish Shirish Keskar,
Tabarak Khan, Logan Kilpatrick, Jong Wook Kim,
ChristinaKim,YongjikKim,JanHendrikKirchner,
JamieKiros,MattKnight,DanielKokotajlo,Łukasz
Kondraciuk,AndrewKondrich,ArisKonstantinidis,
KyleKosic,GretchenKrueger,VishalKuo,Michael
Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Le-
ung, Daniel Levy, Chak Ming Li, Rachel Lim,
MollyLin,StephanieLin,MateuszLitwin,Theresa
Lopez, Ryan Lowe, Patricia Lue, Anna Makanju,
KimMalfacini,SamManning,TodorMarkov,Yaniv
Markovski, Bianca Martin, Katie Mayer, Andrew
Mayne, Bob McGrew, Scott Mayer McKinney,
Christine McLeavey, Paul McMillan, Jake McNeil,
David Medina, Aalok Mehta, Jacob Menick, Luke
Metz, Andrey Mishchenko, Pamela Mishkin, Vin-
nieMonaco,EvanMorikawa,DanielMossing,Tong
Mu, Mira Murati, Oleg Murk, David Mély, Ashvin
Nair, Reiichiro Nakano, Rajeev Nayak, Arvind
Neelakantan, Richard Ngo, Hyeonwoo Noh, Long
Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex
Paino, Joe Palermo, Ashley Pantuliano, Giambat-
tistaParascandolo,JoelParish,EmyParparita,Alex
Passos,MikhailPavlov,AndrewPeng,AdamPerel-
man,FilipedeAvilaBelbutePeres,MichaelPetrov,
Henrique Ponde de Oliveira Pinto, Michael, Poko-
rny,MichellePokrass,VitchyrH.Pong,TollyPow-
ell, Alethea Power, Boris Power, Elizabeth Proehl,
RaulPuri,AlecRadford,JackRae,AdityaRamesh,
Cameron Raymond, Francis Real, Kendra Rim-
bach, Carl Ross, Bob Rotsted, Henri Roussez,
Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani
Santurkar, Girish Sastry, Heather Schmidt, David
Schnurr,JohnSchulman,DanielSelsam,KylaShep-
pard, Toki Sherbakov, Jessica Shieh, Sarah Shoker,
Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie

=== Page 9 ===
Simens, Jordan Sitkin, Katarina Slama, Ian Sohl,
Benjamin Sokolowsky, Yang Song, Natalie Stau-
dacher,FelipePetroskiSuch,NatalieSummers,Ilya
Sutskever, Jie Tang, Nikolas Tezak, Madeleine B.
Thompson, Phil Tillet, Amin Tootoonchian, Eliz-
abeth Tseng, Preston Tuggle, Nick Turley, Jerry
Tworek, Juan Felipe Cerón Uribe, Andrea Vallone,
Arun Vijayvergiya, Chelsea Voss, Carroll Wain-
wright, Justin Jay Wang, Alvin Wang, Ben Wang,
Jonathan Ward, Jason Wei, CJ Weinmann, Ak-
ila Welihinda, Peter Welinder, Jiayi Weng, Lilian
Weng,MattWiethoff,DaveWillner,ClemensWin-
ter, Samuel Wolrich, Hannah Wong, Lauren Work-
man,SherwinWu,JeffWu,MichaelWu,KaiXiao,
Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Woj-
ciechZaremba,RowanZellers,ChongZhang,Mar-
vinZhang,ShengjiaZhao,TianhaoZheng,Juntang
Zhuang,WilliamZhuk,andBarretZoph.2024. Gpt-
4technicalreport. Preprint,arXiv:2303.08774.
Ridong Wu, Shuhong Chen, Xiangbiao Su, Yuankai
Zhu, Yifei Liao, and Jianming Wu. 2024. A
multi-source retrieval question answering frame-
workbasedonrag. Preprint,arXiv:2405.19207.
AnYang,BaosongYang,BeichenZhang,BinyuanHui,
BoZheng,BowenYu,ChengyuanLi,DayihengLiu,
FeiHuang,HaoranWei,etal.2024. Qwen2.5tech-
nicalreport. arXivpreprintarXiv:2412.15115.
Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu,
Mingxuan Ju, Soumya Sanyal, Chenguang Zhu,
Michael Zeng, and Meng Jiang. 2023. Gen-
erate rather than retrieve: Large language mod-
els are strong context generators. Preprint,
arXiv:2209.10063.
ShuningZhang,LyumanshanYe,XinYi,JingyuTang,
Bo Shui, Haobin Xing, Pengfei Liu, and Hewu Li.
2024. "ghostofthepast":identifyingandresolving
privacy leakage from llm’s memory through proac-
tiveuserinteraction. Preprint,arXiv:2410.14931.
LianminZheng,Wei-LinChiang,YingSheng,Siyuan
Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,
ZhuohanLi,DachengLi,EricP.Xing,HaoZhang,
Joseph E. Gonzalez, and Ion Stoica. 2023. Judg-
ingllm-as-a-judgewithmt-benchandchatbotarena.
Preprint,arXiv:2306.05685.
YujiaZhou,ZhengLiu,andZhichengDou.2024. As-
sistrag: Boosting the potential of large language
models with an intelligent information assistant.
Preprint,arXiv:2411.06805.

A RAGFramework
Figure 4 demonstrates both Traditional RAG and
SecMulti-RAGframework.
B Filter
B.1 QueryDataset
Security-sensitive and general (non-sensitive)
queries are carefully constructed by Korean au-
tomotive engineers with the assistance of Claude.
Figure5showstheprompttemplatethattheengi-
neersusedduringdataconstruction,reflectingour
effortstooptimizepromptdesignforquerygener-
ation.
B.2 Training
Full fine-tuning is performed on Qwen2.5-3B-
Instruct (Yang et al., 2024) using a per-device
batch size of 2 and a gradient accumulation step
of 256, effectively simulating a large batch size.
The model is trained for 3 epochs with a learning
rate of 8e-6. Training is conducted on 3 × 48GB
RTXA6000GPUs.
B.3 Prompt
Figure 6 provides the prompt that we use to fil-
ter out user queries that should not be exposed to
closed-sourceLLM.
C EnterpriseKnowledgeBase
Table 7 shows the statistics of the Enterprise
Knowledge Base dataset. Document chunks and
QA pairs are constructed from test reports, meet-
ing reports, and textbook. Refer to Choi et al.
(2025)formoredetails.
Source Data Train Val Test Total
Chunk 3,729 466 467 4,662
TestReport
QAPair 47,660 5,823 5,919 59,402
Chunk 705 88 89 882
MeetingReport
QAPair 6,144 752 800 7,696
Chunk 64 8 9 81
Textbook
QAPair 1,182 162 161 1,505
Table7:EnterpriseKnowledgeBaseDataset:Statistics
bysource,detailingthedistributionofchunksandQA
pairs.
D Pre-writtenExpertKnowledge
D.1 Keywords
Below are some of the keywords we use to gen-
erate pre-written expert knowledge. Reports re-

=== Page 10 ===
Figure4:TraditionalR
lated to these keywords (main problems) are pre-
generatedbyautomotiveengineers.
1. 차체 구조 및 안전성 관련 이슈 (Vehicle
StructuralIntegrityandSafetyIssues)
1. 차체 구조 및 구조적 완전성 (Body Structure
andStructuralIntegrity)
1.1. 필러(Pillar) 관련 문제 (Pillar-Related Is-
sues)
1.1.1.A필러문제(A-PillarIssues)
A필러상부강성부족및변형(Insufficientup-
perstiffnessanddeformationinA-pillar)
A필러 힌지 크랙 발생 (Hinge crack formation
inA-pillar)
A필러와 대시 연결부 찢어짐 (Tearing at the
connection between the A-pillar and the dash-
board)
A필러 변형으로 인한 윈드실드 파손 (Wind-
shielddamageduetoA-pillardeformation)
A필러 이탈 지연으로 인한 타이어 내측 거동
(Delayed detachment of A-pillar affecting inner
tiremovement)
1.1.2.B필러문제(B-PillarIssues)
B필러 하단부 강성 부족으로 인한 변형 과다
(Excessive deformation due to insufficient lower
stiffnessinB-pillar)
B필러 용접부 크랙 및 파단 (Cracks and frac-
turesinB-pillarweldingarea)
B필러상단부꺾임현상(Bendingattheupper
sectionoftheB-pillar)
B필러와 루프라인 연결부 취약성 (Weak con-
nectionbetweenB-pillarandroofline)
B필러 변형으로 인한 생존 공간 감소 (Reduc-
tioninsurvivalspaceduetoB-pillardeformation)

RAGvsSecMulti-RAG
B필러부위접힘현상(Foldingphenomenonin
the B-pillar area) B-PLR INR LWR EXTN 누락
(OmissionofB-PLRINRLWREXTN)
1.1.3. C필러 및 쿼터패널 문제 (C-Pillar and
QuarterPanelIssues)
C필러 부위 접힘 현상 (Folding in the C-pillar
area)
쿼터패널 측면 파고듦 현상 (Intrusion on the
sideofthequarterpanel)
C필러트림파손(C-pillartrimdamage)
쿼터리테이너강성부족(Insufficientstiffness
inquarterretainer)
1.2.도어구조관련문제(DoorStructureIssues)
1.2.1.도어구조체문제(DoorFrameIssues)
도어 임팩트 빔 마운팅부 파단 및 이탈 (Frac-
ture and detachment of door impact beam mount-
ing)
도어빔브라켓강도부족(Insufficientstrength
indoorbeambracket)
도어 힌지 마운팅 볼트 파단 및 뽑힘 (Fracture
anddetachmentofdoorhingemountingbolts)
도어 래치 마운팅부 파손 (Breakage in door
latchmounting)
도어변형으로인한침입량증가(Increasedin-
trusionduetodoordeformation)
임팩트 빔 꺾임 및 마운팅 용접부 파단 (Bend-
ingofimpactbeamandfractureinmountingweld)
1.2.2. 도어 부품 및 연결부 문제 (Door Compo-
nentsandConnectionIssues)
도어 스트라이커 이탈 및 손상 (Detachment
anddamageofdoorstriker)
도어 인너 판넬 분리 및 파손 (Separation and
breakageofdoorinnerpanel)

=== Page 11 ===
Prompt
[Security-sensitive queries without project name]
You are an engineer in charge of vehicle crash safety testing. Based on internal reports, you are tasked with
generating sensitive security-related queries that should not be exposed to the public. The queries must meet
the following requirements:
Query Generation Guidelines:
- Do NOT include any specific project names or test IDs.
- Do NOT ask about exact internal figures or detailed designs directly. Instead, formulate questions that indirectly
imply such information through the context.
- Each question should be capable of revealing internal issues or technical weaknesses if exposed externally.
- Vary the length of the queries (mostly short questions, but some longer ones included).
- Generate 50 questions in total.
- Provide a one-line explanation for why each question is considered security-sensitive.
Example Questions:
- "What is the root cause of the excessive B-pillar deformation observed in recent tests?" (Indirectly reveals an
internal issue)
- "What causes the delayed airbag deployment timing?" (Hints at internal system problems)
- "Why is reinforcement needed in the door hinge area?" (Implies structural vulnerability)
- "Why does a specific area repeatedly exhibit excessive deformation in crash tests?" (Reveals unresolved structural
weaknesses)
Please refer to the examples above and generate 50 diverse security-sensitive questions that indirectly reveal
sensitive internal information.
Here are the internal reports:
<Reports>
{reports}
</Reports>
=======================================================================================================================
[Security-sensitive queries with project name]
You are an engineer in charge of vehicle crash safety testing. Based on internal reports, you are tasked with
generating security-related queries that include a specific project name but exclude test IDs. The queries must
meet the following requirements:
Query Generation Guidelines:
1. MUST include a specific project name (but do NOT include test IDs).
2. In most queries, place the project name at the beginning of the sentence, but vary the position in some queries (
middle or end).
3. It is acceptable to include sensitive internal figures or specific design information.
4. The queries must be security-sensitive and unsuitable for public exposure.
5. Vary the length of the queries (mostly short, but some longer ones included).
6. Provide a one-line explanation for why each question is considered security-sensitive.
7. Maintain the following consistent output format:
- "Query sentence"
(Explanation)
Here are the internal reports:
<Reports>
{reports}
</Reports>
=======================================================================================================================
[General (non-sensitive) queries]
You are an engineer in charge of vehicle crash safety testing. Based on internal reports, generate general queries
that do not pose any security concerns and can be disclosed publicly. These queries should reflect realistic
engineering questions that professionals may encounter in practice. The queries must meet the following
requirements:
Query Generation Guidelines:
1. Do NOT include any specific project names or test IDs.
2. Avoid questions about sensitive internal figures or detailed designs. Instead, focus on general technical concepts
, practical engineering concerns, and issues that engineers would typically discuss.
3. Questions should be centered on issues arising in crash safety testing environments, engineering decision-making,
and practical field concerns.
4. Vary the length of the queries (mostly short, but some longer ones included).
5. Provide a one-line explanation for why each question is NOT considered security-sensitive.
6. Maintain the following consistent output format:
- "Query sentence"
(Explanation)
Here are the internal reports:
<Reports>
{reports}
</Reports>
Figure5:Promptusedforquerydatageneration(TranslatedtoEnglish)

=== Page 12 ===
Prompt
Youareaclassificationmodelforuserqueries.
Thereare**TWOCLASSESONLY**:
0=>ThequerymaycontaininternalorsensitiveinformationandisNOT
1=>Thequeryisgeneralandcanbesafelyprocessed.
**IMPORTANTINSTRUCTION**:
-Ifthequerycontainsanyinternalprojectnames,testingscores,eng
weakness(defects),andinternalsolution,youMUSTclassifyas0.
-Ifuncertain,choose0.
YoumustoutputONLYonenumber:either0or1.
Examples:
[Example1](GPTNotAllowed-CorporateInternalInformation)
UserQuestion:"TellmethetestresultsofLX2P2."
Judgment:0
[Example2](GPTNotAllowed-RequestingInternalEvaluationRepor
UserQuestion:"SharetheinternalcrashtestreportoftheG70fro
Judgment:0
[Example3](GPTAllowed-GeneralAutomotiveSafetyRegulations)
UserQuestion:"ExplaintheU.S.FederalMotorVehicleSafetyStand
Judgment:1
[Example4](GPTAllowed-StructuralImprovementCasesforAutomot
UserQuestion:"Tellmeaboutcasesofsubframefailureandpossibl
Judgment:1
[Example5](GPTNotAllowed-ConfidentialDesignInformationofa
UserQuestion:"TellmethekeydesignchangesinHyundai'sneweng
Judgment:0
[Example6](GPTAllowed-GeneralMechanicalEngineeringTheory)
UserQuestion:"Whataresomemethodstoincreasetherigidityofa
Judgment:1
[Example7](GPTNotAllowed-RequestingInternalTestData)
UserQuestion:"Tellmetheresultsofthein-housecrashtestscon
Judgment:0
[Example8](GPTAllowed-PublicData-BasedInformation)
UserQuestion:"ExplaintheEuropeanNCAPcrashteststandardsand
Judgment:1
Figure6:PromptusedforFiltering
D.2 Pre-writtenReportsGeneration
Togeneratepre-writtenexpertknowledge,Korean
automotiveengineersemploythepromptshownin
Figure7,refinedthroughextensiveprompttuning.
The generated reports include a structured com-
position of problem definition, technical analysis,
caseanalysis,improvementsuggestions,andrele-
vantreferences,andaresubsequentlyreviewedby
domain experts. The keywords provided in Sec-
tion D.1 serve as the core problem topics ad-
dressedineachreport.University-internalClaude
servicefromAWSBedrockisusedforsecurity.
E On-DemandExternalKnowledge
Once the prompt passes the safety filter and
deemed to be safe, we use GPT-4o to provide on-
demandexternalknowledge.Specifically,itgener-
atesageneral-purposetechnicalbackgrounddocu-
menttohelpengineersdraftformalsafetyreports.
The prompt used is shown in Figure 8. The GPT-
generated document is then indexed into the doc-

Tsafe.
gineeringdesigndetails,
rtforaSpecificVehicle)
ontalcrashtest."
dard."
tiveComponents)
leimprovements."
aSpecificCompany)
gineblueprint."
acarchassis?"
nductedbyHMG."
evaluationcriteria."
gProgress(TranslatedtoEnglish)
umentpoolforretrieval.
F Generation
We fine-tune Qwen-2.5-14B-Instruct (Yang et al.,
2024) using a Korean question-answering dataset
focused on the automobile engineering domain.
Full fine-tuning is conducted for the 14B model
withabatchsizeof2,gradientaccumulationsteps
of 64, a learning rate of 2e-5, and 3 training
epochs. 3 × 80GB H100 GPUs are used for the
training. Figure 9 is the prompt used for report
generationofQwenmodel.
G Evaluation
G.1 LLM-basedEvaluation
Figure10isthepromptthatweuseforLLM-based
evaluation.
G.2 HumanandLLMevaluationAgreement
Figure11demonstratesconfusionmatricesshow-
ingtheagreementbetweenLLMandhumaneval-

=== Page 13 ===
Prompt
# You are an expert in writing professional engineering reports in the field of automotive crash safety. Based on the given
problem situation and related report data, you must write a technical report that is useful for field engineers.
## Input Format
1. **Problem Situation**: <Problem> {problem} </Problem>
2. **Reference Reports**: <Reports> {reports} </Reports>
## Output Requirements
1. **Title**: A technical title that clearly reflects the problem situation.
2. **Problem Definition**:
* Detailed description of the problem occurrence.
* Specification of affected vehicle components.
* Analysis of the impact on safety.
* Identification of common problem patterns observed across multiple cases.
3. **Technical Analysis**:
* Root cause analysis (based on report evidence).
* Summary of related test results and pattern identification.
* Inclusion of measured numerical data (if available).
* Comparative analysis and correlation between multiple tests.
4. **Case Comparison Analysis**:
* List and categorize all cases where similar issues occurred.
* Compare and analyze similarities and differences between cases.
* Compare case results in tabular format (recommended).
5. **Improvement Directions**:
* Summarize all improvement measures mentioned in the reports.
* Clearly explain the reasons and expected effects of each improvement.
* Provide a prioritization of improvement measures.
* Identify areas requiring additional testing and justify their necessity.
6. **Conclusion**:
* Summary of key issues.
* Summary of major findings.
* Comprehensive expected effects of the proposed improvements.
7. **References**:
* All information sources must be cited in parentheses right after the corresponding content (e.g., "Due to insufficient upper
A-pillar stiffness, the DASH deformation exceeded the target of 100mm by reaching 128mm (C200728A_CV).")
* Arrange citations appropriately to avoid disrupting readability.
## Key Guidelines
1. **Pattern Identification**: Actively identify and analyze recurring problem patterns across different tests and situations.
2. **Data Integration**: Integrate similar data from multiple reports to provide a more comprehensive analysis.
3. **Importance Evaluation**: Assign higher importance to repeated problems and explicitly indicate this.
4. **Flexible Report Structure**: Use the given structure as a starting point but modify, merge, or add sections as needed based
on data and analysis results.
5. Exclude unnecessary introductions or background explanations and focus on core technical content.
6. Do not make assumptions or use general knowledge to fill in missing report data.
7. Provide specific technical information that engineers can use immediately.
8. Ensure all information can be traced back to its source, but citations should not overshadow the main content.
9. Include relevant data, figures, and specific specifications whenever possible.
10. Focus on the methodology applied to solve the problem and the results achieved.
11. Citations should be concise, placed at the end of the sentence or paragraph, and include only the report code in parentheses.
## Citation Examples
* Incorrect: "According to report C200728A_CV, due to insufficient upper A-pillar stiffness..."
* Correct: "Due to insufficient upper A-pillar stiffness, the DASH deformation exceeded the target of 100mm by reaching 128mm (
C200728A_CV)."
* Multiple citations: "BrIC is an index developed to assess the risk of brain injury caused by head rotational motion (C200728A_CV
, C200730B_NE)."
* Similar issue citation: "The A-pillar deformation issue was consistently observed in three tests (C200728A_CV, C200805B_CV,
C200901A_CV), and in all cases, the deformation exceeded the allowable limit by 20-25%."
## Basic Report Structure
‘‘‘markdown
# Technical Title Based on the Problem Situation
## Problem Definition
- Detailed description of the problem and pattern identification.
- Affected vehicle components.
- Safety impact analysis.
## Technical Analysis
- Root cause analysis.
- Summary of test results.
- Measurement data.
## Case Comparison Analysis
| Test ID | Issue Description | Measured Value | Standard Value | Deviation | Notes |
|-----------|-------------------|----------------|----------------|-----------|-----------------|
| TEST-001 | Issue description | 00.0 | 00.0 | 00.0 | Additional info |
| TEST-002 | Issue description | 00.0 | 00.0 | 00.0 | Additional info |
## Improvement Measures and Effects
- Applied solutions.
- Effectiveness measurement results.
- Technical specifications.
## Improvement Directions
- **Priority 1**: [Improvement measure] - [Clear reason and expected effect]
- **Priority 2**: [Improvement measure] - [Clear reason and expected effect]
- **Additional Tests Needed**: [Test details] - [Reason for necessity]
## Conclusion
- Summary of key issues.
- Summary of major findings.
- Comprehensive expected effects of improvements.
Figure7:Promptusedforgeneratinggoldreports.ThepromptisoriginallyKorean.

=== Page 14 ===
Prompt
You are an expert in automotive crash safety engineering.
You are tasked with generating a general-purpose technical background document **in Korean** that can assist
engineers in drafting formal safety reports.
Only a high-level keyword describing a common engineering issue is provided.
Based on your expert knowledge, please provide background information and reasonable technical discussion,
without fabricating any specific case data, test results, or numeric values that are not grounded in well-known
general principles.
Your output should include the following sections:
1. **Title**: A concise technical title derived from the given keyword.
2. **Issue Overview**:
- Describe the typical nature of this issue in automotive safety engineering.
- Mention which vehicle components are generally involved.
- Explain how this issue may impact structural integrity or passenger safety.
3. **Common Engineering Considerations**:
- Discuss known design challenges, structural constraints, or typical causes.
- Do NOT include fabricated test results or data.
- Only refer to general engineering principles or commonly reported concerns in literature.
4. **Improvement Suggestions (General)**:
- Suggest generic design or material improvements.
- Clarify expected benefits and rationale (without specific test results).
5. **Conclusion**:
- Summarize key considerations.
- Emphasize that this document provides only general technical guidance, not case-specific findings.
Important:
- Do NOT fabricate test results, measured data, or specific incident cases.
- Only refer to general trends, common engineering knowledge, and design principles.
- This is intended to serve as a general technical reference, not a case analysis.
keyword: {keyword}
Figure8:Promptusedforgeneratingon-demandexternalknowledgeusingGPT-4o.
uations. Each cell contains the count and per- Metric Agreement(%) Gwet’sAC1
centage of cases where Claude (vertical axis) and
Correctness 56.74% 0.4295
human evaluators (horizontal axis) made specific
Richness 73.05% 0.6812
judgments about system preference. Darker blue
Helpfulness 69.50% 0.6264
indicateshigherfrequency.Thediagonalcellsrep-
Overall 72.34% 0.6647
resent agreement between both evaluators, while
off-diagonal cells show disagreement patterns. A
Table8:AgreementbetweenClaudeandHumanEval-
large portion of the counts lies along the diago-
uationResults
nal,indicatingasubstantiallevelofagreementbe-
tween the two evaluators. Both evaluators show
preference for the SecMulti-RAG’s generations SecMulti-RAG responses include specific injury
especiallyin‘Richness’and‘Overall’metrics. types, structural causes, and implications for of-
Table 8 reports the agreement rates and Gwet’s ficial safety assessments, demonstrating greater
AC1 scores. Gwet’s AC1 is reported instead of richness and helpfulness compared to the Tradi-
Cohen’s Kappa due to the class imbalance in tionalRAGresponses.
the evaluation results, where SecMulti-RAG is
consistently preferred over Traditional RAG. No-
tably, correctness shows relatively lower agree-
ment,largelyduetotheLLM’stendencytoavoid
assigning ‘tie’ labels, which are more frequently
usedbyhumanevaluators.
G.3 TaskScalability
In this study, we primarily evaluate our RAG
framework on the report generation task. How-
ever,inpractice,theframeworkisscalabletovar-
ious tasks and domains. We conducted a prelimi-
nary test with a few engineering questions in the
automotive domain, as shown in Figure 12. The

=== Page 15 ===
Prompt
You are an expert in writing professional engineering reports in the field of automotive crash safety. Based on the
given problem description and related report data, you are required to generate a technical report that provides
practical insights for field engineers.
## Output Requirements
1. **Title**: A technical title that clearly reflects the problem.
2. **Problem Definition**:
* Describe the situation in which the issue occurred in detail.
* Specify the affected vehicle components.
* Analyze the impact on safety.
* Identify common patterns observed across multiple cases.
3. **Technical Analysis**:
* Analyze the root causes.
* Summarize related test results and identify patterns.
* Include measured numerical data.
* Compare test results and analyze correlations.
4. **Case Comparison Analysis**:
* List and categorize all cases where similar issues occurred.
* Compare similarities and differences across cases.
* Present comparison of results using tables (recommended).
5. **Improvement Directions**:
* Summarize all improvement actions mentioned in the reports.
* Clearly explain the rationale and expected effects of each action.
* Prioritize the improvement directions.
* Identify areas that require additional testing and justify their necessity.
6. **Conclusion**:
* Summarize the key problems.
* Recap the main findings.
* Synthesize the expected benefits of the proposed improvements.
7. **References**:
* Cite all sources immediately after the corresponding information using parentheses.
(e.g., "Due to insufficient upper stiffness of the A-pillar, the DASH deformation exceeded the target value at
128mm compared to the target of 100mm (C200728A_CV).")
* Ensure references are properly placed without compromising readability.
Ensure that the report is written in a professional and technically accurate manner according to the guidelines above
. All conclusions and improvement directions must be based strictly on evidence extracted from the provided
reports. Source citations should be placed directly after each statement or piece of information to ensure
clarity and traceability.
Pay particular attention to identifying recurring patterns observed across multiple tests or cases and include them
in the report. This is critical for understanding the systematic nature of the problem and for proposing
effective solutions.
The structure and content of the report must be optimized so that engineers can clearly understand the issue and
implement effective solutions. Providing data-driven insights and practical engineering perspectives is key. The
conclusion should synthesize the report’s core findings and offer clear directions for future development and
implementation.
Figure 9: Prompt used for report generation of Qwen model based on the retrieved documents. The prompt is
originallyKorean.
Prompt
You are a strict evaluator of AI-generated text for automobile engineering questions.
You must judge two responses, A and B, on the following metrics:
1) Correctness: factual correctness based on the question
2) Richness: level of detail and completeness
3) Helpfulness: clarity, directness, and overall usefulness
Then decide who wins each metric (A/B/tie), and also decide the final overall winner.
Output format strictly:
CorrectnessWINNER: [A/B/tie]
RichnessWINNER: [A/B/tie]
HelpfulnessWINNER: [A/B/tie]
OVERALLWINNER: [A/B/tie]
No explanations.
Question: {question}
Response A: {answer_a}
Response B: {answer_b}
Please provide the winners in the specified format WITHOUT any numerical scores.
Figure10:PromptusedforLLM-basedEvaluation.PairwiseevaluationbetweenTraditionalRAGandSecMulti-
RAGisconductedusingClaude3.7Sonnet.

=== Page 16 ===
Figure11:ConfusionmatricesshowingtheagreementbetweenLLMandhumanevaluations.Mostcountslieon
thediagonalcells,indicatingconsistentagreementbetweenbothevaluators.
Figure12:ComparisonbetweenTraditionalRAGandSecMulti-RAGinQAtask(translatedfromKorean)